Train Metrics
Epoch 0, 25% 	 Loss : 5.1937e+00 	 Res : 4.0960e+00 	 Jac : 8.4031e-02 	 Enc : 5.9026e-01 	 AEnc : 4.2344e-01 	 MSE : 4.5476e+01
Epoch 0, 50% 	 Loss : 1.8461e+00 	 Res : 1.0537e+00 	 Jac : 3.9638e-02 	 Enc : 3.2407e-01 	 AEnc : 4.2874e-01 	 MSE : 4.1333e+01
Epoch 0, 75% 	 Loss : 2.2213e+00 	 Res : 1.3018e+00 	 Jac : 3.3497e-02 	 Enc : 1.4215e-01 	 AEnc : 7.4386e-01 	 MSE : 4.6599e+01
Training Epoch 0 : 	 Train : 2.68738e+00 	 Res : 1.89179e+00 	 Jac : 4.83758e-02 	 Enc : 2.95726e-01 	 AE : 4.51487e-01 	 MSE : 4.47126e+01
Validation Epoch 0 : 	 Train : 1.60432e+00 	 Res : 1.21911e+00 	 Jac : 3.64883e-02 	 Enc : 1.94958e-01 	 AE : 1.53769e-01 	 MSE : 6.60817e+01
Training Epoch 0 finished, took current epoch 331.51s, cumulative time 331.43s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
MODEL SAVED
Epoch 1, 25% 	 Loss : 1.5623e+00 	 Res : 6.8741e-01 	 Jac : 3.8181e-02 	 Enc : 8.1502e-02 	 AEnc : 7.5520e-01 	 MSE : 3.9967e+01
Epoch 1, 50% 	 Loss : 1.3016e+00 	 Res : 8.6387e-01 	 Jac : 3.9354e-02 	 Enc : 7.6232e-02 	 AEnc : 3.2216e-01 	 MSE : 4.6695e+01
Epoch 1, 75% 	 Loss : 1.3663e+00 	 Res : 7.6028e-01 	 Jac : 4.0165e-02 	 Enc : 4.2131e-02 	 AEnc : 5.2377e-01 	 MSE : 3.9621e+01
Training Epoch 1 : 	 Train : 1.41655e+00 	 Res : 7.52740e-01 	 Jac : 4.04211e-02 	 Enc : 6.09010e-02 	 AE : 5.62488e-01 	 MSE : 4.12454e+01
Validation Epoch 1 : 	 Train : 6.31960e-01 	 Res : 4.19535e-01 	 Jac : 4.80501e-02 	 Enc : 4.47597e-02 	 AE : 1.19615e-01 	 MSE : 2.17939e+01
Training Epoch 1 finished, took current epoch 328.14s, cumulative time 659.52s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
MODEL SAVED
Epoch 2, 25% 	 Loss : 1.0485e+00 	 Res : 6.4816e-01 	 Jac : 4.6625e-02 	 Enc : 4.3363e-02 	 AEnc : 3.1039e-01 	 MSE : 3.9100e+01
Epoch 2, 50% 	 Loss : 1.0475e+00 	 Res : 5.3800e-01 	 Jac : 4.3772e-02 	 Enc : 2.6791e-02 	 AEnc : 4.3895e-01 	 MSE : 4.0673e+01
Epoch 2, 75% 	 Loss : 7.3142e-01 	 Res : 4.3578e-01 	 Jac : 4.5805e-02 	 Enc : 2.8487e-02 	 AEnc : 2.2135e-01 	 MSE : 4.0010e+01
Training Epoch 2 : 	 Train : 1.05169e+00 	 Res : 5.86534e-01 	 Jac : 4.53351e-02 	 Enc : 3.20289e-02 	 AE : 3.87792e-01 	 MSE : 4.19520e+01
Validation Epoch 2 : 	 Train : 8.29919e-01 	 Res : 4.77872e-01 	 Jac : 4.88651e-02 	 Enc : 2.40639e-02 	 AE : 2.79117e-01 	 MSE : 3.68536e+01
Training Epoch 2 finished, took current epoch 328.26s, cumulative time 987.76s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 3, 25% 	 Loss : 9.5255e-01 	 Res : 6.3974e-01 	 Jac : 4.5860e-02 	 Enc : 4.0196e-02 	 AEnc : 2.2675e-01 	 MSE : 4.6642e+01
Epoch 3, 50% 	 Loss : 1.2975e+00 	 Res : 5.8602e-01 	 Jac : 4.9648e-02 	 Enc : 3.1380e-02 	 AEnc : 6.3040e-01 	 MSE : 3.3799e+01
Epoch 3, 75% 	 Loss : 1.1650e+00 	 Res : 5.8465e-01 	 Jac : 4.9099e-02 	 Enc : 2.6401e-02 	 AEnc : 5.0481e-01 	 MSE : 3.8130e+01
Training Epoch 3 : 	 Train : 1.16397e+00 	 Res : 6.04377e-01 	 Jac : 4.79853e-02 	 Enc : 3.37528e-02 	 AE : 4.77859e-01 	 MSE : 3.92170e+01
Validation Epoch 3 : 	 Train : 1.44167e+00 	 Res : 8.59801e-01 	 Jac : 5.68372e-02 	 Enc : 3.66327e-02 	 AE : 4.88403e-01 	 MSE : 6.82237e+01
Training Epoch 3 finished, took current epoch 332.22s, cumulative time 1319.96s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 4, 25% 	 Loss : 1.3137e+00 	 Res : 6.3172e-01 	 Jac : 5.0279e-02 	 Enc : 2.6419e-02 	 AEnc : 6.0531e-01 	 MSE : 3.6212e+01
Epoch 4, 50% 	 Loss : 2.0785e+00 	 Res : 8.1827e-01 	 Jac : 5.0482e-02 	 Enc : 3.8398e-02 	 AEnc : 1.1714e+00 	 MSE : 4.2753e+01
Epoch 4, 75% 	 Loss : 1.2850e+00 	 Res : 7.3533e-01 	 Jac : 5.8942e-02 	 Enc : 2.7567e-02 	 AEnc : 4.6311e-01 	 MSE : 4.6469e+01
Training Epoch 4 : 	 Train : 1.45100e+00 	 Res : 7.34029e-01 	 Jac : 5.18006e-02 	 Enc : 2.82974e-02 	 AE : 6.36875e-01 	 MSE : 4.44641e+01
Validation Epoch 4 : 	 Train : 5.38584e-01 	 Res : 3.45300e-01 	 Jac : 4.74097e-02 	 Enc : 2.06241e-02 	 AE : 1.25250e-01 	 MSE : 2.56508e+01
Training Epoch 4 finished, took current epoch 332.03s, cumulative time 1651.92s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
MODEL SAVED
Epoch 5, 25% 	 Loss : 1.9857e+00 	 Res : 6.9851e-01 	 Jac : 5.2374e-02 	 Enc : 2.5002e-02 	 AEnc : 1.2099e+00 	 MSE : 4.1084e+01
Epoch 5, 50% 	 Loss : 1.0474e+00 	 Res : 5.2387e-01 	 Jac : 6.0665e-02 	 Enc : 2.5061e-02 	 AEnc : 4.3784e-01 	 MSE : 3.8347e+01
Epoch 5, 75% 	 Loss : 1.0146e+00 	 Res : 4.4342e-01 	 Jac : 6.5134e-02 	 Enc : 2.2077e-02 	 AEnc : 4.8394e-01 	 MSE : 1.9712e+01
Training Epoch 5 : 	 Train : 1.21215e+00 	 Res : 5.30738e-01 	 Jac : 5.82914e-02 	 Enc : 2.15875e-02 	 AE : 6.01529e-01 	 MSE : 3.34653e+01
Validation Epoch 5 : 	 Train : 3.90763e-01 	 Res : 2.47577e-01 	 Jac : 4.54745e-02 	 Enc : 9.59739e-03 	 AE : 8.81139e-02 	 MSE : 2.18590e+01
Training Epoch 5 finished, took current epoch 333.45s, cumulative time 1985.29s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
MODEL SAVED
Epoch 6, 25% 	 Loss : 1.0179e+00 	 Res : 3.8675e-01 	 Jac : 5.5262e-02 	 Enc : 1.2450e-02 	 AEnc : 5.6347e-01 	 MSE : 2.8315e+01
Epoch 6, 50% 	 Loss : 1.1923e+00 	 Res : 5.4113e-01 	 Jac : 5.5538e-02 	 Enc : 1.7096e-02 	 AEnc : 5.7857e-01 	 MSE : 3.0664e+01
Epoch 6, 75% 	 Loss : 9.5925e-01 	 Res : 3.8965e-01 	 Jac : 6.7363e-02 	 Enc : 1.5667e-02 	 AEnc : 4.8657e-01 	 MSE : 3.0973e+01
Training Epoch 6 : 	 Train : 9.80570e-01 	 Res : 4.41220e-01 	 Jac : 6.01630e-02 	 Enc : 1.58347e-02 	 AE : 4.63352e-01 	 MSE : 3.14426e+01
Validation Epoch 6 : 	 Train : 9.68580e-01 	 Res : 3.99263e-01 	 Jac : 5.46978e-02 	 Enc : 1.77284e-02 	 AE : 4.96891e-01 	 MSE : 4.17525e+01
Training Epoch 6 finished, took current epoch 341.94s, cumulative time 2327.20s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 7, 25% 	 Loss : 1.3902e+00 	 Res : 4.8729e-01 	 Jac : 6.1995e-02 	 Enc : 1.6887e-02 	 AEnc : 8.2406e-01 	 MSE : 3.2156e+01
Epoch 7, 50% 	 Loss : 6.1484e-01 	 Res : 2.9472e-01 	 Jac : 6.6599e-02 	 Enc : 1.3371e-02 	 AEnc : 2.4015e-01 	 MSE : 2.2057e+01
Epoch 7, 75% 	 Loss : 7.5669e-01 	 Res : 3.0571e-01 	 Jac : 5.7426e-02 	 Enc : 1.1998e-02 	 AEnc : 3.8156e-01 	 MSE : 2.1576e+01
Training Epoch 7 : 	 Train : 9.14177e-01 	 Res : 3.70520e-01 	 Jac : 6.24208e-02 	 Enc : 1.43153e-02 	 AE : 4.66921e-01 	 MSE : 2.42895e+01
Validation Epoch 7 : 	 Train : 5.34891e-01 	 Res : 2.39840e-01 	 Jac : 7.04342e-02 	 Enc : 1.27478e-02 	 AE : 2.11868e-01 	 MSE : 1.60887e+01
Training Epoch 7 finished, took current epoch 359.50s, cumulative time 2686.60s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
MODEL SAVED
Epoch 8, 25% 	 Loss : 9.8465e-01 	 Res : 7.3321e-01 	 Jac : 5.1279e-02 	 Enc : 1.3767e-02 	 AEnc : 1.8640e-01 	 MSE : 3.7716e+01
Epoch 8, 50% 	 Loss : 1.2618e+00 	 Res : 4.9782e-01 	 Jac : 5.8132e-02 	 Enc : 2.2104e-02 	 AEnc : 6.8374e-01 	 MSE : 3.9518e+01
Epoch 8, 75% 	 Loss : 5.9190e-01 	 Res : 2.6594e-01 	 Jac : 7.3704e-02 	 Enc : 1.3773e-02 	 AEnc : 2.3848e-01 	 MSE : 2.3618e+01
Training Epoch 8 : 	 Train : 9.18203e-01 	 Res : 4.54287e-01 	 Jac : 6.19956e-02 	 Enc : 1.58494e-02 	 AE : 3.86070e-01 	 MSE : 3.04558e+01
Validation Epoch 8 : 	 Train : 4.90422e-01 	 Res : 2.19209e-01 	 Jac : 6.32317e-02 	 Enc : 1.01804e-02 	 AE : 1.97800e-01 	 MSE : 1.61422e+01
Training Epoch 8 finished, took current epoch 346.05s, cumulative time 3032.60s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
MODEL SAVED
Epoch 9, 25% 	 Loss : 5.7934e-01 	 Res : 2.5552e-01 	 Jac : 6.7704e-02 	 Enc : 1.0371e-02 	 AEnc : 2.4576e-01 	 MSE : 2.0962e+01
Epoch 9, 50% 	 Loss : 6.0318e-01 	 Res : 2.7533e-01 	 Jac : 6.1658e-02 	 Enc : 1.0018e-02 	 AEnc : 2.5617e-01 	 MSE : 2.2546e+01
Epoch 9, 75% 	 Loss : 7.0326e-01 	 Res : 2.9094e-01 	 Jac : 6.2379e-02 	 Enc : 1.0985e-02 	 AEnc : 3.3895e-01 	 MSE : 2.1918e+01
Training Epoch 9 : 	 Train : 5.76081e-01 	 Res : 2.48514e-01 	 Jac : 6.43738e-02 	 Enc : 1.01968e-02 	 AE : 2.52996e-01 	 MSE : 1.98265e+01
Validation Epoch 9 : 	 Train : 3.44393e-01 	 Res : 1.30992e-01 	 Jac : 6.87924e-02 	 Enc : 6.69948e-03 	 AE : 1.37909e-01 	 MSE : 5.12514e+00
Training Epoch 9 finished, took current epoch 392.82s, cumulative time 3425.39s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
MODEL SAVED
Epoch 10, 25% 	 Loss : 7.8584e-01 	 Res : 4.3906e-01 	 Jac : 6.6721e-02 	 Enc : 1.0482e-02 	 AEnc : 2.6957e-01 	 MSE : 2.2524e+01
Epoch 10, 50% 	 Loss : 7.1631e-01 	 Res : 2.4918e-01 	 Jac : 6.5690e-02 	 Enc : 9.7158e-03 	 AEnc : 3.9173e-01 	 MSE : 1.5309e+01
Epoch 10, 75% 	 Loss : 1.1600e+00 	 Res : 6.6760e-01 	 Jac : 6.7437e-02 	 Enc : 2.1715e-02 	 AEnc : 4.0327e-01 	 MSE : 2.6524e+01
Training Epoch 10 : 	 Train : 8.29599e-01 	 Res : 4.14600e-01 	 Jac : 6.98925e-02 	 Enc : 1.52350e-02 	 AE : 3.29872e-01 	 MSE : 2.07714e+01
Validation Epoch 10 : 	 Train : 4.76374e-01 	 Res : 2.45837e-01 	 Jac : 5.87949e-02 	 Enc : 9.38245e-03 	 AE : 1.62359e-01 	 MSE : 2.80325e+01
Training Epoch 10 finished, took current epoch 381.50s, cumulative time 3806.86s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 11, 25% 	 Loss : 7.0815e-01 	 Res : 2.8665e-01 	 Jac : 7.8783e-02 	 Enc : 1.2575e-02 	 AEnc : 3.3014e-01 	 MSE : 2.2435e+01
Epoch 11, 50% 	 Loss : 4.0763e-01 	 Res : 1.7281e-01 	 Jac : 6.7536e-02 	 Enc : 7.2898e-03 	 AEnc : 1.6000e-01 	 MSE : 1.8969e+01
Epoch 11, 75% 	 Loss : 3.6435e-01 	 Res : 1.7544e-01 	 Jac : 6.6693e-02 	 Enc : 8.0238e-03 	 AEnc : 1.1420e-01 	 MSE : 1.8165e+01
Training Epoch 11 : 	 Train : 5.50884e-01 	 Res : 2.19414e-01 	 Jac : 7.06972e-02 	 Enc : 8.98354e-03 	 AE : 2.51789e-01 	 MSE : 1.91753e+01
Validation Epoch 11 : 	 Train : 3.17698e-01 	 Res : 1.43831e-01 	 Jac : 5.74140e-02 	 Enc : 5.54435e-03 	 AE : 1.10909e-01 	 MSE : 1.58059e+01
Training Epoch 11 finished, took current epoch 373.21s, cumulative time 4180.05s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 12, 25% 	 Loss : 3.7254e-01 	 Res : 1.8240e-01 	 Jac : 6.8085e-02 	 Enc : 7.1515e-03 	 AEnc : 1.1490e-01 	 MSE : 1.5075e+01
Epoch 12, 50% 	 Loss : 4.1575e-01 	 Res : 1.8566e-01 	 Jac : 6.8054e-02 	 Enc : 5.8276e-03 	 AEnc : 1.5621e-01 	 MSE : 1.7671e+01
Epoch 12, 75% 	 Loss : 4.3937e-01 	 Res : 1.9088e-01 	 Jac : 5.1412e-02 	 Enc : 5.9190e-03 	 AEnc : 1.9116e-01 	 MSE : 1.6396e+01
Training Epoch 12 : 	 Train : 4.59175e-01 	 Res : 1.88141e-01 	 Jac : 6.22861e-02 	 Enc : 6.53846e-03 	 AE : 2.02209e-01 	 MSE : 1.52105e+01
Validation Epoch 12 : 	 Train : 9.78799e-01 	 Res : 2.35992e-01 	 Jac : 5.95986e-02 	 Enc : 1.25258e-02 	 AE : 6.70682e-01 	 MSE : 6.57851e+00
Training Epoch 12 finished, took current epoch 384.17s, cumulative time 4564.20s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 13, 25% 	 Loss : 8.0415e-01 	 Res : 3.2813e-01 	 Jac : 5.8845e-02 	 Enc : 8.9074e-03 	 AEnc : 4.0827e-01 	 MSE : 1.1294e+01
Epoch 13, 50% 	 Loss : 1.0071e+00 	 Res : 4.7897e-01 	 Jac : 5.1854e-02 	 Enc : 9.4224e-03 	 AEnc : 4.6681e-01 	 MSE : 1.8812e+01
Epoch 13, 75% 	 Loss : 4.2269e-01 	 Res : 1.6703e-01 	 Jac : 5.1578e-02 	 Enc : 6.0378e-03 	 AEnc : 1.9804e-01 	 MSE : 1.2146e+01
Training Epoch 13 : 	 Train : 6.48759e-01 	 Res : 2.88364e-01 	 Jac : 5.29022e-02 	 Enc : 7.13897e-03 	 AE : 3.00354e-01 	 MSE : 1.43130e+01
Validation Epoch 13 : 	 Train : 1.94353e-01 	 Res : 1.24588e-01 	 Jac : 3.85780e-02 	 Enc : 3.03220e-03 	 AE : 2.81554e-02 	 MSE : 1.44728e+01
Training Epoch 13 finished, took current epoch 364.48s, cumulative time 4928.62s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
MODEL SAVED
Epoch 14, 25% 	 Loss : 4.9467e-01 	 Res : 2.7459e-01 	 Jac : 5.2679e-02 	 Enc : 4.9737e-03 	 AEnc : 1.6242e-01 	 MSE : 1.4510e+01
Epoch 14, 50% 	 Loss : 3.1893e-01 	 Res : 1.2562e-01 	 Jac : 5.5881e-02 	 Enc : 4.6465e-03 	 AEnc : 1.3278e-01 	 MSE : 1.1458e+01
Epoch 14, 75% 	 Loss : 3.9310e-01 	 Res : 3.0867e-01 	 Jac : 5.3225e-02 	 Enc : 5.4571e-03 	 AEnc : 2.5753e-02 	 MSE : 1.4961e+01
Training Epoch 14 : 	 Train : 4.04446e-01 	 Res : 2.16651e-01 	 Jac : 5.26390e-02 	 Enc : 4.99008e-03 	 AE : 1.30166e-01 	 MSE : 1.34600e+01
Validation Epoch 14 : 	 Train : 2.99820e-01 	 Res : 9.79148e-02 	 Jac : 4.67080e-02 	 Enc : 2.81415e-03 	 AE : 1.52383e-01 	 MSE : 9.11837e+00
Training Epoch 14 finished, took current epoch 363.96s, cumulative time 5292.51s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
MODEL SAVED
Epoch 15, 25% 	 Loss : 4.5522e-01 	 Res : 2.3403e-01 	 Jac : 4.7194e-02 	 Enc : 4.5549e-03 	 AEnc : 1.6945e-01 	 MSE : 1.0110e+01
Epoch 15, 50% 	 Loss : 5.0731e-01 	 Res : 3.2768e-01 	 Jac : 4.4580e-02 	 Enc : 5.9811e-03 	 AEnc : 1.2908e-01 	 MSE : 1.8318e+01
Epoch 15, 75% 	 Loss : 4.7321e-01 	 Res : 2.7377e-01 	 Jac : 4.3326e-02 	 Enc : 5.3682e-03 	 AEnc : 1.5075e-01 	 MSE : 1.3537e+01
Training Epoch 15 : 	 Train : 4.94198e-01 	 Res : 2.50711e-01 	 Jac : 4.55247e-02 	 Enc : 5.33787e-03 	 AE : 1.92625e-01 	 MSE : 1.29347e+01
Validation Epoch 15 : 	 Train : 1.62802e-01 	 Res : 7.28068e-02 	 Jac : 4.46161e-02 	 Enc : 3.76551e-03 	 AE : 4.16133e-02 	 MSE : 8.25098e+00
Training Epoch 15 finished, took current epoch 367.43s, cumulative time 5659.87s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
MODEL SAVED
Epoch 16, 25% 	 Loss : 7.5264e-01 	 Res : 3.9749e-01 	 Jac : 4.3949e-02 	 Enc : 6.4062e-03 	 AEnc : 3.0480e-01 	 MSE : 1.6753e+01
Epoch 16, 50% 	 Loss : 8.5646e-01 	 Res : 2.4653e-01 	 Jac : 4.3158e-02 	 Enc : 8.9656e-03 	 AEnc : 5.5781e-01 	 MSE : 1.1724e+01
Epoch 16, 75% 	 Loss : 7.8055e-01 	 Res : 5.7361e-01 	 Jac : 4.2629e-02 	 Enc : 4.3872e-03 	 AEnc : 1.5993e-01 	 MSE : 1.3962e+01
Training Epoch 16 : 	 Train : 7.05853e-01 	 Res : 3.50520e-01 	 Jac : 4.18472e-02 	 Enc : 6.50640e-03 	 AE : 3.06979e-01 	 MSE : 1.40489e+01
Validation Epoch 16 : 	 Train : 2.47918e-01 	 Res : 1.09040e-01 	 Jac : 3.20335e-02 	 Enc : 4.24831e-03 	 AE : 1.02596e-01 	 MSE : 1.58839e+01
Training Epoch 16 finished, took current epoch 360.38s, cumulative time 6020.23s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 17, 25% 	 Loss : 6.1646e-01 	 Res : 3.1533e-01 	 Jac : 3.9414e-02 	 Enc : 3.9271e-03 	 AEnc : 2.5779e-01 	 MSE : 1.1638e+01
Epoch 17, 50% 	 Loss : 4.8381e-01 	 Res : 2.7511e-01 	 Jac : 4.3397e-02 	 Enc : 4.1163e-03 	 AEnc : 1.6120e-01 	 MSE : 1.0767e+01
Epoch 17, 75% 	 Loss : 1.6743e+00 	 Res : 1.3528e+00 	 Jac : 4.0950e-02 	 Enc : 1.0180e-02 	 AEnc : 2.7037e-01 	 MSE : 2.5922e+01
Training Epoch 17 : 	 Train : 8.00786e-01 	 Res : 5.38607e-01 	 Jac : 4.63036e-02 	 Enc : 7.01869e-03 	 AE : 2.08857e-01 	 MSE : 1.58580e+01
Validation Epoch 17 : 	 Train : 1.63930e+00 	 Res : 1.46756e+00 	 Jac : 1.16706e-01 	 Enc : 7.53131e-03 	 AE : 4.75109e-02 	 MSE : 1.47654e+01
Training Epoch 17 finished, took current epoch 438.78s, cumulative time 6458.99s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 18, 25% 	 Loss : 5.0737e-01 	 Res : 2.9052e-01 	 Jac : 5.6104e-02 	 Enc : 6.1449e-03 	 AEnc : 1.5460e-01 	 MSE : 1.5159e+01
Epoch 18, 50% 	 Loss : 2.6974e-01 	 Res : 1.0975e-01 	 Jac : 4.7510e-02 	 Enc : 3.5271e-03 	 AEnc : 1.0895e-01 	 MSE : 9.3881e+00
Epoch 18, 75% 	 Loss : 4.6031e-01 	 Res : 3.3976e-01 	 Jac : 4.5070e-02 	 Enc : 3.2513e-03 	 AEnc : 7.2236e-02 	 MSE : 1.6617e+01
Training Epoch 18 : 	 Train : 4.50368e-01 	 Res : 2.44198e-01 	 Jac : 4.60092e-02 	 Enc : 4.37839e-03 	 AE : 1.55783e-01 	 MSE : 1.39614e+01
Validation Epoch 18 : 	 Train : 4.57295e-01 	 Res : 1.42270e-01 	 Jac : 2.93098e-02 	 Enc : 3.08711e-03 	 AE : 2.82628e-01 	 MSE : 1.22861e+01
Training Epoch 18 finished, took current epoch 362.14s, cumulative time 6821.11s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 19, 25% 	 Loss : 2.5118e-01 	 Res : 9.0805e-02 	 Jac : 3.7826e-02 	 Enc : 3.3806e-03 	 AEnc : 1.1917e-01 	 MSE : 8.3699e+00
Epoch 19, 50% 	 Loss : 1.4430e+00 	 Res : 1.2234e+00 	 Jac : 3.8627e-02 	 Enc : 8.0175e-03 	 AEnc : 1.7291e-01 	 MSE : 2.7326e+01
Epoch 19, 75% 	 Loss : 3.5683e-01 	 Res : 2.6484e-01 	 Jac : 3.6898e-02 	 Enc : 9.9689e-03 	 AEnc : 4.5124e-02 	 MSE : 1.9460e+01
Training Epoch 19 : 	 Train : 6.42460e-01 	 Res : 4.51723e-01 	 Jac : 4.09386e-02 	 Enc : 6.89039e-03 	 AE : 1.42909e-01 	 MSE : 1.72840e+01
Validation Epoch 19 : 	 Train : 3.40118e-01 	 Res : 1.09128e-01 	 Jac : 4.87078e-02 	 Enc : 2.72482e-03 	 AE : 1.79557e-01 	 MSE : 7.52874e+00
Training Epoch 19 finished, took current epoch 376.71s, cumulative time 7197.72s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 20, 25% 	 Loss : 2.4951e+00 	 Res : 2.2671e+00 	 Jac : 4.5001e-02 	 Enc : 1.0826e-02 	 AEnc : 1.7211e-01 	 MSE : 2.4334e+01
Epoch 20, 50% 	 Loss : 3.0389e-01 	 Res : 1.5486e-01 	 Jac : 3.8693e-02 	 Enc : 6.7403e-03 	 AEnc : 1.0359e-01 	 MSE : 1.3610e+01
Epoch 20, 75% 	 Loss : 7.5946e-01 	 Res : 5.8036e-01 	 Jac : 3.1854e-02 	 Enc : 5.2404e-03 	 AEnc : 1.4200e-01 	 MSE : 2.4011e+01
Training Epoch 20 : 	 Train : 1.02628e+00 	 Res : 8.38739e-01 	 Jac : 4.31254e-02 	 Enc : 8.22181e-03 	 AE : 1.36191e-01 	 MSE : 1.85420e+01
Validation Epoch 20 : 	 Train : 3.13277e-01 	 Res : 9.59134e-02 	 Jac : 5.10442e-02 	 Enc : 2.78799e-03 	 AE : 1.63531e-01 	 MSE : 7.97252e+00
Training Epoch 20 finished, took current epoch 363.02s, cumulative time 7560.72s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 21, 25% 	 Loss : 3.3554e-01 	 Res : 1.2595e-01 	 Jac : 4.9297e-02 	 Enc : 2.9485e-03 	 AEnc : 1.5735e-01 	 MSE : 8.9181e+00
Epoch 21, 50% 	 Loss : 2.2351e+00 	 Res : 1.6059e+00 	 Jac : 4.5672e-02 	 Enc : 1.4211e-02 	 AEnc : 5.6931e-01 	 MSE : 2.6644e+01
Epoch 21, 75% 	 Loss : 5.2532e-01 	 Res : 2.4456e-01 	 Jac : 4.5704e-02 	 Enc : 6.1783e-03 	 AEnc : 2.2888e-01 	 MSE : 1.0708e+01
Training Epoch 21 : 	 Train : 8.30977e-01 	 Res : 5.18158e-01 	 Jac : 4.47483e-02 	 Enc : 6.63802e-03 	 AE : 2.61433e-01 	 MSE : 1.37167e+01
Validation Epoch 21 : 	 Train : 2.64088e-01 	 Res : 1.05536e-01 	 Jac : 2.91641e-02 	 Enc : 2.98790e-03 	 AE : 1.26401e-01 	 MSE : 1.14289e+01
Training Epoch 21 finished, took current epoch 362.52s, cumulative time 7923.22s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 22, 25% 	 Loss : 4.1473e-01 	 Res : 1.3725e-01 	 Jac : 3.2301e-02 	 Enc : 4.0920e-03 	 AEnc : 2.4108e-01 	 MSE : 1.0976e+01
Epoch 22, 50% 	 Loss : 6.7780e-01 	 Res : 1.7142e-01 	 Jac : 3.4898e-02 	 Enc : 5.2296e-03 	 AEnc : 4.6625e-01 	 MSE : 7.5986e+00
Epoch 22, 75% 	 Loss : 4.5714e-01 	 Res : 2.7540e-01 	 Jac : 3.6049e-02 	 Enc : 6.4612e-03 	 AEnc : 1.3922e-01 	 MSE : 1.2472e+01
Training Epoch 22 : 	 Train : 4.72424e-01 	 Res : 1.90707e-01 	 Jac : 3.39658e-02 	 Enc : 5.16677e-03 	 AE : 2.42585e-01 	 MSE : 1.16419e+01
Validation Epoch 22 : 	 Train : 3.15887e-01 	 Res : 1.25641e-01 	 Jac : 3.62888e-02 	 Enc : 2.81172e-03 	 AE : 1.51145e-01 	 MSE : 8.09450e+00
Training Epoch 22 finished, took current epoch 360.10s, cumulative time 8283.29s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 23, 25% 	 Loss : 2.8986e-01 	 Res : 1.0486e-01 	 Jac : 4.0014e-02 	 Enc : 3.0974e-03 	 AEnc : 1.4189e-01 	 MSE : 9.0773e+00
Epoch 23, 50% 	 Loss : 6.4492e-01 	 Res : 3.9815e-01 	 Jac : 3.6938e-02 	 Enc : 5.6352e-03 	 AEnc : 2.0419e-01 	 MSE : 1.4329e+01
Epoch 23, 75% 	 Loss : 2.3496e-01 	 Res : 9.1812e-02 	 Jac : 3.4713e-02 	 Enc : 3.8762e-03 	 AEnc : 1.0456e-01 	 MSE : 9.0281e+00
Training Epoch 23 : 	 Train : 5.69533e-01 	 Res : 3.12432e-01 	 Jac : 3.72934e-02 	 Enc : 6.29249e-03 	 AE : 2.13515e-01 	 MSE : 1.35164e+01
Validation Epoch 23 : 	 Train : 5.35261e-01 	 Res : 2.11962e-01 	 Jac : 2.88064e-02 	 Enc : 1.00781e-02 	 AE : 2.84415e-01 	 MSE : 1.49393e+01
Training Epoch 23 finished, took current epoch 356.29s, cumulative time 8639.56s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 24, 25% 	 Loss : 3.8528e-01 	 Res : 1.3592e-01 	 Jac : 3.6029e-02 	 Enc : 6.6076e-03 	 AEnc : 2.0672e-01 	 MSE : 8.8202e+00
Epoch 24, 50% 	 Loss : 4.1670e-01 	 Res : 2.4297e-01 	 Jac : 3.1932e-02 	 Enc : 5.1820e-03 	 AEnc : 1.3662e-01 	 MSE : 1.5429e+01
Epoch 24, 75% 	 Loss : 6.8636e-01 	 Res : 4.2275e-01 	 Jac : 3.2442e-02 	 Enc : 5.7003e-03 	 AEnc : 2.2548e-01 	 MSE : 1.3918e+01
Training Epoch 24 : 	 Train : 1.86530e+00 	 Res : 1.62003e+00 	 Jac : 3.90726e-02 	 Enc : 7.51840e-03 	 AE : 1.98673e-01 	 MSE : 2.05608e+01
Validation Epoch 24 : 	 Train : 6.03608e+01 	 Res : 5.80312e+01 	 Jac : 3.54733e-02 	 Enc : 1.61351e-01 	 AE : 2.13276e+00 	 MSE : 2.36890e+02
Training Epoch 24 finished, took current epoch 369.35s, cumulative time 9008.87s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 25, 25% 	 Loss : 4.5525e+00 	 Res : 4.0486e+00 	 Jac : 5.6242e-02 	 Enc : 4.8217e-02 	 AEnc : 3.9946e-01 	 MSE : 4.1646e+01
Epoch 25, 50% 	 Loss : 5.2177e-01 	 Res : 2.4481e-01 	 Jac : 6.5043e-02 	 Enc : 1.4768e-02 	 AEnc : 1.9715e-01 	 MSE : 1.8103e+01
Epoch 25, 75% 	 Loss : 7.5807e-01 	 Res : 3.1290e-01 	 Jac : 4.0375e-02 	 Enc : 9.2474e-03 	 AEnc : 3.9555e-01 	 MSE : 1.8929e+01
Training Epoch 25 : 	 Train : 1.67594e+00 	 Res : 1.23748e+00 	 Jac : 5.16549e-02 	 Enc : 2.01683e-02 	 AE : 3.66633e-01 	 MSE : 2.22777e+01
Validation Epoch 25 : 	 Train : 3.20095e-01 	 Res : 9.94981e-02 	 Jac : 6.15441e-02 	 Enc : 7.22221e-03 	 AE : 1.51830e-01 	 MSE : 3.14882e+00
Training Epoch 25 finished, took current epoch 356.09s, cumulative time 9364.94s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 26, 25% 	 Loss : 3.6811e-01 	 Res : 1.3387e-01 	 Jac : 4.3137e-02 	 Enc : 5.6377e-03 	 AEnc : 1.8546e-01 	 MSE : 9.4256e+00
Epoch 26, 50% 	 Loss : 7.3124e-01 	 Res : 5.7531e-01 	 Jac : 3.3510e-02 	 Enc : 1.1101e-02 	 AEnc : 1.1132e-01 	 MSE : 2.0506e+01
Epoch 26, 75% 	 Loss : 4.8051e-01 	 Res : 2.1536e-01 	 Jac : 4.3617e-02 	 Enc : 7.2887e-03 	 AEnc : 2.1424e-01 	 MSE : 1.3730e+01
Training Epoch 26 : 	 Train : 4.74329e-01 	 Res : 2.62649e-01 	 Jac : 4.00912e-02 	 Enc : 7.19824e-03 	 AE : 1.64390e-01 	 MSE : 1.35247e+01
Validation Epoch 26 : 	 Train : 1.37088e-01 	 Res : 6.12071e-02 	 Jac : 4.23256e-02 	 Enc : 2.09003e-03 	 AE : 3.14648e-02 	 MSE : 8.48373e+00
Training Epoch 26 finished, took current epoch 364.24s, cumulative time 9729.11s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
MODEL SAVED
Epoch 27, 25% 	 Loss : 1.7926e+00 	 Res : 1.5646e+00 	 Jac : 5.2085e-02 	 Enc : 1.6154e-02 	 AEnc : 1.5984e-01 	 MSE : 3.6812e+01
Epoch 27, 50% 	 Loss : 3.0030e-01 	 Res : 1.6166e-01 	 Jac : 4.7599e-02 	 Enc : 1.6012e-02 	 AEnc : 7.5036e-02 	 MSE : 1.4776e+01
Epoch 27, 75% 	 Loss : 2.3450e+00 	 Res : 2.1026e+00 	 Jac : 5.7245e-02 	 Enc : 7.3918e-03 	 AEnc : 1.7776e-01 	 MSE : 3.0695e+01
Training Epoch 27 : 	 Train : 1.27063e+00 	 Res : 1.02655e+00 	 Jac : 4.81770e-02 	 Enc : 1.26515e-02 	 AE : 1.83247e-01 	 MSE : 2.43564e+01
Validation Epoch 27 : 	 Train : 3.88594e-01 	 Res : 1.30467e-01 	 Jac : 5.40363e-02 	 Enc : 3.59627e-03 	 AE : 2.00494e-01 	 MSE : 1.31575e+01
Training Epoch 27 finished, took current epoch 362.56s, cumulative time 10091.64s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 28, 25% 	 Loss : 2.8776e-01 	 Res : 1.6934e-01 	 Jac : 4.6940e-02 	 Enc : 2.6031e-03 	 AEnc : 6.8882e-02 	 MSE : 1.0303e+01
Epoch 28, 50% 	 Loss : 5.2773e-01 	 Res : 3.0788e-01 	 Jac : 3.3738e-02 	 Enc : 5.3507e-03 	 AEnc : 1.8076e-01 	 MSE : 1.8886e+01
Epoch 28, 75% 	 Loss : 2.8411e-01 	 Res : 1.1132e-01 	 Jac : 3.7802e-02 	 Enc : 3.9191e-03 	 AEnc : 1.3108e-01 	 MSE : 1.0375e+01
Training Epoch 28 : 	 Train : 3.82169e-01 	 Res : 2.01927e-01 	 Jac : 3.97558e-02 	 Enc : 3.99379e-03 	 AE : 1.36493e-01 	 MSE : 1.30842e+01
Validation Epoch 28 : 	 Train : 7.98850e-01 	 Res : 7.32669e-01 	 Jac : 4.72689e-02 	 Enc : 9.96043e-03 	 AE : 8.95163e-03 	 MSE : 1.58338e+01
Training Epoch 28 finished, took current epoch 391.59s, cumulative time 10483.20s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 29, 25% 	 Loss : 2.4703e-01 	 Res : 1.1709e-01 	 Jac : 3.1111e-02 	 Enc : 2.9931e-03 	 AEnc : 9.5837e-02 	 MSE : 9.0147e+00
Epoch 29, 50% 	 Loss : 3.3199e-01 	 Res : 1.3434e-01 	 Jac : 3.2035e-02 	 Enc : 2.8581e-03 	 AEnc : 1.6276e-01 	 MSE : 1.0685e+01
Epoch 29, 75% 	 Loss : 1.7782e-01 	 Res : 7.9161e-02 	 Jac : 3.2111e-02 	 Enc : 3.0507e-03 	 AEnc : 6.3495e-02 	 MSE : 8.9840e+00
Training Epoch 29 : 	 Train : 4.64081e-01 	 Res : 2.97911e-01 	 Jac : 3.17400e-02 	 Enc : 4.22583e-03 	 AE : 1.30204e-01 	 MSE : 1.49341e+01
Validation Epoch 29 : 	 Train : 1.47903e-01 	 Res : 9.03225e-02 	 Jac : 2.78408e-02 	 Enc : 9.95323e-03 	 AE : 1.97868e-02 	 MSE : 1.41100e+01
Training Epoch 29 finished, took current epoch 352.45s, cumulative time 10835.63s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 30, 25% 	 Loss : 3.7868e-01 	 Res : 3.0247e-01 	 Jac : 3.7535e-02 	 Enc : 5.7279e-03 	 AEnc : 3.2947e-02 	 MSE : 1.4505e+01
Epoch 30, 50% 	 Loss : 4.3399e-01 	 Res : 1.8441e-01 	 Jac : 3.7179e-02 	 Enc : 3.3374e-03 	 AEnc : 2.0906e-01 	 MSE : 9.6242e+00
Epoch 30, 75% 	 Loss : 2.3571e-01 	 Res : 8.2548e-02 	 Jac : 3.9195e-02 	 Enc : 2.0661e-03 	 AEnc : 1.1190e-01 	 MSE : 7.6128e+00
Training Epoch 30 : 	 Train : 8.59360e-01 	 Res : 5.85135e-01 	 Jac : 3.65388e-02 	 Enc : 5.29768e-03 	 AE : 2.32388e-01 	 MSE : 1.58309e+01
Validation Epoch 30 : 	 Train : 3.89887e-01 	 Res : 1.21312e-01 	 Jac : 2.80562e-02 	 Enc : 9.69089e-03 	 AE : 2.30827e-01 	 MSE : 1.05216e+01
Training Epoch 30 finished, took current epoch 360.62s, cumulative time 11196.22s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 31, 25% 	 Loss : 2.6250e-01 	 Res : 9.9838e-02 	 Jac : 3.8577e-02 	 Enc : 6.8056e-03 	 AEnc : 1.1728e-01 	 MSE : 9.7889e+00
Epoch 31, 50% 	 Loss : 1.4927e-01 	 Res : 6.5167e-02 	 Jac : 3.2177e-02 	 Enc : 2.0707e-03 	 AEnc : 4.9858e-02 	 MSE : 8.3199e+00
Epoch 31, 75% 	 Loss : 2.6152e-01 	 Res : 1.2480e-01 	 Jac : 2.5968e-02 	 Enc : 3.3770e-03 	 AEnc : 1.0738e-01 	 MSE : 9.8433e+00
Training Epoch 31 : 	 Train : 2.68912e-01 	 Res : 1.31567e-01 	 Jac : 3.09437e-02 	 Enc : 3.90884e-03 	 AE : 1.02492e-01 	 MSE : 1.00021e+01
Validation Epoch 31 : 	 Train : 1.70062e+00 	 Res : 3.59803e-01 	 Jac : 2.53902e-02 	 Enc : 8.67788e-03 	 AE : 1.30675e+00 	 MSE : 5.00787e+00
Training Epoch 31 finished, took current epoch 363.92s, cumulative time 11560.12s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 32, 25% 	 Loss : 5.2215e-01 	 Res : 1.4964e-01 	 Jac : 2.6415e-02 	 Enc : 4.5140e-03 	 AEnc : 3.4158e-01 	 MSE : 1.0251e+01
Epoch 32, 50% 	 Loss : 1.6131e-01 	 Res : 8.1285e-02 	 Jac : 2.9410e-02 	 Enc : 2.3130e-03 	 AEnc : 4.8302e-02 	 MSE : 9.3634e+00
Epoch 32, 75% 	 Loss : 2.7662e-01 	 Res : 1.7367e-01 	 Jac : 2.6386e-02 	 Enc : 3.1306e-03 	 AEnc : 7.3435e-02 	 MSE : 1.2221e+01
Training Epoch 32 : 	 Train : 2.94831e-01 	 Res : 1.31077e-01 	 Jac : 2.76498e-02 	 Enc : 3.10073e-03 	 AE : 1.33004e-01 	 MSE : 1.07899e+01
Validation Epoch 32 : 	 Train : 3.19790e-01 	 Res : 1.05899e-01 	 Jac : 2.71256e-02 	 Enc : 2.41359e-03 	 AE : 1.84352e-01 	 MSE : 8.58606e+00
Training Epoch 32 finished, took current epoch 363.43s, cumulative time 11923.53s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 33, 25% 	 Loss : 2.3798e-01 	 Res : 1.1368e-01 	 Jac : 2.9745e-02 	 Enc : 1.7843e-03 	 AEnc : 9.2770e-02 	 MSE : 9.6213e+00
Epoch 33, 50% 	 Loss : 1.8111e-01 	 Res : 6.3359e-02 	 Jac : 2.8626e-02 	 Enc : 2.2612e-03 	 AEnc : 8.6861e-02 	 MSE : 7.2836e+00
Epoch 33, 75% 	 Loss : 1.8100e-01 	 Res : 1.2654e-01 	 Jac : 2.6121e-02 	 Enc : 1.5887e-03 	 AEnc : 2.6752e-02 	 MSE : 9.7283e+00
Training Epoch 33 : 	 Train : 1.86476e-01 	 Res : 9.55160e-02 	 Jac : 2.66156e-02 	 Enc : 1.73600e-03 	 AE : 6.26082e-02 	 MSE : 9.08312e+00
Validation Epoch 33 : 	 Train : 8.86375e-02 	 Res : 4.82608e-02 	 Jac : 2.62612e-02 	 Enc : 9.39338e-04 	 AE : 1.31761e-02 	 MSE : 1.78801e+00
Training Epoch 33 finished, took current epoch 368.92s, cumulative time 12292.32s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
MODEL SAVED
Epoch 34, 25% 	 Loss : 4.2083e-01 	 Res : 2.4308e-01 	 Jac : 2.6214e-02 	 Enc : 2.2981e-03 	 AEnc : 1.4924e-01 	 MSE : 1.2966e+01
Epoch 34, 50% 	 Loss : 2.5441e-01 	 Res : 7.9713e-02 	 Jac : 2.7364e-02 	 Enc : 2.7172e-03 	 AEnc : 1.4462e-01 	 MSE : 7.3675e+00
Epoch 34, 75% 	 Loss : 8.6027e-01 	 Res : 5.9451e-01 	 Jac : 2.8048e-02 	 Enc : 3.5328e-03 	 AEnc : 2.3418e-01 	 MSE : 1.7334e+01
Training Epoch 34 : 	 Train : 4.36713e-01 	 Res : 2.54587e-01 	 Jac : 2.65913e-02 	 Enc : 2.80458e-03 	 AE : 1.52730e-01 	 MSE : 1.17983e+01
Validation Epoch 34 : 	 Train : 2.31409e-01 	 Res : 7.41997e-02 	 Jac : 2.51846e-02 	 Enc : 2.46670e-03 	 AE : 1.29558e-01 	 MSE : 8.83879e+00
Training Epoch 34 finished, took current epoch 364.15s, cumulative time 12656.44s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 35, 25% 	 Loss : 2.1708e-01 	 Res : 1.3780e-01 	 Jac : 2.7747e-02 	 Enc : 1.9684e-03 	 AEnc : 4.9565e-02 	 MSE : 7.8302e+00
Epoch 35, 50% 	 Loss : 2.5255e-01 	 Res : 1.1857e-01 	 Jac : 2.5424e-02 	 Enc : 2.6948e-03 	 AEnc : 1.0586e-01 	 MSE : 1.0027e+01
Epoch 35, 75% 	 Loss : 1.7249e-01 	 Res : 6.7227e-02 	 Jac : 2.3971e-02 	 Enc : 1.5686e-03 	 AEnc : 7.9721e-02 	 MSE : 7.3632e+00
Training Epoch 35 : 	 Train : 2.35217e-01 	 Res : 1.31173e-01 	 Jac : 2.54257e-02 	 Enc : 1.87966e-03 	 AE : 7.67381e-02 	 MSE : 9.41756e+00
Validation Epoch 35 : 	 Train : 6.42158e-01 	 Res : 5.81427e-01 	 Jac : 1.39622e-02 	 Enc : 8.77790e-04 	 AE : 4.58911e-02 	 MSE : 3.19315e+01
Training Epoch 35 finished, took current epoch 357.06s, cumulative time 13013.48s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 36, 25% 	 Loss : 4.2918e-01 	 Res : 2.4867e-01 	 Jac : 2.4360e-02 	 Enc : 1.0335e-02 	 AEnc : 1.4582e-01 	 MSE : 1.9291e+01
Epoch 36, 50% 	 Loss : 7.0036e+00 	 Res : 6.8664e+00 	 Jac : 4.1130e-02 	 Enc : 5.2158e-03 	 AEnc : 9.0910e-02 	 MSE : 5.6294e+01
Epoch 36, 75% 	 Loss : 7.9457e-01 	 Res : 3.3959e-01 	 Jac : 2.5045e-02 	 Enc : 2.2636e-02 	 AEnc : 4.0730e-01 	 MSE : 1.6642e+01
Training Epoch 36 : 	 Train : 2.12857e+00 	 Res : 1.89532e+00 	 Jac : 2.91967e-02 	 Enc : 1.17934e-02 	 AE : 1.92268e-01 	 MSE : 2.61176e+01
Validation Epoch 36 : 	 Train : 1.01785e-01 	 Res : 6.42738e-02 	 Jac : 2.64706e-02 	 Enc : 4.39415e-03 	 AE : 6.64597e-03 	 MSE : 9.88518e+00
Training Epoch 36 finished, took current epoch 360.01s, cumulative time 13373.46s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 37, 25% 	 Loss : 3.9777e-01 	 Res : 3.1349e-01 	 Jac : 3.0720e-02 	 Enc : 3.7611e-03 	 AEnc : 4.9796e-02 	 MSE : 1.3579e+01
Epoch 37, 50% 	 Loss : 2.9222e-01 	 Res : 1.6117e-01 	 Jac : 2.6397e-02 	 Enc : 5.3025e-03 	 AEnc : 9.9349e-02 	 MSE : 1.4884e+01
Epoch 37, 75% 	 Loss : 4.0139e-01 	 Res : 1.4665e-01 	 Jac : 2.9308e-02 	 Enc : 6.2180e-03 	 AEnc : 2.1921e-01 	 MSE : 1.1535e+01
Training Epoch 37 : 	 Train : 3.75962e-01 	 Res : 1.91333e-01 	 Jac : 3.04867e-02 	 Enc : 4.79490e-03 	 AE : 1.49347e-01 	 MSE : 1.23036e+01
Validation Epoch 37 : 	 Train : 1.77050e-01 	 Res : 9.50569e-02 	 Jac : 2.34200e-02 	 Enc : 3.37197e-03 	 AE : 5.52008e-02 	 MSE : 1.45043e+01
Training Epoch 37 finished, took current epoch 356.75s, cumulative time 13730.18s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 38, 25% 	 Loss : 2.0328e-01 	 Res : 9.4740e-02 	 Jac : 2.7296e-02 	 Enc : 3.1011e-03 	 AEnc : 7.8144e-02 	 MSE : 8.2553e+00
Epoch 38, 50% 	 Loss : 1.2591e+00 	 Res : 9.0250e-01 	 Jac : 3.3747e-02 	 Enc : 5.8157e-03 	 AEnc : 3.1706e-01 	 MSE : 2.2097e+01
Epoch 38, 75% 	 Loss : 6.5875e-01 	 Res : 2.3080e-01 	 Jac : 2.5889e-02 	 Enc : 7.8806e-03 	 AEnc : 3.9418e-01 	 MSE : 1.3481e+01
Training Epoch 38 : 	 Train : 1.17757e+00 	 Res : 9.16280e-01 	 Jac : 3.09425e-02 	 Enc : 5.29911e-03 	 AE : 2.25051e-01 	 MSE : 1.96044e+01
Validation Epoch 38 : 	 Train : 4.15743e-01 	 Res : 2.02004e-01 	 Jac : 2.74298e-02 	 Enc : 6.50831e-03 	 AE : 1.79801e-01 	 MSE : 1.00594e+01
Training Epoch 38 finished, took current epoch 369.58s, cumulative time 14099.74s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 39, 25% 	 Loss : 2.2368e-01 	 Res : 1.0622e-01 	 Jac : 2.7165e-02 	 Enc : 1.0287e-02 	 AEnc : 7.9999e-02 	 MSE : 9.9104e+00
Epoch 39, 50% 	 Loss : 4.2876e-01 	 Res : 3.6239e-01 	 Jac : 2.9738e-02 	 Enc : 3.2065e-03 	 AEnc : 3.3430e-02 	 MSE : 1.7099e+01
Epoch 39, 75% 	 Loss : 1.7463e-01 	 Res : 9.0574e-02 	 Jac : 3.2526e-02 	 Enc : 4.3722e-03 	 AEnc : 4.7156e-02 	 MSE : 1.1311e+01
Training Epoch 39 : 	 Train : 2.52959e-01 	 Res : 1.63681e-01 	 Jac : 2.98461e-02 	 Enc : 4.89448e-03 	 AE : 5.45371e-02 	 MSE : 1.17874e+01
Validation Epoch 39 : 	 Train : 1.57736e-01 	 Res : 6.07275e-02 	 Jac : 2.53743e-02 	 Enc : 1.00166e-03 	 AE : 7.06326e-02 	 MSE : 1.04320e+01
Training Epoch 39 finished, took current epoch 358.58s, cumulative time 14458.30s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 40, 25% 	 Loss : 4.7165e-01 	 Res : 3.5545e-01 	 Jac : 2.7607e-02 	 Enc : 3.4645e-03 	 AEnc : 8.5127e-02 	 MSE : 1.5566e+01
Epoch 40, 50% 	 Loss : 1.8107e-01 	 Res : 6.5392e-02 	 Jac : 3.0392e-02 	 Enc : 1.6035e-03 	 AEnc : 8.3686e-02 	 MSE : 7.6845e+00
Epoch 40, 75% 	 Loss : 1.3197e+01 	 Res : 1.2712e+01 	 Jac : 2.8074e-02 	 Enc : 5.7952e-02 	 AEnc : 3.9854e-01 	 MSE : 7.7707e+01
Training Epoch 40 : 	 Train : 3.58355e+00 	 Res : 3.32902e+00 	 Jac : 3.70111e-02 	 Enc : 1.95819e-02 	 AE : 1.97934e-01 	 MSE : 2.84732e+01
Validation Epoch 40 : 	 Train : 2.49596e-01 	 Res : 1.00421e-01 	 Jac : 4.48201e-02 	 Enc : 7.29966e-03 	 AE : 9.70555e-02 	 MSE : 8.31079e+00
Training Epoch 40 finished, took current epoch 361.75s, cumulative time 14820.02s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 41, 25% 	 Loss : 2.6293e-01 	 Res : 9.1094e-02 	 Jac : 3.7973e-02 	 Enc : 3.7048e-03 	 AEnc : 1.3016e-01 	 MSE : 7.7502e+00
Epoch 41, 50% 	 Loss : 7.2149e-01 	 Res : 5.6103e-01 	 Jac : 2.8756e-02 	 Enc : 6.9702e-03 	 AEnc : 1.2473e-01 	 MSE : 2.6475e+01
Epoch 41, 75% 	 Loss : 2.5806e-01 	 Res : 1.0541e-01 	 Jac : 4.4018e-02 	 Enc : 5.8475e-03 	 AEnc : 1.0279e-01 	 MSE : 9.7084e+00
Training Epoch 41 : 	 Train : 5.69633e-01 	 Res : 3.49140e-01 	 Jac : 3.71590e-02 	 Enc : 6.07681e-03 	 AE : 1.77257e-01 	 MSE : 1.89331e+01
Validation Epoch 41 : 	 Train : 4.02073e-01 	 Res : 1.57269e-01 	 Jac : 3.30771e-02 	 Enc : 8.68646e-03 	 AE : 2.03040e-01 	 MSE : 1.30749e+01
Training Epoch 41 finished, took current epoch 357.49s, cumulative time 15177.48s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 42, 25% 	 Loss : 3.0467e-01 	 Res : 1.2931e-01 	 Jac : 4.6488e-02 	 Enc : 4.3887e-03 	 AEnc : 1.2448e-01 	 MSE : 9.3481e+00
Epoch 42, 50% 	 Loss : 5.4637e-01 	 Res : 3.4267e-01 	 Jac : 3.7078e-02 	 Enc : 3.8021e-03 	 AEnc : 1.6281e-01 	 MSE : 1.6184e+01
Epoch 42, 75% 	 Loss : 3.4231e-01 	 Res : 1.4721e-01 	 Jac : 3.5252e-02 	 Enc : 4.1286e-03 	 AEnc : 1.5572e-01 	 MSE : 1.0663e+01
Training Epoch 42 : 	 Train : 3.55307e-01 	 Res : 1.79323e-01 	 Jac : 3.87206e-02 	 Enc : 3.50948e-03 	 AE : 1.33754e-01 	 MSE : 1.10698e+01
Validation Epoch 42 : 	 Train : 2.47922e-01 	 Res : 1.90158e-01 	 Jac : 1.88355e-02 	 Enc : 1.39221e-03 	 AE : 3.75360e-02 	 MSE : 1.96565e+01
Training Epoch 42 finished, took current epoch 365.90s, cumulative time 15543.36s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 43, 25% 	 Loss : 7.4524e-01 	 Res : 3.1767e-01 	 Jac : 2.5036e-02 	 Enc : 5.1192e-03 	 AEnc : 3.9742e-01 	 MSE : 1.4125e+01
Epoch 43, 50% 	 Loss : 3.0833e-01 	 Res : 2.0535e-01 	 Jac : 3.4580e-02 	 Enc : 2.1309e-03 	 AEnc : 6.6268e-02 	 MSE : 9.4909e+00
Epoch 43, 75% 	 Loss : 4.5049e+00 	 Res : 3.9029e+00 	 Jac : 3.5199e-02 	 Enc : 5.9002e-02 	 AEnc : 5.0777e-01 	 MSE : 6.1960e+01
Training Epoch 43 : 	 Train : 1.64637e+00 	 Res : 1.22723e+00 	 Jac : 3.97715e-02 	 Enc : 3.05001e-02 	 AE : 3.48860e-01 	 MSE : 2.70849e+01
Validation Epoch 43 : 	 Train : 8.45788e-01 	 Res : 2.56588e-01 	 Jac : 8.04728e-02 	 Enc : 1.60820e-02 	 AE : 4.92646e-01 	 MSE : 9.78009e+00
Training Epoch 43 finished, took current epoch 396.13s, cumulative time 15939.45s
Current Learning rate DEQ : 0.01
Current Learning rate AUTOENC : 0.05
Epoch 44, 25% 	 Loss : 3.1842e-01 	 Res : 1.1528e-01 	 Jac : 5.6255e-02 	 Enc : 1.0743e-02 	 AEnc : 1.3614e-01 	 MSE : 1.0620e+01
Epoch 44, 50% 	 Loss : 3.6234e-01 	 Res : 1.4481e-01 	 Jac : 3.7354e-02 	 Enc : 4.2591e-03 	 AEnc : 1.7592e-01 	 MSE : 9.6709e+00
Epoch 44, 75% 	 Loss : 5.2117e-01 	 Res : 3.8862e-01 	 Jac : 3.5785e-02 	 Enc : 2.5377e-03 	 AEnc : 9.4233e-02 	 MSE : 1.1131e+01
Training Epoch 44 : 	 Train : 3.55041e-01 	 Res : 1.88772e-01 	 Jac : 4.03864e-02 	 Enc : 5.00684e-03 	 AE : 1.20876e-01 	 MSE : 1.03413e+01
Validation Epoch 44 : 	 Train : 3.05144e-01 	 Res : 8.32034e-02 	 Jac : 2.85965e-02 	 Enc : 2.06592e-03 	 AE : 1.91278e-01 	 MSE : 4.36165e+00
Training Epoch 44 finished, took current epoch 381.01s, cumulative time 16320.44s
Current Learning rate DEQ : 0.008
Current Learning rate AUTOENC : 0.04000000000000001
Epoch 45, 25% 	 Loss : 1.7817e-01 	 Res : 8.8431e-02 	 Jac : 2.8936e-02 	 Enc : 1.5344e-03 	 AEnc : 5.9268e-02 	 MSE : 7.4425e+00
Epoch 45, 50% 	 Loss : 2.5068e+00 	 Res : 1.9620e+00 	 Jac : 3.2236e-02 	 Enc : 8.0706e-03 	 AEnc : 5.0453e-01 	 MSE : 3.3203e+01
Epoch 45, 75% 	 Loss : 2.8626e-01 	 Res : 1.7444e-01 	 Jac : 2.3655e-02 	 Enc : 7.3977e-03 	 AEnc : 8.0762e-02 	 MSE : 1.3844e+01
Training Epoch 45 : 	 Train : 7.92216e-01 	 Res : 5.83314e-01 	 Jac : 2.83283e-02 	 Enc : 4.85781e-03 	 AE : 1.75715e-01 	 MSE : 1.61824e+01
Validation Epoch 45 : 	 Train : 1.20355e-01 	 Res : 4.18750e-02 	 Jac : 2.81103e-02 	 Enc : 1.08968e-03 	 AE : 4.92803e-02 	 MSE : 6.45392e+00
Training Epoch 45 finished, took current epoch 380.03s, cumulative time 16700.40s
Current Learning rate DEQ : 0.008
Current Learning rate AUTOENC : 0.04000000000000001
MODEL SAVED
Epoch 46, 25% 	 Loss : 1.6861e-01 	 Res : 7.1598e-02 	 Jac : 2.9613e-02 	 Enc : 1.1726e-03 	 AEnc : 6.6230e-02 	 MSE : 8.2924e+00
Epoch 46, 50% 	 Loss : 1.4869e+00 	 Res : 1.3638e+00 	 Jac : 2.8572e-02 	 Enc : 6.3559e-03 	 AEnc : 8.8104e-02 	 MSE : 3.0339e+01
Epoch 46, 75% 	 Loss : 1.8563e-01 	 Res : 6.7387e-02 	 Jac : 2.8588e-02 	 Enc : 1.7161e-03 	 AEnc : 8.7937e-02 	 MSE : 7.7180e+00
Training Epoch 46 : 	 Train : 5.39132e-01 	 Res : 4.00363e-01 	 Jac : 2.97852e-02 	 Enc : 2.68181e-03 	 AE : 1.06303e-01 	 MSE : 1.33282e+01
Validation Epoch 46 : 	 Train : 1.93083e-01 	 Res : 8.62325e-02 	 Jac : 2.76381e-02 	 Enc : 1.36261e-03 	 AE : 7.78500e-02 	 MSE : 1.14659e+01
Training Epoch 46 finished, took current epoch 369.42s, cumulative time 17069.79s
Current Learning rate DEQ : 0.008
Current Learning rate AUTOENC : 0.04000000000000001
Epoch 47, 25% 	 Loss : 2.5840e-01 	 Res : 1.5051e-01 	 Jac : 2.9412e-02 	 Enc : 2.5057e-03 	 AEnc : 7.5978e-02 	 MSE : 1.3842e+01
Epoch 47, 50% 	 Loss : 1.4476e-01 	 Res : 5.6104e-02 	 Jac : 2.6557e-02 	 Enc : 1.3428e-03 	 AEnc : 6.0761e-02 	 MSE : 6.6716e+00
Epoch 47, 75% 	 Loss : 1.8131e-01 	 Res : 9.5698e-02 	 Jac : 2.4959e-02 	 Enc : 1.1835e-03 	 AEnc : 5.9467e-02 	 MSE : 1.2655e+01
Training Epoch 47 : 	 Train : 1.83602e-01 	 Res : 9.55543e-02 	 Jac : 2.58348e-02 	 Enc : 1.50259e-03 	 AE : 6.07102e-02 	 MSE : 1.08246e+01
Validation Epoch 47 : 	 Train : 1.06753e-01 	 Res : 5.46534e-02 	 Jac : 1.89504e-02 	 Enc : 6.50469e-04 	 AE : 3.24988e-02 	 MSE : 1.09245e+01
Training Epoch 47 finished, took current epoch 365.67s, cumulative time 17435.44s
Current Learning rate DEQ : 0.008
Current Learning rate AUTOENC : 0.04000000000000001
Epoch 48, 25% 	 Loss : 1.2502e-01 	 Res : 7.8236e-02 	 Jac : 2.3943e-02 	 Enc : 9.6054e-04 	 AEnc : 2.1878e-02 	 MSE : 8.3802e+00
Epoch 48, 50% 	 Loss : 1.8395e-01 	 Res : 9.0697e-02 	 Jac : 2.3667e-02 	 Enc : 1.2775e-03 	 AEnc : 6.8305e-02 	 MSE : 9.8146e+00
Epoch 48, 75% 	 Loss : 1.1206e-01 	 Res : 4.9449e-02 	 Jac : 2.3745e-02 	 Enc : 9.8591e-04 	 AEnc : 3.7884e-02 	 MSE : 6.7182e+00
Training Epoch 48 : 	 Train : 1.78527e-01 	 Res : 1.10918e-01 	 Jac : 2.40214e-02 	 Enc : 1.03499e-03 	 AE : 4.25531e-02 	 MSE : 9.04930e+00
Validation Epoch 48 : 	 Train : 9.37061e-02 	 Res : 6.56617e-02 	 Jac : 2.10668e-02 	 Enc : 2.32650e-03 	 AE : 4.65120e-03 	 MSE : 4.67349e+00
Training Epoch 48 finished, took current epoch 387.12s, cumulative time 17822.53s
Current Learning rate DEQ : 0.008
Current Learning rate AUTOENC : 0.04000000000000001
Epoch 49, 25% 	 Loss : 1.1180e+00 	 Res : 8.9862e-01 	 Jac : 2.1399e-02 	 Enc : 4.6894e-03 	 AEnc : 1.9331e-01 	 MSE : 2.1365e+01
Epoch 49, 50% 	 Loss : 2.9116e-01 	 Res : 9.5754e-02 	 Jac : 2.4444e-02 	 Enc : 2.9145e-03 	 AEnc : 1.6804e-01 	 MSE : 7.4681e+00
Epoch 49, 75% 	 Loss : 5.0042e-01 	 Res : 2.6721e-01 	 Jac : 3.2807e-02 	 Enc : 3.2067e-03 	 AEnc : 1.9720e-01 	 MSE : 1.1602e+01
Training Epoch 49 : 	 Train : 5.17146e-01 	 Res : 3.36403e-01 	 Jac : 2.57150e-02 	 Enc : 3.12960e-03 	 AE : 1.51899e-01 	 MSE : 1.20208e+01
Validation Epoch 49 : 	 Train : 1.14398e-01 	 Res : 3.97412e-02 	 Jac : 2.47056e-02 	 Enc : 1.10934e-03 	 AE : 4.88420e-02 	 MSE : 3.83325e+00
Training Epoch 49 finished, took current epoch 380.25s, cumulative time 18202.73s
Current Learning rate DEQ : 0.008
Current Learning rate AUTOENC : 0.04000000000000001
MODEL SAVED
Epoch 50, 25% 	 Loss : 8.2928e-01 	 Res : 6.9478e-01 	 Jac : 2.4617e-02 	 Enc : 2.7937e-03 	 AEnc : 1.0710e-01 	 MSE : 1.9986e+01
Epoch 50, 50% 	 Loss : 2.1715e-01 	 Res : 1.1067e-01 	 Jac : 2.2678e-02 	 Enc : 3.2305e-03 	 AEnc : 8.0574e-02 	 MSE : 7.7444e+00
Epoch 50, 75% 	 Loss : 3.9897e-01 	 Res : 3.4510e-01 	 Jac : 2.6991e-02 	 Enc : 1.0906e-03 	 AEnc : 2.5796e-02 	 MSE : 1.1355e+01
Training Epoch 50 : 	 Train : 2.53035e+00 	 Res : 2.42996e+00 	 Jac : 2.41649e-02 	 Enc : 3.37667e-03 	 AE : 7.28525e-02 	 MSE : 2.45033e+01
Validation Epoch 50 : 	 Train : 2.68234e-01 	 Res : 2.45419e-01 	 Jac : 1.66260e-02 	 Enc : 3.38479e-03 	 AE : 2.80447e-03 	 MSE : 2.11287e+01
Training Epoch 50 finished, took current epoch 375.98s, cumulative time 18578.68s
Current Learning rate DEQ : 0.008
Current Learning rate AUTOENC : 0.04000000000000001
Epoch 51, 25% 	 Loss : 2.5211e-01 	 Res : 9.9602e-02 	 Jac : 2.1401e-02 	 Enc : 5.0750e-03 	 AEnc : 1.2604e-01 	 MSE : 9.9675e+00
Epoch 51, 50% 	 Loss : 1.1533e-01 	 Res : 4.5690e-02 	 Jac : 2.4231e-02 	 Enc : 1.0209e-03 	 AEnc : 4.4390e-02 	 MSE : 6.0482e+00
Epoch 51, 75% 	 Loss : 7.5083e-01 	 Res : 6.4363e-01 	 Jac : 2.3827e-02 	 Enc : 5.2921e-03 	 AEnc : 7.8082e-02 	 MSE : 2.1539e+01
Training Epoch 51 : 	 Train : 3.30846e-01 	 Res : 2.33619e-01 	 Jac : 2.36966e-02 	 Enc : 3.83362e-03 	 AE : 6.96962e-02 	 MSE : 1.16419e+01
Validation Epoch 51 : 	 Train : 1.93471e-01 	 Res : 1.02690e-01 	 Jac : 2.62052e-02 	 Enc : 3.26119e-03 	 AE : 6.13147e-02 	 MSE : 3.17052e+00
Training Epoch 51 finished, took current epoch 378.92s, cumulative time 18957.56s
Current Learning rate DEQ : 0.008
Current Learning rate AUTOENC : 0.04000000000000001
Epoch 52, 25% 	 Loss : 4.4389e-01 	 Res : 2.5076e-01 	 Jac : 2.5522e-02 	 Enc : 2.7029e-03 	 AEnc : 1.6490e-01 	 MSE : 6.7396e+00
Epoch 52, 50% 	 Loss : 3.4091e-01 	 Res : 9.8038e-02 	 Jac : 2.3686e-02 	 Enc : 2.1114e-03 	 AEnc : 2.1708e-01 	 MSE : 7.1612e+00
Epoch 52, 75% 	 Loss : 1.4149e-01 	 Res : 7.3165e-02 	 Jac : 2.2486e-02 	 Enc : 1.0247e-03 	 AEnc : 4.4813e-02 	 MSE : 6.5225e+00
Training Epoch 52 : 	 Train : 3.01972e-01 	 Res : 1.61883e-01 	 Jac : 2.27934e-02 	 Enc : 2.10951e-03 	 AE : 1.15186e-01 	 MSE : 8.29960e+00
Validation Epoch 52 : 	 Train : 9.19424e-02 	 Res : 5.96804e-02 	 Jac : 1.90614e-02 	 Enc : 1.46420e-03 	 AE : 1.17363e-02 	 MSE : 9.49008e+00
Training Epoch 52 finished, took current epoch 365.83s, cumulative time 19323.35s
Current Learning rate DEQ : 0.008
Current Learning rate AUTOENC : 0.04000000000000001
Epoch 53, 25% 	 Loss : 1.1328e-01 	 Res : 4.8091e-02 	 Jac : 1.9820e-02 	 Enc : 1.1745e-03 	 AEnc : 4.4195e-02 	 MSE : 6.0647e+00
Epoch 53, 50% 	 Loss : 2.6630e+00 	 Res : 2.4649e+00 	 Jac : 2.3934e-02 	 Enc : 4.7621e-03 	 AEnc : 1.6940e-01 	 MSE : 3.4772e+01
Epoch 53, 75% 	 Loss : 1.4891e-01 	 Res : 5.9673e-02 	 Jac : 2.3452e-02 	 Enc : 2.8137e-03 	 AEnc : 6.2970e-02 	 MSE : 6.3408e+00
Training Epoch 53 : 	 Train : 8.08399e-01 	 Res : 6.74611e-01 	 Jac : 2.23983e-02 	 Enc : 2.77071e-03 	 AE : 1.08619e-01 	 MSE : 1.42625e+01
Validation Epoch 53 : 	 Train : 1.11818e-01 	 Res : 4.31961e-02 	 Jac : 2.10649e-02 	 Enc : 3.83226e-03 	 AE : 4.37249e-02 	 MSE : 3.45170e+00
Training Epoch 53 finished, took current epoch 371.78s, cumulative time 19695.10s
Current Learning rate DEQ : 0.008
Current Learning rate AUTOENC : 0.04000000000000001
Epoch 54, 25% 	 Loss : 1.4242e-01 	 Res : 5.4853e-02 	 Jac : 2.0891e-02 	 Enc : 1.7412e-03 	 AEnc : 6.4939e-02 	 MSE : 6.4693e+00
Epoch 54, 50% 	 Loss : 8.5067e-02 	 Res : 4.2706e-02 	 Jac : 2.0040e-02 	 Enc : 7.9636e-04 	 AEnc : 2.1524e-02 	 MSE : 7.0854e+00
Epoch 54, 75% 	 Loss : 4.4594e+00 	 Res : 4.3558e+00 	 Jac : 2.0550e-02 	 Enc : 2.4994e-03 	 AEnc : 8.0604e-02 	 MSE : 1.2356e+01
Training Epoch 54 : 	 Train : 1.20646e+00 	 Res : 1.13109e+00 	 Jac : 2.06311e-02 	 Enc : 1.70087e-03 	 AE : 5.30430e-02 	 MSE : 8.75784e+00
Validation Epoch 54 : 	 Train : 1.22091e-01 	 Res : 6.19038e-02 	 Jac : 1.76120e-02 	 Enc : 1.26147e-03 	 AE : 4.13142e-02 	 MSE : 1.08516e+01
Training Epoch 54 finished, took current epoch 361.83s, cumulative time 20056.90s
Current Learning rate DEQ : 0.008
Current Learning rate AUTOENC : 0.04000000000000001
Epoch 55, 25% 	 Loss : 1.1427e-01 	 Res : 5.5812e-02 	 Jac : 1.9905e-02 	 Enc : 1.3328e-03 	 AEnc : 3.7221e-02 	 MSE : 6.9331e+00
Epoch 55, 50% 	 Loss : 1.6694e-01 	 Res : 8.0476e-02 	 Jac : 2.0328e-02 	 Enc : 1.5682e-03 	 AEnc : 6.4568e-02 	 MSE : 7.6772e+00
Epoch 55, 75% 	 Loss : 1.8164e-01 	 Res : 6.0361e-02 	 Jac : 2.0335e-02 	 Enc : 1.2605e-03 	 AEnc : 9.9684e-02 	 MSE : 6.5527e+00
Training Epoch 55 : 	 Train : 1.47610e-01 	 Res : 6.28751e-02 	 Jac : 2.01411e-02 	 Enc : 1.30187e-03 	 AE : 6.32919e-02 	 MSE : 7.02929e+00
Validation Epoch 55 : 	 Train : 6.90384e-02 	 Res : 4.56648e-02 	 Jac : 1.82462e-02 	 Enc : 1.32616e-03 	 AE : 3.80116e-03 	 MSE : 7.22775e+00
Training Epoch 55 finished, took current epoch 366.57s, cumulative time 20423.43s
Current Learning rate DEQ : 0.008
Current Learning rate AUTOENC : 0.04000000000000001
Epoch 56, 25% 	 Loss : 1.2134e-01 	 Res : 5.2152e-02 	 Jac : 1.9480e-02 	 Enc : 1.2956e-03 	 AEnc : 4.8409e-02 	 MSE : 6.5060e+00
Epoch 56, 50% 	 Loss : 3.9981e-01 	 Res : 3.7018e-01 	 Jac : 1.9545e-02 	 Enc : 1.8592e-03 	 AEnc : 8.2250e-03 	 MSE : 1.5589e+01
Epoch 56, 75% 	 Loss : 1.5294e-01 	 Res : 7.8333e-02 	 Jac : 2.1011e-02 	 Enc : 2.8585e-03 	 AEnc : 5.0741e-02 	 MSE : 8.2327e+00
Training Epoch 56 : 	 Train : 2.06717e-01 	 Res : 1.39883e-01 	 Jac : 2.01703e-02 	 Enc : 1.81801e-03 	 AE : 4.48456e-02 	 MSE : 9.25327e+00
Validation Epoch 56 : 	 Train : 1.05958e-01 	 Res : 5.00706e-02 	 Jac : 1.88180e-02 	 Enc : 1.03643e-03 	 AE : 3.60325e-02 	 MSE : 8.97035e+00
Training Epoch 56 finished, took current epoch 365.92s, cumulative time 20789.32s
Current Learning rate DEQ : 0.008
Current Learning rate AUTOENC : 0.04000000000000001
Epoch 57, 25% 	 Loss : 7.7470e-02 	 Res : 3.6400e-02 	 Jac : 1.9780e-02 	 Enc : 7.9435e-04 	 AEnc : 2.0496e-02 	 MSE : 5.7663e+00
Epoch 57, 50% 	 Loss : 6.5221e-01 	 Res : 6.0047e-01 	 Jac : 2.0485e-02 	 Enc : 2.6717e-03 	 AEnc : 2.8581e-02 	 MSE : 1.6178e+01
Epoch 57, 75% 	 Loss : 1.7289e-01 	 Res : 8.4930e-02 	 Jac : 1.8942e-02 	 Enc : 2.1430e-03 	 AEnc : 6.6875e-02 	 MSE : 9.9616e+00
Training Epoch 57 : 	 Train : 2.70639e-01 	 Res : 1.95944e-01 	 Jac : 1.98802e-02 	 Enc : 1.78435e-03 	 AE : 5.30298e-02 	 MSE : 9.64867e+00
Validation Epoch 57 : 	 Train : 1.78599e-01 	 Res : 6.49260e-02 	 Jac : 1.96718e-02 	 Enc : 1.81906e-03 	 AE : 9.21817e-02 	 MSE : 7.91761e+00
Training Epoch 57 finished, took current epoch 365.85s, cumulative time 21155.14s
Current Learning rate DEQ : 0.008
Current Learning rate AUTOENC : 0.04000000000000001
Epoch 58, 25% 	 Loss : 1.0540e-01 	 Res : 4.9320e-02 	 Jac : 1.9621e-02 	 Enc : 9.8899e-04 	 AEnc : 3.5472e-02 	 MSE : 6.2858e+00
Epoch 58, 50% 	 Loss : 2.8093e-01 	 Res : 1.4182e-01 	 Jac : 2.0069e-02 	 Enc : 2.0960e-03 	 AEnc : 1.1694e-01 	 MSE : 1.0075e+01
Epoch 58, 75% 	 Loss : 8.3446e-02 	 Res : 4.4081e-02 	 Jac : 2.0255e-02 	 Enc : 1.1678e-03 	 AEnc : 1.7943e-02 	 MSE : 6.5708e+00
Training Epoch 58 : 	 Train : 1.54127e-01 	 Res : 7.75015e-02 	 Jac : 1.98213e-02 	 Enc : 1.46597e-03 	 AE : 5.53383e-02 	 MSE : 7.91409e+00
Validation Epoch 58 : 	 Train : 7.38480e-02 	 Res : 3.21203e-02 	 Jac : 1.88935e-02 	 Enc : 1.50202e-03 	 AE : 2.13323e-02 	 MSE : 4.76747e+00
Training Epoch 58 finished, took current epoch 371.79s, cumulative time 21526.85s
Current Learning rate DEQ : 0.008
Current Learning rate AUTOENC : 0.04000000000000001
MODEL SAVED
Epoch 59, 25% 	 Loss : 1.0410e-01 	 Res : 5.2569e-02 	 Jac : 1.8805e-02 	 Enc : 1.4921e-03 	 AEnc : 3.1234e-02 	 MSE : 7.3471e+00
Epoch 59, 50% 	 Loss : 1.0231e-01 	 Res : 5.5041e-02 	 Jac : 1.8256e-02 	 Enc : 7.4338e-04 	 AEnc : 2.8270e-02 	 MSE : 7.7415e+00
Epoch 59, 75% 	 Loss : 9.1727e-02 	 Res : 4.9384e-02 	 Jac : 1.8748e-02 	 Enc : 7.8912e-04 	 AEnc : 2.2806e-02 	 MSE : 7.4771e+00
Training Epoch 59 : 	 Train : 2.24485e-01 	 Res : 1.39916e-01 	 Jac : 1.89384e-02 	 Enc : 1.87310e-03 	 AE : 6.37569e-02 	 MSE : 8.67023e+00
Validation Epoch 59 : 	 Train : 1.63637e+00 	 Res : 1.54806e+00 	 Jac : 2.31158e-02 	 Enc : 2.53941e-03 	 AE : 6.26545e-02 	 MSE : 1.22875e+01
Training Epoch 59 finished, took current epoch 398.99s, cumulative time 21925.80s
Current Learning rate DEQ : 0.008
Current Learning rate AUTOENC : 0.04000000000000001
Epoch 60, 25% 	 Loss : 2.2152e-01 	 Res : 9.5423e-02 	 Jac : 2.1112e-02 	 Enc : 1.7917e-03 	 AEnc : 1.0320e-01 	 MSE : 6.7984e+00
Epoch 60, 50% 	 Loss : 1.3099e-01 	 Res : 6.1025e-02 	 Jac : 2.0385e-02 	 Enc : 9.5787e-04 	 AEnc : 4.8621e-02 	 MSE : 7.6279e+00
Epoch 60, 75% 	 Loss : 1.7843e-01 	 Res : 7.1818e-02 	 Jac : 1.8816e-02 	 Enc : 1.2090e-03 	 AEnc : 8.6582e-02 	 MSE : 8.1018e+00
Training Epoch 60 : 	 Train : 1.63958e-01 	 Res : 6.96341e-02 	 Jac : 1.98022e-02 	 Enc : 1.29086e-03 	 AE : 7.32313e-02 	 MSE : 7.06961e+00
Validation Epoch 60 : 	 Train : 8.55151e-02 	 Res : 6.28402e-02 	 Jac : 1.95303e-02 	 Enc : 7.39010e-04 	 AE : 2.40556e-03 	 MSE : 3.69777e+00
Training Epoch 60 finished, took current epoch 377.50s, cumulative time 22303.30s
Current Learning rate DEQ : 0.008
Current Learning rate AUTOENC : 0.04000000000000001
Epoch 61, 25% 	 Loss : 1.1045e-01 	 Res : 5.3128e-02 	 Jac : 1.8354e-02 	 Enc : 7.8729e-04 	 AEnc : 3.8185e-02 	 MSE : 6.0184e+00
Epoch 61, 50% 	 Loss : 2.6588e-01 	 Res : 1.9379e-01 	 Jac : 1.8096e-02 	 Enc : 1.5880e-03 	 AEnc : 5.2407e-02 	 MSE : 9.7429e+00
Epoch 61, 75% 	 Loss : 9.0580e-02 	 Res : 4.0292e-02 	 Jac : 1.7650e-02 	 Enc : 9.5672e-04 	 AEnc : 3.1682e-02 	 MSE : 6.3861e+00
Training Epoch 61 : 	 Train : 1.41400e-01 	 Res : 8.53192e-02 	 Jac : 1.78488e-02 	 Enc : 1.09787e-03 	 AE : 3.71343e-02 	 MSE : 7.50903e+00
Validation Epoch 61 : 	 Train : 1.22898e-01 	 Res : 9.10992e-02 	 Jac : 1.74043e-02 	 Enc : 2.19910e-03 	 AE : 1.21955e-02 	 MSE : 1.03516e+01
Training Epoch 61 finished, took current epoch 372.05s, cumulative time 22675.33s
Current Learning rate DEQ : 0.008
Current Learning rate AUTOENC : 0.04000000000000001
Epoch 62, 25% 	 Loss : 3.3748e-01 	 Res : 2.7687e-01 	 Jac : 1.9508e-02 	 Enc : 5.0474e-03 	 AEnc : 3.6053e-02 	 MSE : 1.7324e+01
Epoch 62, 50% 	 Loss : 1.2362e-01 	 Res : 5.1531e-02 	 Jac : 2.1327e-02 	 Enc : 2.2781e-03 	 AEnc : 4.8487e-02 	 MSE : 7.4407e+00
Epoch 62, 75% 	 Loss : 8.8927e-02 	 Res : 3.4083e-02 	 Jac : 1.8743e-02 	 Enc : 8.6939e-04 	 AEnc : 3.5232e-02 	 MSE : 4.8031e+00
Training Epoch 62 : 	 Train : 1.77248e-01 	 Res : 1.04594e-01 	 Jac : 1.92485e-02 	 Enc : 2.35042e-03 	 AE : 5.10560e-02 	 MSE : 8.72065e+00
Validation Epoch 62 : 	 Train : 1.88825e-01 	 Res : 5.19670e-02 	 Jac : 1.70545e-02 	 Enc : 1.15604e-03 	 AE : 1.18647e-01 	 MSE : 5.04952e+00
Training Epoch 62 finished, took current epoch 369.47s, cumulative time 23044.78s
Current Learning rate DEQ : 0.008
Current Learning rate AUTOENC : 0.04000000000000001
Epoch 63, 25% 	 Loss : 1.5135e-01 	 Res : 5.5890e-02 	 Jac : 1.7555e-02 	 Enc : 1.2909e-03 	 AEnc : 7.6617e-02 	 MSE : 5.8764e+00
Epoch 63, 50% 	 Loss : 1.5799e-01 	 Res : 1.1394e-01 	 Jac : 1.7755e-02 	 Enc : 1.0954e-03 	 AEnc : 2.5200e-02 	 MSE : 8.9590e+00
Epoch 63, 75% 	 Loss : 1.0219e-01 	 Res : 4.4850e-02 	 Jac : 1.7380e-02 	 Enc : 1.6680e-03 	 AEnc : 3.8292e-02 	 MSE : 5.8507e+00
Training Epoch 63 : 	 Train : 1.49664e-01 	 Res : 7.22884e-02 	 Jac : 1.75896e-02 	 Enc : 1.51425e-03 	 AE : 5.82714e-02 	 MSE : 7.08030e+00
Validation Epoch 63 : 	 Train : 3.26269e-01 	 Res : 8.21627e-02 	 Jac : 1.91574e-02 	 Enc : 3.59021e-03 	 AE : 2.21359e-01 	 MSE : 2.48865e+00
Training Epoch 63 finished, took current epoch 377.14s, cumulative time 23421.91s
Current Learning rate DEQ : 0.008
Current Learning rate AUTOENC : 0.04000000000000001
Epoch 64, 25% 	 Loss : 1.1995e-01 	 Res : 4.6190e-02 	 Jac : 1.8266e-02 	 Enc : 1.7423e-03 	 AEnc : 5.3752e-02 	 MSE : 6.0116e+00
Epoch 64, 50% 	 Loss : 1.2684e-01 	 Res : 5.6897e-02 	 Jac : 1.7599e-02 	 Enc : 1.3473e-03 	 AEnc : 5.0997e-02 	 MSE : 7.6625e+00
Epoch 64, 75% 	 Loss : 7.7937e-01 	 Res : 7.0597e-01 	 Jac : 2.0476e-02 	 Enc : 4.9429e-03 	 AEnc : 4.7980e-02 	 MSE : 1.4512e+01
Training Epoch 64 : 	 Train : 3.33761e-01 	 Res : 2.24705e-01 	 Jac : 1.87020e-02 	 Enc : 2.87093e-03 	 AE : 8.74833e-02 	 MSE : 8.74385e+00
Validation Epoch 64 : 	 Train : 2.08197e-01 	 Res : 6.47256e-02 	 Jac : 1.73667e-02 	 Enc : 3.11238e-03 	 AE : 1.22992e-01 	 MSE : 6.70818e+00
Training Epoch 64 finished, took current epoch 373.28s, cumulative time 23795.14s
Current Learning rate DEQ : 0.008
Current Learning rate AUTOENC : 0.04000000000000001
Epoch 65, 25% 	 Loss : 9.7420e-02 	 Res : 4.4325e-02 	 Jac : 1.8274e-02 	 Enc : 2.4183e-03 	 AEnc : 3.2404e-02 	 MSE : 6.1435e+00
Epoch 65, 50% 	 Loss : 3.3578e-01 	 Res : 2.9442e-01 	 Jac : 1.7840e-02 	 Enc : 4.5969e-03 	 AEnc : 1.8924e-02 	 MSE : 1.3569e+01
Epoch 65, 75% 	 Loss : 3.3388e-01 	 Res : 1.6628e-01 	 Jac : 1.9506e-02 	 Enc : 9.7469e-03 	 AEnc : 1.3835e-01 	 MSE : 7.4167e+00
Training Epoch 65 : 	 Train : 2.45144e-01 	 Res : 1.54333e-01 	 Jac : 1.91281e-02 	 Enc : 5.64827e-03 	 AE : 6.60340e-02 	 MSE : 8.72213e+00
Validation Epoch 65 : 	 Train : 3.41664e-01 	 Res : 9.21971e-02 	 Jac : 2.06313e-02 	 Enc : 2.92704e-03 	 AE : 2.25908e-01 	 MSE : 4.99430e+00
Training Epoch 65 finished, took current epoch 377.22s, cumulative time 24172.34s
Current Learning rate DEQ : 0.008
Current Learning rate AUTOENC : 0.04000000000000001
Epoch 66, 25% 	 Loss : 6.4086e-01 	 Res : 5.1912e-01 	 Jac : 1.9576e-02 	 Enc : 2.4745e-03 	 AEnc : 9.9689e-02 	 MSE : 1.4207e+01
Epoch 66, 50% 	 Loss : 1.0593e-01 	 Res : 5.2083e-02 	 Jac : 1.9524e-02 	 Enc : 2.6368e-03 	 AEnc : 3.1687e-02 	 MSE : 6.5614e+00
Epoch 66, 75% 	 Loss : 1.3028e-01 	 Res : 9.2314e-02 	 Jac : 1.8101e-02 	 Enc : 8.0621e-04 	 AEnc : 1.9061e-02 	 MSE : 9.5261e+00
Training Epoch 66 : 	 Train : 3.39414e-01 	 Res : 2.41143e-01 	 Jac : 1.89674e-02 	 Enc : 2.60343e-03 	 AE : 7.67009e-02 	 MSE : 1.12994e+01
Validation Epoch 66 : 	 Train : 2.31699e-01 	 Res : 8.57090e-02 	 Jac : 2.07323e-02 	 Enc : 2.69093e-03 	 AE : 1.22567e-01 	 MSE : 1.11480e+01
Training Epoch 66 finished, took current epoch 374.11s, cumulative time 24546.44s
Current Learning rate DEQ : 0.0064
Current Learning rate AUTOENC : 0.03200000000000001
Epoch 67, 25% 	 Loss : 1.4607e-01 	 Res : 5.8059e-02 	 Jac : 2.1207e-02 	 Enc : 1.6288e-03 	 AEnc : 6.5176e-02 	 MSE : 7.1040e+00
Epoch 67, 50% 	 Loss : 1.0898e-01 	 Res : 3.9233e-02 	 Jac : 1.8680e-02 	 Enc : 8.0000e-04 	 AEnc : 5.0268e-02 	 MSE : 5.4769e+00
Epoch 67, 75% 	 Loss : 8.7977e-02 	 Res : 3.2718e-02 	 Jac : 1.7146e-02 	 Enc : 6.6839e-04 	 AEnc : 3.7445e-02 	 MSE : 4.5133e+00
Training Epoch 67 : 	 Train : 4.40830e-01 	 Res : 3.76331e-01 	 Jac : 1.90119e-02 	 Enc : 1.23053e-03 	 AE : 4.42566e-02 	 MSE : 9.92117e+00
Validation Epoch 67 : 	 Train : 8.16931e-02 	 Res : 5.14824e-02 	 Jac : 1.74640e-02 	 Enc : 4.30367e-03 	 AE : 8.44298e-03 	 MSE : 5.23093e+00
Training Epoch 67 finished, took current epoch 381.37s, cumulative time 24927.79s
Current Learning rate DEQ : 0.0064
Current Learning rate AUTOENC : 0.03200000000000001
Epoch 68, 25% 	 Loss : 1.8629e-01 	 Res : 1.4222e-01 	 Jac : 2.0573e-02 	 Enc : 3.6393e-03 	 AEnc : 1.9859e-02 	 MSE : 9.1633e+00
Epoch 68, 50% 	 Loss : 7.3547e-02 	 Res : 3.3571e-02 	 Jac : 1.7021e-02 	 Enc : 1.1576e-03 	 AEnc : 2.1798e-02 	 MSE : 5.2849e+00
Epoch 68, 75% 	 Loss : 1.3455e-01 	 Res : 6.2597e-02 	 Jac : 1.6479e-02 	 Enc : 1.1019e-03 	 AEnc : 5.4377e-02 	 MSE : 7.8270e+00
Training Epoch 68 : 	 Train : 1.14761e-01 	 Res : 6.89968e-02 	 Jac : 1.78194e-02 	 Enc : 1.62022e-03 	 AE : 2.63241e-02 	 MSE : 7.06931e+00
Validation Epoch 68 : 	 Train : 6.42910e-02 	 Res : 4.60025e-02 	 Jac : 1.64178e-02 	 Enc : 5.45744e-04 	 AE : 1.32493e-03 	 MSE : 8.22542e+00
Training Epoch 68 finished, took current epoch 373.01s, cumulative time 25300.77s
Current Learning rate DEQ : 0.0064
Current Learning rate AUTOENC : 0.03200000000000001
Epoch 69, 25% 	 Loss : 4.9259e-01 	 Res : 4.4781e-01 	 Jac : 1.6579e-02 	 Enc : 1.6763e-03 	 AEnc : 2.6531e-02 	 MSE : 1.5910e+01
Epoch 69, 50% 	 Loss : 1.3525e-01 	 Res : 8.2264e-02 	 Jac : 1.7741e-02 	 Enc : 2.5798e-03 	 AEnc : 3.2664e-02 	 MSE : 1.1261e+01
Epoch 69, 75% 	 Loss : 1.0784e-01 	 Res : 3.8089e-02 	 Jac : 1.8097e-02 	 Enc : 7.6412e-04 	 AEnc : 5.0893e-02 	 MSE : 4.6497e+00
Training Epoch 69 : 	 Train : 1.38257e+00 	 Res : 1.10580e+00 	 Jac : 7.62061e-02 	 Enc : 1.77217e-02 	 AE : 1.82842e-01 	 MSE : 3.36221e+01
Validation Epoch 69 : 	 Train : 1.28028e+00 	 Res : 1.02917e+00 	 Jac : 2.03302e-02 	 Enc : 9.69077e-02 	 AE : 1.33879e-01 	 MSE : 3.02810e+01
Training Epoch 69 finished, took current epoch 461.56s, cumulative time 25762.30s
Current Learning rate DEQ : 0.0064
Current Learning rate AUTOENC : 0.03200000000000001
Epoch 70, 25% 	 Loss : 9.0043e-01 	 Res : 4.1334e-01 	 Jac : 2.1630e-02 	 Enc : 5.9964e-02 	 AEnc : 4.0550e-01 	 MSE : 2.0936e+01
Epoch 70, 50% 	 Loss : 2.0690e-01 	 Res : 7.3698e-02 	 Jac : 2.2572e-02 	 Enc : 6.3401e-03 	 AEnc : 1.0429e-01 	 MSE : 7.4092e+00
Epoch 70, 75% 	 Loss : 1.4993e-01 	 Res : 4.6785e-02 	 Jac : 2.1084e-02 	 Enc : 1.7881e-03 	 AEnc : 8.0274e-02 	 MSE : 4.5713e+00
Training Epoch 70 : 	 Train : 3.42709e-01 	 Res : 1.46639e-01 	 Jac : 2.10087e-02 	 Enc : 1.77806e-02 	 AE : 1.57281e-01 	 MSE : 9.86068e+00
Validation Epoch 70 : 	 Train : 1.98556e-01 	 Res : 4.22826e-02 	 Jac : 1.82322e-02 	 Enc : 1.01940e-03 	 AE : 1.37022e-01 	 MSE : 2.10529e+00
Training Epoch 70 finished, took current epoch 371.19s, cumulative time 26133.47s
Current Learning rate DEQ : 0.0064
Current Learning rate AUTOENC : 0.03200000000000001
Epoch 71, 25% 	 Loss : 1.2703e-01 	 Res : 4.7532e-02 	 Jac : 1.8314e-02 	 Enc : 9.4393e-04 	 AEnc : 6.0238e-02 	 MSE : 5.5022e+00
Epoch 71, 50% 	 Loss : 4.3777e+00 	 Res : 4.2176e+00 	 Jac : 2.3733e-02 	 Enc : 2.1431e-02 	 AEnc : 1.1495e-01 	 MSE : 6.4676e+01
Epoch 71, 75% 	 Loss : 3.9966e-01 	 Res : 2.6195e-01 	 Jac : 2.4432e-02 	 Enc : 3.0227e-02 	 AEnc : 8.3044e-02 	 MSE : 1.5939e+01
Training Epoch 71 : 	 Train : 1.28477e+00 	 Res : 1.14678e+00 	 Jac : 2.25658e-02 	 Enc : 1.40247e-02 	 AE : 1.01396e-01 	 MSE : 2.27603e+01
Validation Epoch 71 : 	 Train : 4.45456e-01 	 Res : 1.07365e-01 	 Jac : 2.24747e-02 	 Enc : 2.16942e-03 	 AE : 3.13446e-01 	 MSE : 4.18591e+00
Training Epoch 71 finished, took current epoch 371.54s, cumulative time 26504.98s
Current Learning rate DEQ : 0.0064
Current Learning rate AUTOENC : 0.03200000000000001
Epoch 72, 25% 	 Loss : 1.7427e-01 	 Res : 4.5715e-02 	 Jac : 2.2390e-02 	 Enc : 1.1244e-03 	 AEnc : 1.0504e-01 	 MSE : 3.4786e+00
Epoch 72, 50% 	 Loss : 2.2225e-01 	 Res : 1.4219e-01 	 Jac : 2.2015e-02 	 Enc : 1.9187e-03 	 AEnc : 5.6123e-02 	 MSE : 1.0165e+01
Epoch 72, 75% 	 Loss : 2.1012e-01 	 Res : 7.7066e-02 	 Jac : 1.8860e-02 	 Enc : 2.5072e-03 	 AEnc : 1.1169e-01 	 MSE : 7.3023e+00
Training Epoch 72 : 	 Train : 1.71759e-01 	 Res : 7.49796e-02 	 Jac : 2.01352e-02 	 Enc : 1.56875e-03 	 AE : 7.50759e-02 	 MSE : 6.46932e+00
Validation Epoch 72 : 	 Train : 7.95427e-02 	 Res : 2.47837e-02 	 Jac : 1.71644e-02 	 Enc : 5.31038e-04 	 AE : 3.70636e-02 	 MSE : 1.54051e+00
Training Epoch 72 finished, took current epoch 379.59s, cumulative time 26884.50s
Current Learning rate DEQ : 0.0064
Current Learning rate AUTOENC : 0.03200000000000001
MODEL SAVED
Epoch 73, 25% 	 Loss : 1.1490e-01 	 Res : 4.5128e-02 	 Jac : 1.6881e-02 	 Enc : 6.1963e-04 	 AEnc : 5.2271e-02 	 MSE : 5.8018e+00
Epoch 73, 50% 	 Loss : 7.1818e-02 	 Res : 4.9628e-02 	 Jac : 1.7061e-02 	 Enc : 4.3066e-04 	 AEnc : 4.6988e-03 	 MSE : 7.7046e+00
Epoch 73, 75% 	 Loss : 6.2580e-02 	 Res : 4.1809e-02 	 Jac : 1.7032e-02 	 Enc : 4.0634e-04 	 AEnc : 3.3319e-03 	 MSE : 7.9378e+00
Training Epoch 73 : 	 Train : 1.17043e-01 	 Res : 6.68376e-02 	 Jac : 1.69758e-02 	 Enc : 7.35625e-04 	 AE : 3.24935e-02 	 MSE : 8.01655e+00
Validation Epoch 73 : 	 Train : 7.99896e-02 	 Res : 3.68696e-02 	 Jac : 1.61697e-02 	 Enc : 9.91121e-04 	 AE : 2.59591e-02 	 MSE : 7.88415e+00
Training Epoch 73 finished, took current epoch 370.66s, cumulative time 27255.14s
Current Learning rate DEQ : 0.0064
Current Learning rate AUTOENC : 0.03200000000000001
Epoch 74, 25% 	 Loss : 1.4948e-01 	 Res : 4.8996e-02 	 Jac : 1.6851e-02 	 Enc : 1.0814e-03 	 AEnc : 8.2553e-02 	 MSE : 6.0211e+00
Epoch 74, 50% 	 Loss : 1.0064e-01 	 Res : 3.5060e-02 	 Jac : 1.6908e-02 	 Enc : 6.3957e-04 	 AEnc : 4.8029e-02 	 MSE : 4.3477e+00
Epoch 74, 75% 	 Loss : 1.1055e-01 	 Res : 4.2697e-02 	 Jac : 1.6095e-02 	 Enc : 6.6397e-04 	 AEnc : 5.1092e-02 	 MSE : 4.9271e+00
Training Epoch 74 : 	 Train : 1.30761e-01 	 Res : 5.14077e-02 	 Jac : 1.65898e-02 	 Enc : 9.50696e-04 	 AE : 6.18126e-02 	 MSE : 6.39319e+00
Validation Epoch 74 : 	 Train : 9.49791e-02 	 Res : 5.45051e-02 	 Jac : 1.58232e-02 	 Enc : 7.34650e-04 	 AE : 2.39162e-02 	 MSE : 1.07384e+01
Training Epoch 74 finished, took current epoch 368.68s, cumulative time 27623.78s
Current Learning rate DEQ : 0.0064
Current Learning rate AUTOENC : 0.03200000000000001
Epoch 75, 25% 	 Loss : 9.0989e-02 	 Res : 4.7414e-02 	 Jac : 1.7186e-02 	 Enc : 1.2743e-03 	 AEnc : 2.5115e-02 	 MSE : 6.4546e+00
Epoch 75, 50% 	 Loss : 1.2091e-01 	 Res : 8.5386e-02 	 Jac : 1.7230e-02 	 Enc : 6.6632e-04 	 AEnc : 1.7627e-02 	 MSE : 6.7265e+00
Epoch 75, 75% 	 Loss : 1.2869e-01 	 Res : 8.2903e-02 	 Jac : 1.6959e-02 	 Enc : 1.5890e-03 	 AEnc : 2.7236e-02 	 MSE : 1.0511e+01
Training Epoch 75 : 	 Train : 1.01631e-01 	 Res : 6.16257e-02 	 Jac : 1.71582e-02 	 Enc : 1.03535e-03 	 AE : 2.18118e-02 	 MSE : 7.18325e+00
Validation Epoch 75 : 	 Train : 2.81006e-01 	 Res : 2.43986e-01 	 Jac : 1.74268e-02 	 Enc : 3.96094e-04 	 AE : 1.91976e-02 	 MSE : 2.13697e+01
Training Epoch 75 finished, took current epoch 400.16s, cumulative time 28023.92s
Current Learning rate DEQ : 0.0064
Current Learning rate AUTOENC : 0.03200000000000001
Epoch 76, 25% 	 Loss : 1.7450e-01 	 Res : 7.3473e-02 	 Jac : 1.7096e-02 	 Enc : 9.3978e-04 	 AEnc : 8.2993e-02 	 MSE : 8.8999e+00
Epoch 76, 50% 	 Loss : 1.3499e-01 	 Res : 6.5351e-02 	 Jac : 1.6917e-02 	 Enc : 1.3599e-03 	 AEnc : 5.1361e-02 	 MSE : 7.8575e+00
Epoch 76, 75% 	 Loss : 1.3509e-01 	 Res : 4.3895e-02 	 Jac : 1.6854e-02 	 Enc : 9.3854e-04 	 AEnc : 7.3398e-02 	 MSE : 4.8728e+00
Training Epoch 76 : 	 Train : 1.60773e-01 	 Res : 5.93192e-02 	 Jac : 1.68462e-02 	 Enc : 1.15449e-03 	 AE : 8.34535e-02 	 MSE : 6.77304e+00
Validation Epoch 76 : 	 Train : 2.40779e-01 	 Res : 5.89130e-02 	 Jac : 1.67456e-02 	 Enc : 1.47684e-03 	 AE : 1.63643e-01 	 MSE : 3.01632e+00
Training Epoch 76 finished, took current epoch 377.37s, cumulative time 28401.27s
Current Learning rate DEQ : 0.0064
Current Learning rate AUTOENC : 0.03200000000000001
Epoch 77, 25% 	 Loss : 2.5982e-01 	 Res : 1.0376e-01 	 Jac : 1.6881e-02 	 Enc : 2.2057e-03 	 AEnc : 1.3697e-01 	 MSE : 8.2235e+00
Epoch 77, 50% 	 Loss : 2.0870e-01 	 Res : 6.2602e-02 	 Jac : 1.6631e-02 	 Enc : 2.1230e-03 	 AEnc : 1.2734e-01 	 MSE : 5.6711e+00
Epoch 77, 75% 	 Loss : 7.3841e-02 	 Res : 3.5850e-02 	 Jac : 1.6106e-02 	 Enc : 8.0770e-04 	 AEnc : 2.1078e-02 	 MSE : 5.5813e+00
Training Epoch 77 : 	 Train : 1.62062e-01 	 Res : 6.18351e-02 	 Jac : 1.64493e-02 	 Enc : 1.48101e-03 	 AE : 8.22969e-02 	 MSE : 6.33859e+00
Validation Epoch 77 : 	 Train : 3.93560e-02 	 Res : 1.70730e-02 	 Jac : 1.64769e-02 	 Enc : 3.90544e-04 	 AE : 5.41551e-03 	 MSE : 1.79607e+00
Training Epoch 77 finished, took current epoch 384.24s, cumulative time 28785.47s
Current Learning rate DEQ : 0.0064
Current Learning rate AUTOENC : 0.03200000000000001
MODEL SAVED
Epoch 78, 25% 	 Loss : 6.8728e-02 	 Res : 3.7974e-02 	 Jac : 1.6042e-02 	 Enc : 6.1469e-04 	 AEnc : 1.4097e-02 	 MSE : 6.0702e+00
Epoch 78, 50% 	 Loss : 9.2903e-02 	 Res : 3.7038e-02 	 Jac : 1.6087e-02 	 Enc : 7.0572e-04 	 AEnc : 3.9072e-02 	 MSE : 4.7054e+00
Epoch 78, 75% 	 Loss : 2.9924e-01 	 Res : 1.3024e-01 	 Jac : 1.5845e-02 	 Enc : 1.5213e-03 	 AEnc : 1.5164e-01 	 MSE : 7.7071e+00
Training Epoch 78 : 	 Train : 4.40722e-01 	 Res : 3.20027e-01 	 Jac : 1.72371e-02 	 Enc : 2.03346e-03 	 AE : 1.01425e-01 	 MSE : 1.17937e+01
Validation Epoch 78 : 	 Train : 1.00002e+00 	 Res : 3.60804e-01 	 Jac : 1.49392e-02 	 Enc : 9.47087e-03 	 AE : 6.14803e-01 	 MSE : 3.47782e+01
Training Epoch 78 finished, took current epoch 375.09s, cumulative time 29160.53s
Current Learning rate DEQ : 0.0064
Current Learning rate AUTOENC : 0.03200000000000001
Epoch 79, 25% 	 Loss : 2.4572e-01 	 Res : 1.4240e-01 	 Jac : 1.9141e-02 	 Enc : 9.9150e-03 	 AEnc : 7.4269e-02 	 MSE : 1.3976e+01
Epoch 79, 50% 	 Loss : 2.4785e-01 	 Res : 1.9146e-01 	 Jac : 2.0300e-02 	 Enc : 2.2970e-03 	 AEnc : 3.3791e-02 	 MSE : 6.7598e+00
Epoch 79, 75% 	 Loss : 1.4378e-01 	 Res : 6.7918e-02 	 Jac : 2.0482e-02 	 Enc : 2.0094e-03 	 AEnc : 5.3369e-02 	 MSE : 8.8947e+00
Training Epoch 79 : 	 Train : 1.86460e-01 	 Res : 1.11671e-01 	 Jac : 1.97333e-02 	 Enc : 3.94207e-03 	 AE : 5.11134e-02 	 MSE : 8.82737e+00
Validation Epoch 79 : 	 Train : 7.86313e-02 	 Res : 2.52859e-02 	 Jac : 1.79846e-02 	 Enc : 7.93873e-04 	 AE : 3.45669e-02 	 MSE : 3.67329e+00
Training Epoch 79 finished, took current epoch 367.95s, cumulative time 29528.44s
Current Learning rate DEQ : 0.0064
Current Learning rate AUTOENC : 0.03200000000000001
Epoch 80, 25% 	 Loss : 3.4389e+00 	 Res : 3.2349e+00 	 Jac : 1.9379e-02 	 Enc : 1.2454e-02 	 AEnc : 1.7214e-01 	 MSE : 5.2542e+01
Epoch 80, 50% 	 Loss : 2.4074e-01 	 Res : 8.3926e-02 	 Jac : 2.2326e-02 	 Enc : 6.5339e-03 	 AEnc : 1.2795e-01 	 MSE : 7.0670e+00
Epoch 80, 75% 	 Loss : 2.2231e-01 	 Res : 6.7380e-02 	 Jac : 2.2965e-02 	 Enc : 2.1098e-03 	 AEnc : 1.2986e-01 	 MSE : 5.8776e+00
Training Epoch 80 : 	 Train : 1.02104e+00 	 Res : 8.81539e-01 	 Jac : 2.12056e-02 	 Enc : 5.57979e-03 	 AE : 1.12712e-01 	 MSE : 1.80993e+01
Validation Epoch 80 : 	 Train : 5.16250e-02 	 Res : 2.93628e-02 	 Jac : 1.87807e-02 	 Enc : 5.23843e-04 	 AE : 2.95765e-03 	 MSE : 7.18778e+00
Training Epoch 80 finished, took current epoch 363.56s, cumulative time 29891.97s
Current Learning rate DEQ : 0.0064
Current Learning rate AUTOENC : 0.03200000000000001
Epoch 81, 25% 	 Loss : 1.4866e-01 	 Res : 9.7225e-02 	 Jac : 1.9655e-02 	 Enc : 1.1769e-03 	 AEnc : 3.0606e-02 	 MSE : 8.9636e+00
Epoch 81, 50% 	 Loss : 1.3433e-01 	 Res : 7.4010e-02 	 Jac : 1.8364e-02 	 Enc : 1.3982e-03 	 AEnc : 4.0553e-02 	 MSE : 7.8569e+00
Epoch 81, 75% 	 Loss : 1.3478e-01 	 Res : 5.5916e-02 	 Jac : 1.7543e-02 	 Enc : 1.4687e-03 	 AEnc : 5.9852e-02 	 MSE : 7.3517e+00
Training Epoch 81 : 	 Train : 1.34069e-01 	 Res : 6.97438e-02 	 Jac : 1.84015e-02 	 Enc : 1.29362e-03 	 AE : 4.46300e-02 	 MSE : 7.66723e+00
Validation Epoch 81 : 	 Train : 5.39919e-02 	 Res : 2.83336e-02 	 Jac : 1.68058e-02 	 Enc : 8.29363e-04 	 AE : 8.02324e-03 	 MSE : 5.97371e+00
Training Epoch 81 finished, took current epoch 365.06s, cumulative time 30257.00s
Current Learning rate DEQ : 0.0064
Current Learning rate AUTOENC : 0.03200000000000001
Epoch 82, 25% 	 Loss : 1.6701e-01 	 Res : 1.0944e-01 	 Jac : 1.7199e-02 	 Enc : 1.0767e-03 	 AEnc : 3.9294e-02 	 MSE : 7.9921e+00
Epoch 82, 50% 	 Loss : 1.1270e-01 	 Res : 3.7016e-02 	 Jac : 1.5838e-02 	 Enc : 7.9465e-04 	 AEnc : 5.9051e-02 	 MSE : 4.3783e+00
Epoch 82, 75% 	 Loss : 2.2894e-01 	 Res : 1.6910e-01 	 Jac : 1.5599e-02 	 Enc : 7.6740e-04 	 AEnc : 4.3474e-02 	 MSE : 8.0155e+00
Training Epoch 82 : 	 Train : 1.80918e-01 	 Res : 1.07599e-01 	 Jac : 1.65999e-02 	 Enc : 1.23064e-03 	 AE : 5.54879e-02 	 MSE : 7.40994e+00
Validation Epoch 82 : 	 Train : 6.37621e-02 	 Res : 2.75414e-02 	 Jac : 1.69681e-02 	 Enc : 1.49133e-03 	 AE : 1.77613e-02 	 MSE : 3.74246e+00
Training Epoch 82 finished, took current epoch 376.01s, cumulative time 30633.00s
Current Learning rate DEQ : 0.0064
Current Learning rate AUTOENC : 0.03200000000000001
Epoch 83, 25% 	 Loss : 1.0455e-01 	 Res : 5.7211e-02 	 Jac : 1.6677e-02 	 Enc : 1.1913e-03 	 AEnc : 2.9466e-02 	 MSE : 5.8535e+00
Epoch 83, 50% 	 Loss : 2.3700e-01 	 Res : 6.9365e-02 	 Jac : 1.7757e-02 	 Enc : 1.4261e-03 	 AEnc : 1.4846e-01 	 MSE : 5.6832e+00
Epoch 83, 75% 	 Loss : 1.7501e-01 	 Res : 4.7448e-02 	 Jac : 1.6399e-02 	 Enc : 9.9969e-04 	 AEnc : 1.1016e-01 	 MSE : 4.6278e+00
Training Epoch 83 : 	 Train : 1.65493e-01 	 Res : 5.75759e-02 	 Jac : 1.67303e-02 	 Enc : 1.25861e-03 	 AE : 8.99286e-02 	 MSE : 5.60201e+00
Validation Epoch 83 : 	 Train : 1.19782e-01 	 Res : 4.92067e-02 	 Jac : 1.55123e-02 	 Enc : 1.10179e-03 	 AE : 5.39614e-02 	 MSE : 8.27625e+00
Training Epoch 83 finished, took current epoch 370.35s, cumulative time 31003.32s
Current Learning rate DEQ : 0.0064
Current Learning rate AUTOENC : 0.03200000000000001
Epoch 84, 25% 	 Loss : 9.4755e-02 	 Res : 4.0441e-02 	 Jac : 1.6237e-02 	 Enc : 8.3101e-04 	 AEnc : 3.7245e-02 	 MSE : 5.5715e+00
Epoch 84, 50% 	 Loss : 9.5468e-02 	 Res : 4.0311e-02 	 Jac : 1.6206e-02 	 Enc : 7.8804e-04 	 AEnc : 3.8164e-02 	 MSE : 4.9694e+00
Epoch 84, 75% 	 Loss : 1.2028e+00 	 Res : 1.1284e+00 	 Jac : 1.7509e-02 	 Enc : 3.8060e-03 	 AEnc : 5.3124e-02 	 MSE : 3.5098e+01
Training Epoch 84 : 	 Train : 4.14245e-01 	 Res : 3.23406e-01 	 Jac : 1.71018e-02 	 Enc : 2.56872e-03 	 AE : 7.11681e-02 	 MSE : 1.30346e+01
Validation Epoch 84 : 	 Train : 1.93772e-01 	 Res : 5.21698e-02 	 Jac : 1.69409e-02 	 Enc : 1.80223e-03 	 AE : 1.22859e-01 	 MSE : 5.16776e+00
Training Epoch 84 finished, took current epoch 378.66s, cumulative time 31381.95s
Current Learning rate DEQ : 0.0064
Current Learning rate AUTOENC : 0.03200000000000001
Epoch 85, 25% 	 Loss : 1.4763e-01 	 Res : 5.0246e-02 	 Jac : 1.6805e-02 	 Enc : 2.0943e-03 	 AEnc : 7.8483e-02 	 MSE : 5.7133e+00
Epoch 85, 50% 	 Loss : 8.3337e-02 	 Res : 3.8591e-02 	 Jac : 1.7202e-02 	 Enc : 1.2240e-03 	 AEnc : 2.6320e-02 	 MSE : 5.1350e+00
Epoch 85, 75% 	 Loss : 9.8511e-02 	 Res : 4.4761e-02 	 Jac : 1.6256e-02 	 Enc : 7.4328e-04 	 AEnc : 3.6751e-02 	 MSE : 6.3055e+00
Training Epoch 85 : 	 Train : 1.06259e-01 	 Res : 4.38524e-02 	 Jac : 1.67108e-02 	 Enc : 1.36534e-03 	 AE : 4.43302e-02 	 MSE : 5.75899e+00
Validation Epoch 85 : 	 Train : 8.02338e-02 	 Res : 3.72569e-02 	 Jac : 1.73553e-02 	 Enc : 1.16877e-03 	 AE : 2.44528e-02 	 MSE : 3.49024e+00
Training Epoch 85 finished, took current epoch 381.45s, cumulative time 31763.36s
Current Learning rate DEQ : 0.0064
Current Learning rate AUTOENC : 0.03200000000000001
Epoch 86, 25% 	 Loss : 7.5663e-02 	 Res : 3.4462e-02 	 Jac : 1.6220e-02 	 Enc : 6.1844e-04 	 AEnc : 2.4362e-02 	 MSE : 5.1797e+00
Epoch 86, 50% 	 Loss : 4.6746e-01 	 Res : 3.8026e-01 	 Jac : 1.6672e-02 	 Enc : 1.7170e-03 	 AEnc : 6.8807e-02 	 MSE : 1.3894e+01
Epoch 86, 75% 	 Loss : 2.1644e-01 	 Res : 7.8688e-02 	 Jac : 1.7312e-02 	 Enc : 2.6371e-03 	 AEnc : 1.1780e-01 	 MSE : 7.0942e+00
Training Epoch 86 : 	 Train : 2.34574e-01 	 Res : 1.41019e-01 	 Jac : 1.66626e-02 	 Enc : 1.84574e-03 	 AE : 7.50469e-02 	 MSE : 8.37225e+00
Validation Epoch 86 : 	 Train : 9.54900e-02 	 Res : 3.32930e-02 	 Jac : 1.69402e-02 	 Enc : 8.75777e-04 	 AE : 4.43809e-02 	 MSE : 5.25512e+00
Training Epoch 86 finished, took current epoch 369.65s, cumulative time 32132.98s
Current Learning rate DEQ : 0.0064
Current Learning rate AUTOENC : 0.03200000000000001
Epoch 87, 25% 	 Loss : 7.0923e-02 	 Res : 3.1079e-02 	 Jac : 1.6339e-02 	 Enc : 7.7223e-04 	 AEnc : 2.2733e-02 	 MSE : 5.1451e+00
Epoch 87, 50% 	 Loss : 7.5060e-02 	 Res : 3.8634e-02 	 Jac : 1.6080e-02 	 Enc : 5.4721e-04 	 AEnc : 1.9799e-02 	 MSE : 6.4890e+00
Epoch 87, 75% 	 Loss : 6.1775e-02 	 Res : 2.9494e-02 	 Jac : 1.6123e-02 	 Enc : 3.7006e-04 	 AEnc : 1.5788e-02 	 MSE : 5.2892e+00
Training Epoch 87 : 	 Train : 7.18711e-02 	 Res : 3.35665e-02 	 Jac : 1.61510e-02 	 Enc : 5.48885e-04 	 AE : 2.16047e-02 	 MSE : 5.61660e+00
Validation Epoch 87 : 	 Train : 4.47464e-02 	 Res : 2.00211e-02 	 Jac : 1.63902e-02 	 Enc : 3.85562e-04 	 AE : 7.94946e-03 	 MSE : 1.76692e+00
Training Epoch 87 finished, took current epoch 367.11s, cumulative time 32500.04s
Current Learning rate DEQ : 0.0064
Current Learning rate AUTOENC : 0.03200000000000001
Epoch 88, 25% 	 Loss : 2.2410e-01 	 Res : 1.7174e-01 	 Jac : 1.5893e-02 	 Enc : 1.0785e-03 	 AEnc : 3.5389e-02 	 MSE : 9.7584e+00
Epoch 88, 50% 	 Loss : 9.8933e-02 	 Res : 3.7816e-02 	 Jac : 1.5910e-02 	 Enc : 8.2312e-04 	 AEnc : 4.4384e-02 	 MSE : 5.0232e+00
Epoch 88, 75% 	 Loss : 8.8892e-02 	 Res : 3.9100e-02 	 Jac : 1.5572e-02 	 Enc : 7.4911e-04 	 AEnc : 3.3471e-02 	 MSE : 5.6396e+00
Training Epoch 88 : 	 Train : 1.36992e-01 	 Res : 7.76346e-02 	 Jac : 1.57879e-02 	 Enc : 9.36884e-04 	 AE : 4.26328e-02 	 MSE : 6.73247e+00
Validation Epoch 88 : 	 Train : 1.08314e-01 	 Res : 5.74181e-02 	 Jac : 1.47130e-02 	 Enc : 1.01086e-03 	 AE : 3.51721e-02 	 MSE : 8.82401e+00
Training Epoch 88 finished, took current epoch 377.97s, cumulative time 32877.99s
Current Learning rate DEQ : 0.00512
Current Learning rate AUTOENC : 0.025600000000000008
Epoch 89, 25% 	 Loss : 8.6258e-02 	 Res : 4.2195e-02 	 Jac : 1.5979e-02 	 Enc : 1.1145e-03 	 AEnc : 2.6970e-02 	 MSE : 6.5209e+00
Epoch 89, 50% 	 Loss : 7.5887e-02 	 Res : 4.3232e-02 	 Jac : 1.6000e-02 	 Enc : 8.9123e-04 	 AEnc : 1.5764e-02 	 MSE : 7.4356e+00
Epoch 89, 75% 	 Loss : 7.8883e-02 	 Res : 2.8286e-02 	 Jac : 1.5454e-02 	 Enc : 5.7109e-04 	 AEnc : 3.4572e-02 	 MSE : 3.7116e+00
Training Epoch 89 : 	 Train : 8.18572e-02 	 Res : 3.69287e-02 	 Jac : 1.56295e-02 	 Enc : 7.97990e-04 	 AE : 2.85010e-02 	 MSE : 5.74513e+00
Validation Epoch 89 : 	 Train : 8.16806e-02 	 Res : 6.19128e-02 	 Jac : 1.56276e-02 	 Enc : 3.27340e-04 	 AE : 3.81281e-03 	 MSE : 4.42956e+00
Training Epoch 89 finished, took current epoch 381.55s, cumulative time 33259.52s
Current Learning rate DEQ : 0.00512
Current Learning rate AUTOENC : 0.025600000000000008
Epoch 90, 25% 	 Loss : 1.1780e-01 	 Res : 5.4364e-02 	 Jac : 1.5309e-02 	 Enc : 9.4058e-04 	 AEnc : 4.7185e-02 	 MSE : 5.8014e+00
Epoch 90, 50% 	 Loss : 8.3885e-02 	 Res : 3.8938e-02 	 Jac : 1.5310e-02 	 Enc : 6.4992e-04 	 AEnc : 2.8987e-02 	 MSE : 5.1184e+00
Epoch 90, 75% 	 Loss : 8.3124e-02 	 Res : 4.7889e-02 	 Jac : 1.5455e-02 	 Enc : 6.0329e-04 	 AEnc : 1.9176e-02 	 MSE : 5.8266e+00
Training Epoch 90 : 	 Train : 9.38303e-02 	 Res : 4.72620e-02 	 Jac : 1.53684e-02 	 Enc : 7.23074e-04 	 AE : 3.04768e-02 	 MSE : 5.88668e+00
Validation Epoch 90 : 	 Train : 8.82108e-02 	 Res : 6.35403e-02 	 Jac : 1.48921e-02 	 Enc : 9.33798e-04 	 AE : 8.84463e-03 	 MSE : 1.22363e+01
Training Epoch 90 finished, took current epoch 377.18s, cumulative time 33636.67s
Current Learning rate DEQ : 0.00512
Current Learning rate AUTOENC : 0.025600000000000008
Epoch 91, 25% 	 Loss : 7.9269e-02 	 Res : 4.3009e-02 	 Jac : 1.5775e-02 	 Enc : 1.2345e-03 	 AEnc : 1.9250e-02 	 MSE : 6.5557e+00
Epoch 91, 50% 	 Loss : 3.6893e-01 	 Res : 3.4210e-01 	 Jac : 1.5703e-02 	 Enc : 9.0016e-04 	 AEnc : 1.0225e-02 	 MSE : 1.4277e+01
Epoch 91, 75% 	 Loss : 1.2825e-01 	 Res : 8.7635e-02 	 Jac : 1.7083e-02 	 Enc : 2.9003e-03 	 AEnc : 2.0636e-02 	 MSE : 1.1051e+01
Training Epoch 91 : 	 Train : 1.64831e-01 	 Res : 1.26821e-01 	 Jac : 1.62151e-02 	 Enc : 1.49772e-03 	 AE : 2.02977e-02 	 MSE : 9.38987e+00
Validation Epoch 91 : 	 Train : 9.54127e-02 	 Res : 3.78253e-02 	 Jac : 1.67873e-02 	 Enc : 7.91871e-04 	 AE : 4.00082e-02 	 MSE : 4.43246e+00
Training Epoch 91 finished, took current epoch 371.95s, cumulative time 34008.60s
Current Learning rate DEQ : 0.00512
Current Learning rate AUTOENC : 0.025600000000000008
Epoch 92, 25% 	 Loss : 9.1874e-02 	 Res : 4.7003e-02 	 Jac : 1.5895e-02 	 Enc : 7.4381e-04 	 AEnc : 2.8233e-02 	 MSE : 5.6652e+00
Epoch 92, 50% 	 Loss : 7.5027e-02 	 Res : 3.2485e-02 	 Jac : 1.5382e-02 	 Enc : 5.3558e-04 	 AEnc : 2.6624e-02 	 MSE : 4.8519e+00
Epoch 92, 75% 	 Loss : 4.6224e-02 	 Res : 2.3933e-02 	 Jac : 1.5140e-02 	 Enc : 3.0578e-04 	 AEnc : 6.8452e-03 	 MSE : 4.7035e+00
Training Epoch 92 : 	 Train : 6.94134e-02 	 Res : 3.49010e-02 	 Jac : 1.53951e-02 	 Enc : 5.00472e-04 	 AE : 1.86168e-02 	 MSE : 5.35996e+00
Validation Epoch 92 : 	 Train : 6.23535e-02 	 Res : 3.72328e-02 	 Jac : 1.44806e-02 	 Enc : 4.10765e-04 	 AE : 1.02293e-02 	 MSE : 8.90777e+00
Training Epoch 92 finished, took current epoch 368.38s, cumulative time 34376.94s
Current Learning rate DEQ : 0.00512
Current Learning rate AUTOENC : 0.025600000000000008
Epoch 93, 25% 	 Loss : 1.0027e-01 	 Res : 5.7847e-02 	 Jac : 1.5250e-02 	 Enc : 6.5112e-04 	 AEnc : 2.6524e-02 	 MSE : 8.8107e+00
Epoch 93, 50% 	 Loss : 9.0540e-02 	 Res : 3.5640e-02 	 Jac : 1.5332e-02 	 Enc : 7.8575e-04 	 AEnc : 3.8782e-02 	 MSE : 5.1637e+00
Epoch 93, 75% 	 Loss : 3.0177e+00 	 Res : 2.8956e+00 	 Jac : 1.7675e-02 	 Enc : 1.2291e-02 	 AEnc : 9.2135e-02 	 MSE : 6.1046e+01
Training Epoch 93 : 	 Train : 8.27449e-01 	 Res : 7.59940e-01 	 Jac : 1.63023e-02 	 Enc : 4.82106e-03 	 AE : 4.63856e-02 	 MSE : 2.06991e+01
Validation Epoch 93 : 	 Train : 8.42399e-02 	 Res : 3.98685e-02 	 Jac : 1.76318e-02 	 Enc : 1.35954e-03 	 AE : 2.53800e-02 	 MSE : 6.57889e+00
Training Epoch 93 finished, took current epoch 371.55s, cumulative time 34748.44s
Current Learning rate DEQ : 0.00512
Current Learning rate AUTOENC : 0.025600000000000008
Epoch 94, 25% 	 Loss : 2.2219e-01 	 Res : 1.7485e-01 	 Jac : 1.9051e-02 	 Enc : 5.5647e-03 	 AEnc : 2.2718e-02 	 MSE : 1.4720e+01
Epoch 94, 50% 	 Loss : 1.0638e-01 	 Res : 5.4061e-02 	 Jac : 1.9657e-02 	 Enc : 4.1579e-03 	 AEnc : 2.8503e-02 	 MSE : 8.4903e+00
Epoch 94, 75% 	 Loss : 1.2321e-01 	 Res : 4.0991e-02 	 Jac : 1.7339e-02 	 Enc : 9.1036e-04 	 AEnc : 6.3971e-02 	 MSE : 4.2686e+00
Training Epoch 94 : 	 Train : 1.32212e-01 	 Res : 7.66423e-02 	 Jac : 1.80481e-02 	 Enc : 2.79337e-03 	 AE : 3.47286e-02 	 MSE : 8.24149e+00
Validation Epoch 94 : 	 Train : 8.08588e-02 	 Res : 2.56663e-02 	 Jac : 1.55964e-02 	 Enc : 3.78437e-04 	 AE : 3.92177e-02 	 MSE : 4.33007e+00
Training Epoch 94 finished, took current epoch 368.04s, cumulative time 35116.45s
Current Learning rate DEQ : 0.00512
Current Learning rate AUTOENC : 0.025600000000000008
Epoch 95, 25% 	 Loss : 7.8924e-02 	 Res : 3.4718e-02 	 Jac : 1.6128e-02 	 Enc : 4.4385e-04 	 AEnc : 2.7634e-02 	 MSE : 5.2415e+00
Epoch 95, 50% 	 Loss : 1.1008e-01 	 Res : 5.1182e-02 	 Jac : 1.5499e-02 	 Enc : 6.9488e-04 	 AEnc : 4.2708e-02 	 MSE : 7.3488e+00
Epoch 95, 75% 	 Loss : 1.1975e-01 	 Res : 4.7153e-02 	 Jac : 1.5911e-02 	 Enc : 1.0645e-03 	 AEnc : 5.5621e-02 	 MSE : 6.0387e+00
Training Epoch 95 : 	 Train : 1.02488e-01 	 Res : 4.71975e-02 	 Jac : 1.58337e-02 	 Enc : 7.79443e-04 	 AE : 3.86771e-02 	 MSE : 6.74641e+00
Validation Epoch 95 : 	 Train : 5.40423e-02 	 Res : 3.08532e-02 	 Jac : 1.65099e-02 	 Enc : 9.09994e-04 	 AE : 5.76928e-03 	 MSE : 4.35764e+00
Training Epoch 95 finished, took current epoch 379.21s, cumulative time 35495.63s
Current Learning rate DEQ : 0.00512
Current Learning rate AUTOENC : 0.025600000000000008
Epoch 96, 25% 	 Loss : 6.0540e-02 	 Res : 2.8373e-02 	 Jac : 1.5802e-02 	 Enc : 4.8255e-04 	 AEnc : 1.5882e-02 	 MSE : 4.9177e+00
Epoch 96, 50% 	 Loss : 1.4935e-01 	 Res : 4.6750e-02 	 Jac : 1.5423e-02 	 Enc : 6.4087e-04 	 AEnc : 8.6539e-02 	 MSE : 6.3598e+00
Epoch 96, 75% 	 Loss : 1.2960e-01 	 Res : 4.1581e-02 	 Jac : 1.5593e-02 	 Enc : 6.0906e-04 	 AEnc : 7.1817e-02 	 MSE : 5.0158e+00
Training Epoch 96 : 	 Train : 1.01384e-01 	 Res : 3.67325e-02 	 Jac : 1.55658e-02 	 Enc : 5.69413e-04 	 AE : 4.85165e-02 	 MSE : 5.32775e+00
Validation Epoch 96 : 	 Train : 6.41208e-02 	 Res : 3.11382e-02 	 Jac : 1.57360e-02 	 Enc : 4.34872e-04 	 AE : 1.68117e-02 	 MSE : 4.70963e+00
Training Epoch 96 finished, took current epoch 373.70s, cumulative time 35869.30s
Current Learning rate DEQ : 0.00512
Current Learning rate AUTOENC : 0.025600000000000008
Epoch 97, 25% 	 Loss : 6.5359e-02 	 Res : 4.0997e-02 	 Jac : 1.5261e-02 	 Enc : 4.4042e-04 	 AEnc : 8.6613e-03 	 MSE : 6.0145e+00
Epoch 97, 50% 	 Loss : 6.2960e-02 	 Res : 2.9853e-02 	 Jac : 1.5367e-02 	 Enc : 4.2938e-04 	 AEnc : 1.7311e-02 	 MSE : 4.8067e+00
Epoch 97, 75% 	 Loss : 1.5086e-01 	 Res : 6.2603e-02 	 Jac : 1.5271e-02 	 Enc : 7.1811e-04 	 AEnc : 7.2271e-02 	 MSE : 6.5125e+00
Training Epoch 97 : 	 Train : 1.20924e-01 	 Res : 5.07158e-02 	 Jac : 1.52894e-02 	 Enc : 7.89833e-04 	 AE : 5.41294e-02 	 MSE : 6.00936e+00
Validation Epoch 97 : 	 Train : 1.18387e-01 	 Res : 4.50953e-02 	 Jac : 1.61377e-02 	 Enc : 8.65737e-04 	 AE : 5.62885e-02 	 MSE : 4.58841e+00
Training Epoch 97 finished, took current epoch 379.18s, cumulative time 36248.45s
Current Learning rate DEQ : 0.00512
Current Learning rate AUTOENC : 0.025600000000000008
Epoch 98, 25% 	 Loss : 7.7608e-02 	 Res : 2.9425e-02 	 Jac : 1.5502e-02 	 Enc : 5.1455e-04 	 AEnc : 3.2166e-02 	 MSE : 4.4439e+00
Epoch 98, 50% 	 Loss : 1.7943e-01 	 Res : 6.4059e-02 	 Jac : 1.5191e-02 	 Enc : 9.4675e-04 	 AEnc : 9.9231e-02 	 MSE : 7.7773e+00
Epoch 98, 75% 	 Loss : 1.2093e-01 	 Res : 3.7585e-02 	 Jac : 1.5503e-02 	 Enc : 1.0823e-03 	 AEnc : 6.6761e-02 	 MSE : 4.4342e+00
Training Epoch 98 : 	 Train : 1.18287e-01 	 Res : 4.19078e-02 	 Jac : 1.53580e-02 	 Enc : 8.81576e-04 	 AE : 6.01394e-02 	 MSE : 5.22920e+00
Validation Epoch 98 : 	 Train : 6.36737e-02 	 Res : 2.44895e-02 	 Jac : 1.51812e-02 	 Enc : 5.16783e-04 	 AE : 2.34863e-02 	 MSE : 3.67805e+00
Training Epoch 98 finished, took current epoch 370.84s, cumulative time 36619.24s
Current Learning rate DEQ : 0.00512
Current Learning rate AUTOENC : 0.025600000000000008
Epoch 99, 25% 	 Loss : 1.9068e-01 	 Res : 4.8412e-02 	 Jac : 1.5087e-02 	 Enc : 1.5169e-03 	 AEnc : 1.2566e-01 	 MSE : 4.0995e+00
Epoch 99, 50% 	 Loss : 1.0132e-01 	 Res : 3.1629e-02 	 Jac : 1.4933e-02 	 Enc : 1.2671e-03 	 AEnc : 5.3487e-02 	 MSE : 3.3161e+00
Epoch 99, 75% 	 Loss : 1.3495e-01 	 Res : 6.0681e-02 	 Jac : 1.4734e-02 	 Enc : 1.3632e-03 	 AEnc : 5.8174e-02 	 MSE : 6.5366e+00
Training Epoch 99 : 	 Train : 1.57903e-01 	 Res : 7.26129e-02 	 Jac : 1.49996e-02 	 Enc : 1.33689e-03 	 AE : 6.89538e-02 	 MSE : 5.22292e+00
Validation Epoch 99 : 	 Train : 1.31319e-01 	 Res : 9.25088e-02 	 Jac : 1.55909e-02 	 Enc : 2.01772e-03 	 AE : 2.12016e-02 	 MSE : 7.11437e+00
Training Epoch 99 finished, took current epoch 385.62s, cumulative time 37004.83s
Current Learning rate DEQ : 0.004096000000000001
Current Learning rate AUTOENC : 0.02048000000000001
Epoch 100, 25% 	 Loss : 9.7620e-02 	 Res : 7.7849e-02 	 Jac : 1.5005e-02 	 Enc : 1.2737e-03 	 AEnc : 3.4921e-03 	 MSE : 8.1293e+00
Epoch 100, 50% 	 Loss : 2.5520e-01 	 Res : 2.2300e-01 	 Jac : 1.5423e-02 	 Enc : 1.8967e-03 	 AEnc : 1.4879e-02 	 MSE : 1.0991e+01
Epoch 100, 75% 	 Loss : 7.8022e-02 	 Res : 3.3512e-02 	 Jac : 1.5811e-02 	 Enc : 8.2933e-04 	 AEnc : 2.7870e-02 	 MSE : 5.1410e+00
Training Epoch 100 : 	 Train : 1.28310e-01 	 Res : 9.33131e-02 	 Jac : 1.53884e-02 	 Enc : 1.12541e-03 	 AE : 1.84833e-02 	 MSE : 7.79575e+00
Validation Epoch 100 : 	 Train : 6.02461e-02 	 Res : 4.43635e-02 	 Jac : 1.42686e-02 	 Enc : 2.61664e-04 	 AE : 1.35239e-03 	 MSE : 1.02027e+01
Training Epoch 100 finished, took current epoch 362.65s, cumulative time 37367.44s
Current Learning rate DEQ : 0.004096000000000001
Current Learning rate AUTOENC : 0.02048000000000001
Epoch 101, 25% 	 Loss : 7.6748e-02 	 Res : 5.2638e-02 	 Jac : 1.5875e-02 	 Enc : 9.4898e-04 	 AEnc : 7.2864e-03 	 MSE : 6.6977e+00
Epoch 101, 50% 	 Loss : 7.9860e-02 	 Res : 2.9776e-02 	 Jac : 1.5654e-02 	 Enc : 5.1355e-04 	 AEnc : 3.3916e-02 	 MSE : 3.9308e+00
Epoch 101, 75% 	 Loss : 1.1604e-01 	 Res : 4.1628e-02 	 Jac : 1.5237e-02 	 Enc : 6.7592e-04 	 AEnc : 5.8497e-02 	 MSE : 5.8419e+00
Training Epoch 101 : 	 Train : 8.06443e-02 	 Res : 3.70428e-02 	 Jac : 1.54813e-02 	 Enc : 6.82384e-04 	 AE : 2.74378e-02 	 MSE : 5.08639e+00
Validation Epoch 101 : 	 Train : 6.36548e-02 	 Res : 4.16628e-02 	 Jac : 1.61136e-02 	 Enc : 1.01839e-03 	 AE : 4.85999e-03 	 MSE : 3.65253e+00
Training Epoch 101 finished, took current epoch 384.94s, cumulative time 37752.35s
Current Learning rate DEQ : 0.004096000000000001
Current Learning rate AUTOENC : 0.02048000000000001
Epoch 102, 25% 	 Loss : 5.9251e-02 	 Res : 3.5955e-02 	 Jac : 1.4977e-02 	 Enc : 4.4254e-04 	 AEnc : 7.8768e-03 	 MSE : 6.2401e+00
Epoch 102, 50% 	 Loss : 1.0135e-01 	 Res : 5.7813e-02 	 Jac : 1.4840e-02 	 Enc : 8.4507e-04 	 AEnc : 2.7848e-02 	 MSE : 8.3023e+00
Epoch 102, 75% 	 Loss : 6.0350e-02 	 Res : 3.2745e-02 	 Jac : 1.4706e-02 	 Enc : 4.9711e-04 	 AEnc : 1.2402e-02 	 MSE : 5.1685e+00
Training Epoch 102 : 	 Train : 6.63410e-02 	 Res : 3.82103e-02 	 Jac : 1.48252e-02 	 Enc : 5.36375e-04 	 AE : 1.27691e-02 	 MSE : 6.04711e+00
Validation Epoch 102 : 	 Train : 5.83078e-02 	 Res : 4.09099e-02 	 Jac : 1.46578e-02 	 Enc : 1.97488e-04 	 AE : 2.54257e-03 	 MSE : 9.73200e+00
Training Epoch 102 finished, took current epoch 371.01s, cumulative time 38123.31s
Current Learning rate DEQ : 0.004096000000000001
Current Learning rate AUTOENC : 0.02048000000000001
Epoch 103, 25% 	 Loss : 5.4263e-02 	 Res : 3.6750e-02 	 Jac : 1.4724e-02 	 Enc : 3.9138e-04 	 AEnc : 2.3973e-03 	 MSE : 8.1029e+00
Epoch 103, 50% 	 Loss : 9.2776e-02 	 Res : 7.3182e-02 	 Jac : 1.4945e-02 	 Enc : 7.0051e-04 	 AEnc : 3.9481e-03 	 MSE : 1.3856e+01
Epoch 103, 75% 	 Loss : 8.7805e-02 	 Res : 4.9873e-02 	 Jac : 1.5256e-02 	 Enc : 6.3063e-04 	 AEnc : 2.2046e-02 	 MSE : 8.5094e+00
Training Epoch 103 : 	 Train : 7.60066e-02 	 Res : 4.79160e-02 	 Jac : 1.49685e-02 	 Enc : 5.82647e-04 	 AE : 1.25394e-02 	 MSE : 8.81361e+00
Validation Epoch 103 : 	 Train : 5.51763e-02 	 Res : 2.26422e-02 	 Jac : 1.51558e-02 	 Enc : 4.64505e-04 	 AE : 1.69138e-02 	 MSE : 2.12636e+00
Training Epoch 103 finished, took current epoch 375.74s, cumulative time 38499.02s
Current Learning rate DEQ : 0.004096000000000001
Current Learning rate AUTOENC : 0.02048000000000001
Epoch 104, 25% 	 Loss : 4.9954e-02 	 Res : 2.5076e-02 	 Jac : 1.4682e-02 	 Enc : 4.2858e-04 	 AEnc : 9.7679e-03 	 MSE : 3.9165e+00
Epoch 104, 50% 	 Loss : 1.0064e-01 	 Res : 3.2184e-02 	 Jac : 1.4446e-02 	 Enc : 5.4542e-04 	 AEnc : 5.3470e-02 	 MSE : 4.1982e+00
Epoch 104, 75% 	 Loss : 7.5994e-02 	 Res : 4.3502e-02 	 Jac : 1.4543e-02 	 Enc : 4.3585e-04 	 AEnc : 1.7514e-02 	 MSE : 8.2931e+00
Training Epoch 104 : 	 Train : 7.32747e-02 	 Res : 3.27033e-02 	 Jac : 1.46458e-02 	 Enc : 4.60006e-04 	 AE : 2.54656e-02 	 MSE : 5.18571e+00
Validation Epoch 104 : 	 Train : 5.19285e-02 	 Res : 1.92107e-02 	 Jac : 1.47975e-02 	 Enc : 2.65139e-04 	 AE : 1.76551e-02 	 MSE : 2.94787e+00
Training Epoch 104 finished, took current epoch 371.75s, cumulative time 38870.74s
Current Learning rate DEQ : 0.004096000000000001
Current Learning rate AUTOENC : 0.02048000000000001
Epoch 105, 25% 	 Loss : 4.0063e-02 	 Res : 2.1644e-02 	 Jac : 1.4746e-02 	 Enc : 2.5742e-04 	 AEnc : 3.4162e-03 	 MSE : 4.1036e+00
Epoch 105, 50% 	 Loss : 1.3183e+00 	 Res : 1.2834e+00 	 Jac : 1.5549e-02 	 Enc : 1.1565e-03 	 AEnc : 1.8171e-02 	 MSE : 5.9652e+01
Epoch 105, 75% 	 Loss : 3.7502e-01 	 Res : 1.3060e-01 	 Jac : 1.6282e-02 	 Enc : 1.0831e-02 	 AEnc : 2.1730e-01 	 MSE : 1.1241e+01
Training Epoch 105 : 	 Train : 4.70292e-01 	 Res : 3.69753e-01 	 Jac : 1.54983e-02 	 Enc : 3.45123e-03 	 AE : 8.15895e-02 	 MSE : 1.96727e+01
Validation Epoch 105 : 	 Train : 9.59059e-02 	 Res : 2.54937e-02 	 Jac : 1.53348e-02 	 Enc : 8.87505e-04 	 AE : 5.41900e-02 	 MSE : 1.69055e+00
Training Epoch 105 finished, took current epoch 375.92s, cumulative time 39246.63s
Current Learning rate DEQ : 0.004096000000000001
Current Learning rate AUTOENC : 0.02048000000000001
Epoch 106, 25% 	 Loss : 1.3009e-01 	 Res : 3.8800e-02 	 Jac : 1.5310e-02 	 Enc : 1.0588e-03 	 AEnc : 7.4921e-02 	 MSE : 4.1962e+00
Epoch 106, 50% 	 Loss : 1.0225e-01 	 Res : 3.3729e-02 	 Jac : 1.5670e-02 	 Enc : 7.8822e-04 	 AEnc : 5.2063e-02 	 MSE : 4.0824e+00
Epoch 106, 75% 	 Loss : 1.0519e-01 	 Res : 4.6616e-02 	 Jac : 1.5515e-02 	 Enc : 6.3120e-04 	 AEnc : 4.2428e-02 	 MSE : 4.6046e+00
Training Epoch 106 : 	 Train : 1.09276e-01 	 Res : 3.84487e-02 	 Jac : 1.55038e-02 	 Enc : 8.31002e-04 	 AE : 5.44930e-02 	 MSE : 4.40142e+00
Validation Epoch 106 : 	 Train : 1.13395e-01 	 Res : 3.52479e-02 	 Jac : 1.55360e-02 	 Enc : 4.89364e-04 	 AE : 6.21218e-02 	 MSE : 5.34018e+00
Training Epoch 106 finished, took current epoch 368.09s, cumulative time 39614.68s
Current Learning rate DEQ : 0.004096000000000001
Current Learning rate AUTOENC : 0.02048000000000001
Epoch 107, 25% 	 Loss : 8.0118e-02 	 Res : 2.9646e-02 	 Jac : 1.5251e-02 	 Enc : 4.7746e-04 	 AEnc : 3.4744e-02 	 MSE : 3.9568e+00
Epoch 107, 50% 	 Loss : 7.7689e-02 	 Res : 3.5417e-02 	 Jac : 1.4738e-02 	 Enc : 8.3821e-04 	 AEnc : 2.6696e-02 	 MSE : 4.8400e+00
Epoch 107, 75% 	 Loss : 6.9675e-02 	 Res : 3.7742e-02 	 Jac : 1.4590e-02 	 Enc : 4.2169e-04 	 AEnc : 1.6922e-02 	 MSE : 5.7975e+00
Training Epoch 107 : 	 Train : 9.43266e-02 	 Res : 5.38541e-02 	 Jac : 1.48672e-02 	 Enc : 1.08714e-03 	 AE : 2.45182e-02 	 MSE : 7.14485e+00
Validation Epoch 107 : 	 Train : 6.53839e-02 	 Res : 4.11818e-02 	 Jac : 1.42835e-02 	 Enc : 1.49361e-03 	 AE : 8.42491e-03 	 MSE : 7.35857e+00
Training Epoch 107 finished, took current epoch 378.26s, cumulative time 39992.91s
Current Learning rate DEQ : 0.004096000000000001
Current Learning rate AUTOENC : 0.02048000000000001
Epoch 108, 25% 	 Loss : 7.5602e-02 	 Res : 3.0303e-02 	 Jac : 1.4893e-02 	 Enc : 1.1105e-03 	 AEnc : 2.9296e-02 	 MSE : 4.1019e+00
Epoch 108, 50% 	 Loss : 7.6362e-02 	 Res : 3.0148e-02 	 Jac : 1.4818e-02 	 Enc : 9.1263e-04 	 AEnc : 3.0483e-02 	 MSE : 4.6538e+00
Epoch 108, 75% 	 Loss : 5.9424e-02 	 Res : 2.4793e-02 	 Jac : 1.4654e-02 	 Enc : 3.8957e-04 	 AEnc : 1.9588e-02 	 MSE : 4.1728e+00
Training Epoch 108 : 	 Train : 7.66591e-02 	 Res : 2.85261e-02 	 Jac : 1.47039e-02 	 Enc : 7.19996e-04 	 AE : 3.27091e-02 	 MSE : 4.20701e+00
Validation Epoch 108 : 	 Train : 4.02543e-02 	 Res : 1.57457e-02 	 Jac : 1.43596e-02 	 Enc : 3.21851e-04 	 AE : 9.82712e-03 	 MSE : 2.92902e+00
Training Epoch 108 finished, took current epoch 368.28s, cumulative time 40361.12s
Current Learning rate DEQ : 0.004096000000000001
Current Learning rate AUTOENC : 0.02048000000000001
MODEL SAVED
Epoch 109, 25% 	 Loss : 9.6673e-02 	 Res : 2.8168e-02 	 Jac : 1.4459e-02 	 Enc : 4.8796e-04 	 AEnc : 5.3558e-02 	 MSE : 3.5082e+00
Epoch 109, 50% 	 Loss : 6.7828e-02 	 Res : 2.4579e-02 	 Jac : 1.4611e-02 	 Enc : 5.1127e-04 	 AEnc : 2.8127e-02 	 MSE : 3.5808e+00
Epoch 109, 75% 	 Loss : 4.1651e-02 	 Res : 2.4632e-02 	 Jac : 1.4456e-02 	 Enc : 3.0412e-04 	 AEnc : 2.2592e-03 	 MSE : 5.0981e+00
Training Epoch 109 : 	 Train : 7.94612e-02 	 Res : 3.37220e-02 	 Jac : 1.45130e-02 	 Enc : 5.30819e-04 	 AE : 3.06953e-02 	 MSE : 5.52961e+00
Validation Epoch 109 : 	 Train : 5.72414e-01 	 Res : 1.52335e-01 	 Jac : 1.49373e-02 	 Enc : 2.31431e-03 	 AE : 4.02828e-01 	 MSE : 8.86050e+00
Training Epoch 109 finished, took current epoch 382.67s, cumulative time 40743.77s
Current Learning rate DEQ : 0.004096000000000001
Current Learning rate AUTOENC : 0.02048000000000001
Epoch 110, 25% 	 Loss : 1.4650e-01 	 Res : 4.3959e-02 	 Jac : 1.4830e-02 	 Enc : 9.9769e-04 	 AEnc : 8.6711e-02 	 MSE : 4.9419e+00
Epoch 110, 50% 	 Loss : 8.4512e-02 	 Res : 3.7024e-02 	 Jac : 1.4705e-02 	 Enc : 6.4672e-04 	 AEnc : 3.2136e-02 	 MSE : 4.2819e+00
Epoch 110, 75% 	 Loss : 6.1864e-02 	 Res : 3.5789e-02 	 Jac : 1.4525e-02 	 Enc : 1.0001e-03 	 AEnc : 1.0550e-02 	 MSE : 4.9137e+00
Training Epoch 110 : 	 Train : 9.58786e-02 	 Res : 3.80673e-02 	 Jac : 1.46306e-02 	 Enc : 9.03237e-04 	 AE : 4.22774e-02 	 MSE : 4.82385e+00
Validation Epoch 110 : 	 Train : 1.68625e-01 	 Res : 4.17507e-02 	 Jac : 1.46190e-02 	 Enc : 7.58225e-04 	 AE : 1.11497e-01 	 MSE : 2.60824e+00
Training Epoch 110 finished, took current epoch 386.49s, cumulative time 41130.21s
Current Learning rate DEQ : 0.0032768000000000007
Current Learning rate AUTOENC : 0.016384000000000006
Epoch 111, 25% 	 Loss : 5.8510e-02 	 Res : 2.2173e-02 	 Jac : 1.4659e-02 	 Enc : 4.5165e-04 	 AEnc : 2.1226e-02 	 MSE : 3.3513e+00
Epoch 111, 50% 	 Loss : 4.0347e-02 	 Res : 1.7638e-02 	 Jac : 1.4286e-02 	 Enc : 2.6334e-04 	 AEnc : 8.1597e-03 	 MSE : 2.7198e+00
Epoch 111, 75% 	 Loss : 1.1127e-01 	 Res : 8.6024e-02 	 Jac : 1.4429e-02 	 Enc : 7.1249e-04 	 AEnc : 1.0108e-02 	 MSE : 8.9367e+00
Training Epoch 111 : 	 Train : 8.35965e-02 	 Res : 4.35377e-02 	 Jac : 1.44910e-02 	 Enc : 6.22519e-04 	 AE : 2.49453e-02 	 MSE : 5.22388e+00
Validation Epoch 111 : 	 Train : 7.21110e-02 	 Res : 2.13354e-02 	 Jac : 1.44483e-02 	 Enc : 4.52293e-04 	 AE : 3.58749e-02 	 MSE : 3.12978e+00
Training Epoch 111 finished, took current epoch 375.88s, cumulative time 41506.07s
Current Learning rate DEQ : 0.0032768000000000007
Current Learning rate AUTOENC : 0.016384000000000006
Epoch 112, 25% 	 Loss : 4.8425e-02 	 Res : 1.5473e-02 	 Jac : 1.4361e-02 	 Enc : 2.7453e-04 	 AEnc : 1.8317e-02 	 MSE : 1.8766e+00
Epoch 112, 50% 	 Loss : 5.7769e-02 	 Res : 1.8371e-02 	 Jac : 1.4333e-02 	 Enc : 2.7052e-04 	 AEnc : 2.4794e-02 	 MSE : 2.2530e+00
Epoch 112, 75% 	 Loss : 6.9294e-02 	 Res : 4.4077e-02 	 Jac : 1.4209e-02 	 Enc : 6.5464e-04 	 AEnc : 1.0353e-02 	 MSE : 7.0607e+00
Training Epoch 112 : 	 Train : 5.93285e-02 	 Res : 2.83403e-02 	 Jac : 1.42296e-02 	 Enc : 6.08531e-04 	 AE : 1.61501e-02 	 MSE : 4.60693e+00
Validation Epoch 112 : 	 Train : 3.39012e-02 	 Res : 1.50606e-02 	 Jac : 1.39653e-02 	 Enc : 5.70686e-04 	 AE : 4.30460e-03 	 MSE : 3.56324e+00
Training Epoch 112 finished, took current epoch 382.80s, cumulative time 41888.82s
Current Learning rate DEQ : 0.0032768000000000007
Current Learning rate AUTOENC : 0.016384000000000006
MODEL SAVED
Epoch 113, 25% 	 Loss : 4.5315e-02 	 Res : 2.9165e-02 	 Jac : 1.4088e-02 	 Enc : 4.1646e-04 	 AEnc : 1.6450e-03 	 MSE : 6.6610e+00
Epoch 113, 50% 	 Loss : 6.2516e-02 	 Res : 2.5625e-02 	 Jac : 1.4228e-02 	 Enc : 4.4838e-04 	 AEnc : 2.2214e-02 	 MSE : 3.5744e+00
Epoch 113, 75% 	 Loss : 5.8296e-02 	 Res : 1.9281e-02 	 Jac : 1.4111e-02 	 Enc : 3.2682e-04 	 AEnc : 2.4578e-02 	 MSE : 2.6637e+00
Training Epoch 113 : 	 Train : 6.19572e-02 	 Res : 2.50771e-02 	 Jac : 1.40759e-02 	 Enc : 4.09856e-04 	 AE : 2.23945e-02 	 MSE : 4.12429e+00
Validation Epoch 113 : 	 Train : 6.51204e-02 	 Res : 4.01499e-02 	 Jac : 1.42202e-02 	 Enc : 3.08944e-04 	 AE : 1.04413e-02 	 MSE : 7.04266e+00
Training Epoch 113 finished, took current epoch 385.95s, cumulative time 42274.74s
Current Learning rate DEQ : 0.0032768000000000007
Current Learning rate AUTOENC : 0.016384000000000006
Epoch 114, 25% 	 Loss : 6.9705e-02 	 Res : 3.9667e-02 	 Jac : 1.4071e-02 	 Enc : 5.5948e-04 	 AEnc : 1.5407e-02 	 MSE : 8.0475e+00
Epoch 114, 50% 	 Loss : 5.4271e-02 	 Res : 3.1861e-02 	 Jac : 1.4306e-02 	 Enc : 4.3268e-04 	 AEnc : 7.6717e-03 	 MSE : 6.5374e+00
Epoch 114, 75% 	 Loss : 4.3773e-02 	 Res : 2.4461e-02 	 Jac : 1.4307e-02 	 Enc : 3.7280e-04 	 AEnc : 4.6321e-03 	 MSE : 5.1712e+00
Training Epoch 114 : 	 Train : 5.25676e-02 	 Res : 2.98289e-02 	 Jac : 1.42699e-02 	 Enc : 4.43272e-04 	 AE : 8.02548e-03 	 MSE : 5.90150e+00
Validation Epoch 114 : 	 Train : 2.53364e-02 	 Res : 1.02570e-02 	 Jac : 1.40701e-02 	 Enc : 2.95116e-04 	 AE : 7.14118e-04 	 MSE : 1.81603e+00
Training Epoch 114 finished, took current epoch 370.14s, cumulative time 42644.76s
Current Learning rate DEQ : 0.0032768000000000007
Current Learning rate AUTOENC : 0.016384000000000006
MODEL SAVED
Epoch 115, 25% 	 Loss : 3.0561e-02 	 Res : 1.5597e-02 	 Jac : 1.3988e-02 	 Enc : 2.4432e-04 	 AEnc : 7.3169e-04 	 MSE : 2.9472e+00
Epoch 115, 50% 	 Loss : 1.1032e-01 	 Res : 9.2641e-02 	 Jac : 1.4095e-02 	 Enc : 5.4478e-04 	 AEnc : 3.0362e-03 	 MSE : 1.2262e+01
Epoch 115, 75% 	 Loss : 5.1373e-02 	 Res : 2.5596e-02 	 Jac : 1.4408e-02 	 Enc : 6.4811e-04 	 AEnc : 1.0721e-02 	 MSE : 3.7235e+00
Training Epoch 115 : 	 Train : 7.12925e-02 	 Res : 4.48121e-02 	 Jac : 1.42005e-02 	 Enc : 5.36904e-04 	 AE : 1.17429e-02 	 MSE : 5.97082e+00
Validation Epoch 115 : 	 Train : 5.71666e-02 	 Res : 2.20628e-02 	 Jac : 1.42860e-02 	 Enc : 1.16919e-03 	 AE : 1.96486e-02 	 MSE : 3.56744e+00
Training Epoch 115 finished, took current epoch 385.19s, cumulative time 43029.92s
Current Learning rate DEQ : 0.0032768000000000007
Current Learning rate AUTOENC : 0.016384000000000006
Epoch 116, 25% 	 Loss : 5.9319e-02 	 Res : 2.6511e-02 	 Jac : 1.4095e-02 	 Enc : 6.7250e-04 	 AEnc : 1.8041e-02 	 MSE : 4.1635e+00
Epoch 116, 50% 	 Loss : 4.7853e-02 	 Res : 2.0378e-02 	 Jac : 1.3920e-02 	 Enc : 3.3273e-04 	 AEnc : 1.3222e-02 	 MSE : 3.4854e+00
Epoch 116, 75% 	 Loss : 6.5802e-02 	 Res : 3.9118e-02 	 Jac : 1.3903e-02 	 Enc : 4.4064e-04 	 AEnc : 1.2340e-02 	 MSE : 7.4434e+00
Training Epoch 116 : 	 Train : 6.13190e-02 	 Res : 2.92758e-02 	 Jac : 1.40246e-02 	 Enc : 5.60192e-04 	 AE : 1.74584e-02 	 MSE : 5.06874e+00
Validation Epoch 116 : 	 Train : 4.20671e-02 	 Res : 2.65015e-02 	 Jac : 1.44400e-02 	 Enc : 3.39999e-04 	 AE : 7.85623e-04 	 MSE : 2.64712e+00
Training Epoch 116 finished, took current epoch 379.31s, cumulative time 43409.21s
Current Learning rate DEQ : 0.0032768000000000007
Current Learning rate AUTOENC : 0.016384000000000006
Epoch 117, 25% 	 Loss : 5.6694e-02 	 Res : 2.9334e-02 	 Jac : 1.4254e-02 	 Enc : 5.9076e-04 	 AEnc : 1.2516e-02 	 MSE : 4.0989e+00
Epoch 117, 50% 	 Loss : 5.5531e-02 	 Res : 3.2442e-02 	 Jac : 1.4267e-02 	 Enc : 4.1147e-04 	 AEnc : 8.4102e-03 	 MSE : 5.3028e+00
Epoch 117, 75% 	 Loss : 4.9879e-02 	 Res : 2.2441e-02 	 Jac : 1.3960e-02 	 Enc : 4.1191e-04 	 AEnc : 1.3065e-02 	 MSE : 3.8821e+00
Training Epoch 117 : 	 Train : 5.33330e-02 	 Res : 2.89325e-02 	 Jac : 1.41573e-02 	 Enc : 4.43771e-04 	 AE : 9.79945e-03 	 MSE : 5.15406e+00
Validation Epoch 117 : 	 Train : 3.07472e-02 	 Res : 1.58651e-02 	 Jac : 1.42204e-02 	 Enc : 2.38407e-04 	 AE : 4.23307e-04 	 MSE : 2.59998e+00
Training Epoch 117 finished, took current epoch 381.46s, cumulative time 43790.63s
Current Learning rate DEQ : 0.0032768000000000007
Current Learning rate AUTOENC : 0.016384000000000006
Epoch 118, 25% 	 Loss : 3.4085e-01 	 Res : 3.2182e-01 	 Jac : 1.4572e-02 	 Enc : 2.1363e-03 	 AEnc : 2.3229e-03 	 MSE : 2.1452e+01
Epoch 118, 50% 	 Loss : 6.4498e-02 	 Res : 3.1186e-02 	 Jac : 1.4770e-02 	 Enc : 1.7557e-03 	 AEnc : 1.6787e-02 	 MSE : 5.0779e+00
Epoch 118, 75% 	 Loss : 5.2326e-02 	 Res : 2.1132e-02 	 Jac : 1.4269e-02 	 Enc : 5.6069e-04 	 AEnc : 1.6364e-02 	 MSE : 3.4027e+00
Training Epoch 118 : 	 Train : 1.31580e-01 	 Res : 1.01443e-01 	 Jac : 1.44453e-02 	 Enc : 1.23404e-03 	 AE : 1.44571e-02 	 MSE : 8.46294e+00
Validation Epoch 118 : 	 Train : 4.51869e-02 	 Res : 1.58933e-02 	 Jac : 1.44484e-02 	 Enc : 3.94945e-04 	 AE : 1.44502e-02 	 MSE : 1.18875e+00
Training Epoch 118 finished, took current epoch 383.17s, cumulative time 44173.74s
Current Learning rate DEQ : 0.0032768000000000007
Current Learning rate AUTOENC : 0.016384000000000006
Epoch 119, 25% 	 Loss : 4.0908e-02 	 Res : 1.7285e-02 	 Jac : 1.4162e-02 	 Enc : 2.6900e-04 	 AEnc : 9.1928e-03 	 MSE : 3.0548e+00
Epoch 119, 50% 	 Loss : 4.2160e-02 	 Res : 1.8379e-02 	 Jac : 1.4100e-02 	 Enc : 2.0569e-04 	 AEnc : 9.4758e-03 	 MSE : 3.3950e+00
Epoch 119, 75% 	 Loss : 9.0241e-02 	 Res : 3.2926e-02 	 Jac : 1.4224e-02 	 Enc : 5.5620e-04 	 AEnc : 4.2534e-02 	 MSE : 4.3887e+00
Training Epoch 119 : 	 Train : 6.87839e-02 	 Res : 2.62458e-02 	 Jac : 1.41749e-02 	 Enc : 3.74528e-04 	 AE : 2.79886e-02 	 MSE : 4.23260e+00
Validation Epoch 119 : 	 Train : 8.36345e-02 	 Res : 3.11077e-02 	 Jac : 1.42305e-02 	 Enc : 3.92491e-04 	 AE : 3.79038e-02 	 MSE : 5.71236e+00
Training Epoch 119 finished, took current epoch 372.13s, cumulative time 44545.83s
Current Learning rate DEQ : 0.0032768000000000007
Current Learning rate AUTOENC : 0.016384000000000006
Epoch 120, 25% 	 Loss : 1.4245e-01 	 Res : 4.5377e-02 	 Jac : 1.4352e-02 	 Enc : 7.7806e-04 	 AEnc : 8.1943e-02 	 MSE : 5.9751e+00
Epoch 120, 50% 	 Loss : 1.1041e-01 	 Res : 3.5470e-02 	 Jac : 1.4341e-02 	 Enc : 6.1586e-04 	 AEnc : 5.9979e-02 	 MSE : 5.0574e+00
Epoch 120, 75% 	 Loss : 7.0988e-02 	 Res : 2.7456e-02 	 Jac : 1.4505e-02 	 Enc : 4.9988e-04 	 AEnc : 2.8528e-02 	 MSE : 4.3706e+00
Training Epoch 120 : 	 Train : 9.56048e-02 	 Res : 3.23274e-02 	 Jac : 1.43814e-02 	 Enc : 5.60565e-04 	 AE : 4.83354e-02 	 MSE : 4.62789e+00
Validation Epoch 120 : 	 Train : 9.73446e-02 	 Res : 2.86279e-02 	 Jac : 1.40580e-02 	 Enc : 4.29265e-04 	 AE : 5.42295e-02 	 MSE : 4.02752e+00
Training Epoch 120 finished, took current epoch 372.14s, cumulative time 44917.94s
Current Learning rate DEQ : 0.0032768000000000007
Current Learning rate AUTOENC : 0.016384000000000006
Epoch 121, 25% 	 Loss : 5.9526e-02 	 Res : 2.1862e-02 	 Jac : 1.3970e-02 	 Enc : 3.3121e-04 	 AEnc : 2.3363e-02 	 MSE : 3.4958e+00
Epoch 121, 50% 	 Loss : 4.9913e-02 	 Res : 1.8990e-02 	 Jac : 1.4077e-02 	 Enc : 3.4525e-04 	 AEnc : 1.6501e-02 	 MSE : 2.9012e+00
Epoch 121, 75% 	 Loss : 9.3221e-02 	 Res : 4.2521e-02 	 Jac : 1.3953e-02 	 Enc : 3.9585e-04 	 AEnc : 3.6351e-02 	 MSE : 4.5639e+00
Training Epoch 121 : 	 Train : 6.48286e-02 	 Res : 2.65518e-02 	 Jac : 1.39354e-02 	 Enc : 4.07299e-04 	 AE : 2.39341e-02 	 MSE : 3.71809e+00
Validation Epoch 121 : 	 Train : 3.37878e-02 	 Res : 1.51418e-02 	 Jac : 1.37257e-02 	 Enc : 4.45043e-04 	 AE : 4.47520e-03 	 MSE : 2.80959e+00
Training Epoch 121 finished, took current epoch 379.57s, cumulative time 45297.48s
Current Learning rate DEQ : 0.0032768000000000007
Current Learning rate AUTOENC : 0.016384000000000006
Epoch 122, 25% 	 Loss : 7.9450e-02 	 Res : 5.9831e-02 	 Jac : 1.3763e-02 	 Enc : 7.1237e-04 	 AEnc : 5.1436e-03 	 MSE : 1.2735e+01
Epoch 122, 50% 	 Loss : 6.8707e-02 	 Res : 4.8451e-02 	 Jac : 1.4116e-02 	 Enc : 1.0277e-03 	 AEnc : 5.1124e-03 	 MSE : 1.0346e+01
Epoch 122, 75% 	 Loss : 4.9184e-02 	 Res : 2.3743e-02 	 Jac : 1.4369e-02 	 Enc : 4.8738e-04 	 AEnc : 1.0585e-02 	 MSE : 3.8650e+00
Training Epoch 122 : 	 Train : 6.74778e-02 	 Res : 4.07447e-02 	 Jac : 1.40320e-02 	 Enc : 6.79704e-04 	 AE : 1.20214e-02 	 MSE : 8.16470e+00
Validation Epoch 122 : 	 Train : 7.60145e-02 	 Res : 5.75281e-02 	 Jac : 1.41841e-02 	 Enc : 3.24077e-04 	 AE : 3.97823e-03 	 MSE : 1.12468e+01
Training Epoch 122 finished, took current epoch 386.84s, cumulative time 45684.28s
Current Learning rate DEQ : 0.0032768000000000007
Current Learning rate AUTOENC : 0.016384000000000006
Epoch 123, 25% 	 Loss : 6.4510e-02 	 Res : 3.0378e-02 	 Jac : 1.4118e-02 	 Enc : 3.4005e-04 	 AEnc : 1.9673e-02 	 MSE : 6.4631e+00
Epoch 123, 50% 	 Loss : 1.2982e+00 	 Res : 1.2245e+00 	 Jac : 1.4396e-02 	 Enc : 1.1060e-03 	 AEnc : 5.8156e-02 	 MSE : 2.8676e+01
Epoch 123, 75% 	 Loss : 1.0431e-01 	 Res : 4.9194e-02 	 Jac : 1.4123e-02 	 Enc : 2.5875e-03 	 AEnc : 3.8405e-02 	 MSE : 6.8509e+00
Training Epoch 123 : 	 Train : 3.93291e-01 	 Res : 3.39652e-01 	 Jac : 1.42967e-02 	 Enc : 1.27664e-03 	 AE : 3.80657e-02 	 MSE : 1.19326e+01
Validation Epoch 123 : 	 Train : 5.29789e-02 	 Res : 2.64906e-02 	 Jac : 1.42461e-02 	 Enc : 8.98823e-04 	 AE : 1.13434e-02 	 MSE : 6.72349e+00
Training Epoch 123 finished, took current epoch 384.11s, cumulative time 46068.32s
Current Learning rate DEQ : 0.0032768000000000007
Current Learning rate AUTOENC : 0.016384000000000006
Epoch 124, 25% 	 Loss : 4.2937e-02 	 Res : 1.8509e-02 	 Jac : 1.4433e-02 	 Enc : 5.5097e-04 	 AEnc : 9.4440e-03 	 MSE : 3.2126e+00
Epoch 124, 50% 	 Loss : 1.1130e-01 	 Res : 3.3539e-02 	 Jac : 1.4104e-02 	 Enc : 6.0857e-04 	 AEnc : 6.3043e-02 	 MSE : 4.8122e+00
Epoch 124, 75% 	 Loss : 6.3424e-02 	 Res : 3.0158e-02 	 Jac : 1.4288e-02 	 Enc : 4.1036e-04 	 AEnc : 1.8568e-02 	 MSE : 5.9835e+00
Training Epoch 124 : 	 Train : 6.49067e-02 	 Res : 2.59260e-02 	 Jac : 1.42913e-02 	 Enc : 4.95950e-04 	 AE : 2.41934e-02 	 MSE : 4.46068e+00
Validation Epoch 124 : 	 Train : 4.91212e-02 	 Res : 2.91330e-02 	 Jac : 1.47429e-02 	 Enc : 4.78569e-04 	 AE : 4.76671e-03 	 MSE : 2.73267e+00
Training Epoch 124 finished, took current epoch 385.42s, cumulative time 46453.72s
Current Learning rate DEQ : 0.0032768000000000007
Current Learning rate AUTOENC : 0.016384000000000006
Epoch 125, 25% 	 Loss : 5.8957e-02 	 Res : 2.3152e-02 	 Jac : 1.4132e-02 	 Enc : 4.4900e-04 	 AEnc : 2.1224e-02 	 MSE : 3.2044e+00
Epoch 125, 50% 	 Loss : 8.4364e-02 	 Res : 2.4685e-02 	 Jac : 1.3970e-02 	 Enc : 4.0277e-04 	 AEnc : 4.5307e-02 	 MSE : 3.0407e+00
Epoch 125, 75% 	 Loss : 8.6389e-02 	 Res : 2.3695e-02 	 Jac : 1.3921e-02 	 Enc : 4.1626e-04 	 AEnc : 4.8358e-02 	 MSE : 2.6022e+00
Training Epoch 125 : 	 Train : 7.77472e-02 	 Res : 2.40705e-02 	 Jac : 1.39360e-02 	 Enc : 5.55045e-04 	 AE : 3.91857e-02 	 MSE : 3.04599e+00
Validation Epoch 125 : 	 Train : 4.81818e-02 	 Res : 1.66934e-02 	 Jac : 1.41057e-02 	 Enc : 4.29498e-04 	 AE : 1.69532e-02 	 MSE : 1.35545e+00
Training Epoch 125 finished, took current epoch 383.79s, cumulative time 46837.47s
Current Learning rate DEQ : 0.002621440000000001
Current Learning rate AUTOENC : 0.013107200000000006
Epoch 126, 25% 	 Loss : 3.3697e-02 	 Res : 1.3906e-02 	 Jac : 1.3761e-02 	 Enc : 2.3830e-04 	 AEnc : 5.7926e-03 	 MSE : 2.3654e+00
Epoch 126, 50% 	 Loss : 4.9907e-02 	 Res : 3.2122e-02 	 Jac : 1.3692e-02 	 Enc : 4.5085e-04 	 AEnc : 3.6429e-03 	 MSE : 6.2177e+00
Epoch 126, 75% 	 Loss : 3.8893e-02 	 Res : 2.3656e-02 	 Jac : 1.3940e-02 	 Enc : 3.6240e-04 	 AEnc : 9.3423e-04 	 MSE : 5.6692e+00
Training Epoch 126 : 	 Train : 3.81734e-01 	 Res : 3.55503e-01 	 Jac : 1.38241e-02 	 Enc : 2.96360e-03 	 AE : 9.44320e-03 	 MSE : 1.96442e+01
Validation Epoch 126 : 	 Train : 1.78907e-01 	 Res : 1.36659e-01 	 Jac : 1.43249e-02 	 Enc : 1.01453e-02 	 AE : 1.77778e-02 	 MSE : 2.00201e+01
Training Epoch 126 finished, took current epoch 410.57s, cumulative time 47248.01s
Current Learning rate DEQ : 0.002621440000000001
Current Learning rate AUTOENC : 0.013107200000000006
Epoch 127, 25% 	 Loss : 6.8941e-02 	 Res : 3.1475e-02 	 Jac : 1.4417e-02 	 Enc : 6.2371e-03 	 AEnc : 1.6813e-02 	 MSE : 4.5361e+00
Epoch 127, 50% 	 Loss : 9.6686e-02 	 Res : 2.8650e-02 	 Jac : 1.4143e-02 	 Enc : 1.0383e-03 	 AEnc : 5.2854e-02 	 MSE : 3.6541e+00
Epoch 127, 75% 	 Loss : 6.5092e-02 	 Res : 2.6708e-02 	 Jac : 1.4174e-02 	 Enc : 4.4737e-04 	 AEnc : 2.3762e-02 	 MSE : 4.3565e+00
Training Epoch 127 : 	 Train : 7.00594e-02 	 Res : 2.63887e-02 	 Jac : 1.42596e-02 	 Enc : 2.05975e-03 	 AE : 2.73513e-02 	 MSE : 3.79129e+00
Validation Epoch 127 : 	 Train : 7.08034e-02 	 Res : 2.15778e-02 	 Jac : 1.43186e-02 	 Enc : 2.69338e-04 	 AE : 3.46377e-02 	 MSE : 2.60850e+00
Training Epoch 127 finished, took current epoch 368.69s, cumulative time 47616.67s
Current Learning rate DEQ : 0.002621440000000001
Current Learning rate AUTOENC : 0.013107200000000006
Epoch 128, 25% 	 Loss : 4.4214e-02 	 Res : 2.2161e-02 	 Jac : 1.4121e-02 	 Enc : 2.5619e-04 	 AEnc : 7.6754e-03 	 MSE : 4.7986e+00
Epoch 128, 50% 	 Loss : 5.1655e-02 	 Res : 1.9124e-02 	 Jac : 1.4109e-02 	 Enc : 2.4775e-04 	 AEnc : 1.8175e-02 	 MSE : 3.3405e+00
Epoch 128, 75% 	 Loss : 4.9733e-02 	 Res : 1.6604e-02 	 Jac : 1.4124e-02 	 Enc : 1.9768e-04 	 AEnc : 1.8808e-02 	 MSE : 2.4627e+00
Training Epoch 128 : 	 Train : 4.57595e-02 	 Res : 1.81884e-02 	 Jac : 1.41040e-02 	 Enc : 2.17508e-04 	 AE : 1.32496e-02 	 MSE : 3.32593e+00
Validation Epoch 128 : 	 Train : 3.06984e-02 	 Res : 1.54472e-02 	 Jac : 1.38611e-02 	 Enc : 1.34444e-04 	 AE : 1.25574e-03 	 MSE : 3.17274e+00
Training Epoch 128 finished, took current epoch 372.19s, cumulative time 47988.80s
Current Learning rate DEQ : 0.002621440000000001
Current Learning rate AUTOENC : 0.013107200000000006
Epoch 129, 25% 	 Loss : 4.5692e-02 	 Res : 2.7971e-02 	 Jac : 1.3959e-02 	 Enc : 3.0459e-04 	 AEnc : 3.4579e-03 	 MSE : 4.7973e+00
Epoch 129, 50% 	 Loss : 3.8995e-02 	 Res : 2.3832e-02 	 Jac : 1.3899e-02 	 Enc : 2.9974e-04 	 AEnc : 9.6458e-04 	 MSE : 5.1776e+00
Epoch 129, 75% 	 Loss : 6.5178e-02 	 Res : 5.0532e-02 	 Jac : 1.3744e-02 	 Enc : 5.0725e-04 	 AEnc : 3.9529e-04 	 MSE : 1.1877e+01
Training Epoch 129 : 	 Train : 5.82884e-02 	 Res : 4.24220e-02 	 Jac : 1.38858e-02 	 Enc : 4.20943e-04 	 AE : 1.55956e-03 	 MSE : 9.00173e+00
Validation Epoch 129 : 	 Train : 6.50782e-02 	 Res : 4.87102e-02 	 Jac : 1.43623e-02 	 Enc : 1.29098e-03 	 AE : 7.14671e-04 	 MSE : 9.04074e+00
Training Epoch 129 finished, took current epoch 379.40s, cumulative time 48368.17s
Current Learning rate DEQ : 0.002621440000000001
Current Learning rate AUTOENC : 0.013107200000000006
Epoch 130, 25% 	 Loss : 7.2939e-02 	 Res : 5.1026e-02 	 Jac : 1.4286e-02 	 Enc : 6.6053e-04 	 AEnc : 6.9667e-03 	 MSE : 1.1101e+01
Epoch 130, 50% 	 Loss : 5.1173e-02 	 Res : 2.4584e-02 	 Jac : 1.4128e-02 	 Enc : 3.1213e-04 	 AEnc : 1.2149e-02 	 MSE : 4.9466e+00
Epoch 130, 75% 	 Loss : 4.8853e-02 	 Res : 1.9039e-02 	 Jac : 1.3932e-02 	 Enc : 2.4421e-04 	 AEnc : 1.5639e-02 	 MSE : 3.3156e+00
Training Epoch 130 : 	 Train : 6.35696e-02 	 Res : 2.93334e-02 	 Jac : 1.40315e-02 	 Enc : 3.84977e-04 	 AE : 1.98198e-02 	 MSE : 5.48734e+00
Validation Epoch 130 : 	 Train : 7.33372e-02 	 Res : 1.93787e-02 	 Jac : 1.37943e-02 	 Enc : 2.90440e-04 	 AE : 3.98737e-02 	 MSE : 9.79425e-01
Training Epoch 130 finished, took current epoch 373.07s, cumulative time 48741.20s
Current Learning rate DEQ : 0.002621440000000001
Current Learning rate AUTOENC : 0.013107200000000006
Epoch 131, 25% 	 Loss : 5.6071e-02 	 Res : 1.8668e-02 	 Jac : 1.3671e-02 	 Enc : 2.7135e-04 	 AEnc : 2.3461e-02 	 MSE : 2.8165e+00
Epoch 131, 50% 	 Loss : 4.4887e-02 	 Res : 2.1033e-02 	 Jac : 1.3611e-02 	 Enc : 2.7198e-04 	 AEnc : 9.9702e-03 	 MSE : 3.1627e+00
Epoch 131, 75% 	 Loss : 7.1721e-02 	 Res : 4.1973e-02 	 Jac : 1.3847e-02 	 Enc : 4.7838e-04 	 AEnc : 1.5423e-02 	 MSE : 5.4382e+00
Training Epoch 131 : 	 Train : 5.65696e-02 	 Res : 2.48509e-02 	 Jac : 1.37619e-02 	 Enc : 3.43595e-04 	 AE : 1.76132e-02 	 MSE : 3.49372e+00
Validation Epoch 131 : 	 Train : 3.42304e-02 	 Res : 1.70152e-02 	 Jac : 1.38025e-02 	 Enc : 1.53614e-04 	 AE : 3.25911e-03 	 MSE : 3.50829e+00
Training Epoch 131 finished, took current epoch 376.51s, cumulative time 49117.69s
Current Learning rate DEQ : 0.002621440000000001
Current Learning rate AUTOENC : 0.013107200000000006
Epoch 132, 25% 	 Loss : 3.6073e-02 	 Res : 1.5971e-02 	 Jac : 1.3724e-02 	 Enc : 2.1079e-04 	 AEnc : 6.1674e-03 	 MSE : 2.9223e+00
Epoch 132, 50% 	 Loss : 4.0519e-02 	 Res : 2.0770e-02 	 Jac : 1.3742e-02 	 Enc : 2.4799e-04 	 AEnc : 5.7582e-03 	 MSE : 3.6827e+00
Epoch 132, 75% 	 Loss : 5.4688e-02 	 Res : 3.0832e-02 	 Jac : 1.3698e-02 	 Enc : 4.2269e-04 	 AEnc : 9.7345e-03 	 MSE : 5.4729e+00
Training Epoch 132 : 	 Train : 4.53098e-02 	 Res : 2.30554e-02 	 Jac : 1.37810e-02 	 Enc : 3.48281e-04 	 AE : 8.12513e-03 	 MSE : 4.02872e+00
Validation Epoch 132 : 	 Train : 5.54426e-02 	 Res : 1.67707e-02 	 Jac : 1.37493e-02 	 Enc : 4.24719e-04 	 AE : 2.44978e-02 	 MSE : 1.66454e+00
Training Epoch 132 finished, took current epoch 382.37s, cumulative time 49500.04s
Current Learning rate DEQ : 0.002621440000000001
Current Learning rate AUTOENC : 0.013107200000000006
Epoch 133, 25% 	 Loss : 4.2879e-02 	 Res : 1.9982e-02 	 Jac : 1.3661e-02 	 Enc : 2.4450e-04 	 AEnc : 8.9910e-03 	 MSE : 3.8689e+00
Epoch 133, 50% 	 Loss : 7.3111e-02 	 Res : 3.5700e-02 	 Jac : 1.3913e-02 	 Enc : 5.1080e-04 	 AEnc : 2.2987e-02 	 MSE : 5.2294e+00
Epoch 133, 75% 	 Loss : 4.3931e-02 	 Res : 1.4815e-02 	 Jac : 1.3892e-02 	 Enc : 2.8433e-04 	 AEnc : 1.4940e-02 	 MSE : 2.2538e+00
Training Epoch 133 : 	 Train : 5.22075e-02 	 Res : 2.19027e-02 	 Jac : 1.38212e-02 	 Enc : 3.08643e-04 	 AE : 1.61750e-02 	 MSE : 3.47202e+00
Validation Epoch 133 : 	 Train : 2.71096e-02 	 Res : 9.14412e-03 	 Jac : 1.37640e-02 	 Enc : 1.74312e-04 	 AE : 4.02716e-03 	 MSE : 1.67086e+00
Training Epoch 133 finished, took current epoch 372.51s, cumulative time 49872.49s
Current Learning rate DEQ : 0.002621440000000001
Current Learning rate AUTOENC : 0.013107200000000006
MODEL SAVED
Epoch 134, 25% 	 Loss : 4.5956e-02 	 Res : 2.8559e-02 	 Jac : 1.3764e-02 	 Enc : 2.1898e-04 	 AEnc : 3.4136e-03 	 MSE : 6.8728e+00
Epoch 134, 50% 	 Loss : 1.1659e-01 	 Res : 9.5280e-02 	 Jac : 1.3725e-02 	 Enc : 5.3512e-04 	 AEnc : 7.0543e-03 	 MSE : 1.6082e+01
Epoch 134, 75% 	 Loss : 5.6252e-02 	 Res : 2.4962e-02 	 Jac : 1.3971e-02 	 Enc : 5.9824e-04 	 AEnc : 1.6720e-02 	 MSE : 4.1836e+00
Training Epoch 134 : 	 Train : 1.14115e-01 	 Res : 9.02686e-02 	 Jac : 1.37946e-02 	 Enc : 4.63750e-04 	 AE : 9.58830e-03 	 MSE : 1.02806e+01
Validation Epoch 134 : 	 Train : 3.87531e-02 	 Res : 1.89748e-02 	 Jac : 1.33734e-02 	 Enc : 8.87506e-04 	 AE : 5.51734e-03 	 MSE : 2.83445e+00
Training Epoch 134 finished, took current epoch 377.94s, cumulative time 50250.38s
Current Learning rate DEQ : 0.002621440000000001
Current Learning rate AUTOENC : 0.013107200000000006
Epoch 135, 25% 	 Loss : 1.0216e-01 	 Res : 5.3608e-02 	 Jac : 1.3803e-02 	 Enc : 1.3681e-03 	 AEnc : 3.3384e-02 	 MSE : 6.2403e+00
Epoch 135, 50% 	 Loss : 4.5929e-02 	 Res : 1.7253e-02 	 Jac : 1.3676e-02 	 Enc : 3.7090e-04 	 AEnc : 1.4628e-02 	 MSE : 2.6320e+00
Epoch 135, 75% 	 Loss : 8.1514e-02 	 Res : 4.0512e-02 	 Jac : 1.3674e-02 	 Enc : 4.7011e-04 	 AEnc : 2.6858e-02 	 MSE : 7.6797e+00
Training Epoch 135 : 	 Train : 7.43419e-02 	 Res : 3.55507e-02 	 Jac : 1.37800e-02 	 Enc : 6.78270e-04 	 AE : 2.43329e-02 	 MSE : 5.64145e+00
Validation Epoch 135 : 	 Train : 4.86342e-02 	 Res : 2.16022e-02 	 Jac : 1.41591e-02 	 Enc : 3.01235e-04 	 AE : 1.25716e-02 	 MSE : 4.07079e+00
Training Epoch 135 finished, took current epoch 379.00s, cumulative time 50629.35s
Current Learning rate DEQ : 0.002621440000000001
Current Learning rate AUTOENC : 0.013107200000000006
Epoch 136, 25% 	 Loss : 6.9088e-02 	 Res : 2.8754e-02 	 Jac : 1.4023e-02 	 Enc : 2.8912e-04 	 AEnc : 2.6021e-02 	 MSE : 5.5170e+00
Epoch 136, 50% 	 Loss : 5.8883e-02 	 Res : 2.8325e-02 	 Jac : 1.4095e-02 	 Enc : 3.4220e-04 	 AEnc : 1.6121e-02 	 MSE : 6.0245e+00
Epoch 136, 75% 	 Loss : 3.6782e-02 	 Res : 1.4465e-02 	 Jac : 1.3937e-02 	 Enc : 2.9717e-04 	 AEnc : 8.0832e-03 	 MSE : 2.3856e+00
Training Epoch 136 : 	 Train : 5.63070e-02 	 Res : 2.33072e-02 	 Jac : 1.40155e-02 	 Enc : 3.54590e-04 	 AE : 1.86296e-02 	 MSE : 4.31138e+00
Validation Epoch 136 : 	 Train : 2.83064e-02 	 Res : 8.99768e-03 	 Jac : 1.38283e-02 	 Enc : 2.87756e-04 	 AE : 5.19259e-03 	 MSE : 1.29781e+00
Training Epoch 136 finished, took current epoch 373.33s, cumulative time 51002.63s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
MODEL SAVED
Epoch 137, 25% 	 Loss : 4.5984e-02 	 Res : 2.0432e-02 	 Jac : 1.3794e-02 	 Enc : 2.0070e-04 	 AEnc : 1.1557e-02 	 MSE : 3.6375e+00
Epoch 137, 50% 	 Loss : 3.9238e-02 	 Res : 2.1672e-02 	 Jac : 1.3747e-02 	 Enc : 1.8970e-04 	 AEnc : 3.6290e-03 	 MSE : 5.0043e+00
Epoch 137, 75% 	 Loss : 4.5655e-02 	 Res : 1.9135e-02 	 Jac : 1.3704e-02 	 Enc : 1.7800e-04 	 AEnc : 1.2638e-02 	 MSE : 3.7802e+00
Training Epoch 137 : 	 Train : 4.02538e-02 	 Res : 1.82601e-02 	 Jac : 1.37282e-02 	 Enc : 1.67096e-04 	 AE : 8.09837e-03 	 MSE : 3.55244e+00
Validation Epoch 137 : 	 Train : 2.77344e-02 	 Res : 1.19065e-02 	 Jac : 1.36358e-02 	 Enc : 9.00197e-05 	 AE : 2.10208e-03 	 MSE : 2.74794e+00
Training Epoch 137 finished, took current epoch 373.59s, cumulative time 51376.18s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
Epoch 138, 25% 	 Loss : 3.9563e-02 	 Res : 2.4136e-02 	 Jac : 1.3532e-02 	 Enc : 1.8694e-04 	 AEnc : 1.7082e-03 	 MSE : 5.5422e+00
Epoch 138, 50% 	 Loss : 3.5866e-02 	 Res : 1.9262e-02 	 Jac : 1.3484e-02 	 Enc : 2.1576e-04 	 AEnc : 2.9037e-03 	 MSE : 3.2766e+00
Epoch 138, 75% 	 Loss : 3.7938e-02 	 Res : 1.4154e-02 	 Jac : 1.3447e-02 	 Enc : 1.7653e-04 	 AEnc : 1.0160e-02 	 MSE : 2.1596e+00
Training Epoch 138 : 	 Train : 3.64807e-02 	 Res : 1.77001e-02 	 Jac : 1.35127e-02 	 Enc : 1.70718e-04 	 AE : 5.09725e-03 	 MSE : 3.30728e+00
Validation Epoch 138 : 	 Train : 3.43948e-02 	 Res : 1.16049e-02 	 Jac : 1.35583e-02 	 Enc : 1.07450e-04 	 AE : 9.12421e-03 	 MSE : 1.66333e+00
Training Epoch 138 finished, took current epoch 382.88s, cumulative time 51759.03s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
Epoch 139, 25% 	 Loss : 1.2699e-01 	 Res : 9.7943e-02 	 Jac : 1.3529e-02 	 Enc : 5.5247e-04 	 AEnc : 1.4970e-02 	 MSE : 1.6833e+01
Epoch 139, 50% 	 Loss : 5.4322e-02 	 Res : 3.2977e-02 	 Jac : 1.3628e-02 	 Enc : 9.9469e-04 	 AEnc : 6.7219e-03 	 MSE : 5.8291e+00
Epoch 139, 75% 	 Loss : 7.4803e-02 	 Res : 2.0597e-02 	 Jac : 1.3522e-02 	 Enc : 3.2824e-04 	 AEnc : 4.0356e-02 	 MSE : 2.4615e+00
Training Epoch 139 : 	 Train : 7.59876e-02 	 Res : 4.27411e-02 	 Jac : 1.35470e-02 	 Enc : 5.38810e-04 	 AE : 1.91607e-02 	 MSE : 7.08140e+00
Validation Epoch 139 : 	 Train : 3.80787e-02 	 Res : 1.36657e-02 	 Jac : 1.34937e-02 	 Enc : 3.54219e-04 	 AE : 1.05651e-02 	 MSE : 2.52933e+00
Training Epoch 139 finished, took current epoch 379.57s, cumulative time 52138.57s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
Epoch 140, 25% 	 Loss : 4.1258e-02 	 Res : 1.3336e-02 	 Jac : 1.3568e-02 	 Enc : 2.3625e-04 	 AEnc : 1.4117e-02 	 MSE : 1.8335e+00
Epoch 140, 50% 	 Loss : 4.6686e-02 	 Res : 1.4546e-02 	 Jac : 1.3495e-02 	 Enc : 1.5670e-04 	 AEnc : 1.8489e-02 	 MSE : 1.9101e+00
Epoch 140, 75% 	 Loss : 5.2762e-02 	 Res : 1.3342e-02 	 Jac : 1.3460e-02 	 Enc : 1.5699e-04 	 AEnc : 2.5803e-02 	 MSE : 1.3961e+00
Training Epoch 140 : 	 Train : 5.22264e-02 	 Res : 1.54386e-02 	 Jac : 1.34954e-02 	 Enc : 1.81013e-04 	 AE : 2.31114e-02 	 MSE : 2.07835e+00
Validation Epoch 140 : 	 Train : 7.28546e-02 	 Res : 4.13908e-02 	 Jac : 1.35520e-02 	 Enc : 2.32240e-04 	 AE : 1.76796e-02 	 MSE : 9.41862e+00
Training Epoch 140 finished, took current epoch 380.46s, cumulative time 52519.00s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
Epoch 141, 25% 	 Loss : 5.7355e-02 	 Res : 2.9461e-02 	 Jac : 1.3519e-02 	 Enc : 2.2235e-04 	 AEnc : 1.4153e-02 	 MSE : 6.8803e+00
Epoch 141, 50% 	 Loss : 6.1548e-02 	 Res : 4.7027e-02 	 Jac : 1.3455e-02 	 Enc : 2.1435e-04 	 AEnc : 8.5225e-04 	 MSE : 1.1242e+01
Epoch 141, 75% 	 Loss : 3.9428e-02 	 Res : 1.6104e-02 	 Jac : 1.3499e-02 	 Enc : 2.6415e-04 	 AEnc : 9.5613e-03 	 MSE : 2.6898e+00
Training Epoch 141 : 	 Train : 5.35703e-02 	 Res : 2.70197e-02 	 Jac : 1.34789e-02 	 Enc : 2.13503e-04 	 AE : 1.28582e-02 	 MSE : 5.69144e+00
Validation Epoch 141 : 	 Train : 2.66345e-02 	 Res : 9.65139e-03 	 Jac : 1.33481e-02 	 Enc : 7.89863e-05 	 AE : 3.55608e-03 	 MSE : 1.88904e+00
Training Epoch 141 finished, took current epoch 373.78s, cumulative time 52892.74s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
Epoch 142, 25% 	 Loss : 7.5559e-02 	 Res : 3.2485e-02 	 Jac : 1.3504e-02 	 Enc : 2.8279e-04 	 AEnc : 2.9288e-02 	 MSE : 5.1106e+00
Epoch 142, 50% 	 Loss : 1.3834e-01 	 Res : 5.0961e-02 	 Jac : 1.3622e-02 	 Enc : 7.2667e-04 	 AEnc : 7.3030e-02 	 MSE : 6.1842e+00
Epoch 142, 75% 	 Loss : 6.6577e-02 	 Res : 2.2866e-02 	 Jac : 1.3449e-02 	 Enc : 2.9244e-04 	 AEnc : 2.9970e-02 	 MSE : 3.6853e+00
Training Epoch 142 : 	 Train : 8.61482e-02 	 Res : 3.61727e-02 	 Jac : 1.34900e-02 	 Enc : 4.09442e-04 	 AE : 3.60760e-02 	 MSE : 6.04384e+00
Validation Epoch 142 : 	 Train : 4.49506e-02 	 Res : 1.72129e-02 	 Jac : 1.34235e-02 	 Enc : 3.28372e-04 	 AE : 1.39858e-02 	 MSE : 2.99548e+00
Training Epoch 142 finished, took current epoch 384.80s, cumulative time 53277.50s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
Epoch 143, 25% 	 Loss : 3.7557e-02 	 Res : 1.3165e-02 	 Jac : 1.3604e-02 	 Enc : 1.7079e-04 	 AEnc : 1.0617e-02 	 MSE : 1.9746e+00
Epoch 143, 50% 	 Loss : 4.0519e-02 	 Res : 1.3568e-02 	 Jac : 1.3505e-02 	 Enc : 1.3006e-04 	 AEnc : 1.3315e-02 	 MSE : 1.9929e+00
Epoch 143, 75% 	 Loss : 3.5649e-02 	 Res : 1.3473e-02 	 Jac : 1.3330e-02 	 Enc : 1.8294e-04 	 AEnc : 8.6630e-03 	 MSE : 2.0082e+00
Training Epoch 143 : 	 Train : 3.51089e-02 	 Res : 1.26231e-02 	 Jac : 1.34879e-02 	 Enc : 1.47401e-04 	 AE : 8.85053e-03 	 MSE : 1.95464e+00
Validation Epoch 143 : 	 Train : 2.33408e-02 	 Res : 9.65523e-03 	 Jac : 1.33364e-02 	 Enc : 7.36928e-05 	 AE : 2.75431e-04 	 MSE : 1.91517e+00
Training Epoch 143 finished, took current epoch 373.33s, cumulative time 53650.79s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
Epoch 144, 25% 	 Loss : 2.4536e-02 	 Res : 1.0446e-02 	 Jac : 1.3264e-02 	 Enc : 7.2815e-05 	 AEnc : 7.5344e-04 	 MSE : 2.0199e+00
Epoch 144, 50% 	 Loss : 3.4430e-02 	 Res : 1.9807e-02 	 Jac : 1.3291e-02 	 Enc : 1.3528e-04 	 AEnc : 1.1961e-03 	 MSE : 4.1574e+00
Epoch 144, 75% 	 Loss : 3.6133e-02 	 Res : 2.1918e-02 	 Jac : 1.3347e-02 	 Enc : 3.6953e-04 	 AEnc : 4.9914e-04 	 MSE : 4.1321e+00
Training Epoch 144 : 	 Train : 3.23962e-02 	 Res : 1.81495e-02 	 Jac : 1.33245e-02 	 Enc : 1.90728e-04 	 AE : 7.31487e-04 	 MSE : 3.79093e+00
Validation Epoch 144 : 	 Train : 2.29386e-02 	 Res : 7.24839e-03 	 Jac : 1.35764e-02 	 Enc : 8.28507e-05 	 AE : 2.03099e-03 	 MSE : 6.37965e-01
Training Epoch 144 finished, took current epoch 376.53s, cumulative time 54027.29s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
MODEL SAVED
Epoch 145, 25% 	 Loss : 3.8064e-02 	 Res : 1.8827e-02 	 Jac : 1.3379e-02 	 Enc : 1.2692e-04 	 AEnc : 5.7304e-03 	 MSE : 4.0796e+00
Epoch 145, 50% 	 Loss : 4.2174e-02 	 Res : 2.4866e-02 	 Jac : 1.3367e-02 	 Enc : 2.2922e-04 	 AEnc : 3.7121e-03 	 MSE : 6.0332e+00
Epoch 145, 75% 	 Loss : 8.8201e-02 	 Res : 7.0181e-02 	 Jac : 1.3550e-02 	 Enc : 1.7071e-04 	 AEnc : 4.2990e-03 	 MSE : 1.4015e+01
Training Epoch 145 : 	 Train : 5.62521e-02 	 Res : 3.83245e-02 	 Jac : 1.34815e-02 	 Enc : 3.06219e-04 	 AE : 4.13981e-03 	 MSE : 8.17775e+00
Validation Epoch 145 : 	 Train : 3.40168e-02 	 Res : 1.79978e-02 	 Jac : 1.34225e-02 	 Enc : 3.53670e-04 	 AE : 2.24279e-03 	 MSE : 4.52589e+00
Training Epoch 145 finished, took current epoch 368.46s, cumulative time 54395.70s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
Epoch 146, 25% 	 Loss : 4.4764e-02 	 Res : 2.8403e-02 	 Jac : 1.3624e-02 	 Enc : 3.5727e-04 	 AEnc : 2.3796e-03 	 MSE : 5.3003e+00
Epoch 146, 50% 	 Loss : 6.3682e-02 	 Res : 2.3376e-02 	 Jac : 1.3625e-02 	 Enc : 5.3113e-04 	 AEnc : 2.6150e-02 	 MSE : 3.9605e+00
Epoch 146, 75% 	 Loss : 4.0845e-02 	 Res : 2.1230e-02 	 Jac : 1.3675e-02 	 Enc : 2.0793e-04 	 AEnc : 5.7333e-03 	 MSE : 5.0417e+00
Training Epoch 146 : 	 Train : 5.19029e-02 	 Res : 2.31037e-02 	 Jac : 1.36326e-02 	 Enc : 3.34869e-04 	 AE : 1.48318e-02 	 MSE : 4.32433e+00
Validation Epoch 146 : 	 Train : 2.59856e-02 	 Res : 1.08587e-02 	 Jac : 1.35695e-02 	 Enc : 1.96033e-04 	 AE : 1.36134e-03 	 MSE : 2.27984e+00
Training Epoch 146 finished, took current epoch 369.70s, cumulative time 54765.36s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
Epoch 147, 25% 	 Loss : 5.7936e-02 	 Res : 2.1628e-02 	 Jac : 1.3562e-02 	 Enc : 2.0215e-04 	 AEnc : 2.2543e-02 	 MSE : 3.8478e+00
Epoch 147, 50% 	 Loss : 4.6761e-02 	 Res : 1.6006e-02 	 Jac : 1.3660e-02 	 Enc : 2.6027e-04 	 AEnc : 1.6835e-02 	 MSE : 2.3136e+00
Epoch 147, 75% 	 Loss : 5.0139e-02 	 Res : 1.6076e-02 	 Jac : 1.3566e-02 	 Enc : 3.6628e-04 	 AEnc : 2.0131e-02 	 MSE : 2.1810e+00
Training Epoch 147 : 	 Train : 4.80595e-02 	 Res : 1.75347e-02 	 Jac : 1.35948e-02 	 Enc : 2.51876e-04 	 AE : 1.66782e-02 	 MSE : 2.90588e+00
Validation Epoch 147 : 	 Train : 2.40205e-02 	 Res : 9.94046e-03 	 Jac : 1.33427e-02 	 Enc : 1.64661e-04 	 AE : 5.72618e-04 	 MSE : 1.90771e+00
Training Epoch 147 finished, took current epoch 369.82s, cumulative time 55135.16s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
Epoch 148, 25% 	 Loss : 3.3191e-02 	 Res : 1.8352e-02 	 Jac : 1.3469e-02 	 Enc : 1.6167e-04 	 AEnc : 1.2084e-03 	 MSE : 4.2791e+00
Epoch 148, 50% 	 Loss : 3.3156e-02 	 Res : 1.8782e-02 	 Jac : 1.3557e-02 	 Enc : 1.7248e-04 	 AEnc : 6.4397e-04 	 MSE : 4.0159e+00
Epoch 148, 75% 	 Loss : 2.5616e-02 	 Res : 1.1821e-02 	 Jac : 1.3420e-02 	 Enc : 1.2032e-04 	 AEnc : 2.5411e-04 	 MSE : 2.2630e+00
Training Epoch 148 : 	 Train : 4.23452e-02 	 Res : 2.23741e-02 	 Jac : 1.34652e-02 	 Enc : 1.78847e-04 	 AE : 6.32703e-03 	 MSE : 4.39211e+00
Validation Epoch 148 : 	 Train : 2.28911e-02 	 Res : 7.27860e-03 	 Jac : 1.35311e-02 	 Enc : 2.76668e-04 	 AE : 1.80469e-03 	 MSE : 5.51709e-01
Training Epoch 148 finished, took current epoch 379.16s, cumulative time 55514.27s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
Epoch 149, 25% 	 Loss : 5.1569e-02 	 Res : 1.8622e-02 	 Jac : 1.3418e-02 	 Enc : 3.1219e-04 	 AEnc : 1.9218e-02 	 MSE : 2.8656e+00
Epoch 149, 50% 	 Loss : 4.9741e-02 	 Res : 1.4892e-02 	 Jac : 1.3464e-02 	 Enc : 1.4594e-04 	 AEnc : 2.1240e-02 	 MSE : 1.9478e+00
Epoch 149, 75% 	 Loss : 6.1859e-02 	 Res : 2.3021e-02 	 Jac : 1.3446e-02 	 Enc : 2.0155e-04 	 AEnc : 2.5190e-02 	 MSE : 4.6461e+00
Training Epoch 149 : 	 Train : 4.92352e-02 	 Res : 1.85709e-02 	 Jac : 1.34348e-02 	 Enc : 1.94949e-04 	 AE : 1.70345e-02 	 MSE : 3.41500e+00
Validation Epoch 149 : 	 Train : 2.00375e-02 	 Res : 6.22058e-03 	 Jac : 1.33757e-02 	 Enc : 8.00696e-05 	 AE : 3.61182e-04 	 MSE : 8.32351e-01
Training Epoch 149 finished, took current epoch 372.87s, cumulative time 55887.10s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
MODEL SAVED
Epoch 150, 25% 	 Loss : 3.4822e-02 	 Res : 1.1481e-02 	 Jac : 1.3419e-02 	 Enc : 9.8204e-05 	 AEnc : 9.8235e-03 	 MSE : 1.5786e+00
Epoch 150, 50% 	 Loss : 6.2406e-02 	 Res : 1.6421e-02 	 Jac : 1.3393e-02 	 Enc : 1.8298e-04 	 AEnc : 3.2409e-02 	 MSE : 1.9368e+00
Epoch 150, 75% 	 Loss : 7.0193e-01 	 Res : 6.8314e-01 	 Jac : 1.3204e-02 	 Enc : 1.1781e-03 	 AEnc : 4.4079e-03 	 MSE : 2.9344e+01
Training Epoch 150 : 	 Train : 2.08742e-01 	 Res : 1.82285e-01 	 Jac : 1.33323e-02 	 Enc : 6.31870e-04 	 AE : 1.24926e-02 	 MSE : 9.00569e+00
Validation Epoch 150 : 	 Train : 2.67869e-02 	 Res : 9.57545e-03 	 Jac : 1.34648e-02 	 Enc : 7.90616e-04 	 AE : 2.95601e-03 	 MSE : 1.63815e+00
Training Epoch 150 finished, took current epoch 383.81s, cumulative time 56270.87s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
Epoch 151, 25% 	 Loss : 3.5460e-02 	 Res : 1.9380e-02 	 Jac : 1.3388e-02 	 Enc : 4.5396e-04 	 AEnc : 2.2382e-03 	 MSE : 4.7536e+00
Epoch 151, 50% 	 Loss : 3.1149e-02 	 Res : 1.6833e-02 	 Jac : 1.3488e-02 	 Enc : 3.4112e-04 	 AEnc : 4.8773e-04 	 MSE : 3.6999e+00
Epoch 151, 75% 	 Loss : 2.6438e-02 	 Res : 1.2130e-02 	 Jac : 1.3593e-02 	 Enc : 2.0698e-04 	 AEnc : 5.0820e-04 	 MSE : 2.4534e+00
Training Epoch 151 : 	 Train : 3.37334e-02 	 Res : 1.89865e-02 	 Jac : 1.34550e-02 	 Enc : 3.21457e-04 	 AE : 9.70541e-04 	 MSE : 4.16359e+00
Validation Epoch 151 : 	 Train : 2.76655e-02 	 Res : 1.33034e-02 	 Jac : 1.33791e-02 	 Enc : 4.49103e-04 	 AE : 5.33910e-04 	 MSE : 2.90417e+00
Training Epoch 151 finished, took current epoch 375.25s, cumulative time 56646.08s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
Epoch 152, 25% 	 Loss : 2.7977e-02 	 Res : 1.3598e-02 	 Jac : 1.3545e-02 	 Enc : 3.2533e-04 	 AEnc : 5.0865e-04 	 MSE : 2.5317e+00
Epoch 152, 50% 	 Loss : 3.4151e-02 	 Res : 1.6140e-02 	 Jac : 1.3481e-02 	 Enc : 1.7885e-04 	 AEnc : 4.3502e-03 	 MSE : 2.7033e+00
Epoch 152, 75% 	 Loss : 2.7045e-02 	 Res : 1.2143e-02 	 Jac : 1.3490e-02 	 Enc : 1.3799e-04 	 AEnc : 1.2750e-03 	 MSE : 2.4191e+00
Training Epoch 152 : 	 Train : 3.70207e-02 	 Res : 1.44002e-02 	 Jac : 1.34650e-02 	 Enc : 2.16989e-04 	 AE : 8.93857e-03 	 MSE : 2.36299e+00
Validation Epoch 152 : 	 Train : 4.25880e-02 	 Res : 1.42181e-02 	 Jac : 1.34775e-02 	 Enc : 1.67972e-04 	 AE : 1.47245e-02 	 MSE : 2.00047e+00
Training Epoch 152 finished, took current epoch 384.48s, cumulative time 57030.53s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
Epoch 153, 25% 	 Loss : 6.8107e-02 	 Res : 2.8670e-02 	 Jac : 1.3392e-02 	 Enc : 2.4098e-04 	 AEnc : 2.5804e-02 	 MSE : 4.6547e+00
Epoch 153, 50% 	 Loss : 4.5563e-02 	 Res : 2.7055e-02 	 Jac : 1.3345e-02 	 Enc : 6.2612e-04 	 AEnc : 4.5371e-03 	 MSE : 5.5170e+00
Epoch 153, 75% 	 Loss : 5.3792e-02 	 Res : 3.8212e-02 	 Jac : 1.3282e-02 	 Enc : 8.1124e-04 	 AEnc : 1.4860e-03 	 MSE : 7.3760e+00
Training Epoch 153 : 	 Train : 5.74552e-02 	 Res : 2.91573e-02 	 Jac : 1.33844e-02 	 Enc : 5.85675e-04 	 AE : 1.43278e-02 	 MSE : 5.26086e+00
Validation Epoch 153 : 	 Train : 1.79605e-01 	 Res : 3.35614e-02 	 Jac : 1.33314e-02 	 Enc : 5.60220e-04 	 AE : 1.32152e-01 	 MSE : 1.31999e+00
Training Epoch 153 finished, took current epoch 381.09s, cumulative time 57411.59s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
Epoch 154, 25% 	 Loss : 5.6654e-02 	 Res : 1.5339e-02 	 Jac : 1.3305e-02 	 Enc : 2.3588e-04 	 AEnc : 2.7774e-02 	 MSE : 1.9541e+00
Epoch 154, 50% 	 Loss : 1.0250e-01 	 Res : 2.6528e-02 	 Jac : 1.3346e-02 	 Enc : 3.7443e-04 	 AEnc : 6.2255e-02 	 MSE : 3.1206e+00
Epoch 154, 75% 	 Loss : 5.0001e-02 	 Res : 1.6676e-02 	 Jac : 1.3343e-02 	 Enc : 3.3051e-04 	 AEnc : 1.9652e-02 	 MSE : 2.2397e+00
Training Epoch 154 : 	 Train : 6.25270e-02 	 Res : 1.98867e-02 	 Jac : 1.33333e-02 	 Enc : 3.01745e-04 	 AE : 2.90053e-02 	 MSE : 3.01620e+00
Validation Epoch 154 : 	 Train : 5.07359e-02 	 Res : 3.18344e-02 	 Jac : 1.32126e-02 	 Enc : 1.61368e-04 	 AE : 5.52746e-03 	 MSE : 7.11983e+00
Training Epoch 154 finished, took current epoch 366.86s, cumulative time 57778.42s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
Epoch 155, 25% 	 Loss : 5.0964e-02 	 Res : 2.3419e-02 	 Jac : 1.3379e-02 	 Enc : 2.6018e-04 	 AEnc : 1.3906e-02 	 MSE : 4.4673e+00
Epoch 155, 50% 	 Loss : 4.7103e-02 	 Res : 2.0737e-02 	 Jac : 1.3403e-02 	 Enc : 2.4949e-04 	 AEnc : 1.2713e-02 	 MSE : 3.6267e+00
Epoch 155, 75% 	 Loss : 5.5390e-02 	 Res : 2.6713e-02 	 Jac : 1.3422e-02 	 Enc : 3.4335e-04 	 AEnc : 1.4911e-02 	 MSE : 4.2320e+00
Training Epoch 155 : 	 Train : 5.11508e-02 	 Res : 2.15091e-02 	 Jac : 1.33964e-02 	 Enc : 2.64350e-04 	 AE : 1.59809e-02 	 MSE : 3.55418e+00
Validation Epoch 155 : 	 Train : 3.72059e-02 	 Res : 1.67581e-02 	 Jac : 1.34793e-02 	 Enc : 1.18070e-04 	 AE : 6.85037e-03 	 MSE : 2.76101e+00
Training Epoch 155 finished, took current epoch 381.85s, cumulative time 58160.24s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
Epoch 156, 25% 	 Loss : 5.3764e-02 	 Res : 3.1795e-02 	 Jac : 1.3378e-02 	 Enc : 3.3206e-04 	 AEnc : 8.2593e-03 	 MSE : 6.5106e+00
Epoch 156, 50% 	 Loss : 6.2346e-02 	 Res : 1.6227e-02 	 Jac : 1.3373e-02 	 Enc : 2.7661e-04 	 AEnc : 3.2469e-02 	 MSE : 1.7944e+00
Epoch 156, 75% 	 Loss : 1.3185e-01 	 Res : 2.8263e-02 	 Jac : 1.3417e-02 	 Enc : 5.0129e-04 	 AEnc : 8.9666e-02 	 MSE : 2.4591e+00
Training Epoch 156 : 	 Train : 7.44409e-02 	 Res : 2.26407e-02 	 Jac : 1.33684e-02 	 Enc : 3.84855e-04 	 AE : 3.80469e-02 	 MSE : 3.15767e+00
Validation Epoch 156 : 	 Train : 2.98791e-02 	 Res : 7.93551e-03 	 Jac : 1.33642e-02 	 Enc : 1.23969e-04 	 AE : 8.45538e-03 	 MSE : 4.82570e-01
Training Epoch 156 finished, took current epoch 381.18s, cumulative time 58541.38s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
Epoch 157, 25% 	 Loss : 5.2288e-02 	 Res : 1.3764e-02 	 Jac : 1.3289e-02 	 Enc : 1.6431e-04 	 AEnc : 2.5071e-02 	 MSE : 1.6738e+00
Epoch 157, 50% 	 Loss : 1.0128e-01 	 Res : 2.0957e-02 	 Jac : 1.3241e-02 	 Enc : 8.8967e-04 	 AEnc : 6.6191e-02 	 MSE : 1.5856e+00
Epoch 157, 75% 	 Loss : 3.6216e-02 	 Res : 1.1824e-02 	 Jac : 1.3363e-02 	 Enc : 9.3032e-04 	 AEnc : 1.0098e-02 	 MSE : 1.7882e+00
Training Epoch 157 : 	 Train : 5.63936e-02 	 Res : 1.45138e-02 	 Jac : 1.32759e-02 	 Enc : 5.43285e-04 	 AE : 2.80606e-02 	 MSE : 1.70669e+00
Validation Epoch 157 : 	 Train : 2.33109e-02 	 Res : 7.89706e-03 	 Jac : 1.30677e-02 	 Enc : 5.36448e-04 	 AE : 1.80971e-03 	 MSE : 1.34315e+00
Training Epoch 157 finished, took current epoch 369.77s, cumulative time 58911.11s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
Epoch 158, 25% 	 Loss : 5.5187e-02 	 Res : 2.2067e-02 	 Jac : 1.3188e-02 	 Enc : 3.5408e-04 	 AEnc : 1.9578e-02 	 MSE : 2.9313e+00
Epoch 158, 50% 	 Loss : 4.7251e-02 	 Res : 2.6136e-02 	 Jac : 1.3159e-02 	 Enc : 3.9178e-04 	 AEnc : 7.5642e-03 	 MSE : 4.9548e+00
Epoch 158, 75% 	 Loss : 4.2977e-02 	 Res : 2.7821e-02 	 Jac : 1.3177e-02 	 Enc : 5.9681e-04 	 AEnc : 1.3823e-03 	 MSE : 5.2325e+00
Training Epoch 158 : 	 Train : 5.49719e-02 	 Res : 3.11203e-02 	 Jac : 1.32106e-02 	 Enc : 4.88836e-04 	 AE : 1.01522e-02 	 MSE : 4.81679e+00
Validation Epoch 158 : 	 Train : 5.37490e-02 	 Res : 2.61015e-02 	 Jac : 1.30130e-02 	 Enc : 6.05382e-04 	 AE : 1.40292e-02 	 MSE : 5.53230e+00
Training Epoch 158 finished, took current epoch 388.29s, cumulative time 59299.37s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
Epoch 159, 25% 	 Loss : 4.1595e-02 	 Res : 1.7022e-02 	 Jac : 1.3241e-02 	 Enc : 3.0530e-04 	 AEnc : 1.1027e-02 	 MSE : 2.8375e+00
Epoch 159, 50% 	 Loss : 3.6514e-02 	 Res : 1.9193e-02 	 Jac : 1.3365e-02 	 Enc : 2.2541e-04 	 AEnc : 3.7311e-03 	 MSE : 3.2715e+00
Epoch 159, 75% 	 Loss : 1.0960e-01 	 Res : 8.2047e-02 	 Jac : 1.3328e-02 	 Enc : 3.5860e-04 	 AEnc : 1.3862e-02 	 MSE : 1.1261e+01
Training Epoch 159 : 	 Train : 5.72853e-02 	 Res : 3.31274e-02 	 Jac : 1.33331e-02 	 Enc : 2.97419e-04 	 AE : 1.05274e-02 	 MSE : 4.87369e+00
Validation Epoch 159 : 	 Train : 2.93037e-02 	 Res : 7.64024e-03 	 Jac : 1.32696e-02 	 Enc : 9.33638e-05 	 AE : 8.30058e-03 	 MSE : 8.61930e-01
Training Epoch 159 finished, took current epoch 385.27s, cumulative time 59684.61s
Current Learning rate DEQ : 0.002097152000000001
Current Learning rate AUTOENC : 0.010485760000000005
Epoch 160, 25% 	 Loss : 2.7777e-02 	 Res : 1.1546e-02 	 Jac : 1.3378e-02 	 Enc : 7.8083e-05 	 AEnc : 2.7742e-03 	 MSE : 2.1666e+00
Epoch 160, 50% 	 Loss : 4.4177e-02 	 Res : 2.0209e-02 	 Jac : 1.3300e-02 	 Enc : 2.3816e-04 	 AEnc : 1.0429e-02 	 MSE : 3.8233e+00
Epoch 160, 75% 	 Loss : 1.0580e-01 	 Res : 3.1081e-02 	 Jac : 1.3262e-02 	 Enc : 4.1420e-04 	 AEnc : 6.1043e-02 	 MSE : 4.5881e+00
Training Epoch 160 : 	 Train : 5.85245e-02 	 Res : 2.16358e-02 	 Jac : 1.33093e-02 	 Enc : 2.38501e-04 	 AE : 2.33409e-02 	 MSE : 3.85911e+00
Validation Epoch 160 : 	 Train : 5.84037e-02 	 Res : 3.79876e-02 	 Jac : 1.32499e-02 	 Enc : 2.76048e-04 	 AE : 6.89019e-03 	 MSE : 9.53172e+00
Training Epoch 160 finished, took current epoch 380.19s, cumulative time 60064.76s
Current Learning rate DEQ : 0.001677721600000001
Current Learning rate AUTOENC : 0.008388608000000004
Epoch 161, 25% 	 Loss : 7.5668e-02 	 Res : 2.0400e-02 	 Jac : 1.3293e-02 	 Enc : 2.3605e-04 	 AEnc : 4.1739e-02 	 MSE : 2.5877e+00
Epoch 161, 50% 	 Loss : 3.7660e-02 	 Res : 1.0874e-02 	 Jac : 1.3350e-02 	 Enc : 1.3234e-04 	 AEnc : 1.3304e-02 	 MSE : 1.5001e+00
Epoch 161, 75% 	 Loss : 4.1838e-02 	 Res : 1.3761e-02 	 Jac : 1.3283e-02 	 Enc : 1.0031e-04 	 AEnc : 1.4693e-02 	 MSE : 2.0141e+00
Training Epoch 161 : 	 Train : 4.73543e-02 	 Res : 1.51073e-02 	 Jac : 1.33021e-02 	 Enc : 1.43458e-04 	 AE : 1.88014e-02 	 MSE : 2.38838e+00
Validation Epoch 161 : 	 Train : 3.47616e-02 	 Res : 1.96153e-02 	 Jac : 1.31502e-02 	 Enc : 6.94798e-05 	 AE : 1.92662e-03 	 MSE : 5.26846e+00
Training Epoch 161 finished, took current epoch 365.04s, cumulative time 60429.77s
Current Learning rate DEQ : 0.001677721600000001
Current Learning rate AUTOENC : 0.008388608000000004
Epoch 162, 25% 	 Loss : 2.9336e-02 	 Res : 1.4319e-02 	 Jac : 1.3280e-02 	 Enc : 9.4767e-05 	 AEnc : 1.6427e-03 	 MSE : 3.2256e+00
Epoch 162, 50% 	 Loss : 2.5932e-02 	 Res : 1.1960e-02 	 Jac : 1.3282e-02 	 Enc : 6.1613e-05 	 AEnc : 6.2771e-04 	 MSE : 2.3697e+00
Epoch 162, 75% 	 Loss : 2.2857e-02 	 Res : 9.3854e-03 	 Jac : 1.3187e-02 	 Enc : 1.0803e-04 	 AEnc : 1.7680e-04 	 MSE : 1.6045e+00
Training Epoch 162 : 	 Train : 2.54865e-02 	 Res : 1.15212e-02 	 Jac : 1.32348e-02 	 Enc : 7.99172e-05 	 AE : 6.50561e-04 	 MSE : 2.31836e+00
Validation Epoch 162 : 	 Train : 3.42088e-02 	 Res : 2.07790e-02 	 Jac : 1.32687e-02 	 Enc : 4.34820e-05 	 AE : 1.17606e-04 	 MSE : 5.29299e+00
Training Epoch 162 finished, took current epoch 372.60s, cumulative time 60802.34s
Current Learning rate DEQ : 0.001677721600000001
Current Learning rate AUTOENC : 0.008388608000000004
Epoch 163, 25% 	 Loss : 3.1155e-02 	 Res : 1.7569e-02 	 Jac : 1.3143e-02 	 Enc : 1.1219e-04 	 AEnc : 3.3093e-04 	 MSE : 4.2684e+00
Epoch 163, 50% 	 Loss : 5.5348e-02 	 Res : 4.1163e-02 	 Jac : 1.3080e-02 	 Enc : 3.4247e-04 	 AEnc : 7.6201e-04 	 MSE : 1.0225e+01
Epoch 163, 75% 	 Loss : 2.3030e-02 	 Res : 9.3943e-03 	 Jac : 1.3222e-02 	 Enc : 1.9368e-04 	 AEnc : 2.1980e-04 	 MSE : 1.5435e+00
Training Epoch 163 : 	 Train : 3.31945e-02 	 Res : 1.94350e-02 	 Jac : 1.31564e-02 	 Enc : 1.75822e-04 	 AE : 4.27223e-04 	 MSE : 4.47052e+00
Validation Epoch 163 : 	 Train : 2.20471e-02 	 Res : 8.41935e-03 	 Jac : 1.32024e-02 	 Enc : 4.29750e-05 	 AE : 3.82385e-04 	 MSE : 1.17134e+00
Training Epoch 163 finished, took current epoch 379.53s, cumulative time 61181.85s
Current Learning rate DEQ : 0.001677721600000001
Current Learning rate AUTOENC : 0.008388608000000004
Epoch 164, 25% 	 Loss : 2.2014e-02 	 Res : 8.5720e-03 	 Jac : 1.3130e-02 	 Enc : 4.6365e-05 	 AEnc : 2.6607e-04 	 MSE : 1.5724e+00
Epoch 164, 50% 	 Loss : 2.7279e-02 	 Res : 1.2331e-02 	 Jac : 1.3212e-02 	 Enc : 7.0798e-05 	 AEnc : 1.6654e-03 	 MSE : 2.3130e+00
Epoch 164, 75% 	 Loss : 4.4666e-02 	 Res : 1.1246e-02 	 Jac : 1.3203e-02 	 Enc : 1.2732e-04 	 AEnc : 2.0091e-02 	 MSE : 1.2128e+00
Training Epoch 164 : 	 Train : 3.89911e-02 	 Res : 1.12055e-02 	 Jac : 1.31919e-02 	 Enc : 9.30138e-05 	 AE : 1.45007e-02 	 MSE : 1.48267e+00
Validation Epoch 164 : 	 Train : 2.50962e-02 	 Res : 9.38476e-03 	 Jac : 1.30694e-02 	 Enc : 4.62936e-05 	 AE : 2.59579e-03 	 MSE : 1.68965e+00
Training Epoch 164 finished, took current epoch 370.28s, cumulative time 61552.09s
Current Learning rate DEQ : 0.001677721600000001
Current Learning rate AUTOENC : 0.008388608000000004
Epoch 165, 25% 	 Loss : 4.3587e-01 	 Res : 3.7839e-01 	 Jac : 1.3082e-02 	 Enc : 8.7462e-04 	 AEnc : 4.3524e-02 	 MSE : 3.4658e+01
Epoch 165, 50% 	 Loss : 4.3634e-02 	 Res : 1.3881e-02 	 Jac : 1.3204e-02 	 Enc : 6.1231e-04 	 AEnc : 1.5936e-02 	 MSE : 1.6864e+00
Epoch 165, 75% 	 Loss : 3.8740e-02 	 Res : 1.3275e-02 	 Jac : 1.3129e-02 	 Enc : 2.0375e-04 	 AEnc : 1.2132e-02 	 MSE : 2.3440e+00
Training Epoch 165 : 	 Train : 1.40551e-01 	 Res : 1.08315e-01 	 Jac : 1.31423e-02 	 Enc : 4.60120e-04 	 AE : 1.86338e-02 	 MSE : 1.09105e+01
Validation Epoch 165 : 	 Train : 2.23609e-02 	 Res : 9.13277e-03 	 Jac : 1.30236e-02 	 Enc : 9.44445e-05 	 AE : 1.10053e-04 	 MSE : 1.79981e+00
Training Epoch 165 finished, took current epoch 382.21s, cumulative time 61934.24s
Current Learning rate DEQ : 0.001677721600000001
Current Learning rate AUTOENC : 0.008388608000000004
Epoch 166, 25% 	 Loss : 3.2354e-02 	 Res : 1.1669e-02 	 Jac : 1.3125e-02 	 Enc : 1.0569e-04 	 AEnc : 7.4544e-03 	 MSE : 2.0318e+00
Epoch 166, 50% 	 Loss : 3.7944e-02 	 Res : 1.6123e-02 	 Jac : 1.3057e-02 	 Enc : 1.2067e-04 	 AEnc : 8.6429e-03 	 MSE : 3.5494e+00
Epoch 166, 75% 	 Loss : 3.4588e-02 	 Res : 1.6724e-02 	 Jac : 1.3175e-02 	 Enc : 1.6570e-04 	 AEnc : 4.5240e-03 	 MSE : 3.3310e+00
Training Epoch 166 : 	 Train : 3.44375e-02 	 Res : 1.54659e-02 	 Jac : 1.31158e-02 	 Enc : 1.39404e-04 	 AE : 5.71642e-03 	 MSE : 3.11257e+00
Validation Epoch 166 : 	 Train : 3.14134e-02 	 Res : 1.48907e-02 	 Jac : 1.32397e-02 	 Enc : 1.92886e-04 	 AE : 3.09017e-03 	 MSE : 2.96916e+00
Training Epoch 166 finished, took current epoch 382.20s, cumulative time 62316.40s
Current Learning rate DEQ : 0.001677721600000001
Current Learning rate AUTOENC : 0.008388608000000004
Epoch 167, 25% 	 Loss : 3.3606e-02 	 Res : 1.4813e-02 	 Jac : 1.3232e-02 	 Enc : 1.6637e-04 	 AEnc : 5.3954e-03 	 MSE : 3.1564e+00
Epoch 167, 50% 	 Loss : 1.2089e-01 	 Res : 6.3472e-02 	 Jac : 1.3207e-02 	 Enc : 5.0958e-04 	 AEnc : 4.3699e-02 	 MSE : 1.3123e+01
Epoch 167, 75% 	 Loss : 4.5748e-02 	 Res : 2.2362e-02 	 Jac : 1.3385e-02 	 Enc : 3.1228e-04 	 AEnc : 9.6887e-03 	 MSE : 4.1778e+00
Training Epoch 167 : 	 Train : 6.00623e-02 	 Res : 2.99776e-02 	 Jac : 1.33096e-02 	 Enc : 3.11853e-04 	 AE : 1.64632e-02 	 MSE : 6.09063e+00
Validation Epoch 167 : 	 Train : 2.24997e-02 	 Res : 7.29358e-03 	 Jac : 1.32533e-02 	 Enc : 1.27208e-04 	 AE : 1.82554e-03 	 MSE : 1.23704e+00
Training Epoch 167 finished, took current epoch 372.41s, cumulative time 62688.79s
Current Learning rate DEQ : 0.001677721600000001
Current Learning rate AUTOENC : 0.008388608000000004
Epoch 168, 25% 	 Loss : 2.8829e-02 	 Res : 1.3766e-02 	 Jac : 1.3297e-02 	 Enc : 1.2492e-04 	 AEnc : 1.6415e-03 	 MSE : 2.9830e+00
Epoch 168, 50% 	 Loss : 5.2262e-02 	 Res : 1.9499e-02 	 Jac : 1.3187e-02 	 Enc : 1.4706e-04 	 AEnc : 1.9428e-02 	 MSE : 3.3940e+00
Epoch 168, 75% 	 Loss : 3.4666e-02 	 Res : 1.8830e-02 	 Jac : 1.3230e-02 	 Enc : 1.6909e-04 	 AEnc : 2.4373e-03 	 MSE : 3.6668e+00
Training Epoch 168 : 	 Train : 3.65103e-02 	 Res : 1.63372e-02 	 Jac : 1.32491e-02 	 Enc : 1.45772e-04 	 AE : 6.77821e-03 	 MSE : 3.07522e+00
Validation Epoch 168 : 	 Train : 4.21461e-02 	 Res : 8.77133e-03 	 Jac : 1.32088e-02 	 Enc : 1.22920e-04 	 AE : 2.00431e-02 	 MSE : 4.08704e-01
Training Epoch 168 finished, took current epoch 373.67s, cumulative time 63062.41s
Current Learning rate DEQ : 0.001677721600000001
Current Learning rate AUTOENC : 0.008388608000000004
Epoch 169, 25% 	 Loss : 5.2801e-02 	 Res : 1.3837e-02 	 Jac : 1.3251e-02 	 Enc : 1.4210e-04 	 AEnc : 2.5571e-02 	 MSE : 1.6348e+00
Epoch 169, 50% 	 Loss : 3.8448e-02 	 Res : 1.1822e-02 	 Jac : 1.3277e-02 	 Enc : 8.6153e-05 	 AEnc : 1.3264e-02 	 MSE : 1.7247e+00
Epoch 169, 75% 	 Loss : 3.5251e-02 	 Res : 1.1487e-02 	 Jac : 1.3205e-02 	 Enc : 9.7376e-05 	 AEnc : 1.0461e-02 	 MSE : 1.8204e+00
Training Epoch 169 : 	 Train : 3.88859e-02 	 Res : 1.18857e-02 	 Jac : 1.32204e-02 	 Enc : 9.98949e-05 	 AE : 1.36799e-02 	 MSE : 1.74268e+00
Validation Epoch 169 : 	 Train : 2.41268e-02 	 Res : 7.98760e-03 	 Jac : 1.31850e-02 	 Enc : 7.04324e-05 	 AE : 2.88371e-03 	 MSE : 1.07746e+00
Training Epoch 169 finished, took current epoch 376.23s, cumulative time 63438.61s
Current Learning rate DEQ : 0.001677721600000001
Current Learning rate AUTOENC : 0.008388608000000004
Epoch 170, 25% 	 Loss : 3.3881e-02 	 Res : 1.7779e-02 	 Jac : 1.3189e-02 	 Enc : 8.0705e-05 	 AEnc : 2.8327e-03 	 MSE : 4.3312e+00
Epoch 170, 50% 	 Loss : 3.1339e-02 	 Res : 1.7257e-02 	 Jac : 1.3233e-02 	 Enc : 1.3160e-04 	 AEnc : 7.1851e-04 	 MSE : 3.8765e+00
Epoch 170, 75% 	 Loss : 4.8084e-02 	 Res : 3.4159e-02 	 Jac : 1.3124e-02 	 Enc : 1.6462e-04 	 AEnc : 6.3601e-04 	 MSE : 8.7238e+00
Training Epoch 170 : 	 Train : 5.10982e-02 	 Res : 3.11669e-02 	 Jac : 1.31901e-02 	 Enc : 2.13265e-04 	 AE : 6.52798e-03 	 MSE : 7.09168e+00
Validation Epoch 170 : 	 Train : 2.83701e-02 	 Res : 1.40449e-02 	 Jac : 1.33051e-02 	 Enc : 4.15851e-04 	 AE : 6.04213e-04 	 MSE : 1.81735e+00
Training Epoch 170 finished, took current epoch 381.63s, cumulative time 63820.17s
Current Learning rate DEQ : 0.001677721600000001
Current Learning rate AUTOENC : 0.008388608000000004
Epoch 171, 25% 	 Loss : 5.0232e-02 	 Res : 1.9929e-02 	 Jac : 1.3327e-02 	 Enc : 3.1198e-04 	 AEnc : 1.6665e-02 	 MSE : 4.0438e+00
Epoch 171, 50% 	 Loss : 3.0000e-02 	 Res : 1.2243e-02 	 Jac : 1.3383e-02 	 Enc : 1.1009e-04 	 AEnc : 4.2631e-03 	 MSE : 2.3087e+00
Epoch 171, 75% 	 Loss : 5.7162e-02 	 Res : 2.4713e-02 	 Jac : 1.3293e-02 	 Enc : 1.9635e-04 	 AEnc : 1.8960e-02 	 MSE : 4.2018e+00
Training Epoch 171 : 	 Train : 4.45895e-02 	 Res : 1.85576e-02 	 Jac : 1.33081e-02 	 Enc : 1.94285e-04 	 AE : 1.25295e-02 	 MSE : 3.62975e+00
Validation Epoch 171 : 	 Train : 2.62601e-02 	 Res : 1.11312e-02 	 Jac : 1.31152e-02 	 Enc : 9.01705e-05 	 AE : 1.92360e-03 	 MSE : 2.58170e+00
Training Epoch 171 finished, took current epoch 372.66s, cumulative time 64192.79s
Current Learning rate DEQ : 0.0013421772800000008
Current Learning rate AUTOENC : 0.006710886400000004
Epoch 172, 25% 	 Loss : 2.7109e-02 	 Res : 1.3152e-02 	 Jac : 1.3317e-02 	 Enc : 6.7678e-05 	 AEnc : 5.7251e-04 	 MSE : 3.0118e+00
Epoch 172, 50% 	 Loss : 4.0406e-02 	 Res : 1.3444e-02 	 Jac : 1.3225e-02 	 Enc : 9.7589e-05 	 AEnc : 1.3639e-02 	 MSE : 2.0317e+00
Epoch 172, 75% 	 Loss : 2.8682e-02 	 Res : 8.3512e-03 	 Jac : 1.3306e-02 	 Enc : 5.9886e-05 	 AEnc : 6.9653e-03 	 MSE : 1.0929e+00
Training Epoch 172 : 	 Train : 3.13248e-02 	 Res : 1.07173e-02 	 Jac : 1.32594e-02 	 Enc : 6.97528e-05 	 AE : 7.27832e-03 	 MSE : 1.75622e+00
Validation Epoch 172 : 	 Train : 2.75015e-02 	 Res : 1.01436e-02 	 Jac : 1.32416e-02 	 Enc : 5.04499e-05 	 AE : 4.06573e-03 	 MSE : 1.35852e+00
Training Epoch 172 finished, took current epoch 378.14s, cumulative time 64570.90s
Current Learning rate DEQ : 0.0013421772800000008
Current Learning rate AUTOENC : 0.006710886400000004
Epoch 173, 25% 	 Loss : 4.8126e-02 	 Res : 1.3598e-02 	 Jac : 1.3100e-02 	 Enc : 7.5370e-05 	 AEnc : 2.1353e-02 	 MSE : 1.8552e+00
Epoch 173, 50% 	 Loss : 3.2334e-02 	 Res : 9.5959e-03 	 Jac : 1.3176e-02 	 Enc : 8.0025e-05 	 AEnc : 9.4822e-03 	 MSE : 1.2424e+00
Epoch 173, 75% 	 Loss : 2.9201e-02 	 Res : 1.2694e-02 	 Jac : 1.3108e-02 	 Enc : 1.1511e-04 	 AEnc : 3.2845e-03 	 MSE : 2.3245e+00
Training Epoch 173 : 	 Train : 3.36117e-02 	 Res : 1.13590e-02 	 Jac : 1.31177e-02 	 Enc : 9.31341e-05 	 AE : 9.04187e-03 	 MSE : 1.74513e+00
Validation Epoch 173 : 	 Train : 2.67537e-02 	 Res : 9.46696e-03 	 Jac : 1.31715e-02 	 Enc : 1.08143e-04 	 AE : 4.00719e-03 	 MSE : 1.08590e+00
Training Epoch 173 finished, took current epoch 384.55s, cumulative time 64955.43s
Current Learning rate DEQ : 0.0013421772800000008
Current Learning rate AUTOENC : 0.006710886400000004
Epoch 174, 25% 	 Loss : 2.5323e-02 	 Res : 1.0553e-02 	 Jac : 1.3117e-02 	 Enc : 5.3749e-05 	 AEnc : 1.5991e-03 	 MSE : 2.1150e+00
Epoch 174, 50% 	 Loss : 2.8758e-02 	 Res : 1.2260e-02 	 Jac : 1.3029e-02 	 Enc : 7.0131e-05 	 AEnc : 3.3983e-03 	 MSE : 2.3735e+00
Epoch 174, 75% 	 Loss : 2.4516e-02 	 Res : 8.3931e-03 	 Jac : 1.3041e-02 	 Enc : 6.0346e-05 	 AEnc : 3.0209e-03 	 MSE : 1.2991e+00
Training Epoch 174 : 	 Train : 2.94307e-02 	 Res : 1.28647e-02 	 Jac : 1.30551e-02 	 Enc : 7.57441e-05 	 AE : 3.43515e-03 	 MSE : 2.48411e+00
Validation Epoch 174 : 	 Train : 2.82140e-02 	 Res : 1.39426e-02 	 Jac : 1.29721e-02 	 Enc : 8.75558e-05 	 AE : 1.21171e-03 	 MSE : 3.27427e+00
Training Epoch 174 finished, took current epoch 382.74s, cumulative time 65338.14s
Current Learning rate DEQ : 0.0013421772800000008
Current Learning rate AUTOENC : 0.006710886400000004
Epoch 175, 25% 	 Loss : 2.2338e-02 	 Res : 8.5215e-03 	 Jac : 1.3157e-02 	 Enc : 7.7612e-05 	 AEnc : 5.8139e-04 	 MSE : 1.5089e+00
Epoch 175, 50% 	 Loss : 2.7279e-02 	 Res : 1.3920e-02 	 Jac : 1.3055e-02 	 Enc : 5.2891e-05 	 AEnc : 2.5160e-04 	 MSE : 3.4392e+00
Epoch 175, 75% 	 Loss : 2.7416e-02 	 Res : 1.4138e-02 	 Jac : 1.3139e-02 	 Enc : 7.0698e-05 	 AEnc : 6.8392e-05 	 MSE : 3.3991e+00
Training Epoch 175 : 	 Train : 2.57396e-02 	 Res : 1.22997e-02 	 Jac : 1.31062e-02 	 Enc : 6.46625e-05 	 AE : 2.69058e-04 	 MSE : 2.81792e+00
Validation Epoch 175 : 	 Train : 2.52016e-02 	 Res : 1.18252e-02 	 Jac : 1.30079e-02 	 Enc : 4.06230e-05 	 AE : 3.27903e-04 	 MSE : 2.55289e+00
Training Epoch 175 finished, took current epoch 370.02s, cumulative time 65708.12s
Current Learning rate DEQ : 0.0013421772800000008
Current Learning rate AUTOENC : 0.006710886400000004
Epoch 176, 25% 	 Loss : 2.8449e-02 	 Res : 1.5162e-02 	 Jac : 1.3043e-02 	 Enc : 7.4481e-05 	 AEnc : 1.6873e-04 	 MSE : 3.3950e+00
Epoch 176, 50% 	 Loss : 2.8685e-02 	 Res : 1.2624e-02 	 Jac : 1.3093e-02 	 Enc : 1.1178e-04 	 AEnc : 2.8571e-03 	 MSE : 2.4159e+00
Epoch 176, 75% 	 Loss : 4.6611e-02 	 Res : 2.9388e-02 	 Jac : 1.3095e-02 	 Enc : 1.3987e-04 	 AEnc : 3.9882e-03 	 MSE : 8.1265e+00
Training Epoch 176 : 	 Train : 3.82661e-02 	 Res : 2.15980e-02 	 Jac : 1.30783e-02 	 Enc : 1.29884e-04 	 AE : 3.45998e-03 	 MSE : 5.36112e+00
Validation Epoch 176 : 	 Train : 3.59085e-02 	 Res : 1.98425e-02 	 Jac : 1.30574e-02 	 Enc : 1.55323e-04 	 AE : 2.85330e-03 	 MSE : 4.99931e+00
Training Epoch 176 finished, took current epoch 378.08s, cumulative time 66086.15s
Current Learning rate DEQ : 0.0013421772800000008
Current Learning rate AUTOENC : 0.006710886400000004
Epoch 177, 25% 	 Loss : 3.9375e-02 	 Res : 1.2216e-02 	 Jac : 1.3059e-02 	 Enc : 1.6107e-04 	 AEnc : 1.3939e-02 	 MSE : 1.7222e+00
Epoch 177, 50% 	 Loss : 4.7762e-02 	 Res : 1.7476e-02 	 Jac : 1.3029e-02 	 Enc : 9.1306e-05 	 AEnc : 1.7166e-02 	 MSE : 3.5733e+00
Epoch 177, 75% 	 Loss : 3.0235e-02 	 Res : 1.3544e-02 	 Jac : 1.3058e-02 	 Enc : 7.4448e-05 	 AEnc : 3.5583e-03 	 MSE : 3.0645e+00
Training Epoch 177 : 	 Train : 3.59131e-02 	 Res : 1.38156e-02 	 Jac : 1.30603e-02 	 Enc : 9.92931e-05 	 AE : 8.93795e-03 	 MSE : 2.73438e+00
Validation Epoch 177 : 	 Train : 2.02904e-02 	 Res : 6.93200e-03 	 Jac : 1.30425e-02 	 Enc : 7.10064e-05 	 AE : 2.44873e-04 	 MSE : 9.89567e-01
Training Epoch 177 finished, took current epoch 377.76s, cumulative time 66463.89s
Current Learning rate DEQ : 0.0013421772800000008
Current Learning rate AUTOENC : 0.006710886400000004
Epoch 178, 25% 	 Loss : 2.7584e-02 	 Res : 1.4301e-02 	 Jac : 1.3124e-02 	 Enc : 6.5446e-05 	 AEnc : 9.4384e-05 	 MSE : 3.4795e+00
Epoch 178, 50% 	 Loss : 2.5933e-02 	 Res : 1.2688e-02 	 Jac : 1.3086e-02 	 Enc : 5.9966e-05 	 AEnc : 9.9309e-05 	 MSE : 2.7611e+00
Epoch 178, 75% 	 Loss : 2.1691e-02 	 Res : 8.4209e-03 	 Jac : 1.3057e-02 	 Enc : 7.1334e-05 	 AEnc : 1.4176e-04 	 MSE : 1.4595e+00
Training Epoch 178 : 	 Train : 2.47566e-02 	 Res : 1.12417e-02 	 Jac : 1.30752e-02 	 Enc : 7.79932e-05 	 AE : 3.61719e-04 	 MSE : 2.35307e+00
Validation Epoch 178 : 	 Train : 2.13460e-02 	 Res : 7.78626e-03 	 Jac : 1.31184e-02 	 Enc : 5.47906e-05 	 AE : 3.86587e-04 	 MSE : 1.06731e+00
Training Epoch 178 finished, took current epoch 382.84s, cumulative time 66846.71s
Current Learning rate DEQ : 0.0013421772800000008
Current Learning rate AUTOENC : 0.006710886400000004
Epoch 179, 25% 	 Loss : 2.2332e-02 	 Res : 8.8174e-03 	 Jac : 1.3115e-02 	 Enc : 5.1237e-05 	 AEnc : 3.4837e-04 	 MSE : 1.6051e+00
Epoch 179, 50% 	 Loss : 2.1751e-02 	 Res : 8.1097e-03 	 Jac : 1.3127e-02 	 Enc : 3.7818e-05 	 AEnc : 4.7706e-04 	 MSE : 1.4298e+00
Epoch 179, 75% 	 Loss : 2.2397e-02 	 Res : 7.6399e-03 	 Jac : 1.3029e-02 	 Enc : 3.7332e-05 	 AEnc : 1.6912e-03 	 MSE : 1.1449e+00
Training Epoch 179 : 	 Train : 2.53714e-02 	 Res : 9.72319e-03 	 Jac : 1.30903e-02 	 Enc : 4.66326e-05 	 AE : 2.51130e-03 	 MSE : 1.83344e+00
Validation Epoch 179 : 	 Train : 2.72674e-02 	 Res : 1.35755e-02 	 Jac : 1.29807e-02 	 Enc : 4.55271e-05 	 AE : 6.65635e-04 	 MSE : 3.18717e+00
Training Epoch 179 finished, took current epoch 375.37s, cumulative time 67222.07s
Current Learning rate DEQ : 0.0013421772800000008
Current Learning rate AUTOENC : 0.006710886400000004
Epoch 180, 25% 	 Loss : 4.0292e-02 	 Res : 2.5740e-02 	 Jac : 1.3027e-02 	 Enc : 8.1802e-05 	 AEnc : 1.4438e-03 	 MSE : 5.7815e+00
Epoch 180, 50% 	 Loss : 4.8238e-02 	 Res : 1.5524e-02 	 Jac : 1.3019e-02 	 Enc : 1.5342e-04 	 AEnc : 1.9542e-02 	 MSE : 2.3575e+00
Epoch 180, 75% 	 Loss : 3.3593e-02 	 Res : 9.4132e-03 	 Jac : 1.3088e-02 	 Enc : 9.6988e-05 	 AEnc : 1.0995e-02 	 MSE : 1.3085e+00
Training Epoch 180 : 	 Train : 3.61427e-02 	 Res : 1.46341e-02 	 Jac : 1.30511e-02 	 Enc : 9.15838e-05 	 AE : 8.36599e-03 	 MSE : 2.69739e+00
Validation Epoch 180 : 	 Train : 2.30288e-02 	 Res : 8.28327e-03 	 Jac : 1.30093e-02 	 Enc : 2.69590e-05 	 AE : 1.70932e-03 	 MSE : 1.44569e+00
Training Epoch 180 finished, took current epoch 387.57s, cumulative time 67609.58s
Current Learning rate DEQ : 0.0013421772800000008
Current Learning rate AUTOENC : 0.006710886400000004
Epoch 181, 25% 	 Loss : 2.1285e-02 	 Res : 7.1050e-03 	 Jac : 1.3022e-02 	 Enc : 2.6818e-05 	 AEnc : 1.1310e-03 	 MSE : 1.1941e+00
Epoch 181, 50% 	 Loss : 2.0267e-02 	 Res : 7.0769e-03 	 Jac : 1.3048e-02 	 Enc : 2.2233e-05 	 AEnc : 1.1901e-04 	 MSE : 1.2228e+00
Epoch 181, 75% 	 Loss : 2.0897e-02 	 Res : 7.8415e-03 	 Jac : 1.2973e-02 	 Enc : 2.7854e-05 	 AEnc : 5.4463e-05 	 MSE : 1.3663e+00
Training Epoch 181 : 	 Train : 2.08345e-02 	 Res : 7.42389e-03 	 Jac : 1.30299e-02 	 Enc : 2.69525e-05 	 AE : 3.53733e-04 	 MSE : 1.27442e+00
Validation Epoch 181 : 	 Train : 1.89923e-02 	 Res : 5.84437e-03 	 Jac : 1.30645e-02 	 Enc : 3.28385e-05 	 AE : 5.06036e-05 	 MSE : 8.52796e-01
Training Epoch 181 finished, took current epoch 373.37s, cumulative time 67982.84s
Current Learning rate DEQ : 0.0013421772800000008
Current Learning rate AUTOENC : 0.006710886400000004
MODEL SAVED
Epoch 182, 25% 	 Loss : 2.7920e-02 	 Res : 1.2281e-02 	 Jac : 1.2924e-02 	 Enc : 4.9716e-05 	 AEnc : 2.6659e-03 	 MSE : 2.4751e+00
Epoch 182, 50% 	 Loss : 3.6126e-02 	 Res : 1.5673e-02 	 Jac : 1.2889e-02 	 Enc : 8.8422e-05 	 AEnc : 7.4756e-03 	 MSE : 3.5477e+00
Epoch 182, 75% 	 Loss : 4.3145e-02 	 Res : 1.2669e-02 	 Jac : 1.3038e-02 	 Enc : 1.0662e-04 	 AEnc : 1.7331e-02 	 MSE : 1.8005e+00
Training Epoch 182 : 	 Train : 3.60035e-02 	 Res : 1.58946e-02 	 Jac : 1.29412e-02 	 Enc : 8.48885e-05 	 AE : 7.08284e-03 	 MSE : 3.55135e+00
Validation Epoch 182 : 	 Train : 2.44553e-02 	 Res : 1.12794e-02 	 Jac : 1.29698e-02 	 Enc : 1.15122e-04 	 AE : 9.10174e-05 	 MSE : 2.80272e+00
Training Epoch 182 finished, took current epoch 374.10s, cumulative time 68356.91s
Current Learning rate DEQ : 0.0013421772800000008
Current Learning rate AUTOENC : 0.006710886400000004
Epoch 183, 25% 	 Loss : 4.1685e-02 	 Res : 2.8452e-02 	 Jac : 1.2955e-02 	 Enc : 1.5121e-04 	 AEnc : 1.2639e-04 	 MSE : 8.0985e+00
Epoch 183, 50% 	 Loss : 2.6504e-02 	 Res : 1.2366e-02 	 Jac : 1.3079e-02 	 Enc : 8.9825e-05 	 AEnc : 9.7037e-04 	 MSE : 2.6736e+00
Epoch 183, 75% 	 Loss : 4.6916e-02 	 Res : 3.0285e-02 	 Jac : 1.3020e-02 	 Enc : 1.4486e-04 	 AEnc : 3.4658e-03 	 MSE : 8.1347e+00
Training Epoch 183 : 	 Train : 4.32130e-02 	 Res : 2.25705e-02 	 Jac : 1.30293e-02 	 Enc : 1.27139e-04 	 AE : 7.48607e-03 	 MSE : 5.66775e+00
Validation Epoch 183 : 	 Train : 3.36929e-02 	 Res : 1.45468e-02 	 Jac : 1.30425e-02 	 Enc : 9.87454e-05 	 AE : 6.00483e-03 	 MSE : 3.46707e+00
Training Epoch 183 finished, took current epoch 369.78s, cumulative time 68726.67s
Current Learning rate DEQ : 0.0013421772800000008
Current Learning rate AUTOENC : 0.006710886400000004
Epoch 184, 25% 	 Loss : 5.1606e-02 	 Res : 1.1946e-02 	 Jac : 1.3051e-02 	 Enc : 1.2428e-04 	 AEnc : 2.6485e-02 	 MSE : 1.2586e+00
Epoch 184, 50% 	 Loss : 6.6262e-02 	 Res : 3.5169e-02 	 Jac : 1.2978e-02 	 Enc : 2.4413e-04 	 AEnc : 1.7871e-02 	 MSE : 8.4394e+00
Epoch 184, 75% 	 Loss : 3.9048e-02 	 Res : 1.3839e-02 	 Jac : 1.3037e-02 	 Enc : 2.2770e-04 	 AEnc : 1.1945e-02 	 MSE : 2.3345e+00
Training Epoch 184 : 	 Train : 4.90501e-02 	 Res : 1.95262e-02 	 Jac : 1.30247e-02 	 Enc : 1.81119e-04 	 AE : 1.63181e-02 	 MSE : 3.81563e+00
Validation Epoch 184 : 	 Train : 2.85823e-02 	 Res : 1.02861e-02 	 Jac : 1.31318e-02 	 Enc : 1.43455e-04 	 AE : 5.02085e-03 	 MSE : 1.19734e+00
Training Epoch 184 finished, took current epoch 379.58s, cumulative time 69106.18s
Current Learning rate DEQ : 0.0013421772800000008
Current Learning rate AUTOENC : 0.006710886400000004
Epoch 185, 25% 	 Loss : 3.9270e-02 	 Res : 1.3164e-02 	 Jac : 1.3055e-02 	 Enc : 1.7719e-04 	 AEnc : 1.2875e-02 	 MSE : 2.0162e+00
Epoch 185, 50% 	 Loss : 3.2125e-02 	 Res : 1.1667e-02 	 Jac : 1.3085e-02 	 Enc : 8.8929e-05 	 AEnc : 7.2847e-03 	 MSE : 2.1656e+00
Epoch 185, 75% 	 Loss : 2.2931e-02 	 Res : 7.3684e-03 	 Jac : 1.3100e-02 	 Enc : 3.5913e-05 	 AEnc : 2.4263e-03 	 MSE : 1.2029e+00
Training Epoch 185 : 	 Train : 2.93708e-02 	 Res : 1.04419e-02 	 Jac : 1.30666e-02 	 Enc : 8.43021e-05 	 AE : 5.77805e-03 	 MSE : 1.85046e+00
Validation Epoch 185 : 	 Train : 3.85155e-02 	 Res : 2.53851e-02 	 Jac : 1.30454e-02 	 Enc : 5.73898e-05 	 AE : 2.75808e-05 	 MSE : 7.14348e+00
Training Epoch 185 finished, took current epoch 377.09s, cumulative time 69483.21s
Current Learning rate DEQ : 0.0013421772800000008
Current Learning rate AUTOENC : 0.006710886400000004
Epoch 186, 25% 	 Loss : 3.4844e-02 	 Res : 2.0643e-02 	 Jac : 1.3069e-02 	 Enc : 5.8775e-05 	 AEnc : 1.0737e-03 	 MSE : 5.5249e+00
Epoch 186, 50% 	 Loss : 2.2881e-02 	 Res : 7.8082e-03 	 Jac : 1.3091e-02 	 Enc : 4.8713e-05 	 AEnc : 1.9332e-03 	 MSE : 1.3373e+00
Epoch 186, 75% 	 Loss : 1.9967e-02 	 Res : 6.6857e-03 	 Jac : 1.3085e-02 	 Enc : 2.5525e-05 	 AEnc : 1.7082e-04 	 MSE : 1.1441e+00
Training Epoch 186 : 	 Train : 2.45492e-02 	 Res : 1.06168e-02 	 Jac : 1.30800e-02 	 Enc : 3.95052e-05 	 AE : 8.12870e-04 	 MSE : 2.34087e+00
Validation Epoch 186 : 	 Train : 1.96359e-02 	 Res : 6.60530e-03 	 Jac : 1.29677e-02 	 Enc : 2.25657e-05 	 AE : 4.03463e-05 	 MSE : 1.10415e+00
Training Epoch 186 finished, took current epoch 374.60s, cumulative time 69857.77s
Current Learning rate DEQ : 0.0013421772800000008
Current Learning rate AUTOENC : 0.006710886400000004
Epoch 187, 25% 	 Loss : 2.0078e-02 	 Res : 6.9035e-03 	 Jac : 1.3117e-02 	 Enc : 2.2563e-05 	 AEnc : 3.5046e-05 	 MSE : 1.1998e+00
Epoch 187, 50% 	 Loss : 2.1726e-02 	 Res : 8.1734e-03 	 Jac : 1.2975e-02 	 Enc : 3.3990e-05 	 AEnc : 5.4377e-04 	 MSE : 1.3397e+00
Epoch 187, 75% 	 Loss : 6.6115e-02 	 Res : 2.0540e-02 	 Jac : 1.2944e-02 	 Enc : 1.1749e-04 	 AEnc : 3.2513e-02 	 MSE : 3.6614e+00
Training Epoch 187 : 	 Train : 3.55113e-02 	 Res : 1.13236e-02 	 Jac : 1.29827e-02 	 Enc : 6.59279e-05 	 AE : 1.11390e-02 	 MSE : 1.90175e+00
Validation Epoch 187 : 	 Train : 2.39018e-02 	 Res : 7.14641e-03 	 Jac : 1.29072e-02 	 Enc : 5.46352e-05 	 AE : 3.79360e-03 	 MSE : 9.50420e-01
Training Epoch 187 finished, took current epoch 375.09s, cumulative time 70232.81s
Current Learning rate DEQ : 0.0013421772800000008
Current Learning rate AUTOENC : 0.006710886400000004
Epoch 188, 25% 	 Loss : 3.0585e-02 	 Res : 8.9786e-03 	 Jac : 1.3044e-02 	 Enc : 5.1381e-05 	 AEnc : 8.5107e-03 	 MSE : 1.3371e+00
Epoch 188, 50% 	 Loss : 2.4187e-02 	 Res : 8.2354e-03 	 Jac : 1.2937e-02 	 Enc : 3.3710e-05 	 AEnc : 2.9806e-03 	 MSE : 1.4265e+00
Epoch 188, 75% 	 Loss : 2.2879e-02 	 Res : 9.3938e-03 	 Jac : 1.2939e-02 	 Enc : 3.9725e-05 	 AEnc : 5.0704e-04 	 MSE : 1.7421e+00
Training Epoch 188 : 	 Train : 2.76943e-02 	 Res : 1.15546e-02 	 Jac : 1.29406e-02 	 Enc : 7.15389e-05 	 AE : 3.12759e-03 	 MSE : 2.28672e+00
Validation Epoch 188 : 	 Train : 4.01212e-02 	 Res : 2.69705e-02 	 Jac : 1.29098e-02 	 Enc : 1.47054e-04 	 AE : 9.38418e-05 	 MSE : 7.76270e+00
Training Epoch 188 finished, took current epoch 380.48s, cumulative time 70613.27s
Current Learning rate DEQ : 0.0013421772800000008
Current Learning rate AUTOENC : 0.006710886400000004
Epoch 189, 25% 	 Loss : 2.7314e-02 	 Res : 1.4200e-02 	 Jac : 1.2922e-02 	 Enc : 1.1444e-04 	 AEnc : 7.7590e-05 	 MSE : 3.6920e+00
Epoch 189, 50% 	 Loss : 3.0809e-02 	 Res : 1.7634e-02 	 Jac : 1.3020e-02 	 Enc : 8.7010e-05 	 AEnc : 6.8773e-05 	 MSE : 4.6957e+00
Epoch 189, 75% 	 Loss : 7.5355e-02 	 Res : 6.0082e-02 	 Jac : 1.2950e-02 	 Enc : 3.7677e-04 	 AEnc : 1.9470e-03 	 MSE : 1.6114e+01
Training Epoch 189 : 	 Train : 4.06339e-02 	 Res : 2.64964e-02 	 Jac : 1.29917e-02 	 Enc : 2.17610e-04 	 AE : 9.28227e-04 	 MSE : 6.84845e+00
Validation Epoch 189 : 	 Train : 2.17299e-02 	 Res : 6.75973e-03 	 Jac : 1.29331e-02 	 Enc : 3.62562e-04 	 AE : 1.67447e-03 	 MSE : 7.68425e-01
Training Epoch 189 finished, took current epoch 375.03s, cumulative time 70988.25s
Current Learning rate DEQ : 0.0013421772800000008
Current Learning rate AUTOENC : 0.006710886400000004
Epoch 190, 25% 	 Loss : 4.3959e-02 	 Res : 2.2427e-02 	 Jac : 1.3011e-02 	 Enc : 3.2875e-04 	 AEnc : 8.1912e-03 	 MSE : 5.1740e+00
Epoch 190, 50% 	 Loss : 2.8270e-02 	 Res : 1.3157e-02 	 Jac : 1.3178e-02 	 Enc : 2.3426e-04 	 AEnc : 1.7004e-03 	 MSE : 2.6245e+00
Epoch 190, 75% 	 Loss : 1.2857e-01 	 Res : 2.7889e-02 	 Jac : 1.3109e-02 	 Enc : 4.4783e-04 	 AEnc : 8.7121e-02 	 MSE : 2.7378e+00
Training Epoch 190 : 	 Train : 7.33582e-02 	 Res : 2.16252e-02 	 Jac : 1.30968e-02 	 Enc : 3.57763e-04 	 AE : 3.82784e-02 	 MSE : 3.42147e+00
Validation Epoch 190 : 	 Train : 5.20494e-02 	 Res : 1.41120e-02 	 Jac : 1.30936e-02 	 Enc : 1.30481e-04 	 AE : 2.47134e-02 	 MSE : 1.66559e+00
Training Epoch 190 finished, took current epoch 372.48s, cumulative time 71360.70s
Current Learning rate DEQ : 0.0013421772800000008
Current Learning rate AUTOENC : 0.006710886400000004
Epoch 191, 25% 	 Loss : 2.9831e-02 	 Res : 1.3750e-02 	 Jac : 1.3148e-02 	 Enc : 9.0914e-05 	 AEnc : 2.8420e-03 	 MSE : 3.3650e+00
Epoch 191, 50% 	 Loss : 2.5987e-02 	 Res : 1.2683e-02 	 Jac : 1.3076e-02 	 Enc : 6.5618e-05 	 AEnc : 1.6249e-04 	 MSE : 3.2112e+00
Epoch 191, 75% 	 Loss : 2.8161e-02 	 Res : 1.4903e-02 	 Jac : 1.3116e-02 	 Enc : 6.7324e-05 	 AEnc : 7.4401e-05 	 MSE : 3.7887e+00
Training Epoch 191 : 	 Train : 2.79308e-02 	 Res : 1.39258e-02 	 Jac : 1.31133e-02 	 Enc : 7.61063e-05 	 AE : 8.15590e-04 	 MSE : 3.52388e+00
Validation Epoch 191 : 	 Train : 2.01654e-02 	 Res : 6.86915e-03 	 Jac : 1.31555e-02 	 Enc : 8.19961e-05 	 AE : 5.86868e-05 	 MSE : 1.06103e+00
Training Epoch 191 finished, took current epoch 368.04s, cumulative time 71728.73s
Current Learning rate DEQ : 0.0013421772800000008
Current Learning rate AUTOENC : 0.006710886400000004
Epoch 192, 25% 	 Loss : 2.6450e-02 	 Res : 1.2971e-02 	 Jac : 1.3174e-02 	 Enc : 9.4477e-05 	 AEnc : 2.1057e-04 	 MSE : 2.7290e+00
Epoch 192, 50% 	 Loss : 3.7241e-02 	 Res : 2.2719e-02 	 Jac : 1.3122e-02 	 Enc : 3.1331e-04 	 AEnc : 1.0869e-03 	 MSE : 4.7131e+00
Epoch 192, 75% 	 Loss : 3.4147e-02 	 Res : 1.0023e-02 	 Jac : 1.3214e-02 	 Enc : 2.3697e-04 	 AEnc : 1.0672e-02 	 MSE : 1.4187e+00
Training Epoch 192 : 	 Train : 3.15440e-02 	 Res : 1.35426e-02 	 Jac : 1.31437e-02 	 Enc : 1.76623e-04 	 AE : 4.68113e-03 	 MSE : 2.54012e+00
Validation Epoch 192 : 	 Train : 1.95779e-02 	 Res : 5.72432e-03 	 Jac : 1.31698e-02 	 Enc : 3.48857e-05 	 AE : 6.48965e-04 	 MSE : 7.98734e-01
Training Epoch 192 finished, took current epoch 372.64s, cumulative time 72101.29s
Current Learning rate DEQ : 0.0010737418240000006
Current Learning rate AUTOENC : 0.005368709120000003
MODEL SAVED
Epoch 193, 25% 	 Loss : 2.0088e-02 	 Res : 6.3224e-03 	 Jac : 1.3059e-02 	 Enc : 2.6396e-05 	 AEnc : 6.8089e-04 	 MSE : 9.1045e-01
Epoch 193, 50% 	 Loss : 2.1279e-02 	 Res : 6.5218e-03 	 Jac : 1.3080e-02 	 Enc : 2.5038e-05 	 AEnc : 1.6520e-03 	 MSE : 9.3028e-01
Epoch 193, 75% 	 Loss : 1.9884e-02 	 Res : 6.0393e-03 	 Jac : 1.3115e-02 	 Enc : 2.0526e-05 	 AEnc : 7.0903e-04 	 MSE : 8.8071e-01
Training Epoch 193 : 	 Train : 2.00941e-02 	 Res : 6.18973e-03 	 Jac : 1.30894e-02 	 Enc : 2.28942e-05 	 AE : 7.92059e-04 	 MSE : 8.93873e-01
Validation Epoch 193 : 	 Train : 1.91339e-02 	 Res : 6.00070e-03 	 Jac : 1.30643e-02 	 Enc : 1.78504e-05 	 AE : 5.10203e-05 	 MSE : 9.04461e-01
Training Epoch 193 finished, took current epoch 373.12s, cumulative time 72474.39s
Current Learning rate DEQ : 0.0010737418240000006
Current Learning rate AUTOENC : 0.005368709120000003
Epoch 194, 25% 	 Loss : 1.9459e-02 	 Res : 6.3802e-03 	 Jac : 1.3006e-02 	 Enc : 1.7477e-05 	 AEnc : 5.4954e-05 	 MSE : 1.0081e+00
Epoch 194, 50% 	 Loss : 3.1033e-02 	 Res : 1.7954e-02 	 Jac : 1.2937e-02 	 Enc : 6.2932e-05 	 AEnc : 7.8900e-05 	 MSE : 4.6634e+00
Epoch 194, 75% 	 Loss : 3.5449e-02 	 Res : 2.2236e-02 	 Jac : 1.2978e-02 	 Enc : 1.1834e-04 	 AEnc : 1.1632e-04 	 MSE : 5.9805e+00
Training Epoch 194 : 	 Train : 2.84695e-02 	 Res : 1.52496e-02 	 Jac : 1.29916e-02 	 Enc : 7.60023e-05 	 AE : 1.52270e-04 	 MSE : 3.75646e+00
Validation Epoch 194 : 	 Train : 1.93403e-02 	 Res : 6.03111e-03 	 Jac : 1.30802e-02 	 Enc : 3.92743e-05 	 AE : 1.89734e-04 	 MSE : 5.08230e-01
Training Epoch 194 finished, took current epoch 375.54s, cumulative time 72849.91s
Current Learning rate DEQ : 0.0010737418240000006
Current Learning rate AUTOENC : 0.005368709120000003
Epoch 195, 25% 	 Loss : 2.3173e-02 	 Res : 1.0057e-02 	 Jac : 1.2943e-02 	 Enc : 5.1556e-05 	 AEnc : 1.2154e-04 	 MSE : 2.1401e+00
Epoch 195, 50% 	 Loss : 7.3222e-02 	 Res : 4.5998e-02 	 Jac : 1.3026e-02 	 Enc : 1.7874e-04 	 AEnc : 1.4020e-02 	 MSE : 1.2200e+01
Epoch 195, 75% 	 Loss : 6.2470e-02 	 Res : 2.0131e-02 	 Jac : 1.3000e-02 	 Enc : 2.1829e-04 	 AEnc : 2.9121e-02 	 MSE : 3.2700e+00
Training Epoch 195 : 	 Train : 4.59789e-02 	 Res : 2.08329e-02 	 Jac : 1.30003e-02 	 Enc : 1.23911e-04 	 AE : 1.20218e-02 	 MSE : 4.64996e+00
Validation Epoch 195 : 	 Train : 1.73980e-02 	 Res : 4.23268e-03 	 Jac : 1.30503e-02 	 Enc : 2.67897e-05 	 AE : 8.82703e-05 	 MSE : 2.00099e-01
Training Epoch 195 finished, took current epoch 376.54s, cumulative time 73226.39s
Current Learning rate DEQ : 0.0010737418240000006
Current Learning rate AUTOENC : 0.005368709120000003
MODEL SAVED
Epoch 196, 25% 	 Loss : 4.8195e-02 	 Res : 1.0277e-02 	 Jac : 1.3060e-02 	 Enc : 5.9930e-05 	 AEnc : 2.4798e-02 	 MSE : 8.9320e-01
Epoch 196, 50% 	 Loss : 3.3032e-02 	 Res : 1.0309e-02 	 Jac : 1.3043e-02 	 Enc : 3.8194e-05 	 AEnc : 9.6410e-03 	 MSE : 1.7964e+00
Epoch 196, 75% 	 Loss : 4.6768e-02 	 Res : 2.8114e-02 	 Jac : 1.2950e-02 	 Enc : 2.0299e-04 	 AEnc : 5.5013e-03 	 MSE : 6.1958e+00
Training Epoch 196 : 	 Train : 4.78009e-02 	 Res : 1.55864e-02 	 Jac : 1.29866e-02 	 Enc : 1.09819e-04 	 AE : 1.91181e-02 	 MSE : 2.57188e+00
Validation Epoch 196 : 	 Train : 2.20271e-02 	 Res : 8.19957e-03 	 Jac : 1.30373e-02 	 Enc : 7.82231e-05 	 AE : 7.11978e-04 	 MSE : 1.33209e+00
Training Epoch 196 finished, took current epoch 377.99s, cumulative time 73604.38s
Current Learning rate DEQ : 0.0010737418240000006
Current Learning rate AUTOENC : 0.005368709120000003
Epoch 197, 25% 	 Loss : 3.9270e-02 	 Res : 9.1417e-03 	 Jac : 1.3009e-02 	 Enc : 7.1246e-05 	 AEnc : 1.7048e-02 	 MSE : 8.9520e-01
Epoch 197, 50% 	 Loss : 4.5851e-02 	 Res : 1.1768e-02 	 Jac : 1.2955e-02 	 Enc : 7.8347e-05 	 AEnc : 2.1049e-02 	 MSE : 1.6155e+00
Epoch 197, 75% 	 Loss : 5.3591e-02 	 Res : 1.1863e-02 	 Jac : 1.2897e-02 	 Enc : 1.1580e-04 	 AEnc : 2.8716e-02 	 MSE : 1.1437e+00
Training Epoch 197 : 	 Train : 4.33875e-02 	 Res : 1.08871e-02 	 Jac : 1.29695e-02 	 Enc : 8.87180e-05 	 AE : 1.94421e-02 	 MSE : 1.31745e+00
Validation Epoch 197 : 	 Train : 2.85093e-02 	 Res : 6.62001e-03 	 Jac : 1.29133e-02 	 Enc : 1.04201e-04 	 AE : 8.87181e-03 	 MSE : 3.56728e-01
Training Epoch 197 finished, took current epoch 382.30s, cumulative time 73986.62s
Current Learning rate DEQ : 0.0010737418240000006
Current Learning rate AUTOENC : 0.005368709120000003
Epoch 198, 25% 	 Loss : 2.5089e-02 	 Res : 8.7257e-03 	 Jac : 1.2927e-02 	 Enc : 7.6988e-05 	 AEnc : 3.3592e-03 	 MSE : 1.4828e+00
Epoch 198, 50% 	 Loss : 2.5352e-02 	 Res : 8.1031e-03 	 Jac : 1.2959e-02 	 Enc : 4.8851e-05 	 AEnc : 4.2418e-03 	 MSE : 1.1568e+00
Epoch 198, 75% 	 Loss : 2.9651e-02 	 Res : 8.6744e-03 	 Jac : 1.2935e-02 	 Enc : 6.2782e-05 	 AEnc : 7.9786e-03 	 MSE : 1.1943e+00
Training Epoch 198 : 	 Train : 2.76893e-02 	 Res : 8.25819e-03 	 Jac : 1.29306e-02 	 Enc : 5.91735e-05 	 AE : 6.44129e-03 	 MSE : 1.14173e+00
Validation Epoch 198 : 	 Train : 1.95002e-02 	 Res : 4.52492e-03 	 Jac : 1.28926e-02 	 Enc : 3.06255e-05 	 AE : 2.05210e-03 	 MSE : 2.33537e-01
Training Epoch 198 finished, took current epoch 376.20s, cumulative time 74362.81s
Current Learning rate DEQ : 0.0010737418240000006
Current Learning rate AUTOENC : 0.005368709120000003
Epoch 199, 25% 	 Loss : 3.0828e-02 	 Res : 7.3246e-03 	 Jac : 1.3007e-02 	 Enc : 3.9892e-05 	 AEnc : 1.0457e-02 	 MSE : 7.7012e-01
Epoch 199, 50% 	 Loss : 2.6567e-02 	 Res : 1.0938e-02 	 Jac : 1.2926e-02 	 Enc : 3.9203e-05 	 AEnc : 2.6643e-03 	 MSE : 2.3177e+00
Epoch 199, 75% 	 Loss : 2.7407e-02 	 Res : 1.1822e-02 	 Jac : 1.2878e-02 	 Enc : 7.2005e-05 	 AEnc : 2.6356e-03 	 MSE : 2.5801e+00
Training Epoch 199 : 	 Train : 2.79618e-02 	 Res : 9.67009e-03 	 Jac : 1.29304e-02 	 Enc : 5.73954e-05 	 AE : 5.30383e-03 	 MSE : 1.73815e+00
Validation Epoch 199 : 	 Train : 1.97465e-02 	 Res : 6.02041e-03 	 Jac : 1.28509e-02 	 Enc : 4.11716e-05 	 AE : 8.34076e-04 	 MSE : 7.92466e-01
Training Epoch 199 finished, took current epoch 379.12s, cumulative time 74741.89s
Current Learning rate DEQ : 0.0010737418240000006
Current Learning rate AUTOENC : 0.005368709120000003
Epoch 200, 25% 	 Loss : 3.2798e-02 	 Res : 1.9162e-02 	 Jac : 1.2846e-02 	 Enc : 1.0001e-04 	 AEnc : 6.8996e-04 	 MSE : 4.4803e+00
Epoch 200, 50% 	 Loss : 2.0680e-02 	 Res : 7.3118e-03 	 Jac : 1.2868e-02 	 Enc : 1.3609e-04 	 AEnc : 3.6366e-04 	 MSE : 1.1066e+00
Epoch 200, 75% 	 Loss : 2.3605e-02 	 Res : 8.4444e-03 	 Jac : 1.2902e-02 	 Enc : 6.1401e-05 	 AEnc : 2.1971e-03 	 MSE : 1.4317e+00
Training Epoch 200 : 	 Train : 2.42440e-02 	 Res : 1.03619e-02 	 Jac : 1.28756e-02 	 Enc : 8.32990e-05 	 AE : 9.23118e-04 	 MSE : 2.01963e+00
Validation Epoch 200 : 	 Train : 2.00608e-02 	 Res : 6.69316e-03 	 Jac : 1.28777e-02 	 Enc : 2.55629e-05 	 AE : 4.64356e-04 	 MSE : 1.15192e+00
Training Epoch 200 finished, took current epoch 370.75s, cumulative time 75112.63s
Current Learning rate DEQ : 0.0010737418240000006
Current Learning rate AUTOENC : 0.005368709120000003
Epoch 201, 25% 	 Loss : 1.9095e-02 	 Res : 5.8839e-03 	 Jac : 1.2957e-02 	 Enc : 2.1923e-05 	 AEnc : 2.3191e-04 	 MSE : 9.1837e-01
Epoch 201, 50% 	 Loss : 1.9681e-02 	 Res : 6.4359e-03 	 Jac : 1.3029e-02 	 Enc : 2.0977e-05 	 AEnc : 1.9466e-04 	 MSE : 9.7113e-01
Epoch 201, 75% 	 Loss : 2.0060e-02 	 Res : 6.9686e-03 	 Jac : 1.2936e-02 	 Enc : 2.7330e-05 	 AEnc : 1.2854e-04 	 MSE : 1.2165e+00
Training Epoch 201 : 	 Train : 1.97640e-02 	 Res : 6.57731e-03 	 Jac : 1.29518e-02 	 Enc : 2.45162e-05 	 AE : 2.10374e-04 	 MSE : 1.08251e+00
Validation Epoch 201 : 	 Train : 2.10066e-02 	 Res : 7.53095e-03 	 Jac : 1.28364e-02 	 Enc : 2.44870e-05 	 AE : 6.14841e-04 	 MSE : 1.38916e+00
Training Epoch 201 finished, took current epoch 374.53s, cumulative time 75487.14s
Current Learning rate DEQ : 0.0010737418240000006
Current Learning rate AUTOENC : 0.005368709120000003
Epoch 202, 25% 	 Loss : 2.3453e-02 	 Res : 8.0695e-03 	 Jac : 1.2902e-02 	 Enc : 4.0561e-05 	 AEnc : 2.4416e-03 	 MSE : 1.3492e+00
Epoch 202, 50% 	 Loss : 5.4111e-02 	 Res : 1.2425e-02 	 Jac : 1.2906e-02 	 Enc : 1.6582e-04 	 AEnc : 2.8614e-02 	 MSE : 1.3829e+00
Epoch 202, 75% 	 Loss : 3.4512e-02 	 Res : 1.2682e-02 	 Jac : 1.2950e-02 	 Enc : 9.0509e-05 	 AEnc : 8.7901e-03 	 MSE : 2.3810e+00
Training Epoch 202 : 	 Train : 3.75038e-02 	 Res : 1.05718e-02 	 Jac : 1.29275e-02 	 Enc : 9.18427e-05 	 AE : 1.39127e-02 	 MSE : 1.54472e+00
Validation Epoch 202 : 	 Train : 2.57325e-02 	 Res : 6.88361e-03 	 Jac : 1.28968e-02 	 Enc : 6.17161e-05 	 AE : 5.89030e-03 	 MSE : 8.25605e-01
Training Epoch 202 finished, took current epoch 375.68s, cumulative time 75862.81s
Current Learning rate DEQ : 0.0010737418240000006
Current Learning rate AUTOENC : 0.005368709120000003
Epoch 203, 25% 	 Loss : 2.9807e-02 	 Res : 7.6296e-03 	 Jac : 1.2803e-02 	 Enc : 4.2200e-05 	 AEnc : 9.3324e-03 	 MSE : 9.6112e-01
Epoch 203, 50% 	 Loss : 3.5537e-02 	 Res : 1.9541e-02 	 Jac : 1.2919e-02 	 Enc : 5.1409e-05 	 AEnc : 3.0259e-03 	 MSE : 5.0849e+00
Epoch 203, 75% 	 Loss : 3.2402e-02 	 Res : 1.7808e-02 	 Jac : 1.2872e-02 	 Enc : 1.0645e-04 	 AEnc : 1.6155e-03 	 MSE : 4.6629e+00
Training Epoch 203 : 	 Train : 3.05725e-02 	 Res : 1.39066e-02 	 Jac : 1.28567e-02 	 Enc : 6.93316e-05 	 AE : 3.73984e-03 	 MSE : 3.24970e+00
Validation Epoch 203 : 	 Train : 2.17666e-02 	 Res : 8.65800e-03 	 Jac : 1.29640e-02 	 Enc : 6.18545e-05 	 AE : 8.27190e-05 	 MSE : 1.38218e+00
Training Epoch 203 finished, took current epoch 380.71s, cumulative time 76243.50s
Current Learning rate DEQ : 0.0010737418240000006
Current Learning rate AUTOENC : 0.005368709120000003
Epoch 204, 25% 	 Loss : 3.2224e-02 	 Res : 1.9213e-02 	 Jac : 1.2849e-02 	 Enc : 6.5486e-05 	 AEnc : 9.6283e-05 	 MSE : 5.1144e+00
Epoch 204, 50% 	 Loss : 4.3472e-02 	 Res : 2.9821e-02 	 Jac : 1.2854e-02 	 Enc : 3.0985e-04 	 AEnc : 4.8765e-04 	 MSE : 7.4676e+00
Epoch 204, 75% 	 Loss : 4.3769e-02 	 Res : 2.7027e-02 	 Jac : 1.2950e-02 	 Enc : 7.1486e-04 	 AEnc : 3.0776e-03 	 MSE : 6.3709e+00
Training Epoch 204 : 	 Train : 4.29831e-02 	 Res : 2.35241e-02 	 Jac : 1.29242e-02 	 Enc : 3.88309e-04 	 AE : 6.14655e-03 	 MSE : 5.52240e+00
Validation Epoch 204 : 	 Train : 5.37577e-02 	 Res : 1.35828e-02 	 Jac : 1.30789e-02 	 Enc : 3.08921e-04 	 AE : 2.67871e-02 	 MSE : 1.47875e+00
Training Epoch 204 finished, took current epoch 384.15s, cumulative time 76627.61s
Current Learning rate DEQ : 0.0010737418240000006
Current Learning rate AUTOENC : 0.005368709120000003
Epoch 205, 25% 	 Loss : 2.4489e-02 	 Res : 8.0420e-03 	 Jac : 1.2959e-02 	 Enc : 1.2999e-04 	 AEnc : 3.3588e-03 	 MSE : 1.2499e+00
Epoch 205, 50% 	 Loss : 3.4851e-02 	 Res : 1.4997e-02 	 Jac : 1.3003e-02 	 Enc : 7.4839e-05 	 AEnc : 6.7762e-03 	 MSE : 3.4095e+00
Epoch 205, 75% 	 Loss : 5.9820e-02 	 Res : 1.7039e-02 	 Jac : 1.2971e-02 	 Enc : 1.2611e-04 	 AEnc : 2.9684e-02 	 MSE : 2.6876e+00
Training Epoch 205 : 	 Train : 4.59705e-02 	 Res : 1.43256e-02 	 Jac : 1.29892e-02 	 Enc : 1.56036e-04 	 AE : 1.84997e-02 	 MSE : 2.50293e+00
Validation Epoch 205 : 	 Train : 2.73718e-02 	 Res : 8.46177e-03 	 Jac : 1.29061e-02 	 Enc : 1.98269e-04 	 AE : 5.80567e-03 	 MSE : 1.28209e+00
Training Epoch 205 finished, took current epoch 370.21s, cumulative time 76997.80s
Current Learning rate DEQ : 0.0010737418240000006
Current Learning rate AUTOENC : 0.005368709120000003
Epoch 206, 25% 	 Loss : 2.5216e-02 	 Res : 1.1103e-02 	 Jac : 1.2998e-02 	 Enc : 9.7027e-05 	 AEnc : 1.0182e-03 	 MSE : 2.4595e+00
Epoch 206, 50% 	 Loss : 2.3591e-02 	 Res : 1.0460e-02 	 Jac : 1.2939e-02 	 Enc : 7.7499e-05 	 AEnc : 1.1398e-04 	 MSE : 2.2552e+00
Epoch 206, 75% 	 Loss : 2.2026e-02 	 Res : 8.9771e-03 	 Jac : 1.2865e-02 	 Enc : 4.9223e-05 	 AEnc : 1.3422e-04 	 MSE : 1.8278e+00
Training Epoch 206 : 	 Train : 2.51097e-02 	 Res : 1.15802e-02 	 Jac : 1.29625e-02 	 Enc : 9.10786e-05 	 AE : 4.75964e-04 	 MSE : 2.48257e+00
Validation Epoch 206 : 	 Train : 2.65120e-02 	 Res : 6.88757e-03 	 Jac : 1.29497e-02 	 Enc : 1.02447e-04 	 AE : 6.57225e-03 	 MSE : 9.08561e-01
Training Epoch 206 finished, took current epoch 368.86s, cumulative time 77366.62s
Current Learning rate DEQ : 0.0008589934592000006
Current Learning rate AUTOENC : 0.0042949672960000025
Epoch 207, 25% 	 Loss : 2.6749e-02 	 Res : 7.4083e-03 	 Jac : 1.3053e-02 	 Enc : 1.1834e-04 	 AEnc : 6.1699e-03 	 MSE : 8.7923e-01
Epoch 207, 50% 	 Loss : 2.0317e-02 	 Res : 5.6093e-03 	 Jac : 1.2892e-02 	 Enc : 3.5850e-05 	 AEnc : 1.7797e-03 	 MSE : 6.6979e-01
Epoch 207, 75% 	 Loss : 1.9706e-02 	 Res : 5.4677e-03 	 Jac : 1.2934e-02 	 Enc : 1.9681e-05 	 AEnc : 1.2846e-03 	 MSE : 6.7979e-01
Training Epoch 207 : 	 Train : 2.14320e-02 	 Res : 5.94874e-03 	 Jac : 1.29451e-02 	 Enc : 4.84563e-05 	 AE : 2.48977e-03 	 MSE : 7.21846e-01
Validation Epoch 207 : 	 Train : 1.85311e-02 	 Res : 5.49193e-03 	 Jac : 1.28782e-02 	 Enc : 1.65779e-05 	 AE : 1.44419e-04 	 MSE : 6.49452e-01
Training Epoch 207 finished, took current epoch 373.19s, cumulative time 77739.80s
Current Learning rate DEQ : 0.0008589934592000006
Current Learning rate AUTOENC : 0.0042949672960000025
Epoch 208, 25% 	 Loss : 1.8206e-02 	 Res : 5.1959e-03 	 Jac : 1.2909e-02 	 Enc : 1.5064e-05 	 AEnc : 8.5680e-05 	 MSE : 6.7687e-01
Epoch 208, 50% 	 Loss : 1.8310e-02 	 Res : 5.2949e-03 	 Jac : 1.2967e-02 	 Enc : 1.5829e-05 	 AEnc : 3.2274e-05 	 MSE : 6.6884e-01
Epoch 208, 75% 	 Loss : 1.8229e-02 	 Res : 5.2202e-03 	 Jac : 1.2960e-02 	 Enc : 1.5903e-05 	 AEnc : 3.2861e-05 	 MSE : 6.5693e-01
Training Epoch 208 : 	 Train : 1.82224e-02 	 Res : 5.22856e-03 	 Jac : 1.29327e-02 	 Enc : 1.58769e-05 	 AE : 4.52878e-05 	 MSE : 6.72565e-01
Validation Epoch 208 : 	 Train : 1.82358e-02 	 Res : 5.23806e-03 	 Jac : 1.29532e-02 	 Enc : 1.74219e-05 	 AE : 2.71350e-05 	 MSE : 6.63920e-01
Training Epoch 208 finished, took current epoch 369.47s, cumulative time 78109.22s
Current Learning rate DEQ : 0.0008589934592000006
Current Learning rate AUTOENC : 0.0042949672960000025
Epoch 209, 25% 	 Loss : 1.8087e-02 	 Res : 5.1083e-03 	 Jac : 1.2935e-02 	 Enc : 1.5103e-05 	 AEnc : 2.8377e-05 	 MSE : 6.3803e-01
Epoch 209, 50% 	 Loss : 1.8007e-02 	 Res : 5.0829e-03 	 Jac : 1.2882e-02 	 Enc : 1.4686e-05 	 AEnc : 2.7927e-05 	 MSE : 6.4658e-01
Epoch 209, 75% 	 Loss : 1.8159e-02 	 Res : 5.2239e-03 	 Jac : 1.2884e-02 	 Enc : 1.4692e-05 	 AEnc : 3.6038e-05 	 MSE : 7.0021e-01
Training Epoch 209 : 	 Train : 1.80945e-02 	 Res : 5.14345e-03 	 Jac : 1.29032e-02 	 Enc : 1.49851e-05 	 AE : 3.29133e-05 	 MSE : 6.63310e-01
Validation Epoch 209 : 	 Train : 1.94761e-02 	 Res : 6.55952e-03 	 Jac : 1.28755e-02 	 Enc : 1.57478e-05 	 AE : 2.53998e-05 	 MSE : 1.14929e+00
Training Epoch 209 finished, took current epoch 372.04s, cumulative time 78481.25s
Current Learning rate DEQ : 0.0008589934592000006
Current Learning rate AUTOENC : 0.0042949672960000025
Epoch 210, 25% 	 Loss : 1.8705e-02 	 Res : 5.7525e-03 	 Jac : 1.2894e-02 	 Enc : 1.6977e-05 	 AEnc : 4.1139e-05 	 MSE : 8.2971e-01
Epoch 210, 50% 	 Loss : 1.9527e-02 	 Res : 6.3321e-03 	 Jac : 1.2858e-02 	 Enc : 2.1644e-05 	 AEnc : 3.1568e-04 	 MSE : 9.4696e-01
Epoch 210, 75% 	 Loss : 2.6748e-02 	 Res : 7.6934e-03 	 Jac : 1.2860e-02 	 Enc : 5.1885e-05 	 AEnc : 6.1419e-03 	 MSE : 9.4201e-01
Training Epoch 210 : 	 Train : 3.14116e-02 	 Res : 9.00313e-03 	 Jac : 1.28636e-02 	 Enc : 5.03278e-05 	 AE : 9.49449e-03 	 MSE : 1.24151e+00
Validation Epoch 210 : 	 Train : 1.13579e-01 	 Res : 2.18190e-02 	 Jac : 1.28348e-02 	 Enc : 1.85999e-04 	 AE : 7.87396e-02 	 MSE : 7.87575e-01
Training Epoch 210 finished, took current epoch 375.48s, cumulative time 78856.72s
Current Learning rate DEQ : 0.0008589934592000006
Current Learning rate AUTOENC : 0.0042949672960000025
Epoch 211, 25% 	 Loss : 4.5490e-02 	 Res : 1.1496e-02 	 Jac : 1.2952e-02 	 Enc : 1.0016e-04 	 AEnc : 2.0942e-02 	 MSE : 1.6486e+00
Epoch 211, 50% 	 Loss : 2.1768e-02 	 Res : 6.9425e-03 	 Jac : 1.2828e-02 	 Enc : 4.4651e-05 	 AEnc : 1.9534e-03 	 MSE : 1.0549e+00
Epoch 211, 75% 	 Loss : 4.2285e-02 	 Res : 8.8585e-03 	 Jac : 1.2733e-02 	 Enc : 5.6927e-05 	 AEnc : 2.0637e-02 	 MSE : 7.6198e-01
Training Epoch 211 : 	 Train : 3.56222e-02 	 Res : 8.65326e-03 	 Jac : 1.28456e-02 	 Enc : 6.00136e-05 	 AE : 1.40633e-02 	 MSE : 1.05197e+00
Validation Epoch 211 : 	 Train : 1.97272e-02 	 Res : 6.30878e-03 	 Jac : 1.28632e-02 	 Enc : 2.07961e-05 	 AE : 5.34486e-04 	 MSE : 1.12355e+00
Training Epoch 211 finished, took current epoch 375.66s, cumulative time 79232.33s
Current Learning rate DEQ : 0.0008589934592000006
Current Learning rate AUTOENC : 0.0042949672960000025
Epoch 212, 25% 	 Loss : 2.4758e-02 	 Res : 6.2504e-03 	 Jac : 1.2829e-02 	 Enc : 2.1597e-05 	 AEnc : 5.6574e-03 	 MSE : 7.4056e-01
Epoch 212, 50% 	 Loss : 2.1653e-02 	 Res : 5.7267e-03 	 Jac : 1.2868e-02 	 Enc : 2.0781e-05 	 AEnc : 3.0370e-03 	 MSE : 6.9747e-01
Epoch 212, 75% 	 Loss : 2.4650e-02 	 Res : 7.0019e-03 	 Jac : 1.2913e-02 	 Enc : 2.4105e-05 	 AEnc : 4.7111e-03 	 MSE : 9.7249e-01
Training Epoch 212 : 	 Train : 2.45615e-02 	 Res : 6.80073e-03 	 Jac : 1.28707e-02 	 Enc : 2.47176e-05 	 AE : 4.86539e-03 	 MSE : 9.44724e-01
Validation Epoch 212 : 	 Train : 2.84241e-02 	 Res : 9.05931e-03 	 Jac : 1.27121e-02 	 Enc : 3.74898e-05 	 AE : 6.61518e-03 	 MSE : 1.31106e+00
Training Epoch 212 finished, took current epoch 371.15s, cumulative time 79603.47s
Current Learning rate DEQ : 0.0008589934592000006
Current Learning rate AUTOENC : 0.0042949672960000025
Epoch 213, 25% 	 Loss : 2.4707e-02 	 Res : 1.0449e-02 	 Jac : 1.2827e-02 	 Enc : 4.8076e-05 	 AEnc : 1.3831e-03 	 MSE : 2.1912e+00
Epoch 213, 50% 	 Loss : 2.2950e-02 	 Res : 9.9230e-03 	 Jac : 1.2803e-02 	 Enc : 6.3095e-05 	 AEnc : 1.6055e-04 	 MSE : 2.3880e+00
Epoch 213, 75% 	 Loss : 2.8389e-02 	 Res : 1.5412e-02 	 Jac : 1.2858e-02 	 Enc : 6.6177e-05 	 AEnc : 5.2289e-05 	 MSE : 4.2689e+00
Training Epoch 213 : 	 Train : 2.44645e-02 	 Res : 1.11289e-02 	 Jac : 1.28458e-02 	 Enc : 5.79460e-05 	 AE : 4.31936e-04 	 MSE : 2.64273e+00
Validation Epoch 213 : 	 Train : 1.73102e-02 	 Res : 4.32702e-03 	 Jac : 1.28812e-02 	 Enc : 4.79425e-05 	 AE : 5.40456e-05 	 MSE : 4.03455e-01
Training Epoch 213 finished, took current epoch 375.36s, cumulative time 79978.76s
Current Learning rate DEQ : 0.0008589934592000006
Current Learning rate AUTOENC : 0.0042949672960000025
Epoch 214, 25% 	 Loss : 1.8331e-02 	 Res : 5.3624e-03 	 Jac : 1.2894e-02 	 Enc : 2.9898e-05 	 AEnc : 4.4307e-05 	 MSE : 7.2428e-01
Epoch 214, 50% 	 Loss : 1.8098e-02 	 Res : 5.1868e-03 	 Jac : 1.2865e-02 	 Enc : 1.7197e-05 	 AEnc : 2.8837e-05 	 MSE : 7.2304e-01
Epoch 214, 75% 	 Loss : 1.8095e-02 	 Res : 5.1745e-03 	 Jac : 1.2877e-02 	 Enc : 1.7407e-05 	 AEnc : 2.6427e-05 	 MSE : 7.2411e-01
Training Epoch 214 : 	 Train : 1.81752e-02 	 Res : 5.25049e-03 	 Jac : 1.28727e-02 	 Enc : 2.01657e-05 	 AE : 3.18650e-05 	 MSE : 7.28495e-01
Validation Epoch 214 : 	 Train : 1.73947e-02 	 Res : 4.40185e-03 	 Jac : 1.29458e-02 	 Enc : 1.66990e-05 	 AE : 3.02847e-05 	 MSE : 4.00078e-01
Training Epoch 214 finished, took current epoch 370.44s, cumulative time 80349.19s
Current Learning rate DEQ : 0.0008589934592000006
Current Learning rate AUTOENC : 0.0042949672960000025
Epoch 215, 25% 	 Loss : 1.8052e-02 	 Res : 5.0948e-03 	 Jac : 1.2914e-02 	 Enc : 1.5827e-05 	 AEnc : 2.7477e-05 	 MSE : 6.8035e-01
Epoch 215, 50% 	 Loss : 1.8226e-02 	 Res : 5.2759e-03 	 Jac : 1.2911e-02 	 Enc : 1.5354e-05 	 AEnc : 2.3966e-05 	 MSE : 7.7085e-01
Epoch 215, 75% 	 Loss : 1.8033e-02 	 Res : 5.1062e-03 	 Jac : 1.2886e-02 	 Enc : 1.5592e-05 	 AEnc : 2.5505e-05 	 MSE : 7.0631e-01
Training Epoch 215 : 	 Train : 1.81053e-02 	 Res : 5.16155e-03 	 Jac : 1.29031e-02 	 Enc : 1.57276e-05 	 AE : 2.49563e-05 	 MSE : 7.18706e-01
Validation Epoch 215 : 	 Train : 1.77955e-02 	 Res : 4.91230e-03 	 Jac : 1.28463e-02 	 Enc : 1.66622e-05 	 AE : 2.02661e-05 	 MSE : 6.06523e-01
Training Epoch 215 finished, took current epoch 373.38s, cumulative time 80722.52s
Current Learning rate DEQ : 0.0008589934592000006
Current Learning rate AUTOENC : 0.0042949672960000025
Epoch 216, 25% 	 Loss : 1.8169e-02 	 Res : 5.3446e-03 	 Jac : 1.2783e-02 	 Enc : 1.7299e-05 	 AEnc : 2.4371e-05 	 MSE : 7.5841e-01
Epoch 216, 50% 	 Loss : 1.7943e-02 	 Res : 5.0366e-03 	 Jac : 1.2864e-02 	 Enc : 1.5754e-05 	 AEnc : 2.6469e-05 	 MSE : 6.8716e-01
Epoch 216, 75% 	 Loss : 2.2507e-02 	 Res : 9.4975e-03 	 Jac : 1.2858e-02 	 Enc : 3.6768e-05 	 AEnc : 1.1505e-04 	 MSE : 1.9978e+00
Training Epoch 216 : 	 Train : 2.07541e-02 	 Res : 7.82960e-03 	 Jac : 1.28006e-02 	 Enc : 3.64230e-05 	 AE : 8.75339e-05 	 MSE : 1.56265e+00
Validation Epoch 216 : 	 Train : 2.14415e-02 	 Res : 8.30179e-03 	 Jac : 1.28319e-02 	 Enc : 7.25786e-05 	 AE : 2.35206e-04 	 MSE : 1.81746e+00
Training Epoch 216 finished, took current epoch 373.32s, cumulative time 81095.83s
Current Learning rate DEQ : 0.0008589934592000006
Current Learning rate AUTOENC : 0.0042949672960000025
Epoch 217, 25% 	 Loss : 2.3279e-02 	 Res : 1.0317e-02 	 Jac : 1.2826e-02 	 Enc : 7.1729e-05 	 AEnc : 6.4245e-05 	 MSE : 2.4198e+00
Epoch 217, 50% 	 Loss : 1.9112e-02 	 Res : 6.2296e-03 	 Jac : 1.2756e-02 	 Enc : 4.9847e-05 	 AEnc : 7.6371e-05 	 MSE : 9.6596e-01
Epoch 217, 75% 	 Loss : 3.7888e-02 	 Res : 1.0542e-02 	 Jac : 1.2823e-02 	 Enc : 4.9675e-05 	 AEnc : 1.4473e-02 	 MSE : 1.7009e+00
Training Epoch 217 : 	 Train : 2.82644e-02 	 Res : 8.66450e-03 	 Jac : 1.28291e-02 	 Enc : 5.32941e-05 	 AE : 6.71751e-03 	 MSE : 1.47209e+00
Validation Epoch 217 : 	 Train : 2.15573e-02 	 Res : 5.64015e-03 	 Jac : 1.28546e-02 	 Enc : 2.47326e-05 	 AE : 3.03775e-03 	 MSE : 5.90157e-01
Training Epoch 217 finished, took current epoch 370.27s, cumulative time 81466.08s
Current Learning rate DEQ : 0.0008589934592000006
Current Learning rate AUTOENC : 0.0042949672960000025
Epoch 218, 25% 	 Loss : 2.0012e-02 	 Res : 5.5261e-03 	 Jac : 1.2805e-02 	 Enc : 2.1342e-05 	 AEnc : 1.6594e-03 	 MSE : 7.4286e-01
Epoch 218, 50% 	 Loss : 2.0545e-02 	 Res : 5.5711e-03 	 Jac : 1.2902e-02 	 Enc : 1.9990e-05 	 AEnc : 2.0520e-03 	 MSE : 7.4962e-01
Epoch 218, 75% 	 Loss : 1.9533e-02 	 Res : 5.4953e-03 	 Jac : 1.2888e-02 	 Enc : 1.7792e-05 	 AEnc : 1.1319e-03 	 MSE : 7.6360e-01
Training Epoch 218 : 	 Train : 1.96768e-02 	 Res : 5.47440e-03 	 Jac : 1.28724e-02 	 Enc : 1.89376e-05 	 AE : 1.31105e-03 	 MSE : 7.56969e-01
Validation Epoch 218 : 	 Train : 1.85584e-02 	 Res : 5.47317e-03 	 Jac : 1.29081e-02 	 Enc : 1.83149e-05 	 AE : 1.58891e-04 	 MSE : 8.06509e-01
Training Epoch 218 finished, took current epoch 370.25s, cumulative time 81836.31s
Current Learning rate DEQ : 0.0008589934592000006
Current Learning rate AUTOENC : 0.0042949672960000025
Epoch 219, 25% 	 Loss : 1.8088e-02 	 Res : 5.1641e-03 	 Jac : 1.2835e-02 	 Enc : 1.8734e-05 	 AEnc : 7.0402e-05 	 MSE : 7.4125e-01
Epoch 219, 50% 	 Loss : 1.8024e-02 	 Res : 5.0897e-03 	 Jac : 1.2893e-02 	 Enc : 1.6763e-05 	 AEnc : 2.5187e-05 	 MSE : 7.2073e-01
Epoch 219, 75% 	 Loss : 1.7923e-02 	 Res : 5.1064e-03 	 Jac : 1.2778e-02 	 Enc : 1.6785e-05 	 AEnc : 2.2156e-05 	 MSE : 7.0377e-01
Training Epoch 219 : 	 Train : 1.80540e-02 	 Res : 5.15139e-03 	 Jac : 1.28495e-02 	 Enc : 1.74050e-05 	 AE : 3.56704e-05 	 MSE : 7.29026e-01
Validation Epoch 219 : 	 Train : 1.85741e-02 	 Res : 5.71787e-03 	 Jac : 1.28106e-02 	 Enc : 1.88236e-05 	 AE : 2.67650e-05 	 MSE : 8.90324e-01
Training Epoch 219 finished, took current epoch 372.98s, cumulative time 82209.27s
Current Learning rate DEQ : 0.0008589934592000006
Current Learning rate AUTOENC : 0.0042949672960000025
Epoch 220, 25% 	 Loss : 1.8340e-02 	 Res : 5.4105e-03 	 Jac : 1.2884e-02 	 Enc : 1.8566e-05 	 AEnc : 2.7529e-05 	 MSE : 8.1844e-01
Epoch 220, 50% 	 Loss : 1.8466e-02 	 Res : 5.5261e-03 	 Jac : 1.2891e-02 	 Enc : 1.8285e-05 	 AEnc : 3.0852e-05 	 MSE : 8.4611e-01
Epoch 220, 75% 	 Loss : 1.8470e-02 	 Res : 5.4799e-03 	 Jac : 1.2873e-02 	 Enc : 2.0744e-05 	 AEnc : 9.5915e-05 	 MSE : 8.1062e-01
Training Epoch 220 : 	 Train : 1.85370e-02 	 Res : 5.57912e-03 	 Jac : 1.28849e-02 	 Enc : 2.01367e-05 	 AE : 5.28280e-05 	 MSE : 8.50868e-01
Validation Epoch 220 : 	 Train : 2.12034e-02 	 Res : 8.27539e-03 	 Jac : 1.28623e-02 	 Enc : 3.51979e-05 	 AE : 3.05458e-05 	 MSE : 1.84967e+00
Training Epoch 220 finished, took current epoch 376.82s, cumulative time 82586.07s
Current Learning rate DEQ : 0.0008589934592000006
Current Learning rate AUTOENC : 0.0042949672960000025
Epoch 221, 25% 	 Loss : 1.9646e-02 	 Res : 6.5691e-03 	 Jac : 1.2861e-02 	 Enc : 3.4107e-05 	 AEnc : 1.8125e-04 	 MSE : 1.1386e+00
Epoch 221, 50% 	 Loss : 2.7389e-02 	 Res : 1.2693e-02 	 Jac : 1.2790e-02 	 Enc : 7.0782e-05 	 AEnc : 1.8353e-03 	 MSE : 3.0171e+00
Epoch 221, 75% 	 Loss : 3.0458e-02 	 Res : 1.2858e-02 	 Jac : 1.2840e-02 	 Enc : 1.3959e-04 	 AEnc : 4.6206e-03 	 MSE : 2.2720e+00
Training Epoch 221 : 	 Train : 3.11307e-02 	 Res : 1.18070e-02 	 Jac : 1.28389e-02 	 Enc : 9.08551e-05 	 AE : 6.39404e-03 	 MSE : 2.36767e+00
Validation Epoch 221 : 	 Train : 2.20506e-02 	 Res : 4.82694e-03 	 Jac : 1.28585e-02 	 Enc : 5.86170e-05 	 AE : 4.30652e-03 	 MSE : 3.32535e-01
Training Epoch 221 finished, took current epoch 376.82s, cumulative time 82962.88s
Current Learning rate DEQ : 0.0008589934592000006
Current Learning rate AUTOENC : 0.0042949672960000025
Epoch 222, 25% 	 Loss : 2.3280e-02 	 Res : 8.9360e-03 	 Jac : 1.2785e-02 	 Enc : 8.2452e-05 	 AEnc : 1.4769e-03 	 MSE : 1.8530e+00
Epoch 222, 50% 	 Loss : 6.4498e-02 	 Res : 4.7631e-02 	 Jac : 1.2724e-02 	 Enc : 2.7202e-04 	 AEnc : 3.8711e-03 	 MSE : 1.4518e+01
Epoch 222, 75% 	 Loss : 2.9749e-02 	 Res : 1.3194e-02 	 Jac : 1.2884e-02 	 Enc : 2.0098e-04 	 AEnc : 3.4689e-03 	 MSE : 2.7859e+00
Training Epoch 222 : 	 Train : 3.94289e-02 	 Res : 2.01414e-02 	 Jac : 1.28203e-02 	 Enc : 1.68290e-04 	 AE : 6.29885e-03 	 MSE : 5.19652e+00
Validation Epoch 222 : 	 Train : 3.55353e-02 	 Res : 1.00971e-02 	 Jac : 1.27823e-02 	 Enc : 7.43321e-05 	 AE : 1.25816e-02 	 MSE : 1.17502e+00
Training Epoch 222 finished, took current epoch 373.92s, cumulative time 83336.74s
Current Learning rate DEQ : 0.0008589934592000006
Current Learning rate AUTOENC : 0.0042949672960000025
Epoch 223, 25% 	 Loss : 4.0160e-02 	 Res : 1.2726e-02 	 Jac : 1.2874e-02 	 Enc : 1.1484e-04 	 AEnc : 1.4445e-02 	 MSE : 2.3722e+00
Epoch 223, 50% 	 Loss : 2.5357e-02 	 Res : 1.0828e-02 	 Jac : 1.2925e-02 	 Enc : 6.3668e-05 	 AEnc : 1.5412e-03 	 MSE : 2.6779e+00
Epoch 223, 75% 	 Loss : 2.2920e-02 	 Res : 9.8669e-03 	 Jac : 1.2869e-02 	 Enc : 5.0906e-05 	 AEnc : 1.3357e-04 	 MSE : 2.4602e+00
Training Epoch 223 : 	 Train : 2.81701e-02 	 Res : 1.10293e-02 	 Jac : 1.29037e-02 	 Enc : 7.10707e-05 	 AE : 4.16595e-03 	 MSE : 2.53455e+00
Validation Epoch 223 : 	 Train : 1.77262e-02 	 Res : 4.64417e-03 	 Jac : 1.29267e-02 	 Enc : 5.42194e-05 	 AE : 1.01130e-04 	 MSE : 5.11175e-01
Training Epoch 223 finished, took current epoch 367.09s, cumulative time 83703.80s
Current Learning rate DEQ : 0.0008589934592000006
Current Learning rate AUTOENC : 0.0042949672960000025
Epoch 224, 25% 	 Loss : 2.3779e-02 	 Res : 1.0718e-02 	 Jac : 1.2935e-02 	 Enc : 6.4817e-05 	 AEnc : 6.0940e-05 	 MSE : 2.6802e+00
Epoch 224, 50% 	 Loss : 2.3253e-02 	 Res : 1.0224e-02 	 Jac : 1.2928e-02 	 Enc : 6.5018e-05 	 AEnc : 3.5571e-05 	 MSE : 2.4978e+00
Epoch 224, 75% 	 Loss : 2.3825e-02 	 Res : 1.0731e-02 	 Jac : 1.2948e-02 	 Enc : 6.4507e-05 	 AEnc : 8.1848e-05 	 MSE : 2.6275e+00
Training Epoch 224 : 	 Train : 2.34257e-02 	 Res : 1.03904e-02 	 Jac : 1.29145e-02 	 Enc : 6.36941e-05 	 AE : 5.70699e-05 	 MSE : 2.56477e+00
Validation Epoch 224 : 	 Train : 1.97899e-02 	 Res : 6.74218e-03 	 Jac : 1.29572e-02 	 Enc : 5.98923e-05 	 AE : 3.05908e-05 	 MSE : 1.26853e+00
Training Epoch 224 finished, took current epoch 368.08s, cumulative time 84071.85s
Current Learning rate DEQ : 0.0006871947673600005
Current Learning rate AUTOENC : 0.0034359738368000023
Epoch 225, 25% 	 Loss : 2.1018e-02 	 Res : 8.0431e-03 	 Jac : 1.2899e-02 	 Enc : 4.2425e-05 	 AEnc : 3.3689e-05 	 MSE : 1.7142e+00
Epoch 225, 50% 	 Loss : 2.0789e-02 	 Res : 7.8085e-03 	 Jac : 1.2893e-02 	 Enc : 4.2584e-05 	 AEnc : 4.5114e-05 	 MSE : 1.6340e+00
Epoch 225, 75% 	 Loss : 2.0465e-02 	 Res : 7.4738e-03 	 Jac : 1.2930e-02 	 Enc : 3.2283e-05 	 AEnc : 2.7994e-05 	 MSE : 1.5844e+00
Training Epoch 225 : 	 Train : 2.07515e-02 	 Res : 7.74402e-03 	 Jac : 1.29364e-02 	 Enc : 3.72275e-05 	 AE : 3.37618e-05 	 MSE : 1.64642e+00
Validation Epoch 225 : 	 Train : 1.82375e-02 	 Res : 5.23544e-03 	 Jac : 1.29480e-02 	 Enc : 3.15901e-05 	 AE : 2.24679e-05 	 MSE : 7.20925e-01
Training Epoch 225 finished, took current epoch 366.12s, cumulative time 84437.92s
Current Learning rate DEQ : 0.0006871947673600005
Current Learning rate AUTOENC : 0.0034359738368000023
Epoch 226, 25% 	 Loss : 2.0824e-02 	 Res : 7.7728e-03 	 Jac : 1.2995e-02 	 Enc : 2.9853e-05 	 AEnc : 2.5739e-05 	 MSE : 1.7129e+00
Epoch 226, 50% 	 Loss : 2.0629e-02 	 Res : 7.6635e-03 	 Jac : 1.2898e-02 	 Enc : 3.1967e-05 	 AEnc : 3.5637e-05 	 MSE : 1.6116e+00
Epoch 226, 75% 	 Loss : 2.0948e-02 	 Res : 7.9175e-03 	 Jac : 1.2973e-02 	 Enc : 3.1760e-05 	 AEnc : 2.5965e-05 	 MSE : 1.7373e+00
Training Epoch 226 : 	 Train : 2.08004e-02 	 Res : 7.77842e-03 	 Jac : 1.29614e-02 	 Enc : 3.10507e-05 	 AE : 2.94949e-05 	 MSE : 1.68750e+00
Validation Epoch 226 : 	 Train : 1.86825e-02 	 Res : 5.71974e-03 	 Jac : 1.29038e-02 	 Enc : 2.76623e-05 	 AE : 3.13655e-05 	 MSE : 9.13062e-01
Training Epoch 226 finished, took current epoch 369.10s, cumulative time 84806.99s
Current Learning rate DEQ : 0.0006871947673600005
Current Learning rate AUTOENC : 0.0034359738368000023
Epoch 227, 25% 	 Loss : 2.0778e-02 	 Res : 7.7125e-03 	 Jac : 1.3005e-02 	 Enc : 3.3059e-05 	 AEnc : 2.8349e-05 	 MSE : 1.6621e+00
Epoch 227, 50% 	 Loss : 2.1055e-02 	 Res : 8.0921e-03 	 Jac : 1.2884e-02 	 Enc : 3.5589e-05 	 AEnc : 4.3314e-05 	 MSE : 1.7857e+00
Epoch 227, 75% 	 Loss : 2.0758e-02 	 Res : 7.6808e-03 	 Jac : 1.3008e-02 	 Enc : 3.3963e-05 	 AEnc : 3.4315e-05 	 MSE : 1.6802e+00
Training Epoch 227 : 	 Train : 2.08445e-02 	 Res : 7.81433e-03 	 Jac : 1.29620e-02 	 Enc : 3.42369e-05 	 AE : 3.39554e-05 	 MSE : 1.69706e+00
Validation Epoch 227 : 	 Train : 1.87864e-02 	 Res : 5.88626e-03 	 Jac : 1.28391e-02 	 Enc : 3.16564e-05 	 AE : 2.94159e-05 	 MSE : 9.54359e-01
Training Epoch 227 finished, took current epoch 366.11s, cumulative time 85173.06s
Current Learning rate DEQ : 0.0006871947673600005
Current Learning rate AUTOENC : 0.0034359738368000023
Epoch 228, 25% 	 Loss : 2.0905e-02 	 Res : 7.8969e-03 	 Jac : 1.2934e-02 	 Enc : 3.7380e-05 	 AEnc : 3.6146e-05 	 MSE : 1.6844e+00
Epoch 228, 50% 	 Loss : 2.1016e-02 	 Res : 7.9780e-03 	 Jac : 1.2975e-02 	 Enc : 3.3417e-05 	 AEnc : 2.9336e-05 	 MSE : 1.7333e+00
Epoch 228, 75% 	 Loss : 2.8348e-02 	 Res : 1.5249e-02 	 Jac : 1.2943e-02 	 Enc : 7.9905e-05 	 AEnc : 7.6090e-05 	 MSE : 4.3462e+00
Training Epoch 228 : 	 Train : 2.43049e-02 	 Res : 1.12485e-02 	 Jac : 1.29339e-02 	 Enc : 5.94806e-05 	 AE : 6.30078e-05 	 MSE : 2.85430e+00
Validation Epoch 228 : 	 Train : 2.82615e-02 	 Res : 1.45825e-02 	 Jac : 1.29340e-02 	 Enc : 7.90147e-05 	 AE : 6.66064e-04 	 MSE : 3.33127e+00
Training Epoch 228 finished, took current epoch 377.44s, cumulative time 85550.46s
Current Learning rate DEQ : 0.0006871947673600005
Current Learning rate AUTOENC : 0.0034359738368000023
Epoch 229, 25% 	 Loss : 2.0752e-02 	 Res : 7.0171e-03 	 Jac : 1.2977e-02 	 Enc : 7.2641e-05 	 AEnc : 6.8555e-04 	 MSE : 1.1018e+00
Epoch 229, 50% 	 Loss : 1.9647e-02 	 Res : 5.7350e-03 	 Jac : 1.2922e-02 	 Enc : 2.9059e-05 	 AEnc : 9.6139e-04 	 MSE : 8.2702e-01
Epoch 229, 75% 	 Loss : 3.0635e-02 	 Res : 1.6472e-02 	 Jac : 1.2877e-02 	 Enc : 6.1917e-05 	 AEnc : 1.2239e-03 	 MSE : 4.7445e+00
Training Epoch 229 : 	 Train : 2.40857e-02 	 Res : 1.02757e-02 	 Jac : 1.29320e-02 	 Enc : 6.19100e-05 	 AE : 8.16030e-04 	 MSE : 2.40926e+00
Validation Epoch 229 : 	 Train : 1.87351e-02 	 Res : 5.41852e-03 	 Jac : 1.29531e-02 	 Enc : 5.39479e-05 	 AE : 3.09527e-04 	 MSE : 6.91006e-01
Training Epoch 229 finished, took current epoch 368.90s, cumulative time 85919.30s
Current Learning rate DEQ : 0.0006871947673600005
Current Learning rate AUTOENC : 0.0034359738368000023
Epoch 230, 25% 	 Loss : 1.9612e-02 	 Res : 6.4669e-03 	 Jac : 1.2984e-02 	 Enc : 4.1501e-05 	 AEnc : 1.1897e-04 	 MSE : 1.0877e+00
Epoch 230, 50% 	 Loss : 2.5740e-02 	 Res : 6.8778e-03 	 Jac : 1.2957e-02 	 Enc : 2.9648e-05 	 AEnc : 5.8756e-03 	 MSE : 8.0695e-01
Epoch 230, 75% 	 Loss : 3.6438e-02 	 Res : 9.3791e-03 	 Jac : 1.2912e-02 	 Enc : 4.0371e-05 	 AEnc : 1.4107e-02 	 MSE : 1.2918e+00
Training Epoch 230 : 	 Train : 3.97892e-02 	 Res : 9.99185e-03 	 Jac : 1.29334e-02 	 Enc : 6.30023e-05 	 AE : 1.68010e-02 	 MSE : 1.22151e+00
Validation Epoch 230 : 	 Train : 3.04718e-02 	 Res : 6.14514e-03 	 Jac : 1.29441e-02 	 Enc : 1.64820e-04 	 AE : 1.12178e-02 	 MSE : 1.69602e-01
Training Epoch 230 finished, took current epoch 370.66s, cumulative time 86289.93s
Current Learning rate DEQ : 0.0006871947673600005
Current Learning rate AUTOENC : 0.0034359738368000023
Epoch 231, 25% 	 Loss : 5.0049e-02 	 Res : 9.0640e-03 	 Jac : 1.2828e-02 	 Enc : 1.1589e-04 	 AEnc : 2.8040e-02 	 MSE : 3.7953e-01
Epoch 231, 50% 	 Loss : 3.2139e-02 	 Res : 7.0085e-03 	 Jac : 1.2809e-02 	 Enc : 3.6399e-05 	 AEnc : 1.2285e-02 	 MSE : 6.1383e-01
Epoch 231, 75% 	 Loss : 3.7597e-02 	 Res : 1.3873e-02 	 Jac : 1.2841e-02 	 Enc : 4.6150e-05 	 AEnc : 1.0837e-02 	 MSE : 2.9663e+00
Training Epoch 231 : 	 Train : 3.63884e-02 	 Res : 1.03347e-02 	 Jac : 1.28384e-02 	 Enc : 6.93933e-05 	 AE : 1.31459e-02 	 MSE : 1.65703e+00
Validation Epoch 231 : 	 Train : 2.53481e-02 	 Res : 1.23621e-02 	 Jac : 1.28639e-02 	 Enc : 4.35108e-05 	 AE : 7.86347e-05 	 MSE : 3.21815e+00
Training Epoch 231 finished, took current epoch 368.74s, cumulative time 86658.67s
Current Learning rate DEQ : 0.0006871947673600005
Current Learning rate AUTOENC : 0.0034359738368000023
Epoch 232, 25% 	 Loss : 2.4882e-02 	 Res : 8.6502e-03 	 Jac : 1.2811e-02 	 Enc : 5.3782e-05 	 AEnc : 3.3663e-03 	 MSE : 1.6610e+00
Epoch 232, 50% 	 Loss : 1.8979e-02 	 Res : 5.1841e-03 	 Jac : 1.2943e-02 	 Enc : 2.1227e-05 	 AEnc : 8.3038e-04 	 MSE : 6.9004e-01
Epoch 232, 75% 	 Loss : 2.6755e-02 	 Res : 6.9730e-03 	 Jac : 1.2795e-02 	 Enc : 2.9582e-05 	 AEnc : 6.9572e-03 	 MSE : 8.7700e-01
Training Epoch 232 : 	 Train : 3.53506e-02 	 Res : 8.57302e-03 	 Jac : 1.28164e-02 	 Enc : 4.19441e-05 	 AE : 1.39192e-02 	 MSE : 1.08615e+00
Validation Epoch 232 : 	 Train : 2.59581e-02 	 Res : 8.94244e-03 	 Jac : 1.28197e-02 	 Enc : 3.46227e-05 	 AE : 4.16135e-03 	 MSE : 1.75759e+00
Training Epoch 232 finished, took current epoch 365.80s, cumulative time 87024.42s
Current Learning rate DEQ : 0.0006871947673600005
Current Learning rate AUTOENC : 0.0034359738368000023
Epoch 233, 25% 	 Loss : 3.9651e-02 	 Res : 7.5049e-03 	 Jac : 1.2818e-02 	 Enc : 3.5647e-05 	 AEnc : 1.9292e-02 	 MSE : 3.9936e-01
Epoch 233, 50% 	 Loss : 1.9342e-02 	 Res : 4.0930e-03 	 Jac : 1.2729e-02 	 Enc : 1.4037e-05 	 AEnc : 2.5065e-03 	 MSE : 1.9630e-01
Epoch 233, 75% 	 Loss : 2.1325e-02 	 Res : 7.3542e-03 	 Jac : 1.2869e-02 	 Enc : 2.1782e-05 	 AEnc : 1.0801e-03 	 MSE : 1.4729e+00
Training Epoch 233 : 	 Train : 2.55347e-02 	 Res : 6.76518e-03 	 Jac : 1.28189e-02 	 Enc : 2.60506e-05 	 AE : 5.92456e-03 	 MSE : 9.70207e-01
Validation Epoch 233 : 	 Train : 1.81032e-02 	 Res : 5.18611e-03 	 Jac : 1.28162e-02 	 Enc : 3.31249e-05 	 AE : 6.78041e-05 	 MSE : 7.40092e-01
Training Epoch 233 finished, took current epoch 369.80s, cumulative time 87394.21s
Current Learning rate DEQ : 0.0006871947673600005
Current Learning rate AUTOENC : 0.0034359738368000023
Epoch 234, 25% 	 Loss : 2.0864e-02 	 Res : 7.9579e-03 	 Jac : 1.2840e-02 	 Enc : 3.5773e-05 	 AEnc : 3.0784e-05 	 MSE : 1.8036e+00
Epoch 234, 50% 	 Loss : 2.0764e-02 	 Res : 7.8998e-03 	 Jac : 1.2804e-02 	 Enc : 3.7781e-05 	 AEnc : 2.2647e-05 	 MSE : 1.7815e+00
Epoch 234, 75% 	 Loss : 2.1420e-02 	 Res : 8.5286e-03 	 Jac : 1.2818e-02 	 Enc : 4.1542e-05 	 AEnc : 3.2081e-05 	 MSE : 1.9906e+00
Training Epoch 234 : 	 Train : 2.15103e-02 	 Res : 8.62667e-03 	 Jac : 1.28147e-02 	 Enc : 3.92098e-05 	 AE : 2.97327e-05 	 MSE : 2.02187e+00
Validation Epoch 234 : 	 Train : 1.86681e-02 	 Res : 5.75332e-03 	 Jac : 1.28368e-02 	 Enc : 3.10378e-05 	 AE : 4.69306e-05 	 MSE : 8.49953e-01
Training Epoch 234 finished, took current epoch 366.36s, cumulative time 87760.50s
Current Learning rate DEQ : 0.0006871947673600005
Current Learning rate AUTOENC : 0.0034359738368000023
Epoch 235, 25% 	 Loss : 2.3602e-02 	 Res : 1.0725e-02 	 Jac : 1.2806e-02 	 Enc : 2.6574e-05 	 AEnc : 4.4035e-05 	 MSE : 2.6548e+00
Epoch 235, 50% 	 Loss : 2.3928e-02 	 Res : 1.0696e-02 	 Jac : 1.2716e-02 	 Enc : 6.7782e-05 	 AEnc : 4.4816e-04 	 MSE : 2.4012e+00
Epoch 235, 75% 	 Loss : 2.1417e-02 	 Res : 8.5192e-03 	 Jac : 1.2755e-02 	 Enc : 6.1283e-05 	 AEnc : 8.1266e-05 	 MSE : 1.9328e+00
Training Epoch 235 : 	 Train : 2.24853e-02 	 Res : 9.52894e-03 	 Jac : 1.27526e-02 	 Enc : 5.10933e-05 	 AE : 1.52610e-04 	 MSE : 2.22064e+00
Validation Epoch 235 : 	 Train : 1.77953e-02 	 Res : 4.83340e-03 	 Jac : 1.28817e-02 	 Enc : 4.53339e-05 	 AE : 3.48515e-05 	 MSE : 5.80197e-01
Training Epoch 235 finished, took current epoch 371.67s, cumulative time 88132.13s
Current Learning rate DEQ : 0.0005497558138880005
Current Learning rate AUTOENC : 0.002748779069440002
Epoch 236, 25% 	 Loss : 1.9404e-02 	 Res : 6.5465e-03 	 Jac : 1.2798e-02 	 Enc : 3.4810e-05 	 AEnc : 2.4911e-05 	 MSE : 1.2795e+00
Epoch 236, 50% 	 Loss : 1.9285e-02 	 Res : 6.3339e-03 	 Jac : 1.2902e-02 	 Enc : 2.6875e-05 	 AEnc : 2.2025e-05 	 MSE : 1.2143e+00
Epoch 236, 75% 	 Loss : 1.9172e-02 	 Res : 6.2582e-03 	 Jac : 1.2866e-02 	 Enc : 2.5267e-05 	 AEnc : 2.2104e-05 	 MSE : 1.1796e+00
Training Epoch 236 : 	 Train : 1.92268e-02 	 Res : 6.32779e-03 	 Jac : 1.28482e-02 	 Enc : 2.81029e-05 	 AE : 2.26662e-05 	 MSE : 1.20379e+00
Validation Epoch 236 : 	 Train : 2.21956e-02 	 Res : 9.30586e-03 	 Jac : 1.28444e-02 	 Enc : 2.47514e-05 	 AE : 2.06539e-05 	 MSE : 2.26305e+00
Training Epoch 236 finished, took current epoch 370.25s, cumulative time 88502.34s
Current Learning rate DEQ : 0.0005497558138880005
Current Learning rate AUTOENC : 0.002748779069440002
Epoch 237, 25% 	 Loss : 1.9432e-02 	 Res : 6.5814e-03 	 Jac : 1.2802e-02 	 Enc : 2.6725e-05 	 AEnc : 2.1967e-05 	 MSE : 1.2915e+00
Epoch 237, 50% 	 Loss : 1.9482e-02 	 Res : 6.5941e-03 	 Jac : 1.2835e-02 	 Enc : 2.8018e-05 	 AEnc : 2.4189e-05 	 MSE : 1.2702e+00
Epoch 237, 75% 	 Loss : 1.9583e-02 	 Res : 6.7791e-03 	 Jac : 1.2753e-02 	 Enc : 2.6915e-05 	 AEnc : 2.4100e-05 	 MSE : 1.3442e+00
Training Epoch 237 : 	 Train : 1.96535e-02 	 Res : 6.78871e-03 	 Jac : 1.28117e-02 	 Enc : 2.84450e-05 	 AE : 2.46308e-05 	 MSE : 1.34120e+00
Validation Epoch 237 : 	 Train : 1.92588e-02 	 Res : 6.41366e-03 	 Jac : 1.27834e-02 	 Enc : 3.24520e-05 	 AE : 2.92961e-05 	 MSE : 1.17788e+00
Training Epoch 237 finished, took current epoch 371.65s, cumulative time 88873.98s
Current Learning rate DEQ : 0.0005497558138880005
Current Learning rate AUTOENC : 0.002748779069440002
Epoch 238, 25% 	 Loss : 1.9648e-02 	 Res : 6.6757e-03 	 Jac : 1.2914e-02 	 Enc : 3.3566e-05 	 AEnc : 2.5571e-05 	 MSE : 1.2940e+00
Epoch 238, 50% 	 Loss : 1.9252e-02 	 Res : 6.3532e-03 	 Jac : 1.2847e-02 	 Enc : 2.7376e-05 	 AEnc : 2.4556e-05 	 MSE : 1.2122e+00
Epoch 238, 75% 	 Loss : 1.9299e-02 	 Res : 6.4006e-03 	 Jac : 1.2850e-02 	 Enc : 2.6055e-05 	 AEnc : 2.2671e-05 	 MSE : 1.2311e+00
Training Epoch 238 : 	 Train : 1.94350e-02 	 Res : 6.49595e-03 	 Jac : 1.28875e-02 	 Enc : 2.81860e-05 	 AE : 2.33526e-05 	 MSE : 1.25601e+00
Validation Epoch 238 : 	 Train : 1.76613e-02 	 Res : 4.78204e-03 	 Jac : 1.28348e-02 	 Enc : 2.33988e-05 	 AE : 2.10035e-05 	 MSE : 5.94842e-01
Training Epoch 238 finished, took current epoch 367.39s, cumulative time 89241.35s
Current Learning rate DEQ : 0.0005497558138880005
Current Learning rate AUTOENC : 0.002748779069440002
Epoch 239, 25% 	 Loss : 1.9544e-02 	 Res : 6.6911e-03 	 Jac : 1.2809e-02 	 Enc : 2.1327e-05 	 AEnc : 2.2881e-05 	 MSE : 1.3078e+00
Epoch 239, 50% 	 Loss : 2.1742e-02 	 Res : 8.8485e-03 	 Jac : 1.2818e-02 	 Enc : 3.2473e-05 	 AEnc : 4.2764e-05 	 MSE : 2.0615e+00
Epoch 239, 75% 	 Loss : 1.9726e-02 	 Res : 6.8822e-03 	 Jac : 1.2775e-02 	 Enc : 3.4040e-05 	 AEnc : 3.4271e-05 	 MSE : 1.3922e+00
Training Epoch 239 : 	 Train : 2.00484e-02 	 Res : 7.19312e-03 	 Jac : 1.27956e-02 	 Enc : 2.88577e-05 	 AE : 3.07943e-05 	 MSE : 1.49247e+00
Validation Epoch 239 : 	 Train : 2.04046e-02 	 Res : 7.55962e-03 	 Jac : 1.27974e-02 	 Enc : 2.58592e-05 	 AE : 2.16923e-05 	 MSE : 1.65050e+00
Training Epoch 239 finished, took current epoch 368.12s, cumulative time 89609.46s
Current Learning rate DEQ : 0.0005497558138880005
Current Learning rate AUTOENC : 0.002748779069440002
Epoch 240, 25% 	 Loss : 2.9625e-02 	 Res : 1.6587e-02 	 Jac : 1.2758e-02 	 Enc : 5.4348e-05 	 AEnc : 2.2607e-04 	 MSE : 4.7561e+00
Epoch 240, 50% 	 Loss : 3.7655e-02 	 Res : 2.2832e-02 	 Jac : 1.2754e-02 	 Enc : 1.0565e-04 	 AEnc : 1.9623e-03 	 MSE : 6.6333e+00
Epoch 240, 75% 	 Loss : 2.8243e-02 	 Res : 1.1471e-02 	 Jac : 1.2790e-02 	 Enc : 1.5312e-04 	 AEnc : 3.8292e-03 	 MSE : 2.5261e+00
Training Epoch 240 : 	 Train : 2.86990e-02 	 Res : 1.40080e-02 	 Jac : 1.27890e-02 	 Enc : 8.73889e-05 	 AE : 1.81456e-03 	 MSE : 3.63736e+00
Validation Epoch 240 : 	 Train : 1.71298e-02 	 Res : 3.99668e-03 	 Jac : 1.27689e-02 	 Enc : 2.01630e-05 	 AE : 3.44036e-04 	 MSE : 3.02893e-01
Training Epoch 240 finished, took current epoch 371.83s, cumulative time 89981.22s
Current Learning rate DEQ : 0.0005497558138880005
Current Learning rate AUTOENC : 0.002748779069440002
MODEL SAVED
Epoch 241, 25% 	 Loss : 1.8318e-02 	 Res : 4.5071e-03 	 Jac : 1.2854e-02 	 Enc : 1.4082e-05 	 AEnc : 9.4266e-04 	 MSE : 4.8164e-01
Epoch 241, 50% 	 Loss : 1.9046e-02 	 Res : 4.7533e-03 	 Jac : 1.2816e-02 	 Enc : 1.4737e-05 	 AEnc : 1.4620e-03 	 MSE : 5.0779e-01
Epoch 241, 75% 	 Loss : 1.7834e-02 	 Res : 4.6794e-03 	 Jac : 1.2825e-02 	 Enc : 1.4156e-05 	 AEnc : 3.1498e-04 	 MSE : 5.1987e-01
Training Epoch 241 : 	 Train : 1.80820e-02 	 Res : 4.54097e-03 	 Jac : 1.28174e-02 	 Enc : 1.39593e-05 	 AE : 7.09667e-04 	 MSE : 4.85831e-01
Validation Epoch 241 : 	 Train : 1.73660e-02 	 Res : 4.48330e-03 	 Jac : 1.28093e-02 	 Enc : 1.33318e-05 	 AE : 6.00914e-05 	 MSE : 4.90503e-01
Training Epoch 241 finished, took current epoch 370.75s, cumulative time 90351.94s
Current Learning rate DEQ : 0.0005497558138880005
Current Learning rate AUTOENC : 0.002748779069440002
Epoch 242, 25% 	 Loss : 1.7130e-02 	 Res : 4.3328e-03 	 Jac : 1.2755e-02 	 Enc : 1.3279e-05 	 AEnc : 2.9302e-05 	 MSE : 4.6091e-01
Epoch 242, 50% 	 Loss : 2.1374e-02 	 Res : 7.8353e-03 	 Jac : 1.2839e-02 	 Enc : 4.5176e-05 	 AEnc : 6.5408e-04 	 MSE : 1.4051e+00
Epoch 242, 75% 	 Loss : 1.8500e-02 	 Res : 5.1221e-03 	 Jac : 1.2834e-02 	 Enc : 5.3510e-05 	 AEnc : 4.8963e-04 	 MSE : 5.9750e-01
Training Epoch 242 : 	 Train : 1.96686e-02 	 Res : 6.48601e-03 	 Jac : 1.28005e-02 	 Enc : 3.81832e-05 	 AE : 3.43889e-04 	 MSE : 1.11394e+00
Validation Epoch 242 : 	 Train : 2.71057e-02 	 Res : 1.41545e-02 	 Jac : 1.28396e-02 	 Enc : 3.87362e-05 	 AE : 7.29572e-05 	 MSE : 4.05261e+00
Training Epoch 242 finished, took current epoch 373.38s, cumulative time 90725.27s
Current Learning rate DEQ : 0.0005497558138880005
Current Learning rate AUTOENC : 0.002748779069440002
Epoch 243, 25% 	 Loss : 2.0783e-02 	 Res : 7.6852e-03 	 Jac : 1.2792e-02 	 Enc : 3.4396e-05 	 AEnc : 2.7154e-04 	 MSE : 1.6075e+00
Epoch 243, 50% 	 Loss : 2.1095e-02 	 Res : 8.0421e-03 	 Jac : 1.2845e-02 	 Enc : 4.3666e-05 	 AEnc : 1.6414e-04 	 MSE : 1.5839e+00
Epoch 243, 75% 	 Loss : 1.9671e-02 	 Res : 6.6535e-03 	 Jac : 1.2820e-02 	 Enc : 5.2063e-05 	 AEnc : 1.4586e-04 	 MSE : 1.1080e+00
Training Epoch 243 : 	 Train : 1.98692e-02 	 Res : 6.79817e-03 	 Jac : 1.27986e-02 	 Enc : 3.74956e-05 	 AE : 2.34866e-04 	 MSE : 1.21890e+00
Validation Epoch 243 : 	 Train : 1.79325e-02 	 Res : 4.93524e-03 	 Jac : 1.28354e-02 	 Enc : 1.51472e-05 	 AE : 1.46721e-04 	 MSE : 6.57908e-01
Training Epoch 243 finished, took current epoch 368.85s, cumulative time 91094.11s
Current Learning rate DEQ : 0.0005497558138880005
Current Learning rate AUTOENC : 0.002748779069440002
Epoch 244, 25% 	 Loss : 1.7846e-02 	 Res : 4.3647e-03 	 Jac : 1.2805e-02 	 Enc : 1.4234e-05 	 AEnc : 6.6279e-04 	 MSE : 4.5793e-01
Epoch 244, 50% 	 Loss : 1.7175e-02 	 Res : 4.2611e-03 	 Jac : 1.2712e-02 	 Enc : 1.2822e-05 	 AEnc : 1.8961e-04 	 MSE : 4.3794e-01
Epoch 244, 75% 	 Loss : 2.0546e-02 	 Res : 7.2740e-03 	 Jac : 1.2717e-02 	 Enc : 1.6901e-05 	 AEnc : 5.3768e-04 	 MSE : 1.4445e+00
Training Epoch 244 : 	 Train : 2.00784e-02 	 Res : 6.81361e-03 	 Jac : 1.27517e-02 	 Enc : 3.07852e-05 	 AE : 4.82333e-04 	 MSE : 1.33503e+00
Validation Epoch 244 : 	 Train : 1.88171e-02 	 Res : 5.48748e-03 	 Jac : 1.27781e-02 	 Enc : 5.02764e-05 	 AE : 5.01204e-04 	 MSE : 7.41555e-01
Training Epoch 244 finished, took current epoch 365.48s, cumulative time 91459.56s
Current Learning rate DEQ : 0.0005497558138880005
Current Learning rate AUTOENC : 0.002748779069440002
Epoch 245, 25% 	 Loss : 2.9867e-02 	 Res : 1.6852e-02 	 Jac : 1.2726e-02 	 Enc : 7.7661e-05 	 AEnc : 2.1085e-04 	 MSE : 4.9594e+00
Epoch 245, 50% 	 Loss : 2.4530e-02 	 Res : 6.2291e-03 	 Jac : 1.2820e-02 	 Enc : 7.5817e-05 	 AEnc : 5.4057e-03 	 MSE : 7.7076e-01
Epoch 245, 75% 	 Loss : 2.4904e-02 	 Res : 5.7249e-03 	 Jac : 1.2814e-02 	 Enc : 2.4159e-05 	 AEnc : 6.3405e-03 	 MSE : 5.7764e-01
Training Epoch 245 : 	 Train : 3.40111e-02 	 Res : 1.04137e-02 	 Jac : 1.27910e-02 	 Enc : 6.13427e-05 	 AE : 1.07451e-02 	 MSE : 1.94912e+00
Validation Epoch 245 : 	 Train : 3.58467e-02 	 Res : 1.04606e-02 	 Jac : 1.28491e-02 	 Enc : 5.05029e-05 	 AE : 1.24865e-02 	 MSE : 1.90449e+00
Training Epoch 245 finished, took current epoch 369.51s, cumulative time 91829.05s
Current Learning rate DEQ : 0.0005497558138880005
Current Learning rate AUTOENC : 0.002748779069440002
Epoch 246, 25% 	 Loss : 2.3366e-02 	 Res : 7.2221e-03 	 Jac : 1.2772e-02 	 Enc : 3.6596e-05 	 AEnc : 3.3349e-03 	 MSE : 1.3597e+00
Epoch 246, 50% 	 Loss : 2.9800e-02 	 Res : 1.6642e-02 	 Jac : 1.2852e-02 	 Enc : 5.4040e-05 	 AEnc : 2.5260e-04 	 MSE : 4.9393e+00
Epoch 246, 75% 	 Loss : 2.3717e-02 	 Res : 8.7294e-03 	 Jac : 1.2833e-02 	 Enc : 6.3930e-05 	 AEnc : 2.0913e-03 	 MSE : 1.8434e+00
Training Epoch 246 : 	 Train : 2.43335e-02 	 Res : 9.92981e-03 	 Jac : 1.28271e-02 	 Enc : 4.85612e-05 	 AE : 1.52806e-03 	 MSE : 2.40214e+00
Validation Epoch 246 : 	 Train : 1.89479e-02 	 Res : 6.10942e-03 	 Jac : 1.27747e-02 	 Enc : 3.11257e-05 	 AE : 3.26573e-05 	 MSE : 1.12598e+00
Training Epoch 246 finished, took current epoch 365.65s, cumulative time 92194.69s
Current Learning rate DEQ : 0.0005497558138880005
Current Learning rate AUTOENC : 0.002748779069440002
Epoch 247, 25% 	 Loss : 1.9442e-02 	 Res : 6.5622e-03 	 Jac : 1.2811e-02 	 Enc : 3.0340e-05 	 AEnc : 3.8676e-05 	 MSE : 1.2980e+00
Epoch 247, 50% 	 Loss : 1.9601e-02 	 Res : 6.6129e-03 	 Jac : 1.2927e-02 	 Enc : 3.0045e-05 	 AEnc : 3.0824e-05 	 MSE : 1.3556e+00
Epoch 247, 75% 	 Loss : 1.9507e-02 	 Res : 6.6605e-03 	 Jac : 1.2792e-02 	 Enc : 2.9768e-05 	 AEnc : 2.4314e-05 	 MSE : 1.3398e+00
Training Epoch 247 : 	 Train : 1.95415e-02 	 Res : 6.63923e-03 	 Jac : 1.28429e-02 	 Enc : 3.01131e-05 	 AE : 2.91967e-05 	 MSE : 1.34448e+00
Validation Epoch 247 : 	 Train : 1.89668e-02 	 Res : 6.15816e-03 	 Jac : 1.27581e-02 	 Enc : 3.00661e-05 	 AE : 2.04148e-05 	 MSE : 1.14354e+00
Training Epoch 247 finished, took current epoch 363.56s, cumulative time 92558.24s
Current Learning rate DEQ : 0.0005497558138880005
Current Learning rate AUTOENC : 0.002748779069440002
Epoch 248, 25% 	 Loss : 1.9545e-02 	 Res : 6.6313e-03 	 Jac : 1.2862e-02 	 Enc : 3.1703e-05 	 AEnc : 2.0872e-05 	 MSE : 1.3144e+00
Epoch 248, 50% 	 Loss : 1.9511e-02 	 Res : 6.6179e-03 	 Jac : 1.2841e-02 	 Enc : 2.9751e-05 	 AEnc : 2.2268e-05 	 MSE : 1.3538e+00
Epoch 248, 75% 	 Loss : 1.9825e-02 	 Res : 6.9774e-03 	 Jac : 1.2694e-02 	 Enc : 2.9932e-05 	 AEnc : 1.2454e-04 	 MSE : 1.4495e+00
Training Epoch 248 : 	 Train : 1.97050e-02 	 Res : 6.77629e-03 	 Jac : 1.28105e-02 	 Enc : 3.10096e-05 	 AE : 8.71679e-05 	 MSE : 1.38678e+00
Validation Epoch 248 : 	 Train : 1.74515e-02 	 Res : 4.57819e-03 	 Jac : 1.28080e-02 	 Enc : 3.23802e-05 	 AE : 3.29619e-05 	 MSE : 5.46150e-01
Training Epoch 248 finished, took current epoch 364.28s, cumulative time 92922.50s
Current Learning rate DEQ : 0.0005497558138880005
Current Learning rate AUTOENC : 0.002748779069440002
Epoch 249, 25% 	 Loss : 1.9585e-02 	 Res : 6.6509e-03 	 Jac : 1.2872e-02 	 Enc : 3.0414e-05 	 AEnc : 3.2425e-05 	 MSE : 1.3549e+00
Epoch 249, 50% 	 Loss : 1.9787e-02 	 Res : 6.8983e-03 	 Jac : 1.2835e-02 	 Enc : 2.8582e-05 	 AEnc : 2.4573e-05 	 MSE : 1.4430e+00
Epoch 249, 75% 	 Loss : 1.9679e-02 	 Res : 6.7897e-03 	 Jac : 1.2836e-02 	 Enc : 2.9399e-05 	 AEnc : 2.3724e-05 	 MSE : 1.3976e+00
Training Epoch 249 : 	 Train : 1.96076e-02 	 Res : 6.71496e-03 	 Jac : 1.28370e-02 	 Enc : 2.98698e-05 	 AE : 2.57700e-05 	 MSE : 1.37697e+00
Validation Epoch 249 : 	 Train : 2.39044e-02 	 Res : 1.10401e-02 	 Jac : 1.27936e-02 	 Enc : 3.04272e-05 	 AE : 4.02232e-05 	 MSE : 2.93791e+00
Training Epoch 249 finished, took current epoch 365.19s, cumulative time 93287.68s
Current Learning rate DEQ : 0.0005497558138880005
Current Learning rate AUTOENC : 0.002748779069440002
Epoch 250, 25% 	 Loss : 1.9715e-02 	 Res : 6.9037e-03 	 Jac : 1.2756e-02 	 Enc : 3.1303e-05 	 AEnc : 2.3479e-05 	 MSE : 1.4413e+00
Epoch 250, 50% 	 Loss : 1.9612e-02 	 Res : 6.7155e-03 	 Jac : 1.2841e-02 	 Enc : 3.1409e-05 	 AEnc : 2.3557e-05 	 MSE : 1.3718e+00
Epoch 250, 75% 	 Loss : 2.3645e-02 	 Res : 1.0669e-02 	 Jac : 1.2891e-02 	 Enc : 3.6999e-05 	 AEnc : 4.7822e-05 	 MSE : 2.8343e+00
Training Epoch 250 : 	 Train : 2.16721e-02 	 Res : 8.10631e-03 	 Jac : 1.28325e-02 	 Enc : 3.58772e-05 	 AE : 6.97372e-04 	 MSE : 1.78806e+00
Validation Epoch 250 : 	 Train : 3.84599e-02 	 Res : 1.15002e-02 	 Jac : 1.28582e-02 	 Enc : 5.54197e-05 	 AE : 1.40460e-02 	 MSE : 2.26750e+00
Training Epoch 250 finished, took current epoch 371.55s, cumulative time 93659.22s
Current Learning rate DEQ : 0.0005497558138880005
Current Learning rate AUTOENC : 0.002748779069440002
Epoch 251, 25% 	 Loss : 4.0840e-02 	 Res : 9.5353e-03 	 Jac : 1.2784e-02 	 Enc : 5.0866e-05 	 AEnc : 1.8471e-02 	 MSE : 1.0513e+00
Epoch 251, 50% 	 Loss : 2.8471e-02 	 Res : 8.1374e-03 	 Jac : 1.2761e-02 	 Enc : 4.0881e-05 	 AEnc : 7.5320e-03 	 MSE : 1.4885e+00
Epoch 251, 75% 	 Loss : 1.9701e-02 	 Res : 6.6797e-03 	 Jac : 1.2792e-02 	 Enc : 3.3529e-05 	 AEnc : 1.9656e-04 	 MSE : 1.3443e+00
Training Epoch 251 : 	 Train : 2.73654e-02 	 Res : 7.81416e-03 	 Jac : 1.28018e-02 	 Enc : 3.91387e-05 	 AE : 6.71023e-03 	 MSE : 1.32562e+00
Validation Epoch 251 : 	 Train : 1.73692e-02 	 Res : 4.55825e-03 	 Jac : 1.27623e-02 	 Enc : 2.84609e-05 	 AE : 2.01919e-05 	 MSE : 5.36789e-01
Training Epoch 251 finished, took current epoch 365.28s, cumulative time 94024.49s
Current Learning rate DEQ : 0.0004398046511104004
Current Learning rate AUTOENC : 0.002199023255552002
Epoch 252, 25% 	 Loss : 1.8347e-02 	 Res : 5.4415e-03 	 Jac : 1.2859e-02 	 Enc : 2.3308e-05 	 AEnc : 2.3290e-05 	 MSE : 9.1030e-01
Epoch 252, 50% 	 Loss : 1.8501e-02 	 Res : 5.6070e-03 	 Jac : 1.2851e-02 	 Enc : 2.1791e-05 	 AEnc : 2.1204e-05 	 MSE : 9.5042e-01
Epoch 252, 75% 	 Loss : 1.9086e-02 	 Res : 5.3807e-03 	 Jac : 1.2832e-02 	 Enc : 1.7759e-05 	 AEnc : 8.5602e-04 	 MSE : 6.9621e-01
Training Epoch 252 : 	 Train : 1.90656e-02 	 Res : 5.74224e-03 	 Jac : 1.28697e-02 	 Enc : 2.25240e-05 	 AE : 4.31106e-04 	 MSE : 9.43620e-01
Validation Epoch 252 : 	 Train : 2.01930e-02 	 Res : 7.29806e-03 	 Jac : 1.27991e-02 	 Enc : 2.16340e-05 	 AE : 7.42375e-05 	 MSE : 1.57186e+00
Training Epoch 252 finished, took current epoch 363.51s, cumulative time 94387.98s
Current Learning rate DEQ : 0.0004398046511104004
Current Learning rate AUTOENC : 0.002199023255552002
Epoch 253, 25% 	 Loss : 2.4245e-02 	 Res : 1.1194e-02 	 Jac : 1.2863e-02 	 Enc : 3.3732e-05 	 AEnc : 1.5385e-04 	 MSE : 2.9530e+00
Epoch 253, 50% 	 Loss : 2.4847e-02 	 Res : 1.1218e-02 	 Jac : 1.2900e-02 	 Enc : 7.5630e-05 	 AEnc : 6.5347e-04 	 MSE : 2.8329e+00
Epoch 253, 75% 	 Loss : 3.6082e-02 	 Res : 7.6515e-03 	 Jac : 1.2785e-02 	 Enc : 4.2392e-05 	 AEnc : 1.5604e-02 	 MSE : 8.1590e-01
Training Epoch 253 : 	 Train : 2.88537e-02 	 Res : 9.19999e-03 	 Jac : 1.28435e-02 	 Enc : 4.43368e-05 	 AE : 6.76585e-03 	 MSE : 1.83271e+00
Validation Epoch 253 : 	 Train : 2.03348e-02 	 Res : 4.44768e-03 	 Jac : 1.28608e-02 	 Enc : 2.38143e-05 	 AE : 3.00246e-03 	 MSE : 2.48632e-01
Training Epoch 253 finished, took current epoch 366.48s, cumulative time 94754.45s
Current Learning rate DEQ : 0.0004398046511104004
Current Learning rate AUTOENC : 0.002199023255552002
Epoch 254, 25% 	 Loss : 2.1283e-02 	 Res : 4.6095e-03 	 Jac : 1.2788e-02 	 Enc : 1.8872e-05 	 AEnc : 3.8671e-03 	 MSE : 3.4122e-01
Epoch 254, 50% 	 Loss : 2.0601e-02 	 Res : 7.4416e-03 	 Jac : 1.2807e-02 	 Enc : 1.8700e-05 	 AEnc : 3.3380e-04 	 MSE : 1.5796e+00
Epoch 254, 75% 	 Loss : 2.0929e-02 	 Res : 7.9768e-03 	 Jac : 1.2835e-02 	 Enc : 3.6554e-05 	 AEnc : 8.1258e-05 	 MSE : 1.8518e+00
Training Epoch 254 : 	 Train : 2.04052e-02 	 Res : 6.33396e-03 	 Jac : 1.28264e-02 	 Enc : 2.38957e-05 	 AE : 1.22093e-03 	 MSE : 1.13497e+00
Validation Epoch 254 : 	 Train : 1.79853e-02 	 Res : 5.00124e-03 	 Jac : 1.27765e-02 	 Enc : 1.80414e-05 	 AE : 1.89493e-04 	 MSE : 5.76184e-01
Training Epoch 254 finished, took current epoch 372.27s, cumulative time 95126.71s
Current Learning rate DEQ : 0.0004398046511104004
Current Learning rate AUTOENC : 0.002199023255552002
Epoch 255, 25% 	 Loss : 1.8265e-02 	 Res : 5.2844e-03 	 Jac : 1.2837e-02 	 Enc : 1.8126e-05 	 AEnc : 1.2499e-04 	 MSE : 7.9325e-01
Epoch 255, 50% 	 Loss : 1.8757e-02 	 Res : 5.8257e-03 	 Jac : 1.2877e-02 	 Enc : 2.6069e-05 	 AEnc : 2.8819e-05 	 MSE : 1.0499e+00
Epoch 255, 75% 	 Loss : 1.8430e-02 	 Res : 5.6066e-03 	 Jac : 1.2779e-02 	 Enc : 2.3403e-05 	 AEnc : 2.1052e-05 	 MSE : 9.8945e-01
Training Epoch 255 : 	 Train : 1.86554e-02 	 Res : 5.76693e-03 	 Jac : 1.28159e-02 	 Enc : 2.22509e-05 	 AE : 5.03403e-05 	 MSE : 1.00294e+00
Validation Epoch 255 : 	 Train : 1.78146e-02 	 Res : 4.96449e-03 	 Jac : 1.28029e-02 	 Enc : 2.26979e-05 	 AE : 2.44661e-05 	 MSE : 6.94022e-01
Training Epoch 255 finished, took current epoch 372.35s, cumulative time 95499.05s
Current Learning rate DEQ : 0.0004398046511104004
Current Learning rate AUTOENC : 0.002199023255552002
Epoch 256, 25% 	 Loss : 1.8393e-02 	 Res : 5.5345e-03 	 Jac : 1.2816e-02 	 Enc : 2.2546e-05 	 AEnc : 2.0231e-05 	 MSE : 9.4860e-01
Epoch 256, 50% 	 Loss : 1.8634e-02 	 Res : 5.7642e-03 	 Jac : 1.2824e-02 	 Enc : 2.2630e-05 	 AEnc : 2.3135e-05 	 MSE : 1.0174e+00
Epoch 256, 75% 	 Loss : 1.8416e-02 	 Res : 5.6262e-03 	 Jac : 1.2745e-02 	 Enc : 2.3132e-05 	 AEnc : 2.1408e-05 	 MSE : 1.0036e+00
Training Epoch 256 : 	 Train : 1.85083e-02 	 Res : 5.66707e-03 	 Jac : 1.27959e-02 	 Enc : 2.27857e-05 	 AE : 2.24941e-05 	 MSE : 9.99930e-01
Validation Epoch 256 : 	 Train : 1.74472e-02 	 Res : 4.56008e-03 	 Jac : 1.28440e-02 	 Enc : 2.20889e-05 	 AE : 2.10007e-05 	 MSE : 5.41282e-01
Training Epoch 256 finished, took current epoch 366.55s, cumulative time 95865.58s
Current Learning rate DEQ : 0.0004398046511104004
Current Learning rate AUTOENC : 0.002199023255552002
Epoch 257, 25% 	 Loss : 1.8479e-02 	 Res : 5.6292e-03 	 Jac : 1.2803e-02 	 Enc : 2.1810e-05 	 AEnc : 2.4237e-05 	 MSE : 9.8240e-01
Epoch 257, 50% 	 Loss : 1.8492e-02 	 Res : 5.5802e-03 	 Jac : 1.2869e-02 	 Enc : 2.2019e-05 	 AEnc : 2.0337e-05 	 MSE : 9.9591e-01
Epoch 257, 75% 	 Loss : 1.8507e-02 	 Res : 5.6534e-03 	 Jac : 1.2811e-02 	 Enc : 2.2384e-05 	 AEnc : 1.9600e-05 	 MSE : 9.9086e-01
Training Epoch 257 : 	 Train : 1.85102e-02 	 Res : 5.63466e-03 	 Jac : 1.28320e-02 	 Enc : 2.23065e-05 	 AE : 2.11747e-05 	 MSE : 9.87156e-01
Validation Epoch 257 : 	 Train : 1.85983e-02 	 Res : 5.63767e-03 	 Jac : 1.29193e-02 	 Enc : 2.30840e-05 	 AE : 1.82289e-05 	 MSE : 9.31475e-01
Training Epoch 257 finished, took current epoch 368.17s, cumulative time 96233.73s
Current Learning rate DEQ : 0.0004398046511104004
Current Learning rate AUTOENC : 0.002199023255552002
Epoch 258, 25% 	 Loss : 1.8638e-02 	 Res : 5.7432e-03 	 Jac : 1.2848e-02 	 Enc : 2.3864e-05 	 AEnc : 2.3010e-05 	 MSE : 9.9705e-01
Epoch 258, 50% 	 Loss : 1.8479e-02 	 Res : 5.6426e-03 	 Jac : 1.2793e-02 	 Enc : 2.2185e-05 	 AEnc : 2.1470e-05 	 MSE : 1.0106e+00
Epoch 258, 75% 	 Loss : 1.8409e-02 	 Res : 5.6356e-03 	 Jac : 1.2728e-02 	 Enc : 2.2732e-05 	 AEnc : 2.2123e-05 	 MSE : 1.0037e+00
Training Epoch 258 : 	 Train : 1.86309e-02 	 Res : 5.77482e-03 	 Jac : 1.27922e-02 	 Enc : 2.29222e-05 	 AE : 4.10083e-05 	 MSE : 1.03156e+00
Validation Epoch 258 : 	 Train : 1.71604e-02 	 Res : 4.21384e-03 	 Jac : 1.28979e-02 	 Enc : 2.45305e-05 	 AE : 2.41095e-05 	 MSE : 4.30567e-01
Training Epoch 258 finished, took current epoch 369.46s, cumulative time 96603.18s
Current Learning rate DEQ : 0.0004398046511104004
Current Learning rate AUTOENC : 0.002199023255552002
Epoch 259, 25% 	 Loss : 1.8885e-02 	 Res : 6.0692e-03 	 Jac : 1.2746e-02 	 Enc : 2.4730e-05 	 AEnc : 4.4639e-05 	 MSE : 1.0910e+00
Epoch 259, 50% 	 Loss : 2.6668e-02 	 Res : 1.3118e-02 	 Jac : 1.2749e-02 	 Enc : 5.1989e-05 	 AEnc : 7.4978e-04 	 MSE : 3.6486e+00
Epoch 259, 75% 	 Loss : 1.9096e-02 	 Res : 5.9912e-03 	 Jac : 1.2785e-02 	 Enc : 3.4620e-05 	 AEnc : 2.8536e-04 	 MSE : 1.0573e+00
Training Epoch 259 : 	 Train : 2.07969e-02 	 Res : 7.70855e-03 	 Jac : 1.27705e-02 	 Enc : 3.31858e-05 	 AE : 2.84686e-04 	 MSE : 1.70089e+00
Validation Epoch 259 : 	 Train : 1.81927e-02 	 Res : 5.36592e-03 	 Jac : 1.27816e-02 	 Enc : 2.10787e-05 	 AE : 2.40890e-05 	 MSE : 8.36982e-01
Training Epoch 259 finished, took current epoch 369.19s, cumulative time 96972.33s
Current Learning rate DEQ : 0.0004398046511104004
Current Learning rate AUTOENC : 0.002199023255552002
Epoch 260, 25% 	 Loss : 1.8579e-02 	 Res : 5.6828e-03 	 Jac : 1.2844e-02 	 Enc : 2.3873e-05 	 AEnc : 2.8884e-05 	 MSE : 9.8856e-01
Epoch 260, 50% 	 Loss : 1.8550e-02 	 Res : 5.6748e-03 	 Jac : 1.2830e-02 	 Enc : 2.3325e-05 	 AEnc : 2.2120e-05 	 MSE : 1.0053e+00
Epoch 260, 75% 	 Loss : 1.8679e-02 	 Res : 5.7889e-03 	 Jac : 1.2844e-02 	 Enc : 2.2719e-05 	 AEnc : 2.3274e-05 	 MSE : 1.0324e+00
Training Epoch 260 : 	 Train : 1.85744e-02 	 Res : 5.69505e-03 	 Jac : 1.28321e-02 	 Enc : 2.35756e-05 	 AE : 2.36950e-05 	 MSE : 1.00903e+00
Validation Epoch 260 : 	 Train : 1.77984e-02 	 Res : 5.01125e-03 	 Jac : 1.27382e-02 	 Enc : 2.60587e-05 	 AE : 2.29309e-05 	 MSE : 7.49270e-01
Training Epoch 260 finished, took current epoch 369.16s, cumulative time 97341.43s
Current Learning rate DEQ : 0.0004398046511104004
Current Learning rate AUTOENC : 0.002199023255552002
Epoch 261, 25% 	 Loss : 1.8446e-02 	 Res : 5.6015e-03 	 Jac : 1.2802e-02 	 Enc : 2.2117e-05 	 AEnc : 2.1070e-05 	 MSE : 9.6213e-01
Epoch 261, 50% 	 Loss : 1.8478e-02 	 Res : 5.6574e-03 	 Jac : 1.2776e-02 	 Enc : 2.3729e-05 	 AEnc : 2.0977e-05 	 MSE : 1.0082e+00
Epoch 261, 75% 	 Loss : 1.8479e-02 	 Res : 5.6325e-03 	 Jac : 1.2803e-02 	 Enc : 2.2636e-05 	 AEnc : 2.1054e-05 	 MSE : 9.9808e-01
Training Epoch 261 : 	 Train : 1.84819e-02 	 Res : 5.65478e-03 	 Jac : 1.27831e-02 	 Enc : 2.31366e-05 	 AE : 2.08436e-05 	 MSE : 9.98341e-01
Validation Epoch 261 : 	 Train : 1.78713e-02 	 Res : 5.04531e-03 	 Jac : 1.27798e-02 	 Enc : 2.45596e-05 	 AE : 2.15607e-05 	 MSE : 7.48895e-01
Training Epoch 261 finished, took current epoch 368.20s, cumulative time 97709.61s
Current Learning rate DEQ : 0.0004398046511104004
Current Learning rate AUTOENC : 0.002199023255552002
Epoch 262, 25% 	 Loss : 1.8608e-02 	 Res : 5.6345e-03 	 Jac : 1.2927e-02 	 Enc : 2.4101e-05 	 AEnc : 2.1955e-05 	 MSE : 9.7552e-01
Epoch 262, 50% 	 Loss : 1.8698e-02 	 Res : 5.8009e-03 	 Jac : 1.2849e-02 	 Enc : 2.5227e-05 	 AEnc : 2.3532e-05 	 MSE : 1.0422e+00
Epoch 262, 75% 	 Loss : 1.8423e-02 	 Res : 5.6352e-03 	 Jac : 1.2743e-02 	 Enc : 2.3673e-05 	 AEnc : 2.1515e-05 	 MSE : 1.0043e+00
Training Epoch 262 : 	 Train : 1.85547e-02 	 Res : 5.68852e-03 	 Jac : 1.28201e-02 	 Enc : 2.42272e-05 	 AE : 2.18872e-05 	 MSE : 1.00700e+00
Validation Epoch 262 : 	 Train : 1.80342e-02 	 Res : 5.21600e-03 	 Jac : 1.27742e-02 	 Enc : 2.22985e-05 	 AE : 2.17683e-05 	 MSE : 8.39169e-01
Training Epoch 262 finished, took current epoch 371.25s, cumulative time 98080.82s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
Epoch 263, 25% 	 Loss : 1.7819e-02 	 Res : 4.9092e-03 	 Jac : 1.2869e-02 	 Enc : 1.9137e-05 	 AEnc : 2.1703e-05 	 MSE : 7.2716e-01
Epoch 263, 50% 	 Loss : 1.7671e-02 	 Res : 4.8219e-03 	 Jac : 1.2811e-02 	 Enc : 1.7218e-05 	 AEnc : 2.1237e-05 	 MSE : 7.0436e-01
Epoch 263, 75% 	 Loss : 1.7798e-02 	 Res : 4.8784e-03 	 Jac : 1.2882e-02 	 Enc : 1.7146e-05 	 AEnc : 2.0650e-05 	 MSE : 6.9673e-01
Training Epoch 263 : 	 Train : 1.79087e-02 	 Res : 5.01460e-03 	 Jac : 1.28457e-02 	 Enc : 1.81547e-05 	 AE : 3.02121e-05 	 MSE : 7.38940e-01
Validation Epoch 263 : 	 Train : 1.69950e-02 	 Res : 4.07379e-03 	 Jac : 1.28171e-02 	 Enc : 3.11690e-05 	 AE : 7.29416e-05 	 MSE : 2.08449e-01
Training Epoch 263 finished, took current epoch 371.57s, cumulative time 98452.34s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
Epoch 264, 25% 	 Loss : 1.7749e-02 	 Res : 4.6687e-03 	 Jac : 1.2806e-02 	 Enc : 3.6346e-05 	 AEnc : 2.3823e-04 	 MSE : 5.1145e-01
Epoch 264, 50% 	 Loss : 4.1844e-02 	 Res : 9.2671e-03 	 Jac : 1.2885e-02 	 Enc : 4.4046e-05 	 AEnc : 1.9649e-02 	 MSE : 9.4709e-01
Epoch 264, 75% 	 Loss : 3.6334e-02 	 Res : 6.6144e-03 	 Jac : 1.2932e-02 	 Enc : 4.2373e-05 	 AEnc : 1.6745e-02 	 MSE : 3.2010e-01
Training Epoch 264 : 	 Train : 2.84408e-02 	 Res : 6.11813e-03 	 Jac : 1.28539e-02 	 Enc : 3.44354e-05 	 AE : 9.43432e-03 	 MSE : 5.09921e-01
Validation Epoch 264 : 	 Train : 1.70339e-02 	 Res : 3.83926e-03 	 Jac : 1.28137e-02 	 Enc : 1.20563e-05 	 AE : 3.68871e-04 	 MSE : 2.85811e-01
Training Epoch 264 finished, took current epoch 372.50s, cumulative time 98824.75s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
MODEL SAVED
Epoch 265, 25% 	 Loss : 1.6636e-02 	 Res : 3.6954e-03 	 Jac : 1.2766e-02 	 Enc : 1.3163e-05 	 AEnc : 1.6066e-04 	 MSE : 2.3441e-01
Epoch 265, 50% 	 Loss : 1.6858e-02 	 Res : 3.7512e-03 	 Jac : 1.2813e-02 	 Enc : 1.3163e-05 	 AEnc : 2.8080e-04 	 MSE : 2.5195e-01
Epoch 265, 75% 	 Loss : 1.6876e-02 	 Res : 3.6842e-03 	 Jac : 1.2903e-02 	 Enc : 1.2731e-05 	 AEnc : 2.7566e-04 	 MSE : 2.4873e-01
Training Epoch 265 : 	 Train : 1.67330e-02 	 Res : 3.68712e-03 	 Jac : 1.28389e-02 	 Enc : 1.28533e-05 	 AE : 1.94184e-04 	 MSE : 2.44332e-01
Validation Epoch 265 : 	 Train : 1.65519e-02 	 Res : 3.77578e-03 	 Jac : 1.27189e-02 	 Enc : 1.18811e-05 	 AE : 4.54073e-05 	 MSE : 2.59037e-01
Training Epoch 265 finished, took current epoch 370.88s, cumulative time 99195.57s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
MODEL SAVED
Epoch 266, 25% 	 Loss : 1.6646e-02 	 Res : 3.6777e-03 	 Jac : 1.2920e-02 	 Enc : 1.2220e-05 	 AEnc : 3.5596e-05 	 MSE : 2.4610e-01
Epoch 266, 50% 	 Loss : 1.6672e-02 	 Res : 3.8218e-03 	 Jac : 1.2769e-02 	 Enc : 1.3231e-05 	 AEnc : 6.7834e-05 	 MSE : 2.8164e-01
Epoch 266, 75% 	 Loss : 1.6622e-02 	 Res : 3.7252e-03 	 Jac : 1.2789e-02 	 Enc : 1.2779e-05 	 AEnc : 9.4748e-05 	 MSE : 2.6982e-01
Training Epoch 266 : 	 Train : 1.66497e-02 	 Res : 3.73612e-03 	 Jac : 1.28422e-02 	 Enc : 1.26509e-05 	 AE : 5.87520e-05 	 MSE : 2.68550e-01
Validation Epoch 266 : 	 Train : 1.64481e-02 	 Res : 3.50691e-03 	 Jac : 1.28737e-02 	 Enc : 1.08237e-05 	 AE : 5.67019e-05 	 MSE : 1.72355e-01
Training Epoch 266 finished, took current epoch 372.33s, cumulative time 99567.83s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
MODEL SAVED
Epoch 267, 25% 	 Loss : 1.6642e-02 	 Res : 3.7479e-03 	 Jac : 1.2841e-02 	 Enc : 1.2692e-05 	 AEnc : 4.0959e-05 	 MSE : 2.7520e-01
Epoch 267, 50% 	 Loss : 1.6543e-02 	 Res : 3.5832e-03 	 Jac : 1.2910e-02 	 Enc : 1.2705e-05 	 AEnc : 3.7065e-05 	 MSE : 2.3260e-01
Epoch 267, 75% 	 Loss : 2.0550e-02 	 Res : 7.6894e-03 	 Jac : 1.2803e-02 	 Enc : 2.7850e-05 	 AEnc : 2.9575e-05 	 MSE : 1.7770e+00
Training Epoch 267 : 	 Train : 1.86635e-02 	 Res : 5.75333e-03 	 Jac : 1.28548e-02 	 Enc : 2.23396e-05 	 AE : 3.30396e-05 	 MSE : 1.04672e+00
Validation Epoch 267 : 	 Train : 2.35581e-02 	 Res : 1.07484e-02 	 Jac : 1.27456e-02 	 Enc : 3.59400e-05 	 AE : 2.81867e-05 	 MSE : 2.92916e+00
Training Epoch 267 finished, took current epoch 372.54s, cumulative time 99940.33s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
Epoch 268, 25% 	 Loss : 2.0856e-02 	 Res : 7.9412e-03 	 Jac : 1.2852e-02 	 Enc : 3.8916e-05 	 AEnc : 2.4029e-05 	 MSE : 1.8605e+00
Epoch 268, 50% 	 Loss : 2.0953e-02 	 Res : 8.1456e-03 	 Jac : 1.2744e-02 	 Enc : 3.9658e-05 	 AEnc : 2.3683e-05 	 MSE : 1.9807e+00
Epoch 268, 75% 	 Loss : 2.1244e-02 	 Res : 8.4186e-03 	 Jac : 1.2744e-02 	 Enc : 4.1829e-05 	 AEnc : 4.0182e-05 	 MSE : 2.0334e+00
Training Epoch 268 : 	 Train : 2.10539e-02 	 Res : 8.19073e-03 	 Jac : 1.27932e-02 	 Enc : 3.97986e-05 	 AE : 3.02280e-05 	 MSE : 1.96509e+00
Validation Epoch 268 : 	 Train : 1.95127e-02 	 Res : 6.69031e-03 	 Jac : 1.27621e-02 	 Enc : 3.73302e-05 	 AE : 2.29489e-05 	 MSE : 1.35640e+00
Training Epoch 268 finished, took current epoch 367.80s, cumulative time 100308.11s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
Epoch 269, 25% 	 Loss : 2.0930e-02 	 Res : 7.9612e-03 	 Jac : 1.2892e-02 	 Enc : 4.1358e-05 	 AEnc : 3.6297e-05 	 MSE : 1.9248e+00
Epoch 269, 50% 	 Loss : 2.0611e-02 	 Res : 7.7178e-03 	 Jac : 1.2829e-02 	 Enc : 3.8737e-05 	 AEnc : 2.5394e-05 	 MSE : 1.7853e+00
Epoch 269, 75% 	 Loss : 2.0932e-02 	 Res : 8.0520e-03 	 Jac : 1.2818e-02 	 Enc : 3.6466e-05 	 AEnc : 2.5367e-05 	 MSE : 1.8896e+00
Training Epoch 269 : 	 Train : 2.08664e-02 	 Res : 7.96335e-03 	 Jac : 1.28346e-02 	 Enc : 3.90811e-05 	 AE : 2.93120e-05 	 MSE : 1.88147e+00
Validation Epoch 269 : 	 Train : 1.98093e-02 	 Res : 6.98817e-03 	 Jac : 1.27607e-02 	 Enc : 3.92032e-05 	 AE : 2.12421e-05 	 MSE : 1.44061e+00
Training Epoch 269 finished, took current epoch 367.19s, cumulative time 100675.25s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
Epoch 270, 25% 	 Loss : 2.1065e-02 	 Res : 8.1289e-03 	 Jac : 1.2859e-02 	 Enc : 4.1405e-05 	 AEnc : 3.5531e-05 	 MSE : 1.9349e+00
Epoch 270, 50% 	 Loss : 2.0874e-02 	 Res : 7.9715e-03 	 Jac : 1.2830e-02 	 Enc : 4.0415e-05 	 AEnc : 3.1737e-05 	 MSE : 1.8787e+00
Epoch 270, 75% 	 Loss : 2.1238e-02 	 Res : 8.2700e-03 	 Jac : 1.2897e-02 	 Enc : 3.7707e-05 	 AEnc : 3.3657e-05 	 MSE : 1.9841e+00
Training Epoch 270 : 	 Train : 2.09221e-02 	 Res : 8.00715e-03 	 Jac : 1.28433e-02 	 Enc : 3.94988e-05 	 AE : 3.22275e-05 	 MSE : 1.89206e+00
Validation Epoch 270 : 	 Train : 1.96193e-02 	 Res : 6.76897e-03 	 Jac : 1.27907e-02 	 Enc : 3.61341e-05 	 AE : 2.35743e-05 	 MSE : 1.39571e+00
Training Epoch 270 finished, took current epoch 370.00s, cumulative time 101045.20s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
Epoch 271, 25% 	 Loss : 2.0922e-02 	 Res : 8.0794e-03 	 Jac : 1.2777e-02 	 Enc : 3.8502e-05 	 AEnc : 2.7826e-05 	 MSE : 1.9330e+00
Epoch 271, 50% 	 Loss : 2.0691e-02 	 Res : 7.7874e-03 	 Jac : 1.2827e-02 	 Enc : 3.8408e-05 	 AEnc : 3.8685e-05 	 MSE : 1.8263e+00
Epoch 271, 75% 	 Loss : 2.0997e-02 	 Res : 8.1024e-03 	 Jac : 1.2825e-02 	 Enc : 3.9747e-05 	 AEnc : 2.9672e-05 	 MSE : 1.9337e+00
Training Epoch 271 : 	 Train : 2.11364e-02 	 Res : 8.20883e-03 	 Jac : 1.28377e-02 	 Enc : 3.89692e-05 	 AE : 5.08994e-05 	 MSE : 1.95942e+00
Validation Epoch 271 : 	 Train : 1.75513e-02 	 Res : 4.76700e-03 	 Jac : 1.27073e-02 	 Enc : 4.25215e-05 	 AE : 3.44341e-05 	 MSE : 5.65123e-01
Training Epoch 271 finished, took current epoch 370.18s, cumulative time 101415.33s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
Epoch 272, 25% 	 Loss : 2.3384e-02 	 Res : 8.9973e-03 	 Jac : 1.2784e-02 	 Enc : 4.1286e-05 	 AEnc : 1.5619e-03 	 MSE : 2.0523e+00
Epoch 272, 50% 	 Loss : 2.2601e-02 	 Res : 8.3567e-03 	 Jac : 1.2835e-02 	 Enc : 4.3681e-05 	 AEnc : 1.3661e-03 	 MSE : 1.9434e+00
Epoch 272, 75% 	 Loss : 2.1478e-02 	 Res : 8.4797e-03 	 Jac : 1.2831e-02 	 Enc : 4.4153e-05 	 AEnc : 1.2277e-04 	 MSE : 2.0434e+00
Training Epoch 272 : 	 Train : 2.23634e-02 	 Res : 8.68999e-03 	 Jac : 1.28245e-02 	 Enc : 4.30180e-05 	 AE : 8.05893e-04 	 MSE : 2.04603e+00
Validation Epoch 272 : 	 Train : 1.71115e-02 	 Res : 4.04120e-03 	 Jac : 1.28017e-02 	 Enc : 6.58384e-05 	 AE : 2.02760e-04 	 MSE : 3.16663e-01
Training Epoch 272 finished, took current epoch 370.81s, cumulative time 101786.09s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
Epoch 273, 25% 	 Loss : 2.1141e-02 	 Res : 8.1530e-03 	 Jac : 1.2855e-02 	 Enc : 4.6372e-05 	 AEnc : 8.6644e-05 	 MSE : 1.9040e+00
Epoch 273, 50% 	 Loss : 2.0681e-02 	 Res : 7.8744e-03 	 Jac : 1.2738e-02 	 Enc : 3.8693e-05 	 AEnc : 2.9997e-05 	 MSE : 1.8329e+00
Epoch 273, 75% 	 Loss : 2.1432e-02 	 Res : 8.5470e-03 	 Jac : 1.2795e-02 	 Enc : 3.9906e-05 	 AEnc : 5.0496e-05 	 MSE : 2.0751e+00
Training Epoch 273 : 	 Train : 2.21138e-02 	 Res : 7.71941e-03 	 Jac : 1.27926e-02 	 Enc : 3.82598e-05 	 AE : 1.56357e-03 	 MSE : 1.67189e+00
Validation Epoch 273 : 	 Train : 4.92555e-02 	 Res : 9.12933e-03 	 Jac : 1.28326e-02 	 Enc : 3.84353e-05 	 AE : 2.72552e-02 	 MSE : 6.50915e-01
Training Epoch 273 finished, took current epoch 368.72s, cumulative time 102154.76s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
Epoch 274, 25% 	 Loss : 3.0790e-02 	 Res : 6.2195e-03 	 Jac : 1.2771e-02 	 Enc : 2.8810e-05 	 AEnc : 1.1771e-02 	 MSE : 4.3115e-01
Epoch 274, 50% 	 Loss : 1.9977e-02 	 Res : 4.2471e-03 	 Jac : 1.2805e-02 	 Enc : 1.7267e-05 	 AEnc : 2.9078e-03 	 MSE : 2.7401e-01
Epoch 274, 75% 	 Loss : 1.8631e-02 	 Res : 4.0017e-03 	 Jac : 1.2836e-02 	 Enc : 1.5145e-05 	 AEnc : 1.7773e-03 	 MSE : 2.5933e-01
Training Epoch 274 : 	 Train : 2.18625e-02 	 Res : 4.61060e-03 	 Jac : 1.28106e-02 	 Enc : 1.87677e-05 	 AE : 4.42251e-03 	 MSE : 3.10492e-01
Validation Epoch 274 : 	 Train : 1.85444e-02 	 Res : 4.30312e-03 	 Jac : 1.28105e-02 	 Enc : 1.35963e-05 	 AE : 1.41712e-03 	 MSE : 3.64355e-01
Training Epoch 274 finished, took current epoch 368.74s, cumulative time 102523.49s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
Epoch 275, 25% 	 Loss : 1.7600e-02 	 Res : 3.8956e-03 	 Jac : 1.2815e-02 	 Enc : 1.4108e-05 	 AEnc : 8.7541e-04 	 MSE : 2.6170e-01
Epoch 275, 50% 	 Loss : 1.7079e-02 	 Res : 3.8481e-03 	 Jac : 1.2946e-02 	 Enc : 1.3250e-05 	 AEnc : 2.7140e-04 	 MSE : 3.3479e-01
Epoch 275, 75% 	 Loss : 1.9581e-02 	 Res : 5.4151e-03 	 Jac : 1.2857e-02 	 Enc : 2.1996e-05 	 AEnc : 1.2865e-03 	 MSE : 7.5807e-01
Training Epoch 275 : 	 Train : 2.06809e-02 	 Res : 4.94267e-03 	 Jac : 1.28498e-02 	 Enc : 2.34528e-05 	 AE : 2.86496e-03 	 MSE : 5.11059e-01
Validation Epoch 275 : 	 Train : 3.37975e-02 	 Res : 6.84132e-03 	 Jac : 1.28148e-02 	 Enc : 5.07967e-05 	 AE : 1.40906e-02 	 MSE : 7.24787e-01
Training Epoch 275 finished, took current epoch 370.88s, cumulative time 102894.32s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
Epoch 276, 25% 	 Loss : 5.3513e-02 	 Res : 8.9482e-03 	 Jac : 1.2848e-02 	 Enc : 4.7666e-05 	 AEnc : 3.1669e-02 	 MSE : 2.6817e-01
Epoch 276, 50% 	 Loss : 3.5712e-02 	 Res : 6.8406e-03 	 Jac : 1.2854e-02 	 Enc : 3.9001e-05 	 AEnc : 1.5979e-02 	 MSE : 3.7568e-01
Epoch 276, 75% 	 Loss : 2.1861e-02 	 Res : 5.1104e-03 	 Jac : 1.2929e-02 	 Enc : 2.2070e-05 	 AEnc : 3.7995e-03 	 MSE : 5.6313e-01
Training Epoch 276 : 	 Train : 3.25884e-02 	 Res : 6.26695e-03 	 Jac : 1.28515e-02 	 Enc : 3.10436e-05 	 AE : 1.34389e-02 	 MSE : 3.74209e-01
Validation Epoch 276 : 	 Train : 1.63095e-02 	 Res : 3.42282e-03 	 Jac : 1.27882e-02 	 Enc : 1.28324e-05 	 AE : 8.57252e-05 	 MSE : 1.45535e-01
Training Epoch 276 finished, took current epoch 372.12s, cumulative time 103266.35s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
MODEL SAVED
Epoch 277, 25% 	 Loss : 1.6831e-02 	 Res : 3.7919e-03 	 Jac : 1.2830e-02 	 Enc : 1.3296e-05 	 AEnc : 1.9582e-04 	 MSE : 2.6613e-01
Epoch 277, 50% 	 Loss : 1.6462e-02 	 Res : 3.6491e-03 	 Jac : 1.2768e-02 	 Enc : 1.2572e-05 	 AEnc : 3.2607e-05 	 MSE : 2.4987e-01
Epoch 277, 75% 	 Loss : 1.6520e-02 	 Res : 3.6285e-03 	 Jac : 1.2858e-02 	 Enc : 1.2658e-05 	 AEnc : 2.1116e-05 	 MSE : 2.6533e-01
Training Epoch 277 : 	 Train : 1.66100e-02 	 Res : 3.70964e-03 	 Jac : 1.28186e-02 	 Enc : 1.28658e-05 	 AE : 6.89320e-05 	 MSE : 2.65488e-01
Validation Epoch 277 : 	 Train : 1.69012e-02 	 Res : 3.97403e-03 	 Jac : 1.28881e-02 	 Enc : 1.52465e-05 	 AE : 2.38193e-05 	 MSE : 3.07601e-01
Training Epoch 277 finished, took current epoch 373.24s, cumulative time 103639.58s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
Epoch 278, 25% 	 Loss : 1.6754e-02 	 Res : 3.8904e-03 	 Jac : 1.2827e-02 	 Enc : 1.3825e-05 	 AEnc : 2.2389e-05 	 MSE : 3.4274e-01
Epoch 278, 50% 	 Loss : 2.0286e-02 	 Res : 7.4820e-03 	 Jac : 1.2750e-02 	 Enc : 2.0657e-05 	 AEnc : 3.3506e-05 	 MSE : 1.6832e+00
Epoch 278, 75% 	 Loss : 2.1161e-02 	 Res : 8.3047e-03 	 Jac : 1.2792e-02 	 Enc : 3.9168e-05 	 AEnc : 2.4650e-05 	 MSE : 2.0161e+00
Training Epoch 278 : 	 Train : 1.97849e-02 	 Res : 6.94261e-03 	 Jac : 1.27876e-02 	 Enc : 2.86728e-05 	 AE : 2.59749e-05 	 MSE : 1.49686e+00
Validation Epoch 278 : 	 Train : 2.36212e-02 	 Res : 1.07846e-02 	 Jac : 1.27743e-02 	 Enc : 3.76312e-05 	 AE : 2.47025e-05 	 MSE : 2.94721e+00
Training Epoch 278 finished, took current epoch 374.42s, cumulative time 104013.99s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
Epoch 279, 25% 	 Loss : 2.7995e-02 	 Res : 1.5048e-02 	 Jac : 1.2790e-02 	 Enc : 7.3918e-05 	 AEnc : 8.3106e-05 	 MSE : 4.2109e+00
Epoch 279, 50% 	 Loss : 1.8810e-02 	 Res : 5.7677e-03 	 Jac : 1.2925e-02 	 Enc : 4.1550e-05 	 AEnc : 7.5862e-05 	 MSE : 9.6479e-01
Epoch 279, 75% 	 Loss : 1.8400e-02 	 Res : 5.5056e-03 	 Jac : 1.2840e-02 	 Enc : 2.2138e-05 	 AEnc : 3.2893e-05 	 MSE : 9.5354e-01
Training Epoch 279 : 	 Train : 2.08579e-02 	 Res : 7.90746e-03 	 Jac : 1.28555e-02 	 Enc : 4.02650e-05 	 AE : 5.46028e-05 	 MSE : 1.75152e+00
Validation Epoch 279 : 	 Train : 1.75541e-02 	 Res : 4.79930e-03 	 Jac : 1.27111e-02 	 Enc : 1.97996e-05 	 AE : 2.39733e-05 	 MSE : 6.57473e-01
Training Epoch 279 finished, took current epoch 373.10s, cumulative time 104387.06s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
Epoch 280, 25% 	 Loss : 1.8049e-02 	 Res : 5.1677e-03 	 Jac : 1.2839e-02 	 Enc : 1.9508e-05 	 AEnc : 2.2960e-05 	 MSE : 8.2021e-01
Epoch 280, 50% 	 Loss : 1.7959e-02 	 Res : 5.0211e-03 	 Jac : 1.2896e-02 	 Enc : 1.8569e-05 	 AEnc : 2.3406e-05 	 MSE : 7.7415e-01
Epoch 280, 75% 	 Loss : 1.7780e-02 	 Res : 4.9062e-03 	 Jac : 1.2831e-02 	 Enc : 1.9952e-05 	 AEnc : 2.2820e-05 	 MSE : 7.6102e-01
Training Epoch 280 : 	 Train : 1.79427e-02 	 Res : 5.07278e-03 	 Jac : 1.28277e-02 	 Enc : 1.91254e-05 	 AE : 2.31072e-05 	 MSE : 7.94614e-01
Validation Epoch 280 : 	 Train : 1.65602e-02 	 Res : 3.67807e-03 	 Jac : 1.28406e-02 	 Enc : 1.88752e-05 	 AE : 2.26536e-05 	 MSE : 2.55082e-01
Training Epoch 280 finished, took current epoch 370.07s, cumulative time 104757.11s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
Epoch 281, 25% 	 Loss : 1.7797e-02 	 Res : 4.9984e-03 	 Jac : 1.2757e-02 	 Enc : 1.9017e-05 	 AEnc : 2.2393e-05 	 MSE : 7.7523e-01
Epoch 281, 50% 	 Loss : 1.8210e-02 	 Res : 5.2792e-03 	 Jac : 1.2889e-02 	 Enc : 1.9279e-05 	 AEnc : 2.2432e-05 	 MSE : 8.6705e-01
Epoch 281, 75% 	 Loss : 1.8001e-02 	 Res : 5.1178e-03 	 Jac : 1.2839e-02 	 Enc : 1.9386e-05 	 AEnc : 2.4543e-05 	 MSE : 8.2798e-01
Training Epoch 281 : 	 Train : 1.80151e-02 	 Res : 5.12377e-03 	 Jac : 1.28493e-02 	 Enc : 1.90141e-05 	 AE : 2.30535e-05 	 MSE : 8.15559e-01
Validation Epoch 281 : 	 Train : 1.67533e-02 	 Res : 3.97438e-03 	 Jac : 1.27410e-02 	 Enc : 1.84361e-05 	 AE : 1.94530e-05 	 MSE : 3.52816e-01
Training Epoch 281 finished, took current epoch 373.55s, cumulative time 105130.62s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
Epoch 282, 25% 	 Loss : 1.7906e-02 	 Res : 5.0807e-03 	 Jac : 1.2784e-02 	 Enc : 1.9133e-05 	 AEnc : 2.2135e-05 	 MSE : 8.0245e-01
Epoch 282, 50% 	 Loss : 1.8015e-02 	 Res : 5.1153e-03 	 Jac : 1.2858e-02 	 Enc : 1.9406e-05 	 AEnc : 2.2821e-05 	 MSE : 8.2188e-01
Epoch 282, 75% 	 Loss : 1.7993e-02 	 Res : 5.0833e-03 	 Jac : 1.2867e-02 	 Enc : 1.7230e-05 	 AEnc : 2.5102e-05 	 MSE : 7.6863e-01
Training Epoch 282 : 	 Train : 1.90585e-02 	 Res : 6.19156e-03 	 Jac : 1.28147e-02 	 Enc : 2.37599e-05 	 AE : 2.84783e-05 	 MSE : 1.19374e+00
Validation Epoch 282 : 	 Train : 2.03805e-02 	 Res : 7.55668e-03 	 Jac : 1.27561e-02 	 Enc : 4.24738e-05 	 AE : 2.52684e-05 	 MSE : 1.62762e+00
Training Epoch 282 finished, took current epoch 372.39s, cumulative time 105502.96s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
Epoch 283, 25% 	 Loss : 1.8833e-02 	 Res : 5.9363e-03 	 Jac : 1.2814e-02 	 Enc : 3.0081e-05 	 AEnc : 5.2815e-05 	 MSE : 1.0612e+00
Epoch 283, 50% 	 Loss : 2.3032e-02 	 Res : 1.0141e-02 	 Jac : 1.2827e-02 	 Enc : 2.4947e-05 	 AEnc : 3.9017e-05 	 MSE : 2.5747e+00
Epoch 283, 75% 	 Loss : 2.7948e-02 	 Res : 1.4751e-02 	 Jac : 1.2856e-02 	 Enc : 7.6774e-05 	 AEnc : 2.6474e-04 	 MSE : 4.3658e+00
Training Epoch 283 : 	 Train : 2.34420e-02 	 Res : 1.03840e-02 	 Jac : 1.28095e-02 	 Enc : 4.53545e-05 	 AE : 2.03112e-04 	 MSE : 2.71020e+00
Validation Epoch 283 : 	 Train : 2.54106e-02 	 Res : 1.24764e-02 	 Jac : 1.27148e-02 	 Enc : 4.92422e-05 	 AE : 1.70162e-04 	 MSE : 3.09236e+00
Training Epoch 283 finished, took current epoch 371.17s, cumulative time 105874.08s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
Epoch 284, 25% 	 Loss : 1.9041e-02 	 Res : 6.1240e-03 	 Jac : 1.2801e-02 	 Enc : 3.9389e-05 	 AEnc : 7.7182e-05 	 MSE : 1.1010e+00
Epoch 284, 50% 	 Loss : 1.8043e-02 	 Res : 5.1333e-03 	 Jac : 1.2861e-02 	 Enc : 2.1508e-05 	 AEnc : 2.6914e-05 	 MSE : 8.2040e-01
Epoch 284, 75% 	 Loss : 1.7906e-02 	 Res : 5.0576e-03 	 Jac : 1.2804e-02 	 Enc : 1.9097e-05 	 AEnc : 2.5186e-05 	 MSE : 7.7264e-01
Training Epoch 284 : 	 Train : 1.82002e-02 	 Res : 5.32817e-03 	 Jac : 1.28087e-02 	 Enc : 2.46694e-05 	 AE : 3.86307e-05 	 MSE : 8.68530e-01
Validation Epoch 284 : 	 Train : 1.93282e-02 	 Res : 6.48629e-03 	 Jac : 1.28045e-02 	 Enc : 1.73362e-05 	 AE : 2.00879e-05 	 MSE : 1.30076e+00
Training Epoch 284 finished, took current epoch 370.10s, cumulative time 106244.17s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
Epoch 285, 25% 	 Loss : 1.7900e-02 	 Res : 5.0710e-03 	 Jac : 1.2787e-02 	 Enc : 1.8433e-05 	 AEnc : 2.3555e-05 	 MSE : 8.0403e-01
Epoch 285, 50% 	 Loss : 1.8010e-02 	 Res : 5.1029e-03 	 Jac : 1.2864e-02 	 Enc : 1.8060e-05 	 AEnc : 2.4996e-05 	 MSE : 7.8565e-01
Epoch 285, 75% 	 Loss : 1.7984e-02 	 Res : 5.0798e-03 	 Jac : 1.2863e-02 	 Enc : 1.8600e-05 	 AEnc : 2.2474e-05 	 MSE : 8.0471e-01
Training Epoch 285 : 	 Train : 1.79359e-02 	 Res : 5.05468e-03 	 Jac : 1.28394e-02 	 Enc : 1.84085e-05 	 AE : 2.34123e-05 	 MSE : 7.86629e-01
Validation Epoch 285 : 	 Train : 1.96364e-02 	 Res : 6.78833e-03 	 Jac : 1.28093e-02 	 Enc : 1.75858e-05 	 AE : 2.12509e-05 	 MSE : 1.40722e+00
Training Epoch 285 finished, took current epoch 374.37s, cumulative time 106618.50s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
Epoch 286, 25% 	 Loss : 1.8031e-02 	 Res : 5.1201e-03 	 Jac : 1.2870e-02 	 Enc : 1.7527e-05 	 AEnc : 2.2605e-05 	 MSE : 8.1638e-01
Epoch 286, 50% 	 Loss : 1.7873e-02 	 Res : 4.9872e-03 	 Jac : 1.2846e-02 	 Enc : 1.7481e-05 	 AEnc : 2.2061e-05 	 MSE : 7.8326e-01
Epoch 286, 75% 	 Loss : 1.8075e-02 	 Res : 5.2071e-03 	 Jac : 1.2825e-02 	 Enc : 1.8907e-05 	 AEnc : 2.3681e-05 	 MSE : 8.3394e-01
Training Epoch 286 : 	 Train : 1.79612e-02 	 Res : 5.09211e-03 	 Jac : 1.28284e-02 	 Enc : 1.83229e-05 	 AE : 2.24214e-05 	 MSE : 7.99716e-01
Validation Epoch 286 : 	 Train : 2.01218e-02 	 Res : 7.29396e-03 	 Jac : 1.27872e-02 	 Enc : 1.96979e-05 	 AE : 2.09830e-05 	 MSE : 1.60121e+00
Training Epoch 286 finished, took current epoch 371.46s, cumulative time 106989.92s
Current Learning rate DEQ : 0.00035184372088832035
Current Learning rate AUTOENC : 0.0017592186044416017
Epoch 287, 25% 	 Loss : 2.3542e-02 	 Res : 1.0702e-02 	 Jac : 1.2671e-02 	 Enc : 3.7809e-05 	 AEnc : 1.3158e-04 	 MSE : 2.7672e+00
Epoch 287, 50% 	 Loss : 2.6315e-02 	 Res : 1.0839e-02 	 Jac : 1.2762e-02 	 Enc : 4.1027e-05 	 AEnc : 2.6732e-03 	 MSE : 1.9041e+00
Epoch 287, 75% 	 Loss : 2.8311e-02 	 Res : 7.6591e-03 	 Jac : 1.2860e-02 	 Enc : 4.6816e-05 	 AEnc : 7.7449e-03 	 MSE : 1.0485e+00
Training Epoch 287 : 	 Train : 2.43806e-02 	 Res : 8.43209e-03 	 Jac : 1.27765e-02 	 Enc : 3.71920e-05 	 AE : 3.13480e-03 	 MSE : 1.53543e+00
Validation Epoch 287 : 	 Train : 2.10312e-02 	 Res : 4.34065e-03 	 Jac : 1.28174e-02 	 Enc : 1.46354e-05 	 AE : 3.85849e-03 	 MSE : 1.88222e-01
Training Epoch 287 finished, took current epoch 373.04s, cumulative time 107362.92s
Current Learning rate DEQ : 0.0002814749767106563
Current Learning rate AUTOENC : 0.0014073748835532814
Epoch 288, 25% 	 Loss : 1.7695e-02 	 Res : 3.7786e-03 	 Jac : 1.2915e-02 	 Enc : 1.2948e-05 	 AEnc : 9.8808e-04 	 MSE : 2.0419e-01
Epoch 288, 50% 	 Loss : 1.6353e-02 	 Res : 3.4776e-03 	 Jac : 1.2730e-02 	 Enc : 1.0999e-05 	 AEnc : 1.3519e-04 	 MSE : 1.7855e-01
Epoch 288, 75% 	 Loss : 1.6450e-02 	 Res : 3.5599e-03 	 Jac : 1.2829e-02 	 Enc : 1.1428e-05 	 AEnc : 4.9593e-05 	 MSE : 1.9415e-01
Training Epoch 288 : 	 Train : 1.73508e-02 	 Res : 4.16589e-03 	 Jac : 1.28345e-02 	 Enc : 1.21487e-05 	 AE : 3.38231e-04 	 MSE : 4.16051e-01
Validation Epoch 288 : 	 Train : 1.81658e-02 	 Res : 5.29251e-03 	 Jac : 1.27596e-02 	 Enc : 2.33082e-05 	 AE : 9.03282e-05 	 MSE : 7.97035e-01
Training Epoch 288 finished, took current epoch 373.02s, cumulative time 107735.92s
Current Learning rate DEQ : 0.0002814749767106563
Current Learning rate AUTOENC : 0.0014073748835532814
Epoch 289, 25% 	 Loss : 1.8456e-02 	 Res : 5.6406e-03 	 Jac : 1.2739e-02 	 Enc : 2.3590e-05 	 AEnc : 5.2928e-05 	 MSE : 9.9372e-01
Epoch 289, 50% 	 Loss : 1.9776e-02 	 Res : 7.0034e-03 	 Jac : 1.2725e-02 	 Enc : 1.6291e-05 	 AEnc : 3.1402e-05 	 MSE : 1.5252e+00
Epoch 289, 75% 	 Loss : 2.3384e-02 	 Res : 1.0490e-02 	 Jac : 1.2813e-02 	 Enc : 4.1388e-05 	 AEnc : 3.9050e-05 	 MSE : 2.8555e+00
Training Epoch 289 : 	 Train : 2.00265e-02 	 Res : 7.10750e-03 	 Jac : 1.27664e-02 	 Enc : 2.55918e-05 	 AE : 1.27028e-04 	 MSE : 1.53323e+00
Validation Epoch 289 : 	 Train : 1.78984e-02 	 Res : 3.97826e-03 	 Jac : 1.28150e-02 	 Enc : 2.16621e-05 	 AE : 1.08352e-03 	 MSE : 2.29373e-01
Training Epoch 289 finished, took current epoch 373.08s, cumulative time 108108.98s
Current Learning rate DEQ : 0.0002814749767106563
Current Learning rate AUTOENC : 0.0014073748835532814
Epoch 290, 25% 	 Loss : 1.7691e-02 	 Res : 4.7485e-03 	 Jac : 1.2658e-02 	 Enc : 1.9548e-05 	 AEnc : 2.6550e-04 	 MSE : 6.3199e-01
Epoch 290, 50% 	 Loss : 1.7506e-02 	 Res : 4.5790e-03 	 Jac : 1.2876e-02 	 Enc : 1.5687e-05 	 AEnc : 3.5594e-05 	 MSE : 6.0765e-01
Epoch 290, 75% 	 Loss : 1.7340e-02 	 Res : 4.4256e-03 	 Jac : 1.2870e-02 	 Enc : 1.4573e-05 	 AEnc : 2.9237e-05 	 MSE : 5.6805e-01
Training Epoch 290 : 	 Train : 1.74782e-02 	 Res : 4.57315e-03 	 Jac : 1.27973e-02 	 Enc : 1.61025e-05 	 AE : 9.16349e-05 	 MSE : 5.92109e-01
Validation Epoch 290 : 	 Train : 1.75800e-02 	 Res : 4.69206e-03 	 Jac : 1.28352e-02 	 Enc : 1.37222e-05 	 AE : 3.89809e-05 	 MSE : 6.40345e-01
Training Epoch 290 finished, took current epoch 371.53s, cumulative time 108480.49s
Current Learning rate DEQ : 0.0002814749767106563
Current Learning rate AUTOENC : 0.0014073748835532814
Epoch 291, 25% 	 Loss : 1.7303e-02 	 Res : 4.4412e-03 	 Jac : 1.2819e-02 	 Enc : 1.4676e-05 	 AEnc : 2.8290e-05 	 MSE : 5.7390e-01
Epoch 291, 50% 	 Loss : 1.7241e-02 	 Res : 4.4058e-03 	 Jac : 1.2796e-02 	 Enc : 1.4783e-05 	 AEnc : 2.4511e-05 	 MSE : 5.0501e-01
Epoch 291, 75% 	 Loss : 1.6461e-02 	 Res : 3.5943e-03 	 Jac : 1.2789e-02 	 Enc : 1.1762e-05 	 AEnc : 6.6669e-05 	 MSE : 2.4459e-01
Training Epoch 291 : 	 Train : 1.69225e-02 	 Res : 4.01211e-03 	 Jac : 1.28017e-02 	 Enc : 1.29653e-05 	 AE : 9.56816e-05 	 MSE : 3.84413e-01
Validation Epoch 291 : 	 Train : 1.61727e-02 	 Res : 3.30365e-03 	 Jac : 1.27759e-02 	 Enc : 1.10222e-05 	 AE : 8.21650e-05 	 MSE : 9.89917e-02
Training Epoch 291 finished, took current epoch 372.48s, cumulative time 108852.89s
Current Learning rate DEQ : 0.0002814749767106563
Current Learning rate AUTOENC : 0.0014073748835532814
MODEL SAVED
Epoch 292, 25% 	 Loss : 1.6713e-02 	 Res : 3.6338e-03 	 Jac : 1.2815e-02 	 Enc : 1.1163e-05 	 AEnc : 2.5317e-04 	 MSE : 2.1033e-01
Epoch 292, 50% 	 Loss : 1.7552e-02 	 Res : 4.2530e-03 	 Jac : 1.2850e-02 	 Enc : 1.2572e-05 	 AEnc : 4.3552e-04 	 MSE : 4.1503e-01
Epoch 292, 75% 	 Loss : 1.9716e-02 	 Res : 4.4569e-03 	 Jac : 1.2794e-02 	 Enc : 1.5273e-05 	 AEnc : 2.4496e-03 	 MSE : 4.0621e-01
Training Epoch 292 : 	 Train : 1.82582e-02 	 Res : 4.26316e-03 	 Jac : 1.28111e-02 	 Enc : 1.39428e-05 	 AE : 1.17000e-03 	 MSE : 3.98155e-01
Validation Epoch 292 : 	 Train : 1.86484e-02 	 Res : 5.67670e-03 	 Jac : 1.28201e-02 	 Enc : 1.52218e-05 	 AE : 1.36295e-04 	 MSE : 1.00911e+00
Training Epoch 292 finished, took current epoch 372.59s, cumulative time 109225.46s
Current Learning rate DEQ : 0.0002814749767106563
Current Learning rate AUTOENC : 0.0014073748835532814
Epoch 293, 25% 	 Loss : 1.7595e-02 	 Res : 4.5796e-03 	 Jac : 1.2875e-02 	 Enc : 1.5855e-05 	 AEnc : 1.2488e-04 	 MSE : 5.8743e-01
Epoch 293, 50% 	 Loss : 1.7357e-02 	 Res : 4.4543e-03 	 Jac : 1.2861e-02 	 Enc : 1.5911e-05 	 AEnc : 2.5163e-05 	 MSE : 5.6071e-01
Epoch 293, 75% 	 Loss : 1.7412e-02 	 Res : 4.4491e-03 	 Jac : 1.2924e-02 	 Enc : 1.4751e-05 	 AEnc : 2.3852e-05 	 MSE : 5.7345e-01
Training Epoch 293 : 	 Train : 1.74357e-02 	 Res : 4.50141e-03 	 Jac : 1.28684e-02 	 Enc : 1.53827e-05 	 AE : 5.05432e-05 	 MSE : 5.78214e-01
Validation Epoch 293 : 	 Train : 1.69470e-02 	 Res : 4.19160e-03 	 Jac : 1.27197e-02 	 Enc : 1.48493e-05 	 AE : 2.08743e-05 	 MSE : 4.53387e-01
Training Epoch 293 finished, took current epoch 368.75s, cumulative time 109594.16s
Current Learning rate DEQ : 0.0002814749767106563
Current Learning rate AUTOENC : 0.0014073748835532814
Epoch 294, 25% 	 Loss : 1.7286e-02 	 Res : 4.4139e-03 	 Jac : 1.2833e-02 	 Enc : 1.5307e-05 	 AEnc : 2.4060e-05 	 MSE : 5.6417e-01
Epoch 294, 50% 	 Loss : 1.7338e-02 	 Res : 4.4993e-03 	 Jac : 1.2798e-02 	 Enc : 1.5862e-05 	 AEnc : 2.5064e-05 	 MSE : 5.7224e-01
Epoch 294, 75% 	 Loss : 1.7285e-02 	 Res : 4.4533e-03 	 Jac : 1.2791e-02 	 Enc : 1.6401e-05 	 AEnc : 2.4371e-05 	 MSE : 5.6565e-01
Training Epoch 294 : 	 Train : 1.73327e-02 	 Res : 4.45718e-03 	 Jac : 1.28355e-02 	 Enc : 1.58506e-05 	 AE : 2.41880e-05 	 MSE : 5.66673e-01
Validation Epoch 294 : 	 Train : 1.68195e-02 	 Res : 3.99902e-03 	 Jac : 1.27790e-02 	 Enc : 1.69781e-05 	 AE : 2.45577e-05 	 MSE : 3.75996e-01
Training Epoch 294 finished, took current epoch 370.92s, cumulative time 109965.06s
Current Learning rate DEQ : 0.0002814749767106563
Current Learning rate AUTOENC : 0.0014073748835532814
Epoch 295, 25% 	 Loss : 1.7306e-02 	 Res : 4.4327e-03 	 Jac : 1.2834e-02 	 Enc : 1.5894e-05 	 AEnc : 2.3347e-05 	 MSE : 5.6292e-01
Epoch 295, 50% 	 Loss : 1.7239e-02 	 Res : 4.4672e-03 	 Jac : 1.2733e-02 	 Enc : 1.6150e-05 	 AEnc : 2.2846e-05 	 MSE : 5.7988e-01
Epoch 295, 75% 	 Loss : 1.7284e-02 	 Res : 4.4485e-03 	 Jac : 1.2794e-02 	 Enc : 1.5425e-05 	 AEnc : 2.6137e-05 	 MSE : 5.7889e-01
Training Epoch 295 : 	 Train : 1.73349e-02 	 Res : 4.51716e-03 	 Jac : 1.27769e-02 	 Enc : 1.58454e-05 	 AE : 2.49457e-05 	 MSE : 5.81522e-01
Validation Epoch 295 : 	 Train : 1.72206e-02 	 Res : 4.37545e-03 	 Jac : 1.27907e-02 	 Enc : 1.45080e-05 	 AE : 3.99543e-05 	 MSE : 5.12584e-01
Training Epoch 295 finished, took current epoch 369.03s, cumulative time 110334.04s
Current Learning rate DEQ : 0.0002814749767106563
Current Learning rate AUTOENC : 0.0014073748835532814
Epoch 296, 25% 	 Loss : 1.7339e-02 	 Res : 4.4746e-03 	 Jac : 1.2815e-02 	 Enc : 1.5877e-05 	 AEnc : 3.3695e-05 	 MSE : 5.8955e-01
Epoch 296, 50% 	 Loss : 1.7324e-02 	 Res : 4.4869e-03 	 Jac : 1.2796e-02 	 Enc : 1.5218e-05 	 AEnc : 2.5871e-05 	 MSE : 5.7687e-01
Epoch 296, 75% 	 Loss : 1.7242e-02 	 Res : 4.4629e-03 	 Jac : 1.2741e-02 	 Enc : 1.4997e-05 	 AEnc : 2.3069e-05 	 MSE : 5.7017e-01
Training Epoch 296 : 	 Train : 1.73123e-02 	 Res : 4.49532e-03 	 Jac : 1.27746e-02 	 Enc : 1.55770e-05 	 AE : 2.67672e-05 	 MSE : 5.81722e-01
Validation Epoch 296 : 	 Train : 1.72703e-02 	 Res : 4.46090e-03 	 Jac : 1.27755e-02 	 Enc : 1.45227e-05 	 AE : 1.93544e-05 	 MSE : 5.56422e-01
Training Epoch 296 finished, took current epoch 372.66s, cumulative time 110706.69s
Current Learning rate DEQ : 0.0002814749767106563
Current Learning rate AUTOENC : 0.0014073748835532814
Epoch 297, 25% 	 Loss : 1.7341e-02 	 Res : 4.5639e-03 	 Jac : 1.2739e-02 	 Enc : 1.5191e-05 	 AEnc : 2.3152e-05 	 MSE : 5.8930e-01
Epoch 297, 50% 	 Loss : 1.7362e-02 	 Res : 4.5415e-03 	 Jac : 1.2782e-02 	 Enc : 1.5256e-05 	 AEnc : 2.3704e-05 	 MSE : 6.0007e-01
Epoch 297, 75% 	 Loss : 1.7247e-02 	 Res : 4.4783e-03 	 Jac : 1.2726e-02 	 Enc : 1.6065e-05 	 AEnc : 2.6044e-05 	 MSE : 5.9099e-01
Training Epoch 297 : 	 Train : 1.73256e-02 	 Res : 4.53825e-03 	 Jac : 1.27460e-02 	 Enc : 1.56214e-05 	 AE : 2.57635e-05 	 MSE : 5.93449e-01
Validation Epoch 297 : 	 Train : 1.73301e-02 	 Res : 4.41807e-03 	 Jac : 1.28758e-02 	 Enc : 1.57726e-05 	 AE : 2.04595e-05 	 MSE : 5.24998e-01
Training Epoch 297 finished, took current epoch 369.67s, cumulative time 111076.34s
Current Learning rate DEQ : 0.0002814749767106563
Current Learning rate AUTOENC : 0.0014073748835532814
Epoch 298, 25% 	 Loss : 1.9874e-02 	 Res : 6.7191e-03 	 Jac : 1.2854e-02 	 Enc : 1.9438e-05 	 AEnc : 2.8120e-04 	 MSE : 1.3687e+00
Epoch 298, 50% 	 Loss : 2.0452e-02 	 Res : 7.3518e-03 	 Jac : 1.2779e-02 	 Enc : 3.9892e-05 	 AEnc : 2.8182e-04 	 MSE : 1.6346e+00
Epoch 298, 75% 	 Loss : 1.9213e-02 	 Res : 5.4390e-03 	 Jac : 1.2763e-02 	 Enc : 2.3319e-05 	 AEnc : 9.8827e-04 	 MSE : 8.7911e-01
Training Epoch 298 : 	 Train : 2.03981e-02 	 Res : 6.10475e-03 	 Jac : 1.27807e-02 	 Enc : 2.61485e-05 	 AE : 1.48653e-03 	 MSE : 1.06315e+00
Validation Epoch 298 : 	 Train : 1.88710e-02 	 Res : 3.79408e-03 	 Jac : 1.28092e-02 	 Enc : 1.98413e-05 	 AE : 2.24792e-03 	 MSE : 1.37995e-01
Training Epoch 298 finished, took current epoch 371.23s, cumulative time 111447.55s
Current Learning rate DEQ : 0.0002814749767106563
Current Learning rate AUTOENC : 0.0014073748835532814
Epoch 299, 25% 	 Loss : 1.8147e-02 	 Res : 3.9078e-03 	 Jac : 1.2775e-02 	 Enc : 1.4124e-05 	 AEnc : 1.4503e-03 	 MSE : 2.1633e-01
Epoch 299, 50% 	 Loss : 1.9651e-02 	 Res : 3.9885e-03 	 Jac : 1.2783e-02 	 Enc : 1.2740e-05 	 AEnc : 2.8663e-03 	 MSE : 2.1254e-01
Epoch 299, 75% 	 Loss : 1.7046e-02 	 Res : 3.6121e-03 	 Jac : 1.2802e-02 	 Enc : 1.0788e-05 	 AEnc : 6.2152e-04 	 MSE : 2.0980e-01
Training Epoch 299 : 	 Train : 1.78337e-02 	 Res : 3.74905e-03 	 Jac : 1.27954e-02 	 Enc : 1.21557e-05 	 AE : 1.27711e-03 	 MSE : 2.07346e-01
Validation Epoch 299 : 	 Train : 1.62316e-02 	 Res : 3.44646e-03 	 Jac : 1.27200e-02 	 Enc : 1.05727e-05 	 AE : 5.45662e-05 	 MSE : 1.47979e-01
Training Epoch 299 finished, took current epoch 374.22s, cumulative time 111821.76s
Current Learning rate DEQ : 0.0002814749767106563
Current Learning rate AUTOENC : 0.0014073748835532814
Epoch 300, 25% 	 Loss : 1.6403e-02 	 Res : 3.5231e-03 	 Jac : 1.2819e-02 	 Enc : 1.0867e-05 	 AEnc : 5.0435e-05 	 MSE : 2.1670e-01
Epoch 300, 50% 	 Loss : 1.6626e-02 	 Res : 3.6924e-03 	 Jac : 1.2792e-02 	 Enc : 1.1207e-05 	 AEnc : 1.3046e-04 	 MSE : 2.6607e-01
Epoch 300, 75% 	 Loss : 1.9672e-02 	 Res : 5.6234e-03 	 Jac : 1.2753e-02 	 Enc : 1.5311e-05 	 AEnc : 1.2810e-03 	 MSE : 8.9189e-01
Training Epoch 300 : 	 Train : 2.09739e-02 	 Res : 4.62545e-03 	 Jac : 1.28052e-02 	 Enc : 1.57610e-05 	 AE : 3.52750e-03 	 MSE : 3.99445e-01
Validation Epoch 300 : 	 Train : 3.04414e-02 	 Res : 6.00806e-03 	 Jac : 1.28138e-02 	 Enc : 2.58075e-05 	 AE : 1.15937e-02 	 MSE : 3.94789e-01
Training Epoch 300 finished, took current epoch 374.12s, cumulative time 112195.87s
Current Learning rate DEQ : 0.0002814749767106563
Current Learning rate AUTOENC : 0.0014073748835532814
Epoch 301, 25% 	 Loss : 2.0712e-02 	 Res : 4.2006e-03 	 Jac : 1.2824e-02 	 Enc : 1.7826e-05 	 AEnc : 3.6690e-03 	 MSE : 2.3851e-01
Epoch 301, 50% 	 Loss : 1.6996e-02 	 Res : 3.6003e-03 	 Jac : 1.2843e-02 	 Enc : 1.1989e-05 	 AEnc : 5.4048e-04 	 MSE : 2.0425e-01
Epoch 301, 75% 	 Loss : 1.6694e-02 	 Res : 3.6278e-03 	 Jac : 1.2825e-02 	 Enc : 1.0899e-05 	 AEnc : 2.3020e-04 	 MSE : 2.1417e-01
Training Epoch 301 : 	 Train : 1.77358e-02 	 Res : 3.74934e-03 	 Jac : 1.28175e-02 	 Enc : 1.30782e-05 	 AE : 1.15591e-03 	 MSE : 2.17690e-01
Validation Epoch 301 : 	 Train : 1.63117e-02 	 Res : 3.36783e-03 	 Jac : 1.28937e-02 	 Enc : 1.14764e-05 	 AE : 3.87034e-05 	 MSE : 1.24981e-01
Training Epoch 301 finished, took current epoch 375.09s, cumulative time 112570.92s
Current Learning rate DEQ : 0.0002814749767106563
Current Learning rate AUTOENC : 0.0014073748835532814
Epoch 302, 25% 	 Loss : 1.6444e-02 	 Res : 3.5758e-03 	 Jac : 1.2827e-02 	 Enc : 1.0734e-05 	 AEnc : 3.0445e-05 	 MSE : 2.1054e-01
Epoch 302, 50% 	 Loss : 1.6422e-02 	 Res : 3.5509e-03 	 Jac : 1.2835e-02 	 Enc : 1.1234e-05 	 AEnc : 2.4366e-05 	 MSE : 2.2013e-01
Epoch 302, 75% 	 Loss : 1.6409e-02 	 Res : 3.6158e-03 	 Jac : 1.2721e-02 	 Enc : 1.2288e-05 	 AEnc : 6.0418e-05 	 MSE : 2.3878e-01
Training Epoch 302 : 	 Train : 1.73686e-02 	 Res : 4.46650e-03 	 Jac : 1.27904e-02 	 Enc : 1.29371e-05 	 AE : 9.87822e-05 	 MSE : 5.56485e-01
Validation Epoch 302 : 	 Train : 1.95242e-02 	 Res : 6.56105e-03 	 Jac : 1.27919e-02 	 Enc : 3.42988e-05 	 AE : 1.36936e-04 	 MSE : 1.24348e+00
Training Epoch 302 finished, took current epoch 369.23s, cumulative time 112940.10s
Current Learning rate DEQ : 0.00022517998136852504
Current Learning rate AUTOENC : 0.0011258999068426252
Epoch 303, 25% 	 Loss : 1.8669e-02 	 Res : 5.7272e-03 	 Jac : 1.2785e-02 	 Enc : 2.9017e-05 	 AEnc : 1.2814e-04 	 MSE : 9.4874e-01
Epoch 303, 50% 	 Loss : 1.7771e-02 	 Res : 4.0611e-03 	 Jac : 1.2834e-02 	 Enc : 1.5468e-05 	 AEnc : 8.6112e-04 	 MSE : 3.2371e-01
Epoch 303, 75% 	 Loss : 2.1648e-02 	 Res : 8.7337e-03 	 Jac : 1.2746e-02 	 Enc : 2.3012e-05 	 AEnc : 1.4539e-04 	 MSE : 2.1850e+00
Training Epoch 303 : 	 Train : 1.99272e-02 	 Res : 6.82314e-03 	 Jac : 1.27830e-02 	 Enc : 2.56918e-05 	 AE : 2.95430e-04 	 MSE : 1.41152e+00
Validation Epoch 303 : 	 Train : 2.65105e-02 	 Res : 1.37103e-02 	 Jac : 1.27413e-02 	 Enc : 3.20752e-05 	 AE : 2.68783e-05 	 MSE : 4.04179e+00
Training Epoch 303 finished, took current epoch 369.95s, cumulative time 113310.04s
Current Learning rate DEQ : 0.00022517998136852504
Current Learning rate AUTOENC : 0.0011258999068426252
Epoch 304, 25% 	 Loss : 2.2048e-02 	 Res : 9.0797e-03 	 Jac : 1.2904e-02 	 Enc : 3.5543e-05 	 AEnc : 2.8376e-05 	 MSE : 2.3547e+00
Epoch 304, 50% 	 Loss : 2.5681e-02 	 Res : 1.2801e-02 	 Jac : 1.2787e-02 	 Enc : 3.9818e-05 	 AEnc : 5.3595e-05 	 MSE : 3.7146e+00
Epoch 304, 75% 	 Loss : 2.1528e-02 	 Res : 8.4543e-03 	 Jac : 1.2792e-02 	 Enc : 4.9380e-05 	 AEnc : 2.3248e-04 	 MSE : 2.0536e+00
Training Epoch 304 : 	 Train : 2.16709e-02 	 Res : 8.69742e-03 	 Jac : 1.28311e-02 	 Enc : 3.57752e-05 	 AE : 1.06594e-04 	 MSE : 2.17010e+00
Validation Epoch 304 : 	 Train : 1.78808e-02 	 Res : 5.05390e-03 	 Jac : 1.27463e-02 	 Enc : 1.42331e-05 	 AE : 6.63916e-05 	 MSE : 7.74745e-01
Training Epoch 304 finished, took current epoch 371.95s, cumulative time 113681.96s
Current Learning rate DEQ : 0.00022517998136852504
Current Learning rate AUTOENC : 0.0011258999068426252
Epoch 305, 25% 	 Loss : 1.6972e-02 	 Res : 4.1439e-03 	 Jac : 1.2780e-02 	 Enc : 1.3458e-05 	 AEnc : 3.4823e-05 	 MSE : 4.3642e-01
Epoch 305, 50% 	 Loss : 2.2918e-02 	 Res : 1.0132e-02 	 Jac : 1.2724e-02 	 Enc : 2.4616e-05 	 AEnc : 3.7962e-05 	 MSE : 2.7882e+00
Epoch 305, 75% 	 Loss : 2.0391e-02 	 Res : 7.5902e-03 	 Jac : 1.2698e-02 	 Enc : 3.0744e-05 	 AEnc : 7.1922e-05 	 MSE : 1.7222e+00
Training Epoch 305 : 	 Train : 1.94202e-02 	 Res : 6.60235e-03 	 Jac : 1.27389e-02 	 Enc : 2.14293e-05 	 AE : 5.75369e-05 	 MSE : 1.36926e+00
Validation Epoch 305 : 	 Train : 1.75521e-02 	 Res : 4.67210e-03 	 Jac : 1.27918e-02 	 Enc : 1.73549e-05 	 AE : 7.08487e-05 	 MSE : 5.74321e-01
Training Epoch 305 finished, took current epoch 374.17s, cumulative time 114056.12s
Current Learning rate DEQ : 0.00022517998136852504
Current Learning rate AUTOENC : 0.0011258999068426252
Epoch 306, 25% 	 Loss : 1.7480e-02 	 Res : 4.3066e-03 	 Jac : 1.2815e-02 	 Enc : 1.4558e-05 	 AEnc : 3.4456e-04 	 MSE : 4.6707e-01
Epoch 306, 50% 	 Loss : 1.7020e-02 	 Res : 4.1351e-03 	 Jac : 1.2810e-02 	 Enc : 1.3306e-05 	 AEnc : 6.2350e-05 	 MSE : 4.3918e-01
Epoch 306, 75% 	 Loss : 1.7099e-02 	 Res : 4.2904e-03 	 Jac : 1.2762e-02 	 Enc : 1.2561e-05 	 AEnc : 3.4755e-05 	 MSE : 5.0402e-01
Training Epoch 306 : 	 Train : 1.71835e-02 	 Res : 4.26251e-03 	 Jac : 1.27863e-02 	 Enc : 1.32441e-05 	 AE : 1.21350e-04 	 MSE : 4.76805e-01
Validation Epoch 306 : 	 Train : 1.78030e-02 	 Res : 4.98763e-03 	 Jac : 1.27642e-02 	 Enc : 1.37676e-05 	 AE : 3.74022e-05 	 MSE : 6.99226e-01
Training Epoch 306 finished, took current epoch 370.27s, cumulative time 114426.38s
Current Learning rate DEQ : 0.00022517998136852504
Current Learning rate AUTOENC : 0.0011258999068426252
Epoch 307, 25% 	 Loss : 1.7305e-02 	 Res : 4.4492e-03 	 Jac : 1.2808e-02 	 Enc : 1.4649e-05 	 AEnc : 3.2665e-05 	 MSE : 5.4658e-01
Epoch 307, 50% 	 Loss : 1.9375e-02 	 Res : 6.5017e-03 	 Jac : 1.2817e-02 	 Enc : 1.4283e-05 	 AEnc : 4.1942e-05 	 MSE : 1.3315e+00
Epoch 307, 75% 	 Loss : 2.2121e-02 	 Res : 8.8355e-03 	 Jac : 1.2775e-02 	 Enc : 2.5651e-05 	 AEnc : 4.8481e-04 	 MSE : 2.1509e+00
Training Epoch 307 : 	 Train : 1.94281e-02 	 Res : 6.44670e-03 	 Jac : 1.27750e-02 	 Enc : 1.96379e-05 	 AE : 1.86780e-04 	 MSE : 1.28988e+00
Validation Epoch 307 : 	 Train : 1.66969e-02 	 Res : 3.77843e-03 	 Jac : 1.28218e-02 	 Enc : 2.48311e-05 	 AE : 7.18617e-05 	 MSE : 2.79301e-01
Training Epoch 307 finished, took current epoch 372.12s, cumulative time 114798.49s
Current Learning rate DEQ : 0.00022517998136852504
Current Learning rate AUTOENC : 0.0011258999068426252
Epoch 308, 25% 	 Loss : 1.8553e-02 	 Res : 5.6950e-03 	 Jac : 1.2788e-02 	 Enc : 2.3172e-05 	 AEnc : 4.6643e-05 	 MSE : 1.0599e+00
Epoch 308, 50% 	 Loss : 1.8678e-02 	 Res : 5.8813e-03 	 Jac : 1.2749e-02 	 Enc : 2.0471e-05 	 AEnc : 2.7858e-05 	 MSE : 1.0973e+00
Epoch 308, 75% 	 Loss : 1.8614e-02 	 Res : 5.8192e-03 	 Jac : 1.2747e-02 	 Enc : 2.0179e-05 	 AEnc : 2.7565e-05 	 MSE : 1.0836e+00
Training Epoch 308 : 	 Train : 1.86228e-02 	 Res : 5.79531e-03 	 Jac : 1.27732e-02 	 Enc : 2.12080e-05 	 AE : 3.31009e-05 	 MSE : 1.08246e+00
Validation Epoch 308 : 	 Train : 1.64442e-02 	 Res : 3.64496e-03 	 Jac : 1.27527e-02 	 Enc : 2.01615e-05 	 AE : 2.64392e-05 	 MSE : 2.26217e-01
Training Epoch 308 finished, took current epoch 370.46s, cumulative time 115168.92s
Current Learning rate DEQ : 0.00022517998136852504
Current Learning rate AUTOENC : 0.0011258999068426252
Epoch 309, 25% 	 Loss : 1.8685e-02 	 Res : 5.8204e-03 	 Jac : 1.2817e-02 	 Enc : 2.0477e-05 	 AEnc : 2.6768e-05 	 MSE : 1.0723e+00
Epoch 309, 50% 	 Loss : 1.9367e-02 	 Res : 6.5338e-03 	 Jac : 1.2670e-02 	 Enc : 2.3353e-05 	 AEnc : 1.3996e-04 	 MSE : 1.2519e+00
Epoch 309, 75% 	 Loss : 2.1703e-02 	 Res : 5.7713e-03 	 Jac : 1.2800e-02 	 Enc : 2.6516e-05 	 AEnc : 3.1057e-03 	 MSE : 7.4267e-01
Training Epoch 309 : 	 Train : 2.12260e-02 	 Res : 5.89177e-03 	 Jac : 1.27885e-02 	 Enc : 2.39838e-05 	 AE : 2.52175e-03 	 MSE : 8.86076e-01
Validation Epoch 309 : 	 Train : 1.76804e-02 	 Res : 3.44977e-03 	 Jac : 1.27915e-02 	 Enc : 1.52390e-05 	 AE : 1.42387e-03 	 MSE : 7.57020e-02
Training Epoch 309 finished, took current epoch 370.55s, cumulative time 115539.44s
Current Learning rate DEQ : 0.00022517998136852504
Current Learning rate AUTOENC : 0.0011258999068426252
Epoch 310, 25% 	 Loss : 2.5265e-02 	 Res : 5.2878e-03 	 Jac : 1.2740e-02 	 Enc : 1.7734e-05 	 AEnc : 7.2198e-03 	 MSE : 4.2741e-01
Epoch 310, 50% 	 Loss : 1.7226e-02 	 Res : 4.1739e-03 	 Jac : 1.2838e-02 	 Enc : 1.2199e-05 	 AEnc : 2.0237e-04 	 MSE : 4.3674e-01
Epoch 310, 75% 	 Loss : 1.8398e-02 	 Res : 5.5872e-03 	 Jac : 1.2709e-02 	 Enc : 1.4120e-05 	 AEnc : 8.7860e-05 	 MSE : 1.0308e+00
Training Epoch 310 : 	 Train : 1.97073e-02 	 Res : 4.92478e-03 	 Jac : 1.27758e-02 	 Enc : 1.51853e-05 	 AE : 1.99159e-03 	 MSE : 6.19571e-01
Validation Epoch 310 : 	 Train : 1.71617e-02 	 Res : 4.10357e-03 	 Jac : 1.28593e-02 	 Enc : 1.10094e-05 	 AE : 1.87827e-04 	 MSE : 3.17751e-01
Training Epoch 310 finished, took current epoch 368.87s, cumulative time 115908.26s
Current Learning rate DEQ : 0.00022517998136852504
Current Learning rate AUTOENC : 0.0011258999068426252
Epoch 311, 25% 	 Loss : 1.7030e-02 	 Res : 3.8574e-03 	 Jac : 1.2828e-02 	 Enc : 1.4017e-05 	 AEnc : 3.3095e-04 	 MSE : 2.7421e-01
Epoch 311, 50% 	 Loss : 1.7106e-02 	 Res : 3.8646e-03 	 Jac : 1.2853e-02 	 Enc : 1.1565e-05 	 AEnc : 3.7754e-04 	 MSE : 2.9310e-01
Epoch 311, 75% 	 Loss : 1.8010e-02 	 Res : 3.7155e-03 	 Jac : 1.2777e-02 	 Enc : 1.0703e-05 	 AEnc : 1.5071e-03 	 MSE : 1.8795e-01
Training Epoch 311 : 	 Train : 1.72197e-02 	 Res : 3.73370e-03 	 Jac : 1.28133e-02 	 Enc : 1.17695e-05 	 AE : 6.60939e-04 	 MSE : 2.26847e-01
Validation Epoch 311 : 	 Train : 1.62805e-02 	 Res : 3.39823e-03 	 Jac : 1.28425e-02 	 Enc : 1.05911e-05 	 AE : 2.91889e-05 	 MSE : 1.38742e-01
Training Epoch 311 finished, took current epoch 366.95s, cumulative time 116275.20s
Current Learning rate DEQ : 0.00022517998136852504
Current Learning rate AUTOENC : 0.0011258999068426252
Epoch 312, 25% 	 Loss : 1.6358e-02 	 Res : 3.4186e-03 	 Jac : 1.2883e-02 	 Enc : 1.0086e-05 	 AEnc : 4.6846e-05 	 MSE : 1.5123e-01
Epoch 312, 50% 	 Loss : 1.9426e-02 	 Res : 6.2392e-03 	 Jac : 1.2859e-02 	 Enc : 1.3859e-05 	 AEnc : 3.1368e-04 	 MSE : 1.2136e+00
Epoch 312, 75% 	 Loss : 1.8839e-02 	 Res : 6.0515e-03 	 Jac : 1.2710e-02 	 Enc : 2.0897e-05 	 AEnc : 5.7178e-05 	 MSE : 1.1747e+00
Training Epoch 312 : 	 Train : 1.83279e-02 	 Res : 5.38436e-03 	 Jac : 1.28162e-02 	 Enc : 1.60493e-05 	 AE : 1.11317e-04 	 MSE : 9.14720e-01
Validation Epoch 312 : 	 Train : 1.67960e-02 	 Res : 4.05099e-03 	 Jac : 1.27038e-02 	 Enc : 1.95779e-05 	 AE : 2.16552e-05 	 MSE : 4.01031e-01
Training Epoch 312 finished, took current epoch 367.87s, cumulative time 116643.05s
Current Learning rate DEQ : 0.00022517998136852504
Current Learning rate AUTOENC : 0.0011258999068426252
Epoch 313, 25% 	 Loss : 1.8834e-02 	 Res : 5.9054e-03 	 Jac : 1.2883e-02 	 Enc : 1.9907e-05 	 AEnc : 2.5158e-05 	 MSE : 1.1420e+00
Epoch 313, 50% 	 Loss : 1.8666e-02 	 Res : 5.8631e-03 	 Jac : 1.2757e-02 	 Enc : 2.0094e-05 	 AEnc : 2.5819e-05 	 MSE : 1.1419e+00
Epoch 313, 75% 	 Loss : 1.8606e-02 	 Res : 5.7739e-03 	 Jac : 1.2787e-02 	 Enc : 2.0148e-05 	 AEnc : 2.4958e-05 	 MSE : 1.0612e+00
Training Epoch 313 : 	 Train : 1.87296e-02 	 Res : 5.88883e-03 	 Jac : 1.27954e-02 	 Enc : 2.01896e-05 	 AE : 2.51652e-05 	 MSE : 1.12597e+00
Validation Epoch 313 : 	 Train : 1.97836e-02 	 Res : 6.97372e-03 	 Jac : 1.27611e-02 	 Enc : 1.93703e-05 	 AE : 2.94946e-05 	 MSE : 1.51959e+00
Training Epoch 313 finished, took current epoch 366.68s, cumulative time 117009.72s
Current Learning rate DEQ : 0.00018014398509482005
Current Learning rate AUTOENC : 0.0009007199254741002
Epoch 314, 25% 	 Loss : 1.7612e-02 	 Res : 4.8249e-03 	 Jac : 1.2744e-02 	 Enc : 1.7434e-05 	 AEnc : 2.5641e-05 	 MSE : 7.1812e-01
Epoch 314, 50% 	 Loss : 1.7838e-02 	 Res : 4.9555e-03 	 Jac : 1.2841e-02 	 Enc : 1.5525e-05 	 AEnc : 2.5278e-05 	 MSE : 7.6524e-01
Epoch 314, 75% 	 Loss : 1.7769e-02 	 Res : 4.9459e-03 	 Jac : 1.2782e-02 	 Enc : 1.4880e-05 	 AEnc : 2.6312e-05 	 MSE : 7.6739e-01
Training Epoch 314 : 	 Train : 1.78050e-02 	 Res : 4.95001e-03 	 Jac : 1.28117e-02 	 Enc : 1.56277e-05 	 AE : 2.76963e-05 	 MSE : 7.59757e-01
Validation Epoch 314 : 	 Train : 1.82120e-02 	 Res : 5.29781e-03 	 Jac : 1.27891e-02 	 Enc : 1.50327e-05 	 AE : 1.10028e-04 	 MSE : 7.77455e-01
Training Epoch 314 finished, took current epoch 368.69s, cumulative time 117378.40s
Current Learning rate DEQ : 0.00018014398509482005
Current Learning rate AUTOENC : 0.0009007199254741002
Epoch 315, 25% 	 Loss : 1.7413e-02 	 Res : 4.3791e-03 	 Jac : 1.2923e-02 	 Enc : 1.5520e-05 	 AEnc : 9.5282e-05 	 MSE : 4.6397e-01
Epoch 315, 50% 	 Loss : 1.7071e-02 	 Res : 3.6890e-03 	 Jac : 1.2741e-02 	 Enc : 1.3341e-05 	 AEnc : 6.2733e-04 	 MSE : 2.2528e-01
Epoch 315, 75% 	 Loss : 2.0425e-02 	 Res : 3.9993e-03 	 Jac : 1.2778e-02 	 Enc : 1.3050e-05 	 AEnc : 3.6350e-03 	 MSE : 1.3339e-01
Training Epoch 315 : 	 Train : 1.85763e-02 	 Res : 3.94569e-03 	 Jac : 1.28248e-02 	 Enc : 1.31661e-05 	 AE : 1.79265e-03 	 MSE : 2.36015e-01
Validation Epoch 315 : 	 Train : 1.66518e-02 	 Res : 3.44250e-03 	 Jac : 1.27881e-02 	 Enc : 9.93950e-06 	 AE : 4.11223e-04 	 MSE : 1.19927e-01
Training Epoch 315 finished, took current epoch 370.44s, cumulative time 117748.83s
Current Learning rate DEQ : 0.00018014398509482005
Current Learning rate AUTOENC : 0.0009007199254741002
Epoch 316, 25% 	 Loss : 1.6791e-02 	 Res : 3.3864e-03 	 Jac : 1.2900e-02 	 Enc : 9.9208e-06 	 AEnc : 4.9418e-04 	 MSE : 1.1289e-01
Epoch 316, 50% 	 Loss : 1.6382e-02 	 Res : 3.3373e-03 	 Jac : 1.2817e-02 	 Enc : 9.8754e-06 	 AEnc : 2.1861e-04 	 MSE : 1.1977e-01
Epoch 316, 75% 	 Loss : 1.6190e-02 	 Res : 3.2495e-03 	 Jac : 1.2783e-02 	 Enc : 8.9525e-06 	 AEnc : 1.4834e-04 	 MSE : 1.1194e-01
Training Epoch 316 : 	 Train : 1.64226e-02 	 Res : 3.31837e-03 	 Jac : 1.28193e-02 	 Enc : 9.64443e-06 	 AE : 2.75305e-04 	 MSE : 1.12899e-01
Validation Epoch 316 : 	 Train : 1.61874e-02 	 Res : 3.35985e-03 	 Jac : 1.27175e-02 	 Enc : 9.50995e-06 	 AE : 1.00491e-04 	 MSE : 1.20382e-01
Training Epoch 316 finished, took current epoch 365.33s, cumulative time 118114.13s
Current Learning rate DEQ : 0.00018014398509482005
Current Learning rate AUTOENC : 0.0009007199254741002
Epoch 317, 25% 	 Loss : 1.7015e-02 	 Res : 3.8622e-03 	 Jac : 1.2730e-02 	 Enc : 9.9244e-06 	 AEnc : 4.1274e-04 	 MSE : 3.3129e-01
Epoch 317, 50% 	 Loss : 2.0859e-02 	 Res : 4.9243e-03 	 Jac : 1.2842e-02 	 Enc : 1.4743e-05 	 AEnc : 3.0776e-03 	 MSE : 4.7253e-01
Epoch 317, 75% 	 Loss : 1.7191e-02 	 Res : 4.1262e-03 	 Jac : 1.2731e-02 	 Enc : 1.4005e-05 	 AEnc : 3.1950e-04 	 MSE : 3.9585e-01
Training Epoch 317 : 	 Train : 1.79384e-02 	 Res : 4.18670e-03 	 Jac : 1.27593e-02 	 Enc : 1.25290e-05 	 AE : 9.79880e-04 	 MSE : 3.84595e-01
Validation Epoch 317 : 	 Train : 1.71023e-02 	 Res : 4.15004e-03 	 Jac : 1.28267e-02 	 Enc : 1.00240e-05 	 AE : 1.15485e-04 	 MSE : 4.38190e-01
Training Epoch 317 finished, took current epoch 368.61s, cumulative time 118482.74s
Current Learning rate DEQ : 0.00018014398509482005
Current Learning rate AUTOENC : 0.0009007199254741002
Epoch 318, 25% 	 Loss : 1.6641e-02 	 Res : 3.7328e-03 	 Jac : 1.2849e-02 	 Enc : 1.1116e-05 	 AEnc : 4.7815e-05 	 MSE : 3.0469e-01
Epoch 318, 50% 	 Loss : 1.6593e-02 	 Res : 3.7616e-03 	 Jac : 1.2794e-02 	 Enc : 1.0986e-05 	 AEnc : 2.6581e-05 	 MSE : 3.0553e-01
Epoch 318, 75% 	 Loss : 1.6605e-02 	 Res : 3.7867e-03 	 Jac : 1.2783e-02 	 Enc : 1.1058e-05 	 AEnc : 2.4548e-05 	 MSE : 3.0787e-01
Training Epoch 318 : 	 Train : 1.65927e-02 	 Res : 3.76283e-03 	 Jac : 1.27880e-02 	 Enc : 1.10415e-05 	 AE : 3.08448e-05 	 MSE : 3.02193e-01
Validation Epoch 318 : 	 Train : 1.75053e-02 	 Res : 4.63856e-03 	 Jac : 1.28316e-02 	 Enc : 1.08630e-05 	 AE : 2.42676e-05 	 MSE : 6.27435e-01
Training Epoch 318 finished, took current epoch 363.54s, cumulative time 118846.26s
Current Learning rate DEQ : 0.00018014398509482005
Current Learning rate AUTOENC : 0.0009007199254741002
Epoch 319, 25% 	 Loss : 1.6623e-02 	 Res : 3.7382e-03 	 Jac : 1.2850e-02 	 Enc : 1.1229e-05 	 AEnc : 2.4021e-05 	 MSE : 3.1399e-01
Epoch 319, 50% 	 Loss : 1.6604e-02 	 Res : 3.7131e-03 	 Jac : 1.2858e-02 	 Enc : 1.1062e-05 	 AEnc : 2.2562e-05 	 MSE : 3.0242e-01
Epoch 319, 75% 	 Loss : 1.6674e-02 	 Res : 3.7950e-03 	 Jac : 1.2843e-02 	 Enc : 1.1576e-05 	 AEnc : 2.4445e-05 	 MSE : 3.0299e-01
Training Epoch 319 : 	 Train : 1.66084e-02 	 Res : 3.75659e-03 	 Jac : 1.28170e-02 	 Enc : 1.12713e-05 	 AE : 2.35672e-05 	 MSE : 3.04629e-01
Validation Epoch 319 : 	 Train : 1.71122e-02 	 Res : 4.34321e-03 	 Jac : 1.27356e-02 	 Enc : 1.04225e-05 	 AE : 2.29805e-05 	 MSE : 5.19621e-01
Training Epoch 319 finished, took current epoch 363.95s, cumulative time 119210.20s
Current Learning rate DEQ : 0.00018014398509482005
Current Learning rate AUTOENC : 0.0009007199254741002
Epoch 320, 25% 	 Loss : 1.6641e-02 	 Res : 3.7517e-03 	 Jac : 1.2855e-02 	 Enc : 1.1071e-05 	 AEnc : 2.4147e-05 	 MSE : 2.9896e-01
Epoch 320, 50% 	 Loss : 1.6563e-02 	 Res : 3.8061e-03 	 Jac : 1.2722e-02 	 Enc : 1.1166e-05 	 AEnc : 2.3978e-05 	 MSE : 3.2120e-01
Epoch 320, 75% 	 Loss : 1.6529e-02 	 Res : 3.7640e-03 	 Jac : 1.2728e-02 	 Enc : 1.1453e-05 	 AEnc : 2.4905e-05 	 MSE : 3.0349e-01
Training Epoch 320 : 	 Train : 1.65782e-02 	 Res : 3.76401e-03 	 Jac : 1.27787e-02 	 Enc : 1.12688e-05 	 AE : 2.42310e-05 	 MSE : 3.05500e-01
Validation Epoch 320 : 	 Train : 1.71388e-02 	 Res : 4.25799e-03 	 Jac : 1.28461e-02 	 Enc : 1.15053e-05 	 AE : 2.32512e-05 	 MSE : 4.97871e-01
Training Epoch 320 finished, took current epoch 363.12s, cumulative time 119573.30s
Current Learning rate DEQ : 0.00018014398509482005
Current Learning rate AUTOENC : 0.0009007199254741002
Epoch 321, 25% 	 Loss : 1.6587e-02 	 Res : 3.7773e-03 	 Jac : 1.2775e-02 	 Enc : 1.1459e-05 	 AEnc : 2.3601e-05 	 MSE : 3.1314e-01
Epoch 321, 50% 	 Loss : 1.6706e-02 	 Res : 3.8324e-03 	 Jac : 1.2839e-02 	 Enc : 1.1028e-05 	 AEnc : 2.3873e-05 	 MSE : 3.1626e-01
Epoch 321, 75% 	 Loss : 1.6486e-02 	 Res : 3.6806e-03 	 Jac : 1.2770e-02 	 Enc : 1.1310e-05 	 AEnc : 2.3921e-05 	 MSE : 3.0350e-01
Training Epoch 321 : 	 Train : 1.66870e-02 	 Res : 3.83968e-03 	 Jac : 1.28124e-02 	 Enc : 1.12841e-05 	 AE : 2.36132e-05 	 MSE : 3.35429e-01
Validation Epoch 321 : 	 Train : 1.59209e-02 	 Res : 3.07932e-03 	 Jac : 1.28086e-02 	 Enc : 1.14929e-05 	 AE : 2.14272e-05 	 MSE : 2.30035e-02
Training Epoch 321 finished, took current epoch 367.62s, cumulative time 119940.90s
Current Learning rate DEQ : 0.00018014398509482005
Current Learning rate AUTOENC : 0.0009007199254741002
MODEL SAVED
Epoch 322, 25% 	 Loss : 2.0601e-02 	 Res : 7.8139e-03 	 Jac : 1.2743e-02 	 Enc : 1.4853e-05 	 AEnc : 2.9224e-05 	 MSE : 1.8553e+00
Epoch 322, 50% 	 Loss : 2.0379e-02 	 Res : 7.4352e-03 	 Jac : 1.2893e-02 	 Enc : 2.4906e-05 	 AEnc : 2.6470e-05 	 MSE : 1.7107e+00
Epoch 322, 75% 	 Loss : 2.0042e-02 	 Res : 7.2505e-03 	 Jac : 1.2732e-02 	 Enc : 2.5833e-05 	 AEnc : 3.3613e-05 	 MSE : 1.6185e+00
Training Epoch 322 : 	 Train : 1.97483e-02 	 Res : 6.89436e-03 	 Jac : 1.27946e-02 	 Enc : 2.12555e-05 	 AE : 3.80456e-05 	 MSE : 1.47692e+00
Validation Epoch 322 : 	 Train : 1.68347e-02 	 Res : 3.92334e-03 	 Jac : 1.28384e-02 	 Enc : 1.61808e-05 	 AE : 5.68337e-05 	 MSE : 3.32916e-01
Training Epoch 322 finished, took current epoch 366.03s, cumulative time 120306.91s
Current Learning rate DEQ : 0.00018014398509482005
Current Learning rate AUTOENC : 0.0009007199254741002
Epoch 323, 25% 	 Loss : 1.6984e-02 	 Res : 4.1357e-03 	 Jac : 1.2757e-02 	 Enc : 1.4679e-05 	 AEnc : 7.6001e-05 	 MSE : 4.3954e-01
Epoch 323, 50% 	 Loss : 1.7058e-02 	 Res : 4.0613e-03 	 Jac : 1.2767e-02 	 Enc : 1.2600e-05 	 AEnc : 2.1751e-04 	 MSE : 3.3580e-01
Epoch 323, 75% 	 Loss : 1.6338e-02 	 Res : 3.5033e-03 	 Jac : 1.2756e-02 	 Enc : 1.2433e-05 	 AEnc : 6.6308e-05 	 MSE : 1.9124e-01
Training Epoch 323 : 	 Train : 1.66350e-02 	 Res : 3.76318e-03 	 Jac : 1.27611e-02 	 Enc : 1.25398e-05 	 AE : 9.81796e-05 	 MSE : 2.73409e-01
Validation Epoch 323 : 	 Train : 1.61804e-02 	 Res : 3.42232e-03 	 Jac : 1.27242e-02 	 Enc : 9.59410e-06 	 AE : 2.42397e-05 	 MSE : 1.51842e-01
Training Epoch 323 finished, took current epoch 365.36s, cumulative time 120672.26s
Current Learning rate DEQ : 0.00018014398509482005
Current Learning rate AUTOENC : 0.0009007199254741002
Epoch 324, 25% 	 Loss : 1.6080e-02 	 Res : 3.2931e-03 	 Jac : 1.2744e-02 	 Enc : 9.6615e-06 	 AEnc : 3.3176e-05 	 MSE : 1.1636e-01
Epoch 324, 50% 	 Loss : 1.6031e-02 	 Res : 3.1878e-03 	 Jac : 1.2808e-02 	 Enc : 8.7764e-06 	 AEnc : 2.7114e-05 	 MSE : 1.0583e-01
Epoch 324, 75% 	 Loss : 1.6113e-02 	 Res : 3.2788e-03 	 Jac : 1.2799e-02 	 Enc : 9.3180e-06 	 AEnc : 2.5926e-05 	 MSE : 1.1167e-01
Training Epoch 324 : 	 Train : 1.60807e-02 	 Res : 3.26481e-03 	 Jac : 1.27782e-02 	 Enc : 9.29921e-06 	 AE : 2.83180e-05 	 MSE : 1.11515e-01
Validation Epoch 324 : 	 Train : 1.59913e-02 	 Res : 3.24196e-03 	 Jac : 1.27097e-02 	 Enc : 9.48762e-06 	 AE : 3.01583e-05 	 MSE : 8.43574e-02
Training Epoch 324 finished, took current epoch 369.65s, cumulative time 121041.90s
Current Learning rate DEQ : 0.00018014398509482005
Current Learning rate AUTOENC : 0.0009007199254741002
Epoch 325, 25% 	 Loss : 1.6184e-02 	 Res : 3.3766e-03 	 Jac : 1.2771e-02 	 Enc : 9.1725e-06 	 AEnc : 2.7154e-05 	 MSE : 1.3351e-01
Epoch 325, 50% 	 Loss : 1.6085e-02 	 Res : 3.2453e-03 	 Jac : 1.2808e-02 	 Enc : 8.9066e-06 	 AEnc : 2.3706e-05 	 MSE : 1.0716e-01
Epoch 325, 75% 	 Loss : 1.6192e-02 	 Res : 3.3148e-03 	 Jac : 1.2811e-02 	 Enc : 1.0186e-05 	 AEnc : 5.6010e-05 	 MSE : 1.1962e-01
Training Epoch 325 : 	 Train : 1.61159e-02 	 Res : 3.29495e-03 	 Jac : 1.27672e-02 	 Enc : 9.33681e-06 	 AE : 4.44080e-05 	 MSE : 1.18825e-01
Validation Epoch 325 : 	 Train : 1.60362e-02 	 Res : 3.20124e-03 	 Jac : 1.27896e-02 	 Enc : 9.19785e-06 	 AE : 3.61618e-05 	 MSE : 7.21556e-02
Training Epoch 325 finished, took current epoch 363.49s, cumulative time 121405.38s
Current Learning rate DEQ : 0.00018014398509482005
Current Learning rate AUTOENC : 0.0009007199254741002
Epoch 326, 25% 	 Loss : 1.6300e-02 	 Res : 3.4523e-03 	 Jac : 1.2733e-02 	 Enc : 9.8464e-06 	 AEnc : 1.0446e-04 	 MSE : 1.9038e-01
Epoch 326, 50% 	 Loss : 1.7348e-02 	 Res : 4.2493e-03 	 Jac : 1.2818e-02 	 Enc : 1.3972e-05 	 AEnc : 2.6626e-04 	 MSE : 4.1414e-01
Epoch 326, 75% 	 Loss : 1.7478e-02 	 Res : 4.3324e-03 	 Jac : 1.2819e-02 	 Enc : 1.3204e-05 	 AEnc : 3.1367e-04 	 MSE : 4.2605e-01
Training Epoch 326 : 	 Train : 1.69519e-02 	 Res : 3.97245e-03 	 Jac : 1.27856e-02 	 Enc : 1.27068e-05 	 AE : 1.81170e-04 	 MSE : 3.40712e-01
Validation Epoch 326 : 	 Train : 1.76488e-02 	 Res : 4.71582e-03 	 Jac : 1.28898e-02 	 Enc : 1.26578e-05 	 AE : 3.05505e-05 	 MSE : 6.51202e-01
Training Epoch 326 finished, took current epoch 366.06s, cumulative time 121771.42s
Current Learning rate DEQ : 0.00018014398509482005
Current Learning rate AUTOENC : 0.0009007199254741002
Epoch 327, 25% 	 Loss : 1.6795e-02 	 Res : 3.8570e-03 	 Jac : 1.2889e-02 	 Enc : 1.2172e-05 	 AEnc : 3.7033e-05 	 MSE : 3.3727e-01
Epoch 327, 50% 	 Loss : 1.6641e-02 	 Res : 3.8022e-03 	 Jac : 1.2801e-02 	 Enc : 1.0914e-05 	 AEnc : 2.7206e-05 	 MSE : 3.2313e-01
Epoch 327, 75% 	 Loss : 1.6805e-02 	 Res : 3.8495e-03 	 Jac : 1.2918e-02 	 Enc : 1.1504e-05 	 AEnc : 2.6055e-05 	 MSE : 3.3723e-01
Training Epoch 327 : 	 Train : 1.67202e-02 	 Res : 3.82563e-03 	 Jac : 1.28542e-02 	 Enc : 1.13472e-05 	 AE : 2.90130e-05 	 MSE : 3.31009e-01
Validation Epoch 327 : 	 Train : 1.76569e-02 	 Res : 4.73735e-03 	 Jac : 1.28756e-02 	 Enc : 1.14567e-05 	 AE : 3.24791e-05 	 MSE : 6.46158e-01
Training Epoch 327 finished, took current epoch 367.07s, cumulative time 122138.48s
Current Learning rate DEQ : 0.00018014398509482005
Current Learning rate AUTOENC : 0.0009007199254741002
Epoch 328, 25% 	 Loss : 1.6646e-02 	 Res : 3.8621e-03 	 Jac : 1.2746e-02 	 Enc : 1.0995e-05 	 AEnc : 2.6589e-05 	 MSE : 3.2533e-01
Epoch 328, 50% 	 Loss : 2.0135e-02 	 Res : 5.8080e-03 	 Jac : 1.2808e-02 	 Enc : 2.0522e-05 	 AEnc : 1.4990e-03 	 MSE : 9.2346e-01
Epoch 328, 75% 	 Loss : 1.8327e-02 	 Res : 5.4005e-03 	 Jac : 1.2789e-02 	 Enc : 1.8965e-05 	 AEnc : 1.1893e-04 	 MSE : 9.1917e-01
Training Epoch 328 : 	 Train : 1.83101e-02 	 Res : 5.09988e-03 	 Jac : 1.27707e-02 	 Enc : 1.64065e-05 	 AE : 4.23148e-04 	 MSE : 7.67189e-01
Validation Epoch 328 : 	 Train : 1.91568e-02 	 Res : 6.29503e-03 	 Jac : 1.28066e-02 	 Enc : 1.72737e-05 	 AE : 3.79426e-05 	 MSE : 1.25454e+00
Training Epoch 328 finished, took current epoch 364.30s, cumulative time 122502.77s
Current Learning rate DEQ : 0.00018014398509482005
Current Learning rate AUTOENC : 0.0009007199254741002
Epoch 329, 25% 	 Loss : 1.7867e-02 	 Res : 5.1259e-03 	 Jac : 1.2693e-02 	 Enc : 1.6679e-05 	 AEnc : 3.1445e-05 	 MSE : 8.1498e-01
Epoch 329, 50% 	 Loss : 1.8069e-02 	 Res : 5.2720e-03 	 Jac : 1.2755e-02 	 Enc : 1.5735e-05 	 AEnc : 2.5923e-05 	 MSE : 8.8895e-01
Epoch 329, 75% 	 Loss : 1.7831e-02 	 Res : 4.9960e-03 	 Jac : 1.2794e-02 	 Enc : 1.6228e-05 	 AEnc : 2.5359e-05 	 MSE : 7.8557e-01
Training Epoch 329 : 	 Train : 1.79203e-02 	 Res : 5.12382e-03 	 Jac : 1.27525e-02 	 Enc : 1.61521e-05 	 AE : 2.78439e-05 	 MSE : 8.38175e-01
Validation Epoch 329 : 	 Train : 1.89742e-02 	 Res : 6.11948e-03 	 Jac : 1.28159e-02 	 Enc : 1.67946e-05 	 AE : 2.19990e-05 	 MSE : 1.16862e+00
Training Epoch 329 finished, took current epoch 363.01s, cumulative time 122865.75s
Current Learning rate DEQ : 0.00018014398509482005
Current Learning rate AUTOENC : 0.0009007199254741002
Epoch 330, 25% 	 Loss : 1.7828e-02 	 Res : 5.0410e-03 	 Jac : 1.2744e-02 	 Enc : 1.6613e-05 	 AEnc : 2.5913e-05 	 MSE : 8.2122e-01
Epoch 330, 50% 	 Loss : 2.1596e-02 	 Res : 5.4073e-03 	 Jac : 1.2745e-02 	 Enc : 1.6533e-05 	 AEnc : 3.4269e-03 	 MSE : 6.7647e-01
Epoch 330, 75% 	 Loss : 2.1592e-02 	 Res : 4.6897e-03 	 Jac : 1.2783e-02 	 Enc : 1.7172e-05 	 AEnc : 4.1023e-03 	 MSE : 3.6061e-01
Training Epoch 330 : 	 Train : 1.97272e-02 	 Res : 4.95702e-03 	 Jac : 1.27626e-02 	 Enc : 1.56435e-05 	 AE : 1.99195e-03 	 MSE : 6.23072e-01
Validation Epoch 330 : 	 Train : 2.57641e-02 	 Res : 1.28678e-02 	 Jac : 1.26999e-02 	 Enc : 1.24349e-05 	 AE : 1.84000e-04 	 MSE : 3.80238e+00
Training Epoch 330 finished, took current epoch 362.49s, cumulative time 123228.23s
Current Learning rate DEQ : 0.00018014398509482005
Current Learning rate AUTOENC : 0.0009007199254741002
Epoch 331, 25% 	 Loss : 1.9693e-02 	 Res : 5.9351e-03 	 Jac : 1.2833e-02 	 Enc : 1.6264e-05 	 AEnc : 9.0852e-04 	 MSE : 1.0453e+00
Epoch 331, 50% 	 Loss : 2.3182e-02 	 Res : 4.9514e-03 	 Jac : 1.2883e-02 	 Enc : 1.5667e-05 	 AEnc : 5.3319e-03 	 MSE : 3.9993e-01
Epoch 331, 75% 	 Loss : 1.8859e-02 	 Res : 5.3441e-03 	 Jac : 1.2731e-02 	 Enc : 1.2328e-05 	 AEnc : 7.7176e-04 	 MSE : 8.8770e-01
Training Epoch 331 : 	 Train : 2.16431e-02 	 Res : 6.08466e-03 	 Jac : 1.27858e-02 	 Enc : 1.55488e-05 	 AE : 2.75713e-03 	 MSE : 1.02912e+00
Validation Epoch 331 : 	 Train : 4.14490e-02 	 Res : 1.05414e-02 	 Jac : 1.28054e-02 	 Enc : 2.36723e-05 	 AE : 1.80785e-02 	 MSE : 1.63247e+00
Training Epoch 331 finished, took current epoch 364.03s, cumulative time 123592.22s
Current Learning rate DEQ : 0.00018014398509482005
Current Learning rate AUTOENC : 0.0009007199254741002
Epoch 332, 25% 	 Loss : 2.2043e-02 	 Res : 5.9765e-03 	 Jac : 1.2795e-02 	 Enc : 1.9420e-05 	 AEnc : 3.2513e-03 	 MSE : 9.1985e-01
Epoch 332, 50% 	 Loss : 1.8729e-02 	 Res : 5.7694e-03 	 Jac : 1.2731e-02 	 Enc : 1.5482e-05 	 AEnc : 2.1245e-04 	 MSE : 1.0398e+00
Epoch 332, 75% 	 Loss : 1.7572e-02 	 Res : 4.6947e-03 	 Jac : 1.2818e-02 	 Enc : 1.2150e-05 	 AEnc : 4.7521e-05 	 MSE : 6.3557e-01
Training Epoch 332 : 	 Train : 1.90447e-02 	 Res : 5.33281e-03 	 Jac : 1.27663e-02 	 Enc : 1.53507e-05 	 AE : 9.30308e-04 	 MSE : 8.17199e-01
Validation Epoch 332 : 	 Train : 1.75449e-02 	 Res : 4.64978e-03 	 Jac : 1.28169e-02 	 Enc : 1.21966e-05 	 AE : 6.60382e-05 	 MSE : 5.60019e-01
Training Epoch 332 finished, took current epoch 362.18s, cumulative time 123954.36s
Current Learning rate DEQ : 0.00014411518807585605
Current Learning rate AUTOENC : 0.0007205759403792802
Epoch 333, 25% 	 Loss : 1.6580e-02 	 Res : 3.7077e-03 	 Jac : 1.2815e-02 	 Enc : 1.1046e-05 	 AEnc : 4.5984e-05 	 MSE : 2.7918e-01
Epoch 333, 50% 	 Loss : 1.6379e-02 	 Res : 3.5517e-03 	 Jac : 1.2779e-02 	 Enc : 1.0444e-05 	 AEnc : 3.7172e-05 	 MSE : 2.2579e-01
Epoch 333, 75% 	 Loss : 1.6433e-02 	 Res : 3.6388e-03 	 Jac : 1.2755e-02 	 Enc : 1.0319e-05 	 AEnc : 2.9040e-05 	 MSE : 2.3160e-01
Training Epoch 333 : 	 Train : 1.64271e-02 	 Res : 3.60504e-03 	 Jac : 1.27768e-02 	 Enc : 1.06018e-05 	 AE : 3.46635e-05 	 MSE : 2.39179e-01
Validation Epoch 333 : 	 Train : 1.65917e-02 	 Res : 3.71790e-03 	 Jac : 1.28369e-02 	 Enc : 1.04848e-05 	 AE : 2.64488e-05 	 MSE : 2.64446e-01
Training Epoch 333 finished, took current epoch 360.86s, cumulative time 124315.21s
Current Learning rate DEQ : 0.00014411518807585605
Current Learning rate AUTOENC : 0.0007205759403792802
Epoch 334, 25% 	 Loss : 1.6400e-02 	 Res : 3.5556e-03 	 Jac : 1.2810e-02 	 Enc : 9.8735e-06 	 AEnc : 2.4526e-05 	 MSE : 2.2612e-01
Epoch 334, 50% 	 Loss : 1.6337e-02 	 Res : 3.5471e-03 	 Jac : 1.2757e-02 	 Enc : 9.8626e-06 	 AEnc : 2.3690e-05 	 MSE : 2.2454e-01
Epoch 334, 75% 	 Loss : 1.9552e-02 	 Res : 6.7059e-03 	 Jac : 1.2780e-02 	 Enc : 1.4535e-05 	 AEnc : 5.1824e-05 	 MSE : 1.4213e+00
Training Epoch 334 : 	 Train : 1.75704e-02 	 Res : 4.72799e-03 	 Jac : 1.27688e-02 	 Enc : 1.23123e-05 	 AE : 6.13066e-05 	 MSE : 6.69668e-01
Validation Epoch 334 : 	 Train : 1.84448e-02 	 Res : 5.63076e-03 	 Jac : 1.27669e-02 	 Enc : 1.19399e-05 	 AE : 3.52117e-05 	 MSE : 1.01512e+00
Training Epoch 334 finished, took current epoch 364.72s, cumulative time 124679.92s
Current Learning rate DEQ : 0.00014411518807585605
Current Learning rate AUTOENC : 0.0007205759403792802
Epoch 335, 25% 	 Loss : 1.7321e-02 	 Res : 4.5338e-03 	 Jac : 1.2733e-02 	 Enc : 1.2831e-05 	 AEnc : 4.1264e-05 	 MSE : 5.8077e-01
Epoch 335, 50% 	 Loss : 1.7271e-02 	 Res : 4.4521e-03 	 Jac : 1.2782e-02 	 Enc : 1.3095e-05 	 AEnc : 2.3614e-05 	 MSE : 5.6954e-01
Epoch 335, 75% 	 Loss : 1.7163e-02 	 Res : 4.3248e-03 	 Jac : 1.2802e-02 	 Enc : 1.2494e-05 	 AEnc : 2.3156e-05 	 MSE : 5.5656e-01
Training Epoch 335 : 	 Train : 1.72351e-02 	 Res : 4.42249e-03 	 Jac : 1.27715e-02 	 Enc : 1.28781e-05 	 AE : 2.82217e-05 	 MSE : 5.63281e-01
Validation Epoch 335 : 	 Train : 1.84985e-02 	 Res : 5.63240e-03 	 Jac : 1.28276e-02 	 Enc : 1.27996e-05 	 AE : 2.57805e-05 	 MSE : 1.03103e+00
Training Epoch 335 finished, took current epoch 369.15s, cumulative time 125049.02s
Current Learning rate DEQ : 0.00014411518807585605
Current Learning rate AUTOENC : 0.0007205759403792802
Epoch 336, 25% 	 Loss : 1.7449e-02 	 Res : 4.5365e-03 	 Jac : 1.2874e-02 	 Enc : 1.3069e-05 	 AEnc : 2.5039e-05 	 MSE : 5.7967e-01
Epoch 336, 50% 	 Loss : 1.7266e-02 	 Res : 4.4338e-03 	 Jac : 1.2795e-02 	 Enc : 1.2266e-05 	 AEnc : 2.5460e-05 	 MSE : 5.9191e-01
Epoch 336, 75% 	 Loss : 1.7185e-02 	 Res : 4.3585e-03 	 Jac : 1.2789e-02 	 Enc : 1.2741e-05 	 AEnc : 2.5450e-05 	 MSE : 5.4921e-01
Training Epoch 336 : 	 Train : 1.72828e-02 	 Res : 4.44842e-03 	 Jac : 1.27966e-02 	 Enc : 1.27055e-05 	 AE : 2.51323e-05 	 MSE : 5.74703e-01
Validation Epoch 336 : 	 Train : 1.77747e-02 	 Res : 4.98597e-03 	 Jac : 1.27518e-02 	 Enc : 1.16050e-05 	 AE : 2.53477e-05 	 MSE : 7.82523e-01
Training Epoch 336 finished, took current epoch 368.66s, cumulative time 125417.63s
Current Learning rate DEQ : 0.00014411518807585605
Current Learning rate AUTOENC : 0.0007205759403792802
Epoch 337, 25% 	 Loss : 1.7240e-02 	 Res : 4.4213e-03 	 Jac : 1.2782e-02 	 Enc : 1.2273e-05 	 AEnc : 2.4601e-05 	 MSE : 5.9672e-01
Epoch 337, 50% 	 Loss : 1.7393e-02 	 Res : 4.5446e-03 	 Jac : 1.2811e-02 	 Enc : 1.2839e-05 	 AEnc : 2.5057e-05 	 MSE : 5.7890e-01
Epoch 337, 75% 	 Loss : 1.7206e-02 	 Res : 4.3712e-03 	 Jac : 1.2796e-02 	 Enc : 1.2483e-05 	 AEnc : 2.6249e-05 	 MSE : 5.6375e-01
Training Epoch 337 : 	 Train : 1.73023e-02 	 Res : 4.45130e-03 	 Jac : 1.28135e-02 	 Enc : 1.24590e-05 	 AE : 2.49438e-05 	 MSE : 5.77811e-01
Validation Epoch 337 : 	 Train : 1.80275e-02 	 Res : 5.30498e-03 	 Jac : 1.26891e-02 	 Enc : 1.21982e-05 	 AE : 2.11728e-05 	 MSE : 9.06325e-01
Training Epoch 337 finished, took current epoch 368.90s, cumulative time 125786.47s
Current Learning rate DEQ : 0.00014411518807585605
Current Learning rate AUTOENC : 0.0007205759403792802
Epoch 338, 25% 	 Loss : 1.7149e-02 	 Res : 4.3893e-03 	 Jac : 1.2723e-02 	 Enc : 1.2944e-05 	 AEnc : 2.4232e-05 	 MSE : 5.7464e-01
Epoch 338, 50% 	 Loss : 1.7283e-02 	 Res : 4.4559e-03 	 Jac : 1.2791e-02 	 Enc : 1.2533e-05 	 AEnc : 2.3895e-05 	 MSE : 5.8826e-01
Epoch 338, 75% 	 Loss : 1.7272e-02 	 Res : 4.5328e-03 	 Jac : 1.2702e-02 	 Enc : 1.2160e-05 	 AEnc : 2.4870e-05 	 MSE : 5.9041e-01
Training Epoch 338 : 	 Train : 1.72305e-02 	 Res : 4.44916e-03 	 Jac : 1.27443e-02 	 Enc : 1.26602e-05 	 AE : 2.43978e-05 	 MSE : 5.78107e-01
Validation Epoch 338 : 	 Train : 1.89399e-02 	 Res : 6.22442e-03 	 Jac : 1.26763e-02 	 Enc : 1.16216e-05 	 AE : 2.75233e-05 	 MSE : 1.24083e+00
Training Epoch 338 finished, took current epoch 368.05s, cumulative time 126154.47s
Current Learning rate DEQ : 0.00014411518807585605
Current Learning rate AUTOENC : 0.0007205759403792802
Epoch 339, 25% 	 Loss : 1.7424e-02 	 Res : 4.6274e-03 	 Jac : 1.2759e-02 	 Enc : 1.1942e-05 	 AEnc : 2.5556e-05 	 MSE : 6.4942e-01
Epoch 339, 50% 	 Loss : 1.7289e-02 	 Res : 4.4779e-03 	 Jac : 1.2772e-02 	 Enc : 1.3326e-05 	 AEnc : 2.5838e-05 	 MSE : 5.9539e-01
Epoch 339, 75% 	 Loss : 1.7243e-02 	 Res : 4.5021e-03 	 Jac : 1.2704e-02 	 Enc : 1.2853e-05 	 AEnc : 2.4091e-05 	 MSE : 5.7917e-01
Training Epoch 339 : 	 Train : 1.73448e-02 	 Res : 4.55912e-03 	 Jac : 1.27484e-02 	 Enc : 1.26241e-05 	 AE : 2.46131e-05 	 MSE : 6.05846e-01
Validation Epoch 339 : 	 Train : 1.84027e-02 	 Res : 5.65085e-03 	 Jac : 1.27162e-02 	 Enc : 1.19485e-05 	 AE : 2.36887e-05 	 MSE : 1.04222e+00
Training Epoch 339 finished, took current epoch 366.67s, cumulative time 126521.07s
Current Learning rate DEQ : 0.00014411518807585605
Current Learning rate AUTOENC : 0.0007205759403792802
Epoch 340, 25% 	 Loss : 1.7176e-02 	 Res : 4.4331e-03 	 Jac : 1.2707e-02 	 Enc : 1.2348e-05 	 AEnc : 2.3410e-05 	 MSE : 5.9194e-01
Epoch 340, 50% 	 Loss : 1.7306e-02 	 Res : 4.4647e-03 	 Jac : 1.2806e-02 	 Enc : 1.2176e-05 	 AEnc : 2.3440e-05 	 MSE : 5.8077e-01
Epoch 340, 75% 	 Loss : 1.7398e-02 	 Res : 4.4990e-03 	 Jac : 1.2860e-02 	 Enc : 1.3155e-05 	 AEnc : 2.5293e-05 	 MSE : 5.8997e-01
Training Epoch 340 : 	 Train : 1.72826e-02 	 Res : 4.45617e-03 	 Jac : 1.27896e-02 	 Enc : 1.25739e-05 	 AE : 2.42816e-05 	 MSE : 5.84160e-01
Validation Epoch 340 : 	 Train : 1.92673e-02 	 Res : 6.42824e-03 	 Jac : 1.27955e-02 	 Enc : 1.21006e-05 	 AE : 3.14698e-05 	 MSE : 1.30900e+00
Training Epoch 340 finished, took current epoch 368.46s, cumulative time 126889.48s
Current Learning rate DEQ : 0.00014411518807585605
Current Learning rate AUTOENC : 0.0007205759403792802
Epoch 341, 25% 	 Loss : 1.7324e-02 	 Res : 4.5301e-03 	 Jac : 1.2755e-02 	 Enc : 1.2754e-05 	 AEnc : 2.6231e-05 	 MSE : 6.1021e-01
Epoch 341, 50% 	 Loss : 1.7301e-02 	 Res : 4.4808e-03 	 Jac : 1.2784e-02 	 Enc : 1.2034e-05 	 AEnc : 2.4133e-05 	 MSE : 5.9641e-01
Epoch 341, 75% 	 Loss : 1.7248e-02 	 Res : 4.5132e-03 	 Jac : 1.2698e-02 	 Enc : 1.1769e-05 	 AEnc : 2.4834e-05 	 MSE : 6.0398e-01
Training Epoch 341 : 	 Train : 1.72824e-02 	 Res : 4.50464e-03 	 Jac : 1.27398e-02 	 Enc : 1.23770e-05 	 AE : 2.56216e-05 	 MSE : 5.97673e-01
Validation Epoch 341 : 	 Train : 1.83029e-02 	 Res : 5.54654e-03 	 Jac : 1.27176e-02 	 Enc : 1.20409e-05 	 AE : 2.67397e-05 	 MSE : 9.97274e-01
Training Epoch 341 finished, took current epoch 370.73s, cumulative time 127260.15s
Current Learning rate DEQ : 0.00014411518807585605
Current Learning rate AUTOENC : 0.0007205759403792802
Epoch 342, 25% 	 Loss : 1.7352e-02 	 Res : 4.5668e-03 	 Jac : 1.2749e-02 	 Enc : 1.2214e-05 	 AEnc : 2.4197e-05 	 MSE : 6.0548e-01
Epoch 342, 50% 	 Loss : 1.7253e-02 	 Res : 4.5215e-03 	 Jac : 1.2693e-02 	 Enc : 1.2775e-05 	 AEnc : 2.5423e-05 	 MSE : 5.8324e-01
Epoch 342, 75% 	 Loss : 1.7372e-02 	 Res : 4.5707e-03 	 Jac : 1.2758e-02 	 Enc : 1.2329e-05 	 AEnc : 3.0136e-05 	 MSE : 6.1486e-01
Training Epoch 342 : 	 Train : 1.72961e-02 	 Res : 4.49965e-03 	 Jac : 1.27578e-02 	 Enc : 1.23511e-05 	 AE : 2.62474e-05 	 MSE : 5.95066e-01
Validation Epoch 342 : 	 Train : 1.68905e-02 	 Res : 4.10287e-03 	 Jac : 1.27524e-02 	 Enc : 1.20369e-05 	 AE : 2.32338e-05 	 MSE : 4.26100e-01
Training Epoch 342 finished, took current epoch 369.42s, cumulative time 127629.52s
Current Learning rate DEQ : 0.00014411518807585605
Current Learning rate AUTOENC : 0.0007205759403792802
Epoch 343, 25% 	 Loss : 1.7328e-02 	 Res : 4.5213e-03 	 Jac : 1.2771e-02 	 Enc : 1.2315e-05 	 AEnc : 2.4115e-05 	 MSE : 6.1266e-01
Epoch 343, 50% 	 Loss : 1.7388e-02 	 Res : 4.5053e-03 	 Jac : 1.2845e-02 	 Enc : 1.2055e-05 	 AEnc : 2.5627e-05 	 MSE : 5.7513e-01
Epoch 343, 75% 	 Loss : 1.7307e-02 	 Res : 4.5039e-03 	 Jac : 1.2761e-02 	 Enc : 1.2546e-05 	 AEnc : 2.9608e-05 	 MSE : 6.2715e-01
Training Epoch 343 : 	 Train : 1.73397e-02 	 Res : 4.50413e-03 	 Jac : 1.27969e-02 	 Enc : 1.23913e-05 	 AE : 2.62627e-05 	 MSE : 5.98137e-01
Validation Epoch 343 : 	 Train : 1.65167e-02 	 Res : 3.79410e-03 	 Jac : 1.26835e-02 	 Enc : 1.20405e-05 	 AE : 2.70209e-05 	 MSE : 3.16317e-01
Training Epoch 343 finished, took current epoch 368.89s, cumulative time 127998.38s
Current Learning rate DEQ : 0.00011529215046068484
Current Learning rate AUTOENC : 0.0005764607523034242
Epoch 344, 25% 	 Loss : 1.6709e-02 	 Res : 3.9203e-03 	 Jac : 1.2753e-02 	 Enc : 1.1282e-05 	 AEnc : 2.4945e-05 	 MSE : 4.0081e-01
Epoch 344, 50% 	 Loss : 1.6815e-02 	 Res : 3.9687e-03 	 Jac : 1.2809e-02 	 Enc : 1.0540e-05 	 AEnc : 2.7291e-05 	 MSE : 3.8827e-01
Epoch 344, 75% 	 Loss : 1.6959e-02 	 Res : 4.1002e-03 	 Jac : 1.2822e-02 	 Enc : 1.0441e-05 	 AEnc : 2.6028e-05 	 MSE : 4.2281e-01
Training Epoch 344 : 	 Train : 1.68304e-02 	 Res : 3.98961e-03 	 Jac : 1.28046e-02 	 Enc : 1.07007e-05 	 AE : 2.54944e-05 	 MSE : 3.99692e-01
Validation Epoch 344 : 	 Train : 1.64759e-02 	 Res : 3.69260e-03 	 Jac : 1.27502e-02 	 Enc : 1.07377e-05 	 AE : 2.23747e-05 	 MSE : 2.71985e-01
Training Epoch 344 finished, took current epoch 370.63s, cumulative time 128368.97s
Current Learning rate DEQ : 0.00011529215046068484
Current Learning rate AUTOENC : 0.0005764607523034242
Epoch 345, 25% 	 Loss : 1.6777e-02 	 Res : 4.0076e-03 	 Jac : 1.2735e-02 	 Enc : 1.0718e-05 	 AEnc : 2.3518e-05 	 MSE : 4.0733e-01
Epoch 345, 50% 	 Loss : 1.6703e-02 	 Res : 3.9227e-03 	 Jac : 1.2747e-02 	 Enc : 1.0505e-05 	 AEnc : 2.2947e-05 	 MSE : 3.8388e-01
Epoch 345, 75% 	 Loss : 1.6303e-02 	 Res : 3.5088e-03 	 Jac : 1.2760e-02 	 Enc : 9.8962e-06 	 AEnc : 2.4091e-05 	 MSE : 1.9585e-01
Training Epoch 345 : 	 Train : 1.66301e-02 	 Res : 3.81401e-03 	 Jac : 1.27569e-02 	 Enc : 1.02113e-05 	 AE : 4.89552e-05 	 MSE : 3.14428e-01
Validation Epoch 345 : 	 Train : 1.74875e-02 	 Res : 4.28838e-03 	 Jac : 1.27619e-02 	 Enc : 1.10795e-05 	 AE : 4.26199e-04 	 MSE : 3.89043e-01
Training Epoch 345 finished, took current epoch 370.73s, cumulative time 128739.66s
Current Learning rate DEQ : 0.00011529215046068484
Current Learning rate AUTOENC : 0.0005764607523034242
Epoch 346, 25% 	 Loss : 1.6809e-02 	 Res : 3.5137e-03 	 Jac : 1.2772e-02 	 Enc : 1.0294e-05 	 AEnc : 5.1233e-04 	 MSE : 1.6875e-01
Epoch 346, 50% 	 Loss : 1.7765e-02 	 Res : 3.5965e-03 	 Jac : 1.2789e-02 	 Enc : 1.0402e-05 	 AEnc : 1.3690e-03 	 MSE : 1.6596e-01
Epoch 346, 75% 	 Loss : 1.6301e-02 	 Res : 3.3824e-03 	 Jac : 1.2815e-02 	 Enc : 8.8460e-06 	 AEnc : 9.4338e-05 	 MSE : 1.5855e-01
Training Epoch 346 : 	 Train : 1.67796e-02 	 Res : 3.46953e-03 	 Jac : 1.27962e-02 	 Enc : 9.47482e-06 	 AE : 5.04379e-04 	 MSE : 1.64116e-01
Validation Epoch 346 : 	 Train : 1.62213e-02 	 Res : 3.46827e-03 	 Jac : 1.27222e-02 	 Enc : 8.24815e-06 	 AE : 2.26180e-05 	 MSE : 1.76812e-01
Training Epoch 346 finished, took current epoch 369.56s, cumulative time 129109.17s
Current Learning rate DEQ : 0.00011529215046068484
Current Learning rate AUTOENC : 0.0005764607523034242
Epoch 347, 25% 	 Loss : 1.6097e-02 	 Res : 3.2947e-03 	 Jac : 1.2771e-02 	 Enc : 8.4338e-06 	 AEnc : 2.3047e-05 	 MSE : 1.6552e-01
Epoch 347, 50% 	 Loss : 1.6080e-02 	 Res : 3.3658e-03 	 Jac : 1.2681e-02 	 Enc : 8.7711e-06 	 AEnc : 2.3903e-05 	 MSE : 1.6635e-01
Epoch 347, 75% 	 Loss : 1.6237e-02 	 Res : 3.4394e-03 	 Jac : 1.2765e-02 	 Enc : 8.8761e-06 	 AEnc : 2.4299e-05 	 MSE : 1.7390e-01
Training Epoch 347 : 	 Train : 1.61669e-02 	 Res : 3.38085e-03 	 Jac : 1.27541e-02 	 Enc : 8.60296e-06 	 AE : 2.33292e-05 	 MSE : 1.67026e-01
Validation Epoch 347 : 	 Train : 1.60241e-02 	 Res : 3.22210e-03 	 Jac : 1.27716e-02 	 Enc : 8.10655e-06 	 AE : 2.22580e-05 	 MSE : 9.08082e-02
Training Epoch 347 finished, took current epoch 369.98s, cumulative time 129479.13s
Current Learning rate DEQ : 0.00011529215046068484
Current Learning rate AUTOENC : 0.0005764607523034242
Epoch 348, 25% 	 Loss : 1.6101e-02 	 Res : 3.3752e-03 	 Jac : 1.2691e-02 	 Enc : 8.3330e-06 	 AEnc : 2.6802e-05 	 MSE : 1.5798e-01
Epoch 348, 50% 	 Loss : 1.6377e-02 	 Res : 3.5229e-03 	 Jac : 1.2809e-02 	 Enc : 9.1093e-06 	 AEnc : 3.6447e-05 	 MSE : 1.9913e-01
Epoch 348, 75% 	 Loss : 1.6106e-02 	 Res : 3.3442e-03 	 Jac : 1.2728e-02 	 Enc : 8.1975e-06 	 AEnc : 2.5537e-05 	 MSE : 1.7239e-01
Training Epoch 348 : 	 Train : 1.63481e-02 	 Res : 3.45269e-03 	 Jac : 1.27446e-02 	 Enc : 8.61282e-06 	 AE : 1.42126e-04 	 MSE : 1.82933e-01
Validation Epoch 348 : 	 Train : 1.65964e-02 	 Res : 3.45596e-03 	 Jac : 1.27707e-02 	 Enc : 8.60301e-06 	 AE : 3.61117e-04 	 MSE : 1.53367e-01
Training Epoch 348 finished, took current epoch 367.56s, cumulative time 129846.63s
Current Learning rate DEQ : 0.00011529215046068484
Current Learning rate AUTOENC : 0.0005764607523034242
Epoch 349, 25% 	 Loss : 1.6307e-02 	 Res : 3.4187e-03 	 Jac : 1.2787e-02 	 Enc : 8.8330e-06 	 AEnc : 9.2931e-05 	 MSE : 1.6911e-01
Epoch 349, 50% 	 Loss : 1.6238e-02 	 Res : 3.3744e-03 	 Jac : 1.2829e-02 	 Enc : 8.4554e-06 	 AEnc : 2.6084e-05 	 MSE : 1.6907e-01
Epoch 349, 75% 	 Loss : 1.7641e-02 	 Res : 4.8898e-03 	 Jac : 1.2669e-02 	 Enc : 8.4151e-06 	 AEnc : 7.3923e-05 	 MSE : 7.5254e-01
Training Epoch 349 : 	 Train : 1.78857e-02 	 Res : 4.11380e-03 	 Jac : 1.27570e-02 	 Enc : 9.52845e-06 	 AE : 1.00537e-03 	 MSE : 3.84399e-01
Validation Epoch 349 : 	 Train : 2.84908e-02 	 Res : 4.98024e-03 	 Jac : 1.28191e-02 	 Enc : 1.33323e-05 	 AE : 1.06781e-02 	 MSE : 5.53517e-02
Training Epoch 349 finished, took current epoch 369.62s, cumulative time 130216.19s
Current Learning rate DEQ : 0.00011529215046068484
Current Learning rate AUTOENC : 0.0005764607523034242
Epoch 350, 25% 	 Loss : 2.0539e-02 	 Res : 3.7986e-03 	 Jac : 1.2865e-02 	 Enc : 1.0368e-05 	 AEnc : 3.8654e-03 	 MSE : 7.8081e-02
Epoch 350, 50% 	 Loss : 2.4115e-02 	 Res : 4.4650e-03 	 Jac : 1.2696e-02 	 Enc : 1.0576e-05 	 AEnc : 6.9436e-03 	 MSE : 1.4331e-01
Epoch 350, 75% 	 Loss : 1.7912e-02 	 Res : 3.4764e-03 	 Jac : 1.2838e-02 	 Enc : 8.3042e-06 	 AEnc : 1.5896e-03 	 MSE : 1.1366e-01
Training Epoch 350 : 	 Train : 2.05725e-02 	 Res : 3.93044e-03 	 Jac : 1.28025e-02 	 Enc : 9.54329e-06 	 AE : 3.83001e-03 	 MSE : 1.30973e-01
Validation Epoch 350 : 	 Train : 1.71554e-02 	 Res : 3.70557e-03 	 Jac : 1.27700e-02 	 Enc : 8.49187e-06 	 AE : 6.71366e-04 	 MSE : 2.59867e-01
Training Epoch 350 finished, took current epoch 370.44s, cumulative time 130586.59s
Current Learning rate DEQ : 0.00011529215046068484
Current Learning rate AUTOENC : 0.0005764607523034242
Epoch 351, 25% 	 Loss : 1.7491e-02 	 Res : 3.5484e-03 	 Jac : 1.2737e-02 	 Enc : 8.3631e-06 	 AEnc : 1.1966e-03 	 MSE : 1.8450e-01
Epoch 351, 50% 	 Loss : 1.7213e-02 	 Res : 3.5974e-03 	 Jac : 1.2707e-02 	 Enc : 8.0733e-06 	 AEnc : 9.0081e-04 	 MSE : 1.7332e-01
Epoch 351, 75% 	 Loss : 1.6336e-02 	 Res : 3.4160e-03 	 Jac : 1.2735e-02 	 Enc : 7.8644e-06 	 AEnc : 1.7670e-04 	 MSE : 1.6803e-01
Training Epoch 351 : 	 Train : 1.68382e-02 	 Res : 3.48552e-03 	 Jac : 1.27600e-02 	 Enc : 8.07643e-06 	 AE : 5.84612e-04 	 MSE : 1.72546e-01
Validation Epoch 351 : 	 Train : 1.67967e-02 	 Res : 3.94996e-03 	 Jac : 1.28119e-02 	 Enc : 8.09711e-06 	 AE : 2.66798e-05 	 MSE : 3.30148e-01
Training Epoch 351 finished, took current epoch 372.24s, cumulative time 130958.75s
Current Learning rate DEQ : 0.00011529215046068484
Current Learning rate AUTOENC : 0.0005764607523034242
Epoch 352, 25% 	 Loss : 1.6182e-02 	 Res : 3.4319e-03 	 Jac : 1.2719e-02 	 Enc : 8.3361e-06 	 AEnc : 2.2481e-05 	 MSE : 1.7609e-01
Epoch 352, 50% 	 Loss : 1.6227e-02 	 Res : 3.3747e-03 	 Jac : 1.2823e-02 	 Enc : 8.0430e-06 	 AEnc : 2.1335e-05 	 MSE : 1.6878e-01
Epoch 352, 75% 	 Loss : 1.6183e-02 	 Res : 3.3636e-03 	 Jac : 1.2790e-02 	 Enc : 7.9502e-06 	 AEnc : 2.0788e-05 	 MSE : 1.7031e-01
Training Epoch 352 : 	 Train : 1.61981e-02 	 Res : 3.39263e-03 	 Jac : 1.27760e-02 	 Enc : 8.12098e-06 	 AE : 2.13911e-05 	 MSE : 1.70634e-01
Validation Epoch 352 : 	 Train : 1.67656e-02 	 Res : 3.93693e-03 	 Jac : 1.27988e-02 	 Enc : 8.36197e-06 	 AE : 2.14540e-05 	 MSE : 3.57579e-01
Training Epoch 352 finished, took current epoch 368.83s, cumulative time 131327.56s
Current Learning rate DEQ : 0.00011529215046068484
Current Learning rate AUTOENC : 0.0005764607523034242
Epoch 353, 25% 	 Loss : 1.6119e-02 	 Res : 3.3698e-03 	 Jac : 1.2719e-02 	 Enc : 8.1467e-06 	 AEnc : 2.1848e-05 	 MSE : 1.7851e-01
Epoch 353, 50% 	 Loss : 1.6308e-02 	 Res : 3.4477e-03 	 Jac : 1.2831e-02 	 Enc : 8.3974e-06 	 AEnc : 2.1280e-05 	 MSE : 1.7253e-01
Epoch 353, 75% 	 Loss : 1.6295e-02 	 Res : 3.4060e-03 	 Jac : 1.2859e-02 	 Enc : 8.3397e-06 	 AEnc : 2.1676e-05 	 MSE : 1.7525e-01
Training Epoch 353 : 	 Train : 1.62165e-02 	 Res : 3.39991e-03 	 Jac : 1.27866e-02 	 Enc : 8.24048e-06 	 AE : 2.17257e-05 	 MSE : 1.75017e-01
Validation Epoch 353 : 	 Train : 1.65445e-02 	 Res : 3.71791e-03 	 Jac : 1.27970e-02 	 Enc : 8.02793e-06 	 AE : 2.15495e-05 	 MSE : 2.75116e-01
Training Epoch 353 finished, took current epoch 368.91s, cumulative time 131696.40s
Current Learning rate DEQ : 0.00011529215046068484
Current Learning rate AUTOENC : 0.0005764607523034242
Epoch 354, 25% 	 Loss : 1.6192e-02 	 Res : 3.4456e-03 	 Jac : 1.2716e-02 	 Enc : 8.2582e-06 	 AEnc : 2.2189e-05 	 MSE : 1.7529e-01
Epoch 354, 50% 	 Loss : 1.6209e-02 	 Res : 3.3631e-03 	 Jac : 1.2817e-02 	 Enc : 8.2040e-06 	 AEnc : 2.1324e-05 	 MSE : 1.6909e-01
Epoch 354, 75% 	 Loss : 1.6187e-02 	 Res : 3.4275e-03 	 Jac : 1.2729e-02 	 Enc : 8.2958e-06 	 AEnc : 2.2198e-05 	 MSE : 1.7563e-01
Training Epoch 354 : 	 Train : 1.61850e-02 	 Res : 3.39176e-03 	 Jac : 1.27631e-02 	 Enc : 8.23217e-06 	 AE : 2.18280e-05 	 MSE : 1.73380e-01
Validation Epoch 354 : 	 Train : 1.61856e-02 	 Res : 3.40312e-03 	 Jac : 1.27531e-02 	 Enc : 8.16272e-06 	 AE : 2.12771e-05 	 MSE : 1.62490e-01
Training Epoch 354 finished, took current epoch 369.66s, cumulative time 132066.02s
Current Learning rate DEQ : 9.223372036854788e-05
Current Learning rate AUTOENC : 0.00046116860184273935
Epoch 355, 25% 	 Loss : 1.5981e-02 	 Res : 3.2445e-03 	 Jac : 1.2706e-02 	 Enc : 7.8621e-06 	 AEnc : 2.2465e-05 	 MSE : 1.2839e-01
Epoch 355, 50% 	 Loss : 1.6044e-02 	 Res : 3.3134e-03 	 Jac : 1.2700e-02 	 Enc : 8.0390e-06 	 AEnc : 2.2224e-05 	 MSE : 1.1543e-01
Epoch 355, 75% 	 Loss : 1.6036e-02 	 Res : 3.2162e-03 	 Jac : 1.2790e-02 	 Enc : 8.1100e-06 	 AEnc : 2.1669e-05 	 MSE : 1.1389e-01
Training Epoch 355 : 	 Train : 1.60501e-02 	 Res : 3.25233e-03 	 Jac : 1.27677e-02 	 Enc : 7.92705e-06 	 AE : 2.21258e-05 	 MSE : 1.18285e-01
Validation Epoch 355 : 	 Train : 1.60830e-02 	 Res : 3.20995e-03 	 Jac : 1.28434e-02 	 Enc : 7.98158e-06 	 AE : 2.17614e-05 	 MSE : 8.90622e-02
Training Epoch 355 finished, took current epoch 370.50s, cumulative time 132436.46s
Current Learning rate DEQ : 9.223372036854788e-05
Current Learning rate AUTOENC : 0.00046116860184273935
Epoch 356, 25% 	 Loss : 1.6047e-02 	 Res : 3.2498e-03 	 Jac : 1.2767e-02 	 Enc : 8.1283e-06 	 AEnc : 2.1965e-05 	 MSE : 1.1645e-01
Epoch 356, 50% 	 Loss : 1.5998e-02 	 Res : 3.2320e-03 	 Jac : 1.2736e-02 	 Enc : 7.9773e-06 	 AEnc : 2.1508e-05 	 MSE : 1.1684e-01
Epoch 356, 75% 	 Loss : 1.6049e-02 	 Res : 3.2534e-03 	 Jac : 1.2766e-02 	 Enc : 7.7775e-06 	 AEnc : 2.1944e-05 	 MSE : 1.1801e-01
Training Epoch 356 : 	 Train : 1.60576e-02 	 Res : 3.24527e-03 	 Jac : 1.27827e-02 	 Enc : 7.88397e-06 	 AE : 2.17746e-05 	 MSE : 1.17975e-01
Validation Epoch 356 : 	 Train : 1.58907e-02 	 Res : 3.14771e-03 	 Jac : 1.27122e-02 	 Enc : 7.60981e-06 	 AE : 2.32219e-05 	 MSE : 6.49945e-02
Training Epoch 356 finished, took current epoch 366.16s, cumulative time 132802.57s
Current Learning rate DEQ : 9.223372036854788e-05
Current Learning rate AUTOENC : 0.00046116860184273935
Epoch 357, 25% 	 Loss : 1.6019e-02 	 Res : 3.2556e-03 	 Jac : 1.2733e-02 	 Enc : 7.6983e-06 	 AEnc : 2.2782e-05 	 MSE : 1.1195e-01
Epoch 357, 50% 	 Loss : 1.5974e-02 	 Res : 3.1733e-03 	 Jac : 1.2770e-02 	 Enc : 8.1603e-06 	 AEnc : 2.2008e-05 	 MSE : 1.1730e-01
Epoch 357, 75% 	 Loss : 1.6178e-02 	 Res : 3.2854e-03 	 Jac : 1.2863e-02 	 Enc : 8.1071e-06 	 AEnc : 2.1325e-05 	 MSE : 1.2328e-01
Training Epoch 357 : 	 Train : 1.60585e-02 	 Res : 3.24552e-03 	 Jac : 1.27832e-02 	 Enc : 7.90145e-06 	 AE : 2.19225e-05 	 MSE : 1.18287e-01
Validation Epoch 357 : 	 Train : 1.59711e-02 	 Res : 3.13437e-03 	 Jac : 1.28085e-02 	 Enc : 7.57552e-06 	 AE : 2.06752e-05 	 MSE : 6.05478e-02
Training Epoch 357 finished, took current epoch 365.64s, cumulative time 133168.20s
Current Learning rate DEQ : 9.223372036854788e-05
Current Learning rate AUTOENC : 0.00046116860184273935
Epoch 358, 25% 	 Loss : 1.6027e-02 	 Res : 3.2225e-03 	 Jac : 1.2776e-02 	 Enc : 7.6401e-06 	 AEnc : 2.1048e-05 	 MSE : 1.2303e-01
Epoch 358, 50% 	 Loss : 1.6100e-02 	 Res : 3.2359e-03 	 Jac : 1.2835e-02 	 Enc : 7.9974e-06 	 AEnc : 2.0967e-05 	 MSE : 1.1793e-01
Epoch 358, 75% 	 Loss : 1.6074e-02 	 Res : 3.2596e-03 	 Jac : 1.2784e-02 	 Enc : 7.9876e-06 	 AEnc : 2.2137e-05 	 MSE : 1.2227e-01
Training Epoch 358 : 	 Train : 1.60853e-02 	 Res : 3.24916e-03 	 Jac : 1.28069e-02 	 Enc : 7.87592e-06 	 AE : 2.13679e-05 	 MSE : 1.20548e-01
Validation Epoch 358 : 	 Train : 1.60221e-02 	 Res : 3.25806e-03 	 Jac : 1.27360e-02 	 Enc : 7.72139e-06 	 AE : 2.03119e-05 	 MSE : 1.03492e-01
Training Epoch 358 finished, took current epoch 365.87s, cumulative time 133534.06s
Current Learning rate DEQ : 9.223372036854788e-05
Current Learning rate AUTOENC : 0.00046116860184273935
Epoch 359, 25% 	 Loss : 1.6105e-02 	 Res : 3.2641e-03 	 Jac : 1.2811e-02 	 Enc : 7.7322e-06 	 AEnc : 2.1507e-05 	 MSE : 1.2879e-01
Epoch 359, 50% 	 Loss : 1.6121e-02 	 Res : 3.3282e-03 	 Jac : 1.2764e-02 	 Enc : 7.4309e-06 	 AEnc : 2.1417e-05 	 MSE : 1.1788e-01
Epoch 359, 75% 	 Loss : 1.6038e-02 	 Res : 3.1711e-03 	 Jac : 1.2838e-02 	 Enc : 7.8327e-06 	 AEnc : 2.1832e-05 	 MSE : 1.1741e-01
Training Epoch 359 : 	 Train : 1.60769e-02 	 Res : 3.25102e-03 	 Jac : 1.27963e-02 	 Enc : 7.71949e-06 	 AE : 2.18559e-05 	 MSE : 1.21265e-01
Validation Epoch 359 : 	 Train : 1.59186e-02 	 Res : 3.16317e-03 	 Jac : 1.27243e-02 	 Enc : 7.80715e-06 	 AE : 2.33709e-05 	 MSE : 7.66722e-02
Training Epoch 359 finished, took current epoch 366.92s, cumulative time 133900.97s
Current Learning rate DEQ : 9.223372036854788e-05
Current Learning rate AUTOENC : 0.00046116860184273935
Epoch 360, 25% 	 Loss : 1.6042e-02 	 Res : 3.2291e-03 	 Jac : 1.2782e-02 	 Enc : 7.9807e-06 	 AEnc : 2.2387e-05 	 MSE : 1.1399e-01
Epoch 360, 50% 	 Loss : 1.6079e-02 	 Res : 3.2339e-03 	 Jac : 1.2816e-02 	 Enc : 7.8965e-06 	 AEnc : 2.1344e-05 	 MSE : 1.2208e-01
Epoch 360, 75% 	 Loss : 1.7009e-02 	 Res : 4.1592e-03 	 Jac : 1.2820e-02 	 Enc : 8.1071e-06 	 AEnc : 2.1534e-05 	 MSE : 4.5360e-01
Training Epoch 360 : 	 Train : 1.66260e-02 	 Res : 3.79021e-03 	 Jac : 1.28057e-02 	 Enc : 8.37126e-06 	 AE : 2.16734e-05 	 MSE : 3.30294e-01
Validation Epoch 360 : 	 Train : 1.64012e-02 	 Res : 3.60831e-03 	 Jac : 1.27629e-02 	 Enc : 9.87728e-06 	 AE : 2.00900e-05 	 MSE : 2.51891e-01
Training Epoch 360 finished, took current epoch 363.48s, cumulative time 134264.42s
Current Learning rate DEQ : 9.223372036854788e-05
Current Learning rate AUTOENC : 0.00046116860184273935
Epoch 361, 25% 	 Loss : 1.7393e-02 	 Res : 4.5351e-03 	 Jac : 1.2826e-02 	 Enc : 9.9992e-06 	 AEnc : 2.1875e-05 	 MSE : 6.2628e-01
Epoch 361, 50% 	 Loss : 1.7505e-02 	 Res : 4.6748e-03 	 Jac : 1.2794e-02 	 Enc : 1.0825e-05 	 AEnc : 2.5397e-05 	 MSE : 6.4627e-01
Epoch 361, 75% 	 Loss : 1.7384e-02 	 Res : 4.5660e-03 	 Jac : 1.2783e-02 	 Enc : 1.1145e-05 	 AEnc : 2.4249e-05 	 MSE : 6.2526e-01
Training Epoch 361 : 	 Train : 1.74347e-02 	 Res : 4.58931e-03 	 Jac : 1.28111e-02 	 Enc : 1.07738e-05 	 AE : 2.35239e-05 	 MSE : 6.37190e-01
Validation Epoch 361 : 	 Train : 1.66785e-02 	 Res : 3.91622e-03 	 Jac : 1.27267e-02 	 Enc : 1.13537e-05 	 AE : 2.42500e-05 	 MSE : 3.78979e-01
Training Epoch 361 finished, took current epoch 365.01s, cumulative time 134629.40s
Current Learning rate DEQ : 9.223372036854788e-05
Current Learning rate AUTOENC : 0.00046116860184273935
Epoch 362, 25% 	 Loss : 1.7314e-02 	 Res : 4.5401e-03 	 Jac : 1.2740e-02 	 Enc : 1.1155e-05 	 AEnc : 2.3062e-05 	 MSE : 6.2581e-01
Epoch 362, 50% 	 Loss : 1.7477e-02 	 Res : 4.6236e-03 	 Jac : 1.2820e-02 	 Enc : 1.1104e-05 	 AEnc : 2.2893e-05 	 MSE : 6.3441e-01
Epoch 362, 75% 	 Loss : 1.7366e-02 	 Res : 4.5532e-03 	 Jac : 1.2778e-02 	 Enc : 1.1401e-05 	 AEnc : 2.3545e-05 	 MSE : 6.1074e-01
Training Epoch 362 : 	 Train : 1.73762e-02 	 Res : 4.55146e-03 	 Jac : 1.27903e-02 	 Enc : 1.11965e-05 	 AE : 2.32876e-05 	 MSE : 6.26473e-01
Validation Epoch 362 : 	 Train : 1.68914e-02 	 Res : 4.06763e-03 	 Jac : 1.27914e-02 	 Enc : 1.09120e-05 	 AE : 2.14712e-05 	 MSE : 4.30398e-01
Training Epoch 362 finished, took current epoch 366.56s, cumulative time 134995.95s
Current Learning rate DEQ : 9.223372036854788e-05
Current Learning rate AUTOENC : 0.00046116860184273935
Epoch 363, 25% 	 Loss : 1.7474e-02 	 Res : 4.5741e-03 	 Jac : 1.2867e-02 	 Enc : 1.0986e-05 	 AEnc : 2.2412e-05 	 MSE : 6.3817e-01
Epoch 363, 50% 	 Loss : 1.7495e-02 	 Res : 4.5457e-03 	 Jac : 1.2914e-02 	 Enc : 1.0932e-05 	 AEnc : 2.4246e-05 	 MSE : 6.2662e-01
Epoch 363, 75% 	 Loss : 1.7317e-02 	 Res : 4.5613e-03 	 Jac : 1.2721e-02 	 Enc : 1.1266e-05 	 AEnc : 2.3700e-05 	 MSE : 6.3758e-01
Training Epoch 363 : 	 Train : 1.72113e-02 	 Res : 4.34720e-03 	 Jac : 1.28140e-02 	 Enc : 1.08836e-05 	 AE : 3.92319e-05 	 MSE : 5.46938e-01
Validation Epoch 363 : 	 Train : 1.88964e-02 	 Res : 4.20537e-03 	 Jac : 1.27540e-02 	 Enc : 9.56640e-06 	 AE : 1.92741e-03 	 MSE : 3.31221e-01
Training Epoch 363 finished, took current epoch 365.30s, cumulative time 135361.21s
Current Learning rate DEQ : 9.223372036854788e-05
Current Learning rate AUTOENC : 0.00046116860184273935
Epoch 364, 25% 	 Loss : 1.6860e-02 	 Res : 3.4267e-03 	 Jac : 1.2768e-02 	 Enc : 8.9510e-06 	 AEnc : 6.5607e-04 	 MSE : 1.4910e-01
Epoch 364, 50% 	 Loss : 1.6133e-02 	 Res : 3.2471e-03 	 Jac : 1.2831e-02 	 Enc : 7.9261e-06 	 AEnc : 4.6628e-05 	 MSE : 1.1702e-01
Epoch 364, 75% 	 Loss : 1.6145e-02 	 Res : 3.2474e-03 	 Jac : 1.2865e-02 	 Enc : 7.9232e-06 	 AEnc : 2.4288e-05 	 MSE : 1.2098e-01
Training Epoch 364 : 	 Train : 1.63090e-02 	 Res : 3.28932e-03 	 Jac : 1.28189e-02 	 Enc : 8.25128e-06 	 AE : 1.92548e-04 	 MSE : 1.26619e-01
Validation Epoch 364 : 	 Train : 1.63363e-02 	 Res : 3.55496e-03 	 Jac : 1.27523e-02 	 Enc : 8.08823e-06 	 AE : 2.09525e-05 	 MSE : 2.17080e-01
Training Epoch 364 finished, took current epoch 365.04s, cumulative time 135726.20s
Current Learning rate DEQ : 9.223372036854788e-05
Current Learning rate AUTOENC : 0.00046116860184273935
Epoch 365, 25% 	 Loss : 1.6140e-02 	 Res : 3.2759e-03 	 Jac : 1.2835e-02 	 Enc : 7.9468e-06 	 AEnc : 2.1266e-05 	 MSE : 1.2246e-01
Epoch 365, 50% 	 Loss : 1.5979e-02 	 Res : 3.2149e-03 	 Jac : 1.2735e-02 	 Enc : 7.8451e-06 	 AEnc : 2.1172e-05 	 MSE : 1.1800e-01
Epoch 365, 75% 	 Loss : 1.6130e-02 	 Res : 3.2308e-03 	 Jac : 1.2870e-02 	 Enc : 8.1880e-06 	 AEnc : 2.1301e-05 	 MSE : 1.2039e-01
Training Epoch 365 : 	 Train : 1.60964e-02 	 Res : 3.25005e-03 	 Jac : 1.28167e-02 	 Enc : 8.03905e-06 	 AE : 2.16801e-05 	 MSE : 1.21462e-01
Validation Epoch 365 : 	 Train : 1.60845e-02 	 Res : 3.23634e-03 	 Jac : 1.28200e-02 	 Enc : 7.73123e-06 	 AE : 2.03971e-05 	 MSE : 1.08643e-01
Training Epoch 365 finished, took current epoch 366.00s, cumulative time 136092.16s
Current Learning rate DEQ : 9.223372036854788e-05
Current Learning rate AUTOENC : 0.00046116860184273935
Epoch 366, 25% 	 Loss : 1.6098e-02 	 Res : 3.2712e-03 	 Jac : 1.2798e-02 	 Enc : 7.7431e-06 	 AEnc : 2.1276e-05 	 MSE : 1.2361e-01
Epoch 366, 50% 	 Loss : 1.6045e-02 	 Res : 3.2859e-03 	 Jac : 1.2727e-02 	 Enc : 8.0877e-06 	 AEnc : 2.4354e-05 	 MSE : 1.3140e-01
Epoch 366, 75% 	 Loss : 1.6064e-02 	 Res : 3.2615e-03 	 Jac : 1.2772e-02 	 Enc : 8.2202e-06 	 AEnc : 2.2384e-05 	 MSE : 1.2418e-01
Training Epoch 366 : 	 Train : 1.60519e-02 	 Res : 3.26015e-03 	 Jac : 1.27613e-02 	 Enc : 8.05086e-06 	 AE : 2.24211e-05 	 MSE : 1.24573e-01
Validation Epoch 366 : 	 Train : 1.62243e-02 	 Res : 3.40054e-03 	 Jac : 1.27969e-02 	 Enc : 8.04577e-06 	 AE : 1.88125e-05 	 MSE : 1.75183e-01
Training Epoch 366 finished, took current epoch 365.20s, cumulative time 136457.34s
Current Learning rate DEQ : 9.223372036854788e-05
Current Learning rate AUTOENC : 0.00046116860184273935
Epoch 367, 25% 	 Loss : 1.6096e-02 	 Res : 3.2339e-03 	 Jac : 1.2832e-02 	 Enc : 7.8272e-06 	 AEnc : 2.2377e-05 	 MSE : 1.2347e-01
Epoch 367, 50% 	 Loss : 1.6141e-02 	 Res : 3.2617e-03 	 Jac : 1.2850e-02 	 Enc : 7.8297e-06 	 AEnc : 2.1334e-05 	 MSE : 1.2282e-01
Epoch 367, 75% 	 Loss : 1.6106e-02 	 Res : 3.2656e-03 	 Jac : 1.2809e-02 	 Enc : 8.2278e-06 	 AEnc : 2.2710e-05 	 MSE : 1.2218e-01
Training Epoch 367 : 	 Train : 1.61762e-02 	 Res : 3.31215e-03 	 Jac : 1.28339e-02 	 Enc : 7.97031e-06 	 AE : 2.22205e-05 	 MSE : 1.47084e-01
Validation Epoch 367 : 	 Train : 1.93742e-02 	 Res : 6.51942e-03 	 Jac : 1.28274e-02 	 Enc : 7.90521e-06 	 AE : 1.94808e-05 	 MSE : 1.34472e+00
Training Epoch 367 finished, took current epoch 366.18s, cumulative time 136823.51s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
Epoch 368, 25% 	 Loss : 1.6232e-02 	 Res : 3.4058e-03 	 Jac : 1.2792e-02 	 Enc : 7.5695e-06 	 AEnc : 2.5995e-05 	 MSE : 1.7047e-01
Epoch 368, 50% 	 Loss : 1.5968e-02 	 Res : 3.1640e-03 	 Jac : 1.2763e-02 	 Enc : 7.7404e-06 	 AEnc : 3.3416e-05 	 MSE : 9.1615e-02
Epoch 368, 75% 	 Loss : 1.5936e-02 	 Res : 3.1267e-03 	 Jac : 1.2775e-02 	 Enc : 7.7252e-06 	 AEnc : 2.5947e-05 	 MSE : 8.2574e-02
Training Epoch 368 : 	 Train : 1.60244e-02 	 Res : 3.21679e-03 	 Jac : 1.27729e-02 	 Enc : 7.63393e-06 	 AE : 2.69943e-05 	 MSE : 1.08958e-01
Validation Epoch 368 : 	 Train : 1.58880e-02 	 Res : 3.07808e-03 	 Jac : 1.27792e-02 	 Enc : 7.45842e-06 	 AE : 2.32567e-05 	 MSE : 4.67048e-02
Training Epoch 368 finished, took current epoch 365.34s, cumulative time 137188.81s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
MODEL SAVED
Epoch 369, 25% 	 Loss : 1.6077e-02 	 Res : 3.1916e-03 	 Jac : 1.2856e-02 	 Enc : 7.7157e-06 	 AEnc : 2.1709e-05 	 MSE : 8.1930e-02
Epoch 369, 50% 	 Loss : 1.7931e-02 	 Res : 3.9811e-03 	 Jac : 1.2799e-02 	 Enc : 8.3806e-06 	 AEnc : 1.1424e-03 	 MSE : 3.5768e-01
Epoch 369, 75% 	 Loss : 1.8181e-02 	 Res : 3.4039e-03 	 Jac : 1.2745e-02 	 Enc : 8.0472e-06 	 AEnc : 2.0243e-03 	 MSE : 5.5081e-02
Training Epoch 369 : 	 Train : 1.77152e-02 	 Res : 3.53150e-03 	 Jac : 1.28136e-02 	 Enc : 8.07478e-06 	 AE : 1.36203e-03 	 MSE : 1.41817e-01
Validation Epoch 369 : 	 Train : 1.63153e-02 	 Res : 3.13075e-03 	 Jac : 1.28254e-02 	 Enc : 7.82550e-06 	 AE : 3.51264e-04 	 MSE : 4.82725e-02
Training Epoch 369 finished, took current epoch 368.61s, cumulative time 137557.38s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
Epoch 370, 25% 	 Loss : 1.6098e-02 	 Res : 3.0682e-03 	 Jac : 1.2762e-02 	 Enc : 7.7514e-06 	 AEnc : 2.6017e-04 	 MSE : 4.2771e-02
Epoch 370, 50% 	 Loss : 1.5963e-02 	 Res : 3.1057e-03 	 Jac : 1.2819e-02 	 Enc : 7.2368e-06 	 AEnc : 3.0758e-05 	 MSE : 3.6163e-02
Epoch 370, 75% 	 Loss : 1.6026e-02 	 Res : 3.1759e-03 	 Jac : 1.2820e-02 	 Enc : 7.3593e-06 	 AEnc : 2.2269e-05 	 MSE : 8.7333e-02
Training Epoch 370 : 	 Train : 1.60071e-02 	 Res : 3.11381e-03 	 Jac : 1.27992e-02 	 Enc : 7.43335e-06 	 AE : 8.66157e-05 	 MSE : 6.56122e-02
Validation Epoch 370 : 	 Train : 1.60040e-02 	 Res : 3.15489e-03 	 Jac : 1.28185e-02 	 Enc : 7.69855e-06 	 AE : 2.29414e-05 	 MSE : 6.98065e-02
Training Epoch 370 finished, took current epoch 363.51s, cumulative time 137920.87s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
Epoch 371, 25% 	 Loss : 1.5931e-02 	 Res : 3.1586e-03 	 Jac : 1.2744e-02 	 Enc : 7.3244e-06 	 AEnc : 2.1465e-05 	 MSE : 8.6847e-02
Epoch 371, 50% 	 Loss : 1.5855e-02 	 Res : 3.1408e-03 	 Jac : 1.2685e-02 	 Enc : 7.2822e-06 	 AEnc : 2.2172e-05 	 MSE : 8.4224e-02
Epoch 371, 75% 	 Loss : 1.6017e-02 	 Res : 3.1178e-03 	 Jac : 1.2871e-02 	 Enc : 7.7067e-06 	 AEnc : 2.0649e-05 	 MSE : 8.3693e-02
Training Epoch 371 : 	 Train : 1.59498e-02 	 Res : 3.15059e-03 	 Jac : 1.27706e-02 	 Enc : 7.41685e-06 	 AE : 2.12208e-05 	 MSE : 8.69599e-02
Validation Epoch 371 : 	 Train : 1.58935e-02 	 Res : 3.04950e-03 	 Jac : 1.28172e-02 	 Enc : 6.95771e-06 	 AE : 1.98676e-05 	 MSE : 3.72220e-02
Training Epoch 371 finished, took current epoch 364.78s, cumulative time 138285.58s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
MODEL SAVED
Epoch 372, 25% 	 Loss : 1.6048e-02 	 Res : 3.1924e-03 	 Jac : 1.2827e-02 	 Enc : 7.1292e-06 	 AEnc : 2.1427e-05 	 MSE : 8.5856e-02
Epoch 372, 50% 	 Loss : 1.5921e-02 	 Res : 3.0970e-03 	 Jac : 1.2796e-02 	 Enc : 7.1058e-06 	 AEnc : 2.0903e-05 	 MSE : 8.2063e-02
Epoch 372, 75% 	 Loss : 1.6536e-02 	 Res : 3.5674e-03 	 Jac : 1.2936e-02 	 Enc : 7.2681e-06 	 AEnc : 2.5373e-05 	 MSE : 2.0002e-01
Training Epoch 372 : 	 Train : 1.61133e-02 	 Res : 3.24454e-03 	 Jac : 1.28393e-02 	 Enc : 7.27621e-06 	 AE : 2.22367e-05 	 MSE : 1.14567e-01
Validation Epoch 372 : 	 Train : 1.58969e-02 	 Res : 3.10129e-03 	 Jac : 1.27686e-02 	 Enc : 7.42585e-06 	 AE : 1.95730e-05 	 MSE : 6.02296e-02
Training Epoch 372 finished, took current epoch 367.90s, cumulative time 138653.42s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
Epoch 373, 25% 	 Loss : 1.6263e-02 	 Res : 3.4707e-03 	 Jac : 1.2762e-02 	 Enc : 7.5663e-06 	 AEnc : 2.1988e-05 	 MSE : 1.8938e-01
Epoch 373, 50% 	 Loss : 1.5965e-02 	 Res : 3.1294e-03 	 Jac : 1.2806e-02 	 Enc : 7.3379e-06 	 AEnc : 2.2091e-05 	 MSE : 8.4847e-02
Epoch 373, 75% 	 Loss : 1.6608e-02 	 Res : 3.8408e-03 	 Jac : 1.2737e-02 	 Enc : 7.3383e-06 	 AEnc : 2.3207e-05 	 MSE : 3.5801e-01
Training Epoch 373 : 	 Train : 1.64103e-02 	 Res : 3.61647e-03 	 Jac : 1.27640e-02 	 Enc : 7.61893e-06 	 AE : 2.21625e-05 	 MSE : 2.63808e-01
Validation Epoch 373 : 	 Train : 1.77969e-02 	 Res : 4.99480e-03 	 Jac : 1.27728e-02 	 Enc : 8.29822e-06 	 AE : 2.10149e-05 	 MSE : 7.97225e-01
Training Epoch 373 finished, took current epoch 365.65s, cumulative time 139019.05s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
Epoch 374, 25% 	 Loss : 1.6241e-02 	 Res : 3.4196e-03 	 Jac : 1.2775e-02 	 Enc : 7.9736e-06 	 AEnc : 3.8485e-05 	 MSE : 1.9069e-01
Epoch 374, 50% 	 Loss : 1.6455e-02 	 Res : 3.2539e-03 	 Jac : 1.2749e-02 	 Enc : 7.6839e-06 	 AEnc : 4.4438e-04 	 MSE : 9.7338e-02
Epoch 374, 75% 	 Loss : 1.9378e-02 	 Res : 3.5630e-03 	 Jac : 1.2779e-02 	 Enc : 8.0379e-06 	 AEnc : 3.0282e-03 	 MSE : 4.4508e-02
Training Epoch 374 : 	 Train : 1.71662e-02 	 Res : 3.35859e-03 	 Jac : 1.27711e-02 	 Enc : 7.74920e-06 	 AE : 1.02874e-03 	 MSE : 1.01924e-01
Validation Epoch 374 : 	 Train : 1.65107e-02 	 Res : 3.55181e-03 	 Jac : 1.28150e-02 	 Enc : 6.95668e-06 	 AE : 1.36937e-04 	 MSE : 2.24461e-01
Training Epoch 374 finished, took current epoch 369.53s, cumulative time 139388.52s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
Epoch 375, 25% 	 Loss : 1.5991e-02 	 Res : 3.1230e-03 	 Jac : 1.2803e-02 	 Enc : 6.7895e-06 	 AEnc : 5.8591e-05 	 MSE : 8.7807e-02
Epoch 375, 50% 	 Loss : 1.5943e-02 	 Res : 3.1751e-03 	 Jac : 1.2737e-02 	 Enc : 6.9720e-06 	 AEnc : 2.4232e-05 	 MSE : 8.5030e-02
Epoch 375, 75% 	 Loss : 1.6107e-02 	 Res : 3.2516e-03 	 Jac : 1.2826e-02 	 Enc : 7.0574e-06 	 AEnc : 2.1520e-05 	 MSE : 1.3654e-01
Training Epoch 375 : 	 Train : 1.61479e-02 	 Res : 3.29716e-03 	 Jac : 1.28082e-02 	 Enc : 6.97736e-06 	 AE : 3.56243e-05 	 MSE : 1.41214e-01
Validation Epoch 375 : 	 Train : 1.60470e-02 	 Res : 3.16779e-03 	 Jac : 1.27851e-02 	 Enc : 6.90722e-06 	 AE : 8.72148e-05 	 MSE : 7.18882e-02
Training Epoch 375 finished, took current epoch 362.20s, cumulative time 139750.70s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
Epoch 376, 25% 	 Loss : 1.5847e-02 	 Res : 3.0622e-03 	 Jac : 1.2737e-02 	 Enc : 7.0086e-06 	 AEnc : 4.1452e-05 	 MSE : 4.4772e-02
Epoch 376, 50% 	 Loss : 1.5979e-02 	 Res : 3.0802e-03 	 Jac : 1.2746e-02 	 Enc : 6.8644e-06 	 AEnc : 1.4631e-04 	 MSE : 4.2123e-02
Epoch 376, 75% 	 Loss : 1.5870e-02 	 Res : 3.0733e-03 	 Jac : 1.2746e-02 	 Enc : 7.0352e-06 	 AEnc : 4.4068e-05 	 MSE : 5.3396e-02
Training Epoch 376 : 	 Train : 1.59993e-02 	 Res : 3.09393e-03 	 Jac : 1.27541e-02 	 Enc : 6.92598e-06 	 AE : 1.44310e-04 	 MSE : 5.48639e-02
Validation Epoch 376 : 	 Train : 1.59794e-02 	 Res : 3.14331e-03 	 Jac : 1.27205e-02 	 Enc : 6.67571e-06 	 AE : 1.08871e-04 	 MSE : 7.50428e-02
Training Epoch 376 finished, took current epoch 368.19s, cumulative time 140118.87s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
Epoch 377, 25% 	 Loss : 1.6013e-02 	 Res : 3.1609e-03 	 Jac : 1.2697e-02 	 Enc : 6.9702e-06 	 AEnc : 1.4798e-04 	 MSE : 8.2299e-02
Epoch 377, 50% 	 Loss : 1.6050e-02 	 Res : 3.0960e-03 	 Jac : 1.2849e-02 	 Enc : 7.3802e-06 	 AEnc : 9.7244e-05 	 MSE : 8.9522e-02
Epoch 377, 75% 	 Loss : 1.6042e-02 	 Res : 3.1750e-03 	 Jac : 1.2825e-02 	 Enc : 6.9741e-06 	 AEnc : 3.5276e-05 	 MSE : 9.7305e-02
Training Epoch 377 : 	 Train : 1.60489e-02 	 Res : 3.16874e-03 	 Jac : 1.27966e-02 	 Enc : 7.06048e-06 	 AE : 7.65425e-05 	 MSE : 9.13849e-02
Validation Epoch 377 : 	 Train : 1.58516e-02 	 Res : 3.05979e-03 	 Jac : 1.27629e-02 	 Enc : 6.98549e-06 	 AE : 2.19486e-05 	 MSE : 4.01563e-02
Training Epoch 377 finished, took current epoch 367.18s, cumulative time 140486.00s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
Epoch 378, 25% 	 Loss : 1.5971e-02 	 Res : 3.1299e-03 	 Jac : 1.2813e-02 	 Enc : 6.9779e-06 	 AEnc : 2.0751e-05 	 MSE : 8.2365e-02
Epoch 378, 50% 	 Loss : 1.5963e-02 	 Res : 3.0641e-03 	 Jac : 1.2869e-02 	 Enc : 7.1866e-06 	 AEnc : 2.2304e-05 	 MSE : 6.7705e-02
Epoch 378, 75% 	 Loss : 1.6074e-02 	 Res : 3.2009e-03 	 Jac : 1.2813e-02 	 Enc : 6.9210e-06 	 AEnc : 5.2468e-05 	 MSE : 8.0279e-02
Training Epoch 378 : 	 Train : 1.59897e-02 	 Res : 3.12050e-03 	 Jac : 1.28187e-02 	 Enc : 6.98953e-06 	 AE : 4.35620e-05 	 MSE : 7.29297e-02
Validation Epoch 378 : 	 Train : 1.60762e-02 	 Res : 3.22641e-03 	 Jac : 1.28177e-02 	 Enc : 6.82495e-06 	 AE : 2.52934e-05 	 MSE : 1.01321e-01
Training Epoch 378 finished, took current epoch 366.50s, cumulative time 140852.47s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
Epoch 379, 25% 	 Loss : 1.5974e-02 	 Res : 3.0719e-03 	 Jac : 1.2867e-02 	 Enc : 7.0228e-06 	 AEnc : 2.7476e-05 	 MSE : 4.4249e-02
Epoch 379, 50% 	 Loss : 1.5934e-02 	 Res : 3.0782e-03 	 Jac : 1.2828e-02 	 Enc : 7.0653e-06 	 AEnc : 2.1159e-05 	 MSE : 4.1962e-02
Epoch 379, 75% 	 Loss : 1.5850e-02 	 Res : 2.9820e-03 	 Jac : 1.2840e-02 	 Enc : 6.8184e-06 	 AEnc : 2.1506e-05 	 MSE : 4.6830e-02
Training Epoch 379 : 	 Train : 1.59145e-02 	 Res : 3.02865e-03 	 Jac : 1.28551e-02 	 Enc : 6.89380e-06 	 AE : 2.38550e-05 	 MSE : 4.07362e-02
Validation Epoch 379 : 	 Train : 1.59187e-02 	 Res : 3.04323e-03 	 Jac : 1.28380e-02 	 Enc : 6.71101e-06 	 AE : 3.08068e-05 	 MSE : 3.99859e-02
Training Epoch 379 finished, took current epoch 365.44s, cumulative time 141217.86s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
MODEL SAVED
Epoch 380, 25% 	 Loss : 1.6223e-02 	 Res : 3.3384e-03 	 Jac : 1.2802e-02 	 Enc : 6.7996e-06 	 AEnc : 7.6654e-05 	 MSE : 1.2794e-01
Epoch 380, 50% 	 Loss : 1.5962e-02 	 Res : 3.1222e-03 	 Jac : 1.2785e-02 	 Enc : 7.0006e-06 	 AEnc : 4.7251e-05 	 MSE : 8.4827e-02
Epoch 380, 75% 	 Loss : 1.5974e-02 	 Res : 3.1653e-03 	 Jac : 1.2780e-02 	 Enc : 6.9976e-06 	 AEnc : 2.1989e-05 	 MSE : 9.6721e-02
Training Epoch 380 : 	 Train : 1.60614e-02 	 Res : 3.21518e-03 	 Jac : 1.27972e-02 	 Enc : 6.90559e-06 	 AE : 4.22000e-05 	 MSE : 1.05537e-01
Validation Epoch 380 : 	 Train : 1.58940e-02 	 Res : 3.04873e-03 	 Jac : 1.28171e-02 	 Enc : 6.94666e-06 	 AE : 2.11578e-05 	 MSE : 3.45014e-02
Training Epoch 380 finished, took current epoch 368.59s, cumulative time 141586.43s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
Epoch 381, 25% 	 Loss : 1.5927e-02 	 Res : 3.0802e-03 	 Jac : 1.2819e-02 	 Enc : 6.7700e-06 	 AEnc : 2.1748e-05 	 MSE : 8.6072e-02
Epoch 381, 50% 	 Loss : 1.6089e-02 	 Res : 3.2144e-03 	 Jac : 1.2846e-02 	 Enc : 6.9930e-06 	 AEnc : 2.0832e-05 	 MSE : 8.8966e-02
Epoch 381, 75% 	 Loss : 1.5882e-02 	 Res : 3.1398e-03 	 Jac : 1.2714e-02 	 Enc : 7.2225e-06 	 AEnc : 2.1002e-05 	 MSE : 9.6964e-02
Training Epoch 381 : 	 Train : 1.59665e-02 	 Res : 3.15106e-03 	 Jac : 1.27873e-02 	 Enc : 7.01482e-06 	 AE : 2.11585e-05 	 MSE : 8.99244e-02
Validation Epoch 381 : 	 Train : 1.58137e-02 	 Res : 3.04177e-03 	 Jac : 1.27423e-02 	 Enc : 6.96451e-06 	 AE : 2.26795e-05 	 MSE : 3.77190e-02
Training Epoch 381 finished, took current epoch 367.57s, cumulative time 141953.95s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
MODEL SAVED
Epoch 382, 25% 	 Loss : 1.5995e-02 	 Res : 3.1390e-03 	 Jac : 1.2829e-02 	 Enc : 6.9304e-06 	 AEnc : 2.0444e-05 	 MSE : 8.3872e-02
Epoch 382, 50% 	 Loss : 1.5969e-02 	 Res : 3.1635e-03 	 Jac : 1.2778e-02 	 Enc : 6.9854e-06 	 AEnc : 2.0544e-05 	 MSE : 9.1772e-02
Epoch 382, 75% 	 Loss : 1.5966e-02 	 Res : 3.1153e-03 	 Jac : 1.2823e-02 	 Enc : 6.8504e-06 	 AEnc : 2.1320e-05 	 MSE : 8.3563e-02
Training Epoch 382 : 	 Train : 1.59475e-02 	 Res : 3.13484e-03 	 Jac : 1.27848e-02 	 Enc : 6.94570e-06 	 AE : 2.08803e-05 	 MSE : 8.60636e-02
Validation Epoch 382 : 	 Train : 1.59441e-02 	 Res : 3.21090e-03 	 Jac : 1.27066e-02 	 Enc : 6.84366e-06 	 AE : 1.97032e-05 	 MSE : 1.03201e-01
Training Epoch 382 finished, took current epoch 366.49s, cumulative time 142320.39s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
Epoch 383, 25% 	 Loss : 1.5914e-02 	 Res : 3.1451e-03 	 Jac : 1.2740e-02 	 Enc : 6.8259e-06 	 AEnc : 2.1280e-05 	 MSE : 8.6555e-02
Epoch 383, 50% 	 Loss : 1.6013e-02 	 Res : 3.2112e-03 	 Jac : 1.2774e-02 	 Enc : 6.9513e-06 	 AEnc : 2.1238e-05 	 MSE : 8.7595e-02
Epoch 383, 75% 	 Loss : 1.5975e-02 	 Res : 3.1394e-03 	 Jac : 1.2808e-02 	 Enc : 7.0209e-06 	 AEnc : 2.0290e-05 	 MSE : 8.9183e-02
Training Epoch 383 : 	 Train : 1.62572e-02 	 Res : 3.43041e-03 	 Jac : 1.27981e-02 	 Enc : 7.04191e-06 	 AE : 2.16022e-05 	 MSE : 1.99122e-01
Validation Epoch 383 : 	 Train : 1.62688e-02 	 Res : 3.47073e-03 	 Jac : 1.27338e-02 	 Enc : 8.12568e-06 	 AE : 5.61124e-05 	 MSE : 1.63224e-01
Training Epoch 383 finished, took current epoch 370.76s, cumulative time 142691.07s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
Epoch 384, 25% 	 Loss : 1.7042e-02 	 Res : 4.1908e-03 	 Jac : 1.2817e-02 	 Enc : 8.4925e-06 	 AEnc : 2.5651e-05 	 MSE : 4.7493e-01
Epoch 384, 50% 	 Loss : 1.6872e-02 	 Res : 4.0833e-03 	 Jac : 1.2758e-02 	 Enc : 8.6905e-06 	 AEnc : 2.2293e-05 	 MSE : 4.5920e-01
Epoch 384, 75% 	 Loss : 1.6894e-02 	 Res : 4.0713e-03 	 Jac : 1.2793e-02 	 Enc : 8.8947e-06 	 AEnc : 2.1049e-05 	 MSE : 4.6184e-01
Training Epoch 384 : 	 Train : 1.69362e-02 	 Res : 4.10568e-03 	 Jac : 1.27993e-02 	 Enc : 8.76419e-06 	 AE : 2.24434e-05 	 MSE : 4.61861e-01
Validation Epoch 384 : 	 Train : 1.58636e-02 	 Res : 3.04080e-03 	 Jac : 1.27939e-02 	 Enc : 8.93370e-06 	 AE : 1.99723e-05 	 MSE : 3.72061e-02
Training Epoch 384 finished, took current epoch 368.00s, cumulative time 143058.96s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
MODEL SAVED
Epoch 385, 25% 	 Loss : 1.6806e-02 	 Res : 4.0888e-03 	 Jac : 1.2689e-02 	 Enc : 9.0201e-06 	 AEnc : 1.9990e-05 	 MSE : 4.4311e-01
Epoch 385, 50% 	 Loss : 1.6975e-02 	 Res : 4.1469e-03 	 Jac : 1.2798e-02 	 Enc : 8.6385e-06 	 AEnc : 2.2022e-05 	 MSE : 4.6207e-01
Epoch 385, 75% 	 Loss : 1.6896e-02 	 Res : 4.0427e-03 	 Jac : 1.2823e-02 	 Enc : 9.1548e-06 	 AEnc : 2.0703e-05 	 MSE : 4.5184e-01
Training Epoch 385 : 	 Train : 1.69056e-02 	 Res : 4.09613e-03 	 Jac : 1.27794e-02 	 Enc : 8.94408e-06 	 AE : 2.11058e-05 	 MSE : 4.57948e-01
Validation Epoch 385 : 	 Train : 1.59974e-02 	 Res : 3.12052e-03 	 Jac : 1.28453e-02 	 Enc : 8.96782e-06 	 AE : 2.25685e-05 	 MSE : 6.94866e-02
Training Epoch 385 finished, took current epoch 367.43s, cumulative time 143426.34s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
Epoch 386, 25% 	 Loss : 1.6788e-02 	 Res : 3.9704e-03 	 Jac : 1.2788e-02 	 Enc : 8.9237e-06 	 AEnc : 2.0752e-05 	 MSE : 4.3818e-01
Epoch 386, 50% 	 Loss : 1.6828e-02 	 Res : 4.1364e-03 	 Jac : 1.2662e-02 	 Enc : 9.2351e-06 	 AEnc : 2.1077e-05 	 MSE : 4.5918e-01
Epoch 386, 75% 	 Loss : 1.6769e-02 	 Res : 4.0689e-03 	 Jac : 1.2670e-02 	 Enc : 9.2349e-06 	 AEnc : 2.1326e-05 	 MSE : 4.5287e-01
Training Epoch 386 : 	 Train : 1.68283e-02 	 Res : 4.08144e-03 	 Jac : 1.27164e-02 	 Enc : 9.15408e-06 	 AE : 2.12527e-05 	 MSE : 4.54368e-01
Validation Epoch 386 : 	 Train : 1.58821e-02 	 Res : 3.11704e-03 	 Jac : 1.27362e-02 	 Enc : 9.27669e-06 	 AE : 1.95954e-05 	 MSE : 7.35647e-02
Training Epoch 386 finished, took current epoch 367.70s, cumulative time 143793.99s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
Epoch 387, 25% 	 Loss : 1.6834e-02 	 Res : 4.0630e-03 	 Jac : 1.2740e-02 	 Enc : 9.4002e-06 	 AEnc : 2.1668e-05 	 MSE : 4.5099e-01
Epoch 387, 50% 	 Loss : 1.7027e-02 	 Res : 4.1321e-03 	 Jac : 1.2865e-02 	 Enc : 9.3125e-06 	 AEnc : 2.1419e-05 	 MSE : 4.6480e-01
Epoch 387, 75% 	 Loss : 1.6877e-02 	 Res : 4.0627e-03 	 Jac : 1.2784e-02 	 Enc : 9.1923e-06 	 AEnc : 2.0897e-05 	 MSE : 4.6793e-01
Training Epoch 387 : 	 Train : 1.69389e-02 	 Res : 4.10760e-03 	 Jac : 1.28005e-02 	 Enc : 9.18594e-06 	 AE : 2.15495e-05 	 MSE : 4.65861e-01
Validation Epoch 387 : 	 Train : 1.59916e-02 	 Res : 3.17772e-03 	 Jac : 1.27830e-02 	 Enc : 8.46143e-06 	 AE : 2.24277e-05 	 MSE : 9.11863e-02
Training Epoch 387 finished, took current epoch 365.79s, cumulative time 144159.76s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
Epoch 388, 25% 	 Loss : 1.6920e-02 	 Res : 4.0506e-03 	 Jac : 1.2840e-02 	 Enc : 8.5842e-06 	 AEnc : 2.0591e-05 	 MSE : 4.5127e-01
Epoch 388, 50% 	 Loss : 1.8880e-02 	 Res : 6.0316e-03 	 Jac : 1.2813e-02 	 Enc : 9.5097e-06 	 AEnc : 2.5473e-05 	 MSE : 1.2001e+00
Epoch 388, 75% 	 Loss : 1.7502e-02 	 Res : 4.1904e-03 	 Jac : 1.2838e-02 	 Enc : 1.1908e-05 	 AEnc : 4.6205e-04 	 MSE : 4.6103e-01
Training Epoch 388 : 	 Train : 1.75905e-02 	 Res : 4.40650e-03 	 Jac : 1.28261e-02 	 Enc : 9.67406e-06 	 AE : 3.48236e-04 	 MSE : 5.55153e-01
Validation Epoch 388 : 	 Train : 1.59934e-02 	 Res : 3.15727e-03 	 Jac : 1.28048e-02 	 Enc : 7.94299e-06 	 AE : 2.33899e-05 	 MSE : 8.19787e-02
Training Epoch 388 finished, took current epoch 372.01s, cumulative time 144531.72s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
Epoch 389, 25% 	 Loss : 1.6803e-02 	 Res : 4.0099e-03 	 Jac : 1.2759e-02 	 Enc : 8.1065e-06 	 AEnc : 2.5658e-05 	 MSE : 4.0102e-01
Epoch 389, 50% 	 Loss : 1.6841e-02 	 Res : 4.1695e-03 	 Jac : 1.2642e-02 	 Enc : 9.1910e-06 	 AEnc : 2.0946e-05 	 MSE : 4.5932e-01
Epoch 389, 75% 	 Loss : 1.6927e-02 	 Res : 4.0902e-03 	 Jac : 1.2807e-02 	 Enc : 9.2058e-06 	 AEnc : 2.1113e-05 	 MSE : 4.5927e-01
Training Epoch 389 : 	 Train : 1.68449e-02 	 Res : 4.08991e-03 	 Jac : 1.27236e-02 	 Enc : 8.85780e-06 	 AE : 2.25393e-05 	 MSE : 4.47842e-01
Validation Epoch 389 : 	 Train : 1.62846e-02 	 Res : 3.51253e-03 	 Jac : 1.27453e-02 	 Enc : 8.80769e-06 	 AE : 1.80093e-05 	 MSE : 2.27266e-01
Training Epoch 389 finished, took current epoch 369.98s, cumulative time 144901.68s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
Epoch 390, 25% 	 Loss : 1.6865e-02 	 Res : 4.0513e-03 	 Jac : 1.2784e-02 	 Enc : 9.0077e-06 	 AEnc : 2.0186e-05 	 MSE : 4.3936e-01
Epoch 390, 50% 	 Loss : 1.6895e-02 	 Res : 4.0873e-03 	 Jac : 1.2777e-02 	 Enc : 9.1338e-06 	 AEnc : 2.0749e-05 	 MSE : 4.6513e-01
Epoch 390, 75% 	 Loss : 1.6927e-02 	 Res : 4.1281e-03 	 Jac : 1.2767e-02 	 Enc : 9.5803e-06 	 AEnc : 2.1666e-05 	 MSE : 4.7257e-01
Training Epoch 390 : 	 Train : 1.69118e-02 	 Res : 4.09442e-03 	 Jac : 1.27871e-02 	 Enc : 9.26203e-06 	 AE : 2.10190e-05 	 MSE : 4.59480e-01
Validation Epoch 390 : 	 Train : 1.66108e-02 	 Res : 3.72702e-03 	 Jac : 1.28539e-02 	 Enc : 9.05206e-06 	 AE : 2.08004e-05 	 MSE : 3.05770e-01
Training Epoch 390 finished, took current epoch 367.14s, cumulative time 145268.81s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
Epoch 391, 25% 	 Loss : 1.6959e-02 	 Res : 4.1158e-03 	 Jac : 1.2811e-02 	 Enc : 9.3760e-06 	 AEnc : 2.2283e-05 	 MSE : 4.4940e-01
Epoch 391, 50% 	 Loss : 1.6910e-02 	 Res : 4.1264e-03 	 Jac : 1.2753e-02 	 Enc : 9.6324e-06 	 AEnc : 2.1757e-05 	 MSE : 4.6870e-01
Epoch 391, 75% 	 Loss : 1.6916e-02 	 Res : 4.1379e-03 	 Jac : 1.2748e-02 	 Enc : 9.1414e-06 	 AEnc : 2.0833e-05 	 MSE : 4.6545e-01
Training Epoch 391 : 	 Train : 1.69361e-02 	 Res : 4.14013e-03 	 Jac : 1.27652e-02 	 Enc : 9.38103e-06 	 AE : 2.13956e-05 	 MSE : 4.70470e-01
Validation Epoch 391 : 	 Train : 1.68142e-02 	 Res : 4.10477e-03 	 Jac : 1.26797e-02 	 Enc : 9.17110e-06 	 AE : 2.05388e-05 	 MSE : 4.35366e-01
Training Epoch 391 finished, took current epoch 368.95s, cumulative time 145637.70s
Current Learning rate DEQ : 7.378697629483831e-05
Current Learning rate AUTOENC : 0.0003689348814741915
Epoch 392, 25% 	 Loss : 1.6225e-02 	 Res : 3.4823e-03 	 Jac : 1.2701e-02 	 Enc : 8.7578e-06 	 AEnc : 3.2724e-05 	 MSE : 2.1987e-01
Epoch 392, 50% 	 Loss : 1.6255e-02 	 Res : 3.4745e-03 	 Jac : 1.2750e-02 	 Enc : 7.9500e-06 	 AEnc : 2.1808e-05 	 MSE : 2.1856e-01
Epoch 392, 75% 	 Loss : 1.6272e-02 	 Res : 3.5002e-03 	 Jac : 1.2742e-02 	 Enc : 8.0853e-06 	 AEnc : 2.1270e-05 	 MSE : 2.1834e-01
Training Epoch 392 : 	 Train : 1.62488e-02 	 Res : 3.46936e-03 	 Jac : 1.27461e-02 	 Enc : 8.26025e-06 	 AE : 2.50474e-05 	 MSE : 2.16801e-01
Validation Epoch 392 : 	 Train : 1.68582e-02 	 Res : 4.07109e-03 	 Jac : 1.27597e-02 	 Enc : 8.03160e-06 	 AE : 1.93731e-05 	 MSE : 4.45989e-01
Training Epoch 392 finished, took current epoch 366.71s, cumulative time 146004.38s
Current Learning rate DEQ : 5.902958103587065e-05
Current Learning rate AUTOENC : 0.00029514790517935324
Epoch 393, 25% 	 Loss : 1.7285e-02 	 Res : 3.4721e-03 	 Jac : 1.2706e-02 	 Enc : 8.0883e-06 	 AEnc : 1.0981e-03 	 MSE : 1.3579e-01
Epoch 393, 50% 	 Loss : 1.7675e-02 	 Res : 3.5302e-03 	 Jac : 1.2688e-02 	 Enc : 7.9405e-06 	 AEnc : 1.4494e-03 	 MSE : 1.4872e-01
Epoch 393, 75% 	 Loss : 1.6246e-02 	 Res : 3.3426e-03 	 Jac : 1.2742e-02 	 Enc : 7.0840e-06 	 AEnc : 1.5440e-04 	 MSE : 1.5048e-01
Training Epoch 393 : 	 Train : 1.68042e-02 	 Res : 3.39823e-03 	 Jac : 1.27081e-02 	 Enc : 7.56707e-06 	 AE : 6.90373e-04 	 MSE : 1.43493e-01
Validation Epoch 393 : 	 Train : 1.59552e-02 	 Res : 3.16348e-03 	 Jac : 1.27652e-02 	 Enc : 7.11210e-06 	 AE : 1.93736e-05 	 MSE : 8.44489e-02
Training Epoch 393 finished, took current epoch 367.03s, cumulative time 146371.37s
Current Learning rate DEQ : 5.902958103587065e-05
Current Learning rate AUTOENC : 0.00029514790517935324
Epoch 394, 25% 	 Loss : 1.6090e-02 	 Res : 3.2620e-03 	 Jac : 1.2800e-02 	 Enc : 7.1905e-06 	 AEnc : 2.1200e-05 	 MSE : 1.4722e-01
Epoch 394, 50% 	 Loss : 1.6071e-02 	 Res : 3.3594e-03 	 Jac : 1.2684e-02 	 Enc : 7.2239e-06 	 AEnc : 2.0239e-05 	 MSE : 1.4910e-01
Epoch 394, 75% 	 Loss : 1.6049e-02 	 Res : 3.3188e-03 	 Jac : 1.2702e-02 	 Enc : 7.0715e-06 	 AEnc : 2.1208e-05 	 MSE : 1.5323e-01
Training Epoch 394 : 	 Train : 1.61005e-02 	 Res : 3.32024e-03 	 Jac : 1.27521e-02 	 Enc : 7.17295e-06 	 AE : 2.09357e-05 	 MSE : 1.58085e-01
Validation Epoch 394 : 	 Train : 1.57331e-02 	 Res : 2.97560e-03 	 Jac : 1.27275e-02 	 Enc : 7.21357e-06 	 AE : 2.27181e-05 	 MSE : 1.66099e-02
Training Epoch 394 finished, took current epoch 369.65s, cumulative time 146740.92s
Current Learning rate DEQ : 5.902958103587065e-05
Current Learning rate AUTOENC : 0.00029514790517935324
MODEL SAVED
Epoch 395, 25% 	 Loss : 1.6089e-02 	 Res : 3.2529e-03 	 Jac : 1.2732e-02 	 Enc : 6.6121e-06 	 AEnc : 9.7483e-05 	 MSE : 1.2527e-01
Epoch 395, 50% 	 Loss : 1.6038e-02 	 Res : 3.0843e-03 	 Jac : 1.2740e-02 	 Enc : 6.7481e-06 	 AEnc : 2.0720e-04 	 MSE : 7.4253e-02
Epoch 395, 75% 	 Loss : 1.6857e-02 	 Res : 3.2521e-03 	 Jac : 1.2797e-02 	 Enc : 6.9818e-06 	 AEnc : 8.0115e-04 	 MSE : 4.6296e-02
Training Epoch 395 : 	 Train : 1.64923e-02 	 Res : 3.21822e-03 	 Jac : 1.27441e-02 	 Enc : 6.75572e-06 	 AE : 5.23266e-04 	 MSE : 8.32867e-02
Validation Epoch 395 : 	 Train : 1.67400e-02 	 Res : 3.20884e-03 	 Jac : 1.28390e-02 	 Enc : 6.81978e-06 	 AE : 6.85314e-04 	 MSE : 7.61093e-02
Training Epoch 395 finished, took current epoch 364.97s, cumulative time 147105.88s
Current Learning rate DEQ : 5.902958103587065e-05
Current Learning rate AUTOENC : 0.00029514790517935324
Epoch 396, 25% 	 Loss : 1.5980e-02 	 Res : 3.0916e-03 	 Jac : 1.2814e-02 	 Enc : 6.5695e-06 	 AEnc : 6.7671e-05 	 MSE : 5.7645e-02
Epoch 396, 50% 	 Loss : 1.5906e-02 	 Res : 3.1653e-03 	 Jac : 1.2691e-02 	 Enc : 6.6534e-06 	 AEnc : 4.2560e-05 	 MSE : 1.2395e-01
Epoch 396, 75% 	 Loss : 1.5806e-02 	 Res : 3.0197e-03 	 Jac : 1.2699e-02 	 Enc : 6.5462e-06 	 AEnc : 8.1165e-05 	 MSE : 3.5886e-02
Training Epoch 396 : 	 Train : 1.58694e-02 	 Res : 3.08711e-03 	 Jac : 1.27188e-02 	 Enc : 6.56533e-06 	 AE : 5.69910e-05 	 MSE : 6.32589e-02
Validation Epoch 396 : 	 Train : 1.58074e-02 	 Res : 3.07625e-03 	 Jac : 1.26973e-02 	 Enc : 6.41742e-06 	 AE : 2.73744e-05 	 MSE : 4.93283e-02
Training Epoch 396 finished, took current epoch 366.56s, cumulative time 147472.41s
Current Learning rate DEQ : 5.902958103587065e-05
Current Learning rate AUTOENC : 0.00029514790517935324
Epoch 397, 25% 	 Loss : 1.5844e-02 	 Res : 2.9945e-03 	 Jac : 1.2809e-02 	 Enc : 6.4341e-06 	 AEnc : 3.3758e-05 	 MSE : 3.2713e-02
Epoch 397, 50% 	 Loss : 1.5771e-02 	 Res : 2.9529e-03 	 Jac : 1.2790e-02 	 Enc : 6.3797e-06 	 AEnc : 2.1745e-05 	 MSE : 2.9028e-02
Epoch 397, 75% 	 Loss : 1.5983e-02 	 Res : 3.1982e-03 	 Jac : 1.2757e-02 	 Enc : 6.3359e-06 	 AEnc : 2.1979e-05 	 MSE : 1.1325e-01
Training Epoch 397 : 	 Train : 1.59201e-02 	 Res : 3.11228e-03 	 Jac : 1.27764e-02 	 Enc : 6.45662e-06 	 AE : 2.49882e-05 	 MSE : 8.10266e-02
Validation Epoch 397 : 	 Train : 1.57759e-02 	 Res : 2.98863e-03 	 Jac : 1.27603e-02 	 Enc : 6.43801e-06 	 AE : 2.04687e-05 	 MSE : 2.25534e-02
Training Epoch 397 finished, took current epoch 366.15s, cumulative time 147838.54s
Current Learning rate DEQ : 5.902958103587065e-05
Current Learning rate AUTOENC : 0.00029514790517935324
Epoch 398, 25% 	 Loss : 1.6063e-02 	 Res : 3.3149e-03 	 Jac : 1.2720e-02 	 Enc : 6.6020e-06 	 AEnc : 2.1258e-05 	 MSE : 1.6609e-01
Epoch 398, 50% 	 Loss : 1.6088e-02 	 Res : 3.2950e-03 	 Jac : 1.2766e-02 	 Enc : 6.8378e-06 	 AEnc : 2.0598e-05 	 MSE : 1.5274e-01
Epoch 398, 75% 	 Loss : 1.6429e-02 	 Res : 3.6453e-03 	 Jac : 1.2757e-02 	 Enc : 6.8028e-06 	 AEnc : 1.9875e-05 	 MSE : 2.9383e-01
Training Epoch 398 : 	 Train : 1.64568e-02 	 Res : 3.67861e-03 	 Jac : 1.27506e-02 	 Enc : 6.86224e-06 	 AE : 2.07367e-05 	 MSE : 2.99661e-01
Validation Epoch 398 : 	 Train : 1.82871e-02 	 Res : 5.58761e-03 	 Jac : 1.26672e-02 	 Enc : 7.71018e-06 	 AE : 2.46487e-05 	 MSE : 1.04363e+00
Training Epoch 398 finished, took current epoch 367.93s, cumulative time 148206.44s
Current Learning rate DEQ : 5.902958103587065e-05
Current Learning rate AUTOENC : 0.00029514790517935324
Epoch 399, 25% 	 Loss : 1.6355e-02 	 Res : 3.5949e-03 	 Jac : 1.2731e-02 	 Enc : 7.7566e-06 	 AEnc : 2.1640e-05 	 MSE : 2.8597e-01
Epoch 399, 50% 	 Loss : 1.6115e-02 	 Res : 3.2941e-03 	 Jac : 1.2790e-02 	 Enc : 6.3040e-06 	 AEnc : 2.4813e-05 	 MSE : 1.3214e-01
Epoch 399, 75% 	 Loss : 1.5752e-02 	 Res : 2.9841e-03 	 Jac : 1.2696e-02 	 Enc : 6.5214e-06 	 AEnc : 6.5365e-05 	 MSE : 4.2791e-02
Training Epoch 399 : 	 Train : 1.60286e-02 	 Res : 3.23299e-03 	 Jac : 1.27503e-02 	 Enc : 6.71518e-06 	 AE : 3.85577e-05 	 MSE : 1.25565e-01
Validation Epoch 399 : 	 Train : 1.57841e-02 	 Res : 3.00174e-03 	 Jac : 1.27515e-02 	 Enc : 6.21661e-06 	 AE : 2.46031e-05 	 MSE : 2.57984e-02
Training Epoch 399 finished, took current epoch 366.84s, cumulative time 148573.24s
Current Learning rate DEQ : 5.902958103587065e-05
Current Learning rate AUTOENC : 0.00029514790517935324
Epoch 400, 25% 	 Loss : 1.5841e-02 	 Res : 3.0153e-03 	 Jac : 1.2789e-02 	 Enc : 6.3957e-06 	 AEnc : 3.0250e-05 	 MSE : 3.4848e-02
Epoch 400, 50% 	 Loss : 1.6115e-02 	 Res : 3.0916e-03 	 Jac : 1.2812e-02 	 Enc : 6.5882e-06 	 AEnc : 2.0450e-04 	 MSE : 5.0336e-02
Epoch 400, 75% 	 Loss : 1.6048e-02 	 Res : 3.1194e-03 	 Jac : 1.2731e-02 	 Enc : 6.1168e-06 	 AEnc : 1.9106e-04 	 MSE : 6.9555e-02
Training Epoch 400 : 	 Train : 1.59884e-02 	 Res : 3.08050e-03 	 Jac : 1.27813e-02 	 Enc : 6.40140e-06 	 AE : 1.20266e-04 	 MSE : 5.75649e-02
Validation Epoch 400 : 	 Train : 1.58907e-02 	 Res : 3.08521e-03 	 Jac : 1.27735e-02 	 Enc : 6.42068e-06 	 AE : 2.55070e-05 	 MSE : 6.30917e-02
Training Epoch 400 finished, took current epoch 368.02s, cumulative time 148941.25s
Current Learning rate DEQ : 5.902958103587065e-05
Current Learning rate AUTOENC : 0.00029514790517935324
Epoch 401, 25% 	 Loss : 1.5820e-02 	 Res : 3.0620e-03 	 Jac : 1.2720e-02 	 Enc : 6.4392e-06 	 AEnc : 3.1552e-05 	 MSE : 6.3260e-02
Epoch 401, 50% 	 Loss : 1.5879e-02 	 Res : 3.0654e-03 	 Jac : 1.2784e-02 	 Enc : 6.7667e-06 	 AEnc : 2.2195e-05 	 MSE : 6.0212e-02
Epoch 401, 75% 	 Loss : 1.5837e-02 	 Res : 3.0288e-03 	 Jac : 1.2780e-02 	 Enc : 6.8224e-06 	 AEnc : 2.0525e-05 	 MSE : 6.8017e-02
Training Epoch 401 : 	 Train : 1.58685e-02 	 Res : 3.06903e-03 	 Jac : 1.27692e-02 	 Enc : 6.60976e-06 	 AE : 2.37173e-05 	 MSE : 6.40436e-02
Validation Epoch 401 : 	 Train : 1.58333e-02 	 Res : 3.03756e-03 	 Jac : 1.27682e-02 	 Enc : 6.42964e-06 	 AE : 2.10857e-05 	 MSE : 4.02496e-02
Training Epoch 401 finished, took current epoch 367.57s, cumulative time 149308.80s
Current Learning rate DEQ : 5.902958103587065e-05
Current Learning rate AUTOENC : 0.00029514790517935324
Epoch 402, 25% 	 Loss : 1.5925e-02 	 Res : 3.0682e-03 	 Jac : 1.2830e-02 	 Enc : 6.4655e-06 	 AEnc : 2.0780e-05 	 MSE : 6.3910e-02
Epoch 402, 50% 	 Loss : 1.5804e-02 	 Res : 3.0882e-03 	 Jac : 1.2689e-02 	 Enc : 6.5659e-06 	 AEnc : 2.0292e-05 	 MSE : 6.3549e-02
Epoch 402, 75% 	 Loss : 1.5937e-02 	 Res : 3.1342e-03 	 Jac : 1.2775e-02 	 Enc : 6.6425e-06 	 AEnc : 2.1344e-05 	 MSE : 7.0987e-02
Training Epoch 402 : 	 Train : 1.58661e-02 	 Res : 3.07459e-03 	 Jac : 1.27644e-02 	 Enc : 6.53197e-06 	 AE : 2.06444e-05 	 MSE : 6.62341e-02
Validation Epoch 402 : 	 Train : 1.60063e-02 	 Res : 3.09057e-03 	 Jac : 1.28888e-02 	 Enc : 6.45560e-06 	 AE : 2.04760e-05 	 MSE : 5.94569e-02
Training Epoch 402 finished, took current epoch 368.61s, cumulative time 149677.40s
Current Learning rate DEQ : 5.902958103587065e-05
Current Learning rate AUTOENC : 0.00029514790517935324
Epoch 403, 25% 	 Loss : 1.5950e-02 	 Res : 3.0856e-03 	 Jac : 1.2837e-02 	 Enc : 6.2295e-06 	 AEnc : 2.0938e-05 	 MSE : 6.9915e-02
Epoch 403, 50% 	 Loss : 1.5806e-02 	 Res : 3.0164e-03 	 Jac : 1.2758e-02 	 Enc : 6.7648e-06 	 AEnc : 2.4864e-05 	 MSE : 6.2990e-02
Epoch 403, 75% 	 Loss : 1.6017e-02 	 Res : 3.1613e-03 	 Jac : 1.2824e-02 	 Enc : 6.7456e-06 	 AEnc : 2.4858e-05 	 MSE : 7.6936e-02
Training Epoch 403 : 	 Train : 1.59594e-02 	 Res : 3.09299e-03 	 Jac : 1.28369e-02 	 Enc : 6.60218e-06 	 AE : 2.29695e-05 	 MSE : 6.97770e-02
Validation Epoch 403 : 	 Train : 1.58745e-02 	 Res : 3.04507e-03 	 Jac : 1.28007e-02 	 Enc : 6.47934e-06 	 AE : 2.23131e-05 	 MSE : 4.30451e-02
Training Epoch 403 finished, took current epoch 366.10s, cumulative time 150043.45s
Current Learning rate DEQ : 5.902958103587065e-05
Current Learning rate AUTOENC : 0.00029514790517935324
Epoch 404, 25% 	 Loss : 1.5877e-02 	 Res : 3.0746e-03 	 Jac : 1.2774e-02 	 Enc : 6.5179e-06 	 AEnc : 2.1529e-05 	 MSE : 6.5851e-02
Epoch 404, 50% 	 Loss : 1.5919e-02 	 Res : 3.1253e-03 	 Jac : 1.2766e-02 	 Enc : 6.4903e-06 	 AEnc : 2.1480e-05 	 MSE : 6.6960e-02
Epoch 404, 75% 	 Loss : 1.5904e-02 	 Res : 3.0601e-03 	 Jac : 1.2816e-02 	 Enc : 6.5993e-06 	 AEnc : 2.0609e-05 	 MSE : 6.8274e-02
Training Epoch 404 : 	 Train : 1.58939e-02 	 Res : 3.07407e-03 	 Jac : 1.27924e-02 	 Enc : 6.50888e-06 	 AE : 2.09256e-05 	 MSE : 6.59954e-02
Validation Epoch 404 : 	 Train : 1.58967e-02 	 Res : 3.12386e-03 	 Jac : 1.27452e-02 	 Enc : 6.40138e-06 	 AE : 2.11700e-05 	 MSE : 7.07066e-02
Training Epoch 404 finished, took current epoch 365.38s, cumulative time 150408.82s
Current Learning rate DEQ : 5.902958103587065e-05
Current Learning rate AUTOENC : 0.00029514790517935324
Epoch 405, 25% 	 Loss : 1.5788e-02 	 Res : 3.0745e-03 	 Jac : 1.2685e-02 	 Enc : 6.4795e-06 	 AEnc : 2.1604e-05 	 MSE : 6.6078e-02
Epoch 405, 50% 	 Loss : 1.5893e-02 	 Res : 3.0765e-03 	 Jac : 1.2790e-02 	 Enc : 6.5266e-06 	 AEnc : 1.9826e-05 	 MSE : 6.2544e-02
Epoch 405, 75% 	 Loss : 1.5895e-02 	 Res : 3.0962e-03 	 Jac : 1.2772e-02 	 Enc : 6.3835e-06 	 AEnc : 2.0679e-05 	 MSE : 5.9844e-02
Training Epoch 405 : 	 Train : 1.58505e-02 	 Res : 3.06844e-03 	 Jac : 1.27550e-02 	 Enc : 6.45464e-06 	 AE : 2.06417e-05 	 MSE : 6.32123e-02
Validation Epoch 405 : 	 Train : 1.58255e-02 	 Res : 3.05090e-03 	 Jac : 1.27471e-02 	 Enc : 6.62002e-06 	 AE : 2.08479e-05 	 MSE : 4.77817e-02
Training Epoch 405 finished, took current epoch 367.31s, cumulative time 150776.10s
Current Learning rate DEQ : 4.722366482869652e-05
Current Learning rate AUTOENC : 0.0002361183241434826
Epoch 406, 25% 	 Loss : 1.5854e-02 	 Res : 3.0442e-03 	 Jac : 1.2783e-02 	 Enc : 6.6236e-06 	 AEnc : 2.0644e-05 	 MSE : 4.4742e-02
Epoch 406, 50% 	 Loss : 1.5851e-02 	 Res : 3.0407e-03 	 Jac : 1.2783e-02 	 Enc : 6.4281e-06 	 AEnc : 2.0986e-05 	 MSE : 4.7029e-02
Epoch 406, 75% 	 Loss : 1.5813e-02 	 Res : 3.0444e-03 	 Jac : 1.2742e-02 	 Enc : 6.1033e-06 	 AEnc : 2.1024e-05 	 MSE : 4.5928e-02
Training Epoch 406 : 	 Train : 1.58052e-02 	 Res : 3.01948e-03 	 Jac : 1.27586e-02 	 Enc : 6.41809e-06 	 AE : 2.07449e-05 	 MSE : 4.56159e-02
Validation Epoch 406 : 	 Train : 1.58992e-02 	 Res : 3.08066e-03 	 Jac : 1.27927e-02 	 Enc : 6.59115e-06 	 AE : 1.92978e-05 	 MSE : 6.22665e-02
Training Epoch 406 finished, took current epoch 362.54s, cumulative time 151138.60s
Current Learning rate DEQ : 4.722366482869652e-05
Current Learning rate AUTOENC : 0.0002361183241434826
Epoch 407, 25% 	 Loss : 1.5889e-02 	 Res : 3.0493e-03 	 Jac : 1.2812e-02 	 Enc : 6.5090e-06 	 AEnc : 2.0715e-05 	 MSE : 4.7588e-02
Epoch 407, 50% 	 Loss : 1.5784e-02 	 Res : 3.0188e-03 	 Jac : 1.2738e-02 	 Enc : 6.3848e-06 	 AEnc : 2.0899e-05 	 MSE : 4.7639e-02
Epoch 407, 75% 	 Loss : 1.5772e-02 	 Res : 2.9921e-03 	 Jac : 1.2753e-02 	 Enc : 6.4540e-06 	 AEnc : 2.0507e-05 	 MSE : 4.6366e-02
Training Epoch 407 : 	 Train : 1.58440e-02 	 Res : 3.01984e-03 	 Jac : 1.27970e-02 	 Enc : 6.39256e-06 	 AE : 2.07094e-05 	 MSE : 4.63299e-02
Validation Epoch 407 : 	 Train : 1.59268e-02 	 Res : 3.09585e-03 	 Jac : 1.28045e-02 	 Enc : 6.28007e-06 	 AE : 2.02172e-05 	 MSE : 6.50851e-02
Training Epoch 407 finished, took current epoch 367.75s, cumulative time 151506.32s
Current Learning rate DEQ : 4.722366482869652e-05
Current Learning rate AUTOENC : 0.0002361183241434826
Epoch 408, 25% 	 Loss : 1.5948e-02 	 Res : 3.0169e-03 	 Jac : 1.2905e-02 	 Enc : 6.2808e-06 	 AEnc : 1.9888e-05 	 MSE : 4.5870e-02
Epoch 408, 50% 	 Loss : 1.5817e-02 	 Res : 3.0020e-03 	 Jac : 1.2787e-02 	 Enc : 6.2658e-06 	 AEnc : 2.1317e-05 	 MSE : 4.5260e-02
Epoch 408, 75% 	 Loss : 1.5854e-02 	 Res : 3.0722e-03 	 Jac : 1.2755e-02 	 Enc : 6.1851e-06 	 AEnc : 2.0159e-05 	 MSE : 4.6005e-02
Training Epoch 408 : 	 Train : 1.58741e-02 	 Res : 3.02064e-03 	 Jac : 1.28266e-02 	 Enc : 6.30004e-06 	 AE : 2.06059e-05 	 MSE : 4.58629e-02
Validation Epoch 408 : 	 Train : 1.58779e-02 	 Res : 3.09994e-03 	 Jac : 1.27539e-02 	 Enc : 6.23859e-06 	 AE : 1.77759e-05 	 MSE : 6.78700e-02
Training Epoch 408 finished, took current epoch 365.32s, cumulative time 151871.63s
Current Learning rate DEQ : 4.722366482869652e-05
Current Learning rate AUTOENC : 0.0002361183241434826
Epoch 409, 25% 	 Loss : 1.5861e-02 	 Res : 3.0415e-03 	 Jac : 1.2792e-02 	 Enc : 6.3010e-06 	 AEnc : 2.1598e-05 	 MSE : 4.8099e-02
Epoch 409, 50% 	 Loss : 1.5829e-02 	 Res : 3.0166e-03 	 Jac : 1.2786e-02 	 Enc : 6.4126e-06 	 AEnc : 2.0623e-05 	 MSE : 4.7043e-02
Epoch 409, 75% 	 Loss : 1.5856e-02 	 Res : 3.0389e-03 	 Jac : 1.2790e-02 	 Enc : 6.4407e-06 	 AEnc : 2.0856e-05 	 MSE : 4.6366e-02
Training Epoch 409 : 	 Train : 1.58346e-02 	 Res : 3.02300e-03 	 Jac : 1.27842e-02 	 Enc : 6.38261e-06 	 AE : 2.09814e-05 	 MSE : 4.70779e-02
Validation Epoch 409 : 	 Train : 1.58996e-02 	 Res : 3.06949e-03 	 Jac : 1.28032e-02 	 Enc : 6.15280e-06 	 AE : 2.07166e-05 	 MSE : 5.59251e-02
Training Epoch 409 finished, took current epoch 369.00s, cumulative time 152240.62s
Current Learning rate DEQ : 4.722366482869652e-05
Current Learning rate AUTOENC : 0.0002361183241434826
Epoch 410, 25% 	 Loss : 1.5823e-02 	 Res : 3.0737e-03 	 Jac : 1.2722e-02 	 Enc : 6.5058e-06 	 AEnc : 2.0913e-05 	 MSE : 4.6543e-02
Epoch 410, 50% 	 Loss : 1.5693e-02 	 Res : 2.9608e-03 	 Jac : 1.2705e-02 	 Enc : 6.3623e-06 	 AEnc : 2.1049e-05 	 MSE : 4.6801e-02
Epoch 410, 75% 	 Loss : 1.5828e-02 	 Res : 2.9719e-03 	 Jac : 1.2829e-02 	 Enc : 6.2674e-06 	 AEnc : 2.0768e-05 	 MSE : 4.5708e-02
Training Epoch 410 : 	 Train : 1.57969e-02 	 Res : 3.02279e-03 	 Jac : 1.27466e-02 	 Enc : 6.33141e-06 	 AE : 2.11113e-05 	 MSE : 4.76049e-02
Validation Epoch 410 : 	 Train : 1.58933e-02 	 Res : 3.06959e-03 	 Jac : 1.27928e-02 	 Enc : 6.42528e-06 	 AE : 2.45481e-05 	 MSE : 5.68439e-02
Training Epoch 410 finished, took current epoch 365.93s, cumulative time 152606.49s
Current Learning rate DEQ : 4.722366482869652e-05
Current Learning rate AUTOENC : 0.0002361183241434826
Epoch 411, 25% 	 Loss : 1.5918e-02 	 Res : 3.0237e-03 	 Jac : 1.2865e-02 	 Enc : 6.4347e-06 	 AEnc : 2.2645e-05 	 MSE : 4.7508e-02
Epoch 411, 50% 	 Loss : 1.6415e-02 	 Res : 3.1737e-03 	 Jac : 1.2774e-02 	 Enc : 6.4674e-06 	 AEnc : 4.6103e-04 	 MSE : 8.0550e-02
Epoch 411, 75% 	 Loss : 1.6647e-02 	 Res : 3.1523e-03 	 Jac : 1.2788e-02 	 Enc : 6.3260e-06 	 AEnc : 7.0063e-04 	 MSE : 4.7074e-02
Training Epoch 411 : 	 Train : 1.63406e-02 	 Res : 3.15567e-03 	 Jac : 1.28175e-02 	 Enc : 6.33783e-06 	 AE : 3.61131e-04 	 MSE : 7.49352e-02
Validation Epoch 411 : 	 Train : 1.60734e-02 	 Res : 3.08724e-03 	 Jac : 1.28238e-02 	 Enc : 6.32072e-06 	 AE : 1.56040e-04 	 MSE : 5.24563e-02
Training Epoch 411 finished, took current epoch 362.14s, cumulative time 152968.59s
Current Learning rate DEQ : 4.722366482869652e-05
Current Learning rate AUTOENC : 0.0002361183241434826
Epoch 412, 25% 	 Loss : 1.6135e-02 	 Res : 3.0790e-03 	 Jac : 1.2765e-02 	 Enc : 6.7064e-06 	 AEnc : 2.8365e-04 	 MSE : 4.0240e-02
Epoch 412, 50% 	 Loss : 1.6073e-02 	 Res : 3.0312e-03 	 Jac : 1.2860e-02 	 Enc : 6.6569e-06 	 AEnc : 1.7527e-04 	 MSE : 5.0212e-02
Epoch 412, 75% 	 Loss : 1.5947e-02 	 Res : 3.0153e-03 	 Jac : 1.2868e-02 	 Enc : 6.1578e-06 	 AEnc : 5.7601e-05 	 MSE : 5.0353e-02
Training Epoch 412 : 	 Train : 1.59980e-02 	 Res : 3.03771e-03 	 Jac : 1.28168e-02 	 Enc : 6.37023e-06 	 AE : 1.37136e-04 	 MSE : 4.69518e-02
Validation Epoch 412 : 	 Train : 1.59541e-02 	 Res : 3.12740e-03 	 Jac : 1.28011e-02 	 Enc : 5.97439e-06 	 AE : 1.96547e-05 	 MSE : 8.05091e-02
Training Epoch 412 finished, took current epoch 365.45s, cumulative time 153333.99s
Current Learning rate DEQ : 4.722366482869652e-05
Current Learning rate AUTOENC : 0.0002361183241434826
Epoch 413, 25% 	 Loss : 1.5807e-02 	 Res : 3.0528e-03 	 Jac : 1.2727e-02 	 Enc : 6.0895e-06 	 AEnc : 2.1040e-05 	 MSE : 4.6737e-02
Epoch 413, 50% 	 Loss : 1.5852e-02 	 Res : 3.0414e-03 	 Jac : 1.2784e-02 	 Enc : 6.0562e-06 	 AEnc : 2.0324e-05 	 MSE : 4.8763e-02
Epoch 413, 75% 	 Loss : 1.5740e-02 	 Res : 3.0075e-03 	 Jac : 1.2705e-02 	 Enc : 6.2418e-06 	 AEnc : 2.1509e-05 	 MSE : 4.8648e-02
Training Epoch 413 : 	 Train : 1.58012e-02 	 Res : 3.02095e-03 	 Jac : 1.27532e-02 	 Enc : 6.17443e-06 	 AE : 2.08356e-05 	 MSE : 4.72785e-02
Validation Epoch 413 : 	 Train : 1.60810e-02 	 Res : 3.21787e-03 	 Jac : 1.28357e-02 	 Enc : 6.26281e-06 	 AE : 2.11807e-05 	 MSE : 1.05851e-01
Training Epoch 413 finished, took current epoch 367.75s, cumulative time 153701.70s
Current Learning rate DEQ : 4.722366482869652e-05
Current Learning rate AUTOENC : 0.0002361183241434826
Epoch 414, 25% 	 Loss : 1.5799e-02 	 Res : 3.0504e-03 	 Jac : 1.2721e-02 	 Enc : 6.1770e-06 	 AEnc : 2.0963e-05 	 MSE : 4.7987e-02
Epoch 414, 50% 	 Loss : 1.5799e-02 	 Res : 2.9848e-03 	 Jac : 1.2787e-02 	 Enc : 6.1492e-06 	 AEnc : 2.1172e-05 	 MSE : 4.6263e-02
Epoch 414, 75% 	 Loss : 1.5877e-02 	 Res : 3.0244e-03 	 Jac : 1.2825e-02 	 Enc : 6.2519e-06 	 AEnc : 2.0820e-05 	 MSE : 4.5735e-02
Training Epoch 414 : 	 Train : 1.58186e-02 	 Res : 3.01846e-03 	 Jac : 1.27731e-02 	 Enc : 6.22999e-06 	 AE : 2.07411e-05 	 MSE : 4.67681e-02
Validation Epoch 414 : 	 Train : 1.60419e-02 	 Res : 3.18979e-03 	 Jac : 1.28263e-02 	 Enc : 6.19862e-06 	 AE : 1.96840e-05 	 MSE : 1.06190e-01
Training Epoch 414 finished, took current epoch 363.74s, cumulative time 154065.43s
Current Learning rate DEQ : 4.722366482869652e-05
Current Learning rate AUTOENC : 0.0002361183241434826
Epoch 415, 25% 	 Loss : 1.5806e-02 	 Res : 3.0167e-03 	 Jac : 1.2761e-02 	 Enc : 6.4487e-06 	 AEnc : 2.1304e-05 	 MSE : 5.2232e-02
Epoch 415, 50% 	 Loss : 1.5773e-02 	 Res : 2.9956e-03 	 Jac : 1.2751e-02 	 Enc : 6.2169e-06 	 AEnc : 2.1047e-05 	 MSE : 4.7085e-02
Epoch 415, 75% 	 Loss : 1.5786e-02 	 Res : 3.0282e-03 	 Jac : 1.2731e-02 	 Enc : 6.2677e-06 	 AEnc : 2.0993e-05 	 MSE : 4.6606e-02
Training Epoch 415 : 	 Train : 1.58037e-02 	 Res : 3.02086e-03 	 Jac : 1.27555e-02 	 Enc : 6.34382e-06 	 AE : 2.09139e-05 	 MSE : 4.78276e-02
Validation Epoch 415 : 	 Train : 1.59285e-02 	 Res : 3.13986e-03 	 Jac : 1.27628e-02 	 Enc : 6.15142e-06 	 AE : 1.96923e-05 	 MSE : 8.70961e-02
Training Epoch 415 finished, took current epoch 363.95s, cumulative time 154429.34s
Current Learning rate DEQ : 4.722366482869652e-05
Current Learning rate AUTOENC : 0.0002361183241434826
Epoch 416, 25% 	 Loss : 1.5892e-02 	 Res : 3.0235e-03 	 Jac : 1.2841e-02 	 Enc : 6.4225e-06 	 AEnc : 2.0747e-05 	 MSE : 4.8727e-02
Epoch 416, 50% 	 Loss : 1.5988e-02 	 Res : 3.1073e-03 	 Jac : 1.2852e-02 	 Enc : 6.3563e-06 	 AEnc : 2.2224e-05 	 MSE : 8.0580e-02
Epoch 416, 75% 	 Loss : 1.5965e-02 	 Res : 3.0956e-03 	 Jac : 1.2832e-02 	 Enc : 6.6706e-06 	 AEnc : 3.0323e-05 	 MSE : 5.4906e-02
Training Epoch 416 : 	 Train : 1.59741e-02 	 Res : 3.10143e-03 	 Jac : 1.28330e-02 	 Enc : 6.45127e-06 	 AE : 3.32223e-05 	 MSE : 7.34720e-02
Validation Epoch 416 : 	 Train : 1.63020e-02 	 Res : 3.45457e-03 	 Jac : 1.28114e-02 	 Enc : 6.29991e-06 	 AE : 2.97473e-05 	 MSE : 1.93981e-01
Training Epoch 416 finished, took current epoch 364.85s, cumulative time 154794.18s
Current Learning rate DEQ : 3.777893186295722e-05
Current Learning rate AUTOENC : 0.0001888946593147861
Epoch 417, 25% 	 Loss : 1.6020e-02 	 Res : 3.1620e-03 	 Jac : 1.2795e-02 	 Enc : 6.3780e-06 	 AEnc : 5.6739e-05 	 MSE : 7.1903e-02
Epoch 417, 50% 	 Loss : 1.5997e-02 	 Res : 3.1033e-03 	 Jac : 1.2842e-02 	 Enc : 6.2914e-06 	 AEnc : 4.6159e-05 	 MSE : 7.8358e-02
Epoch 417, 75% 	 Loss : 1.5850e-02 	 Res : 3.0827e-03 	 Jac : 1.2737e-02 	 Enc : 6.5175e-06 	 AEnc : 2.3624e-05 	 MSE : 7.4131e-02
Training Epoch 417 : 	 Train : 1.59467e-02 	 Res : 3.10248e-03 	 Jac : 1.28005e-02 	 Enc : 6.40632e-06 	 AE : 3.73763e-05 	 MSE : 7.54599e-02
Validation Epoch 417 : 	 Train : 1.58738e-02 	 Res : 3.14339e-03 	 Jac : 1.27054e-02 	 Enc : 6.26999e-06 	 AE : 1.87820e-05 	 MSE : 8.35789e-02
Training Epoch 417 finished, took current epoch 364.19s, cumulative time 155158.36s
Current Learning rate DEQ : 3.777893186295722e-05
Current Learning rate AUTOENC : 0.0001888946593147861
Epoch 418, 25% 	 Loss : 1.6385e-02 	 Res : 3.5761e-03 	 Jac : 1.2782e-02 	 Enc : 6.3526e-06 	 AEnc : 2.1274e-05 	 MSE : 2.6352e-01
Epoch 418, 50% 	 Loss : 1.6350e-02 	 Res : 3.5970e-03 	 Jac : 1.2726e-02 	 Enc : 6.8531e-06 	 AEnc : 2.0505e-05 	 MSE : 2.7349e-01
Epoch 418, 75% 	 Loss : 1.5925e-02 	 Res : 3.0393e-03 	 Jac : 1.2854e-02 	 Enc : 6.6388e-06 	 AEnc : 2.5691e-05 	 MSE : 4.3899e-02
Training Epoch 418 : 	 Train : 1.61206e-02 	 Res : 3.30141e-03 	 Jac : 1.27901e-02 	 Enc : 6.52684e-06 	 AE : 2.25288e-05 	 MSE : 1.56020e-01
Validation Epoch 418 : 	 Train : 1.57741e-02 	 Res : 3.03660e-03 	 Jac : 1.27084e-02 	 Enc : 6.19358e-06 	 AE : 2.29280e-05 	 MSE : 4.36504e-02
Training Epoch 418 finished, took current epoch 364.01s, cumulative time 155522.35s
Current Learning rate DEQ : 3.777893186295722e-05
Current Learning rate AUTOENC : 0.0001888946593147861
Epoch 419, 25% 	 Loss : 1.5912e-02 	 Res : 3.0101e-03 	 Jac : 1.2874e-02 	 Enc : 6.2450e-06 	 AEnc : 2.2336e-05 	 MSE : 3.5113e-02
Epoch 419, 50% 	 Loss : 1.6061e-02 	 Res : 3.2435e-03 	 Jac : 1.2790e-02 	 Enc : 6.0299e-06 	 AEnc : 2.2397e-05 	 MSE : 1.3155e-01
Epoch 419, 75% 	 Loss : 1.6198e-02 	 Res : 3.3344e-03 	 Jac : 1.2835e-02 	 Enc : 6.2712e-06 	 AEnc : 2.2280e-05 	 MSE : 1.5549e-01
Training Epoch 419 : 	 Train : 1.60253e-02 	 Res : 3.19850e-03 	 Jac : 1.27983e-02 	 Enc : 6.27713e-06 	 AE : 2.21824e-05 	 MSE : 1.16643e-01
Validation Epoch 419 : 	 Train : 1.62965e-02 	 Res : 3.36956e-03 	 Jac : 1.28969e-02 	 Enc : 6.64029e-06 	 AE : 2.34508e-05 	 MSE : 1.67428e-01
Training Epoch 419 finished, took current epoch 363.85s, cumulative time 155886.20s
Current Learning rate DEQ : 3.777893186295722e-05
Current Learning rate AUTOENC : 0.0001888946593147861
Epoch 420, 25% 	 Loss : 1.6102e-02 	 Res : 3.2683e-03 	 Jac : 1.2806e-02 	 Enc : 6.8054e-06 	 AEnc : 2.0443e-05 	 MSE : 1.4823e-01
Epoch 420, 50% 	 Loss : 1.6178e-02 	 Res : 3.2783e-03 	 Jac : 1.2872e-02 	 Enc : 6.6807e-06 	 AEnc : 2.1739e-05 	 MSE : 1.4654e-01
Epoch 420, 75% 	 Loss : 1.6126e-02 	 Res : 3.3113e-03 	 Jac : 1.2786e-02 	 Enc : 6.5990e-06 	 AEnc : 2.2465e-05 	 MSE : 1.5214e-01
Training Epoch 420 : 	 Train : 1.61167e-02 	 Res : 3.27420e-03 	 Jac : 1.28144e-02 	 Enc : 6.70625e-06 	 AE : 2.14201e-05 	 MSE : 1.48725e-01
Validation Epoch 420 : 	 Train : 1.60411e-02 	 Res : 3.26073e-03 	 Jac : 1.27530e-02 	 Enc : 6.67444e-06 	 AE : 2.06613e-05 	 MSE : 1.27820e-01
Training Epoch 420 finished, took current epoch 363.77s, cumulative time 156249.95s
Current Learning rate DEQ : 3.777893186295722e-05
Current Learning rate AUTOENC : 0.0001888946593147861
Epoch 421, 25% 	 Loss : 1.6004e-02 	 Res : 3.2523e-03 	 Jac : 1.2723e-02 	 Enc : 6.7411e-06 	 AEnc : 2.1916e-05 	 MSE : 1.4981e-01
Epoch 421, 50% 	 Loss : 1.6043e-02 	 Res : 3.2550e-03 	 Jac : 1.2758e-02 	 Enc : 6.4587e-06 	 AEnc : 2.3618e-05 	 MSE : 1.5000e-01
Epoch 421, 75% 	 Loss : 1.6166e-02 	 Res : 3.3836e-03 	 Jac : 1.2755e-02 	 Enc : 6.6319e-06 	 AEnc : 2.1318e-05 	 MSE : 1.4782e-01
Training Epoch 421 : 	 Train : 1.60606e-02 	 Res : 3.27757e-03 	 Jac : 1.27541e-02 	 Enc : 6.64668e-06 	 AE : 2.22602e-05 	 MSE : 1.47825e-01
Validation Epoch 421 : 	 Train : 1.63868e-02 	 Res : 3.54972e-03 	 Jac : 1.28106e-02 	 Enc : 6.75991e-06 	 AE : 1.96776e-05 	 MSE : 2.37291e-01
Training Epoch 421 finished, took current epoch 363.73s, cumulative time 156613.66s
Current Learning rate DEQ : 3.777893186295722e-05
Current Learning rate AUTOENC : 0.0001888946593147861
Epoch 422, 25% 	 Loss : 1.6172e-02 	 Res : 3.2872e-03 	 Jac : 1.2857e-02 	 Enc : 6.7994e-06 	 AEnc : 2.0920e-05 	 MSE : 1.5276e-01
Epoch 422, 50% 	 Loss : 1.6119e-02 	 Res : 3.3148e-03 	 Jac : 1.2775e-02 	 Enc : 6.8746e-06 	 AEnc : 2.1869e-05 	 MSE : 1.4593e-01
Epoch 422, 75% 	 Loss : 1.5899e-02 	 Res : 3.2342e-03 	 Jac : 1.2636e-02 	 Enc : 6.6605e-06 	 AEnc : 2.1687e-05 	 MSE : 1.5015e-01
Training Epoch 422 : 	 Train : 1.60683e-02 	 Res : 3.27910e-03 	 Jac : 1.27611e-02 	 Enc : 6.73243e-06 	 AE : 2.13243e-05 	 MSE : 1.49702e-01
Validation Epoch 422 : 	 Train : 1.63424e-02 	 Res : 3.64935e-03 	 Jac : 1.26661e-02 	 Enc : 6.47593e-06 	 AE : 2.05118e-05 	 MSE : 2.76363e-01
Training Epoch 422 finished, took current epoch 364.12s, cumulative time 156977.76s
Current Learning rate DEQ : 3.777893186295722e-05
Current Learning rate AUTOENC : 0.0001888946593147861
Epoch 423, 25% 	 Loss : 1.6107e-02 	 Res : 3.2446e-03 	 Jac : 1.2834e-02 	 Enc : 6.6365e-06 	 AEnc : 2.1500e-05 	 MSE : 1.5493e-01
Epoch 423, 50% 	 Loss : 1.6141e-02 	 Res : 3.2932e-03 	 Jac : 1.2819e-02 	 Enc : 6.6402e-06 	 AEnc : 2.1700e-05 	 MSE : 1.5092e-01
Epoch 423, 75% 	 Loss : 1.6157e-02 	 Res : 3.2248e-03 	 Jac : 1.2905e-02 	 Enc : 6.6669e-06 	 AEnc : 2.1423e-05 	 MSE : 1.5085e-01
Training Epoch 423 : 	 Train : 1.61679e-02 	 Res : 3.28238e-03 	 Jac : 1.28573e-02 	 Enc : 6.71431e-06 	 AE : 2.14372e-05 	 MSE : 1.51820e-01
Validation Epoch 423 : 	 Train : 1.62481e-02 	 Res : 3.47129e-03 	 Jac : 1.27487e-02 	 Enc : 6.97173e-06 	 AE : 2.10975e-05 	 MSE : 2.09915e-01
Training Epoch 423 finished, took current epoch 362.83s, cumulative time 157340.56s
Current Learning rate DEQ : 3.777893186295722e-05
Current Learning rate AUTOENC : 0.0001888946593147861
Epoch 424, 25% 	 Loss : 1.5968e-02 	 Res : 3.2125e-03 	 Jac : 1.2727e-02 	 Enc : 6.8066e-06 	 AEnc : 2.1381e-05 	 MSE : 1.5413e-01
Epoch 424, 50% 	 Loss : 1.6155e-02 	 Res : 3.3101e-03 	 Jac : 1.2816e-02 	 Enc : 6.6348e-06 	 AEnc : 2.2063e-05 	 MSE : 1.5340e-01
Epoch 424, 75% 	 Loss : 1.6143e-02 	 Res : 3.3563e-03 	 Jac : 1.2759e-02 	 Enc : 6.5562e-06 	 AEnc : 2.1936e-05 	 MSE : 1.5774e-01
Training Epoch 424 : 	 Train : 1.60904e-02 	 Res : 3.28850e-03 	 Jac : 1.27734e-02 	 Enc : 6.66381e-06 	 AE : 2.19256e-05 	 MSE : 1.52911e-01
Validation Epoch 424 : 	 Train : 1.64177e-02 	 Res : 3.54386e-03 	 Jac : 1.28472e-02 	 Enc : 6.77912e-06 	 AE : 1.97805e-05 	 MSE : 2.33802e-01
Training Epoch 424 finished, took current epoch 366.13s, cumulative time 157706.66s
Current Learning rate DEQ : 3.777893186295722e-05
Current Learning rate AUTOENC : 0.0001888946593147861
Epoch 425, 25% 	 Loss : 1.6048e-02 	 Res : 3.2665e-03 	 Jac : 1.2752e-02 	 Enc : 6.7737e-06 	 AEnc : 2.2400e-05 	 MSE : 1.5421e-01
Epoch 425, 50% 	 Loss : 1.6101e-02 	 Res : 3.2420e-03 	 Jac : 1.2831e-02 	 Enc : 6.7541e-06 	 AEnc : 2.1601e-05 	 MSE : 1.5427e-01
Epoch 425, 75% 	 Loss : 1.6093e-02 	 Res : 3.2740e-03 	 Jac : 1.2791e-02 	 Enc : 6.6010e-06 	 AEnc : 2.1036e-05 	 MSE : 1.3689e-01
Training Epoch 425 : 	 Train : 1.60590e-02 	 Res : 3.22575e-03 	 Jac : 1.28033e-02 	 Enc : 6.52629e-06 	 AE : 2.34139e-05 	 MSE : 1.27784e-01
Validation Epoch 425 : 	 Train : 1.59345e-02 	 Res : 3.13883e-03 	 Jac : 1.27687e-02 	 Enc : 5.78274e-06 	 AE : 2.11699e-05 	 MSE : 7.09881e-02
Training Epoch 425 finished, took current epoch 364.03s, cumulative time 158070.66s
Current Learning rate DEQ : 3.777893186295722e-05
Current Learning rate AUTOENC : 0.0001888946593147861
Epoch 426, 25% 	 Loss : 1.6027e-02 	 Res : 3.1957e-03 	 Jac : 1.2797e-02 	 Enc : 6.4839e-06 	 AEnc : 2.7518e-05 	 MSE : 8.4468e-02
Epoch 426, 50% 	 Loss : 1.5878e-02 	 Res : 3.1211e-03 	 Jac : 1.2730e-02 	 Enc : 6.3741e-06 	 AEnc : 2.1194e-05 	 MSE : 7.9747e-02
Epoch 426, 75% 	 Loss : 1.5876e-02 	 Res : 3.0433e-03 	 Jac : 1.2805e-02 	 Enc : 6.1567e-06 	 AEnc : 2.1763e-05 	 MSE : 7.7076e-02
Training Epoch 426 : 	 Train : 1.59031e-02 	 Res : 3.10581e-03 	 Jac : 1.27678e-02 	 Enc : 6.35321e-06 	 AE : 2.30655e-05 	 MSE : 7.88542e-02
Validation Epoch 426 : 	 Train : 1.60442e-02 	 Res : 3.23064e-03 	 Jac : 1.27862e-02 	 Enc : 6.45329e-06 	 AE : 2.08919e-05 	 MSE : 1.16819e-01
Training Epoch 426 finished, took current epoch 364.64s, cumulative time 158435.29s
Current Learning rate DEQ : 3.777893186295722e-05
Current Learning rate AUTOENC : 0.0001888946593147861
Epoch 427, 25% 	 Loss : 1.5865e-02 	 Res : 3.0915e-03 	 Jac : 1.2746e-02 	 Enc : 6.3035e-06 	 AEnc : 2.1267e-05 	 MSE : 7.7015e-02
Epoch 427, 50% 	 Loss : 1.5880e-02 	 Res : 3.0559e-03 	 Jac : 1.2796e-02 	 Enc : 6.4790e-06 	 AEnc : 2.2098e-05 	 MSE : 7.5538e-02
Epoch 427, 75% 	 Loss : 1.5879e-02 	 Res : 3.1181e-03 	 Jac : 1.2733e-02 	 Enc : 6.4475e-06 	 AEnc : 2.1527e-05 	 MSE : 7.1790e-02
Training Epoch 427 : 	 Train : 1.60127e-02 	 Res : 3.22033e-03 	 Jac : 1.27641e-02 	 Enc : 6.44201e-06 	 AE : 2.18045e-05 	 MSE : 1.26679e-01
Validation Epoch 427 : 	 Train : 1.60974e-02 	 Res : 3.32010e-03 	 Jac : 1.27525e-02 	 Enc : 6.64889e-06 	 AE : 1.81752e-05 	 MSE : 1.52641e-01
Training Epoch 427 finished, took current epoch 367.01s, cumulative time 158802.28s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 428, 25% 	 Loss : 1.6050e-02 	 Res : 3.1603e-03 	 Jac : 1.2781e-02 	 Enc : 6.7181e-06 	 AEnc : 1.0161e-04 	 MSE : 1.1570e-01
Epoch 428, 50% 	 Loss : 1.6723e-02 	 Res : 3.1795e-03 	 Jac : 1.2731e-02 	 Enc : 6.1635e-06 	 AEnc : 8.0656e-04 	 MSE : 3.2523e-02
Epoch 428, 75% 	 Loss : 1.5929e-02 	 Res : 2.9780e-03 	 Jac : 1.2790e-02 	 Enc : 5.9547e-06 	 AEnc : 1.5535e-04 	 MSE : 2.5691e-02
Training Epoch 428 : 	 Train : 1.61320e-02 	 Res : 3.07357e-03 	 Jac : 1.27786e-02 	 Enc : 6.23044e-06 	 AE : 2.73648e-04 	 MSE : 5.15322e-02
Validation Epoch 428 : 	 Train : 1.58953e-02 	 Res : 3.02815e-03 	 Jac : 1.28388e-02 	 Enc : 6.20994e-06 	 AE : 2.21304e-05 	 MSE : 4.04521e-02
Training Epoch 428 finished, took current epoch 366.78s, cumulative time 159169.03s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 429, 25% 	 Loss : 1.5709e-02 	 Res : 2.9348e-03 	 Jac : 1.2747e-02 	 Enc : 6.1496e-06 	 AEnc : 2.1651e-05 	 MSE : 2.7652e-02
Epoch 429, 50% 	 Loss : 1.5714e-02 	 Res : 2.9390e-03 	 Jac : 1.2747e-02 	 Enc : 6.0330e-06 	 AEnc : 2.1227e-05 	 MSE : 2.7968e-02
Epoch 429, 75% 	 Loss : 1.5776e-02 	 Res : 2.9757e-03 	 Jac : 1.2773e-02 	 Enc : 6.0215e-06 	 AEnc : 2.1010e-05 	 MSE : 2.8035e-02
Training Epoch 429 : 	 Train : 1.57509e-02 	 Res : 2.96179e-03 	 Jac : 1.27614e-02 	 Enc : 6.14184e-06 	 AE : 2.15506e-05 	 MSE : 2.76928e-02
Validation Epoch 429 : 	 Train : 1.57606e-02 	 Res : 2.95252e-03 	 Jac : 1.27834e-02 	 Enc : 6.42207e-06 	 AE : 1.82406e-05 	 MSE : 1.23346e-02
Training Epoch 429 finished, took current epoch 361.35s, cumulative time 159530.28s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
MODEL SAVED
Epoch 430, 25% 	 Loss : 1.5828e-02 	 Res : 3.0039e-03 	 Jac : 1.2797e-02 	 Enc : 6.1987e-06 	 AEnc : 2.1323e-05 	 MSE : 2.9880e-02
Epoch 430, 50% 	 Loss : 1.5809e-02 	 Res : 2.9943e-03 	 Jac : 1.2780e-02 	 Enc : 5.8921e-06 	 AEnc : 2.8049e-05 	 MSE : 6.4243e-02
Epoch 430, 75% 	 Loss : 1.5764e-02 	 Res : 2.9725e-03 	 Jac : 1.2760e-02 	 Enc : 5.9203e-06 	 AEnc : 2.5194e-05 	 MSE : 2.6203e-02
Training Epoch 430 : 	 Train : 1.58243e-02 	 Res : 2.99444e-03 	 Jac : 1.27996e-02 	 Enc : 6.05229e-06 	 AE : 2.42198e-05 	 MSE : 3.78327e-02
Validation Epoch 430 : 	 Train : 1.58047e-02 	 Res : 3.02454e-03 	 Jac : 1.27522e-02 	 Enc : 5.98164e-06 	 AE : 2.20219e-05 	 MSE : 4.18937e-02
Training Epoch 430 finished, took current epoch 365.15s, cumulative time 159895.40s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 431, 25% 	 Loss : 1.5797e-02 	 Res : 2.9555e-03 	 Jac : 1.2815e-02 	 Enc : 5.8999e-06 	 AEnc : 2.0477e-05 	 MSE : 2.6903e-02
Epoch 431, 50% 	 Loss : 1.5830e-02 	 Res : 3.0181e-03 	 Jac : 1.2783e-02 	 Enc : 6.1077e-06 	 AEnc : 2.2859e-05 	 MSE : 3.2855e-02
Epoch 431, 75% 	 Loss : 1.5947e-02 	 Res : 2.9786e-03 	 Jac : 1.2717e-02 	 Enc : 6.1066e-06 	 AEnc : 2.4552e-04 	 MSE : 3.0311e-02
Training Epoch 431 : 	 Train : 1.58753e-02 	 Res : 2.97943e-03 	 Jac : 1.27929e-02 	 Enc : 5.98249e-06 	 AE : 9.70388e-05 	 MSE : 2.95172e-02
Validation Epoch 431 : 	 Train : 1.58175e-02 	 Res : 3.01473e-03 	 Jac : 1.27561e-02 	 Enc : 5.53739e-06 	 AE : 4.10874e-05 	 MSE : 3.56577e-02
Training Epoch 431 finished, took current epoch 364.01s, cumulative time 160259.38s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 432, 25% 	 Loss : 1.5819e-02 	 Res : 2.9607e-03 	 Jac : 1.2803e-02 	 Enc : 5.8913e-06 	 AEnc : 4.9257e-05 	 MSE : 3.0230e-02
Epoch 432, 50% 	 Loss : 1.5776e-02 	 Res : 2.9472e-03 	 Jac : 1.2765e-02 	 Enc : 5.9870e-06 	 AEnc : 5.7294e-05 	 MSE : 2.5010e-02
Epoch 432, 75% 	 Loss : 1.5817e-02 	 Res : 2.9836e-03 	 Jac : 1.2727e-02 	 Enc : 5.7550e-06 	 AEnc : 1.0054e-04 	 MSE : 3.4826e-02
Training Epoch 432 : 	 Train : 1.58516e-02 	 Res : 2.97971e-03 	 Jac : 1.27403e-02 	 Enc : 5.83870e-06 	 AE : 1.25759e-04 	 MSE : 2.79735e-02
Validation Epoch 432 : 	 Train : 1.58665e-02 	 Res : 2.99730e-03 	 Jac : 1.28063e-02 	 Enc : 5.77647e-06 	 AE : 5.71613e-05 	 MSE : 3.07387e-02
Training Epoch 432 finished, took current epoch 363.91s, cumulative time 160623.25s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 433, 25% 	 Loss : 1.6567e-02 	 Res : 3.0854e-03 	 Jac : 1.2822e-02 	 Enc : 6.1516e-06 	 AEnc : 6.5392e-04 	 MSE : 5.1167e-02
Epoch 433, 50% 	 Loss : 1.6232e-02 	 Res : 3.0209e-03 	 Jac : 1.2756e-02 	 Enc : 5.8383e-06 	 AEnc : 4.4981e-04 	 MSE : 2.7349e-02
Epoch 433, 75% 	 Loss : 1.5857e-02 	 Res : 2.9506e-03 	 Jac : 1.2850e-02 	 Enc : 5.6178e-06 	 AEnc : 5.0152e-05 	 MSE : 2.7113e-02
Training Epoch 433 : 	 Train : 1.61401e-02 	 Res : 3.02404e-03 	 Jac : 1.28106e-02 	 Enc : 5.83363e-06 	 AE : 2.99642e-04 	 MSE : 3.34113e-02
Validation Epoch 433 : 	 Train : 1.57418e-02 	 Res : 2.96073e-03 	 Jac : 1.27526e-02 	 Enc : 5.79112e-06 	 AE : 2.26977e-05 	 MSE : 1.73783e-02
Training Epoch 433 finished, took current epoch 363.17s, cumulative time 160986.40s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 434, 25% 	 Loss : 1.5814e-02 	 Res : 2.9717e-03 	 Jac : 1.2815e-02 	 Enc : 5.9074e-06 	 AEnc : 2.0743e-05 	 MSE : 2.6761e-02
Epoch 434, 50% 	 Loss : 1.5717e-02 	 Res : 2.9288e-03 	 Jac : 1.2762e-02 	 Enc : 5.8695e-06 	 AEnc : 2.0233e-05 	 MSE : 2.7991e-02
Epoch 434, 75% 	 Loss : 1.5729e-02 	 Res : 2.9528e-03 	 Jac : 1.2749e-02 	 Enc : 5.8203e-06 	 AEnc : 2.1184e-05 	 MSE : 2.7537e-02
Training Epoch 434 : 	 Train : 1.58829e-02 	 Res : 3.05216e-03 	 Jac : 1.28040e-02 	 Enc : 5.87680e-06 	 AE : 2.07853e-05 	 MSE : 5.93555e-02
Validation Epoch 434 : 	 Train : 1.60020e-02 	 Res : 3.18283e-03 	 Jac : 1.27925e-02 	 Enc : 6.04777e-06 	 AE : 2.06313e-05 	 MSE : 1.06806e-01
Training Epoch 434 finished, took current epoch 363.64s, cumulative time 161350.01s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 435, 25% 	 Loss : 1.6168e-02 	 Res : 3.3570e-03 	 Jac : 1.2782e-02 	 Enc : 6.1708e-06 	 AEnc : 2.3426e-05 	 MSE : 1.6731e-01
Epoch 435, 50% 	 Loss : 1.6191e-02 	 Res : 3.4067e-03 	 Jac : 1.2755e-02 	 Enc : 5.9633e-06 	 AEnc : 2.3637e-05 	 MSE : 1.9327e-01
Epoch 435, 75% 	 Loss : 1.6119e-02 	 Res : 3.3561e-03 	 Jac : 1.2736e-02 	 Enc : 6.1860e-06 	 AEnc : 2.0852e-05 	 MSE : 1.9875e-01
Training Epoch 435 : 	 Train : 1.61535e-02 	 Res : 3.38010e-03 	 Jac : 1.27450e-02 	 Enc : 6.12774e-06 	 AE : 2.23213e-05 	 MSE : 1.89848e-01
Validation Epoch 435 : 	 Train : 1.59487e-02 	 Res : 3.17773e-03 	 Jac : 1.27452e-02 	 Enc : 6.09307e-06 	 AE : 1.97206e-05 	 MSE : 9.97424e-02
Training Epoch 435 finished, took current epoch 363.08s, cumulative time 161713.08s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 436, 25% 	 Loss : 1.6085e-02 	 Res : 3.3667e-03 	 Jac : 1.2692e-02 	 Enc : 6.1409e-06 	 AEnc : 2.0755e-05 	 MSE : 1.9487e-01
Epoch 436, 50% 	 Loss : 1.6164e-02 	 Res : 3.3935e-03 	 Jac : 1.2743e-02 	 Enc : 6.3108e-06 	 AEnc : 2.0526e-05 	 MSE : 1.9303e-01
Epoch 436, 75% 	 Loss : 1.6147e-02 	 Res : 3.3079e-03 	 Jac : 1.2811e-02 	 Enc : 6.2762e-06 	 AEnc : 2.1680e-05 	 MSE : 1.5436e-01
Training Epoch 436 : 	 Train : 1.60439e-02 	 Res : 3.25608e-03 	 Jac : 1.27606e-02 	 Enc : 6.22186e-06 	 AE : 2.10158e-05 	 MSE : 1.43583e-01
Validation Epoch 436 : 	 Train : 1.56848e-02 	 Res : 3.00565e-03 	 Jac : 1.26520e-02 	 Enc : 6.00062e-06 	 AE : 2.11225e-05 	 MSE : 3.66095e-02
Training Epoch 436 finished, took current epoch 364.55s, cumulative time 162077.61s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 437, 25% 	 Loss : 1.5802e-02 	 Res : 2.9367e-03 	 Jac : 1.2838e-02 	 Enc : 6.0323e-06 	 AEnc : 2.1195e-05 	 MSE : 2.6985e-02
Epoch 437, 50% 	 Loss : 1.5798e-02 	 Res : 2.9593e-03 	 Jac : 1.2810e-02 	 Enc : 5.9910e-06 	 AEnc : 2.2264e-05 	 MSE : 3.3450e-02
Epoch 437, 75% 	 Loss : 1.5761e-02 	 Res : 2.9617e-03 	 Jac : 1.2767e-02 	 Enc : 6.1579e-06 	 AEnc : 2.6395e-05 	 MSE : 2.8461e-02
Training Epoch 437 : 	 Train : 1.57752e-02 	 Res : 2.96433e-03 	 Jac : 1.27816e-02 	 Enc : 5.99418e-06 	 AE : 2.31971e-05 	 MSE : 2.98227e-02
Validation Epoch 437 : 	 Train : 1.59178e-02 	 Res : 3.07204e-03 	 Jac : 1.28167e-02 	 Enc : 5.54583e-06 	 AE : 2.35418e-05 	 MSE : 6.39891e-02
Training Epoch 437 finished, took current epoch 365.09s, cumulative time 162442.69s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 438, 25% 	 Loss : 1.5761e-02 	 Res : 2.9037e-03 	 Jac : 1.2824e-02 	 Enc : 5.4967e-06 	 AEnc : 2.8150e-05 	 MSE : 2.2487e-02
Epoch 438, 50% 	 Loss : 1.5986e-02 	 Res : 2.9725e-03 	 Jac : 1.2790e-02 	 Enc : 5.8885e-06 	 AEnc : 2.1817e-04 	 MSE : 1.8246e-02
Epoch 438, 75% 	 Loss : 1.5987e-02 	 Res : 3.0823e-03 	 Jac : 1.2745e-02 	 Enc : 5.6749e-06 	 AEnc : 1.5402e-04 	 MSE : 3.1663e-02
Training Epoch 438 : 	 Train : 1.58656e-02 	 Res : 2.96572e-03 	 Jac : 1.27867e-02 	 Enc : 5.66773e-06 	 AE : 1.07473e-04 	 MSE : 2.47593e-02
Validation Epoch 438 : 	 Train : 1.57875e-02 	 Res : 2.96995e-03 	 Jac : 1.27843e-02 	 Enc : 5.65521e-06 	 AE : 2.75967e-05 	 MSE : 2.00971e-02
Training Epoch 438 finished, took current epoch 363.22s, cumulative time 162805.90s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 439, 25% 	 Loss : 1.5876e-02 	 Res : 3.0342e-03 	 Jac : 1.2814e-02 	 Enc : 5.6287e-06 	 AEnc : 2.2205e-05 	 MSE : 2.7358e-02
Epoch 439, 50% 	 Loss : 1.5690e-02 	 Res : 2.9153e-03 	 Jac : 1.2746e-02 	 Enc : 5.8336e-06 	 AEnc : 2.2233e-05 	 MSE : 2.6111e-02
Epoch 439, 75% 	 Loss : 1.5749e-02 	 Res : 2.9520e-03 	 Jac : 1.2769e-02 	 Enc : 5.8874e-06 	 AEnc : 2.1283e-05 	 MSE : 2.9172e-02
Training Epoch 439 : 	 Train : 1.57503e-02 	 Res : 2.95482e-03 	 Jac : 1.27680e-02 	 Enc : 5.76046e-06 	 AE : 2.17288e-05 	 MSE : 2.75628e-02
Validation Epoch 439 : 	 Train : 1.57945e-02 	 Res : 3.03694e-03 	 Jac : 1.27319e-02 	 Enc : 5.66894e-06 	 AE : 1.99144e-05 	 MSE : 4.59890e-02
Training Epoch 439 finished, took current epoch 365.03s, cumulative time 163170.92s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 440, 25% 	 Loss : 1.5817e-02 	 Res : 2.9741e-03 	 Jac : 1.2816e-02 	 Enc : 5.6333e-06 	 AEnc : 2.2008e-05 	 MSE : 2.9284e-02
Epoch 440, 50% 	 Loss : 1.5690e-02 	 Res : 3.0006e-03 	 Jac : 1.2662e-02 	 Enc : 5.5760e-06 	 AEnc : 2.1292e-05 	 MSE : 2.5875e-02
Epoch 440, 75% 	 Loss : 1.5669e-02 	 Res : 2.8984e-03 	 Jac : 1.2743e-02 	 Enc : 5.7571e-06 	 AEnc : 2.1786e-05 	 MSE : 2.7016e-02
Training Epoch 440 : 	 Train : 1.57158e-02 	 Res : 2.95384e-03 	 Jac : 1.27347e-02 	 Enc : 5.69984e-06 	 AE : 2.15303e-05 	 MSE : 2.69279e-02
Validation Epoch 440 : 	 Train : 1.58521e-02 	 Res : 3.00171e-03 	 Jac : 1.28229e-02 	 Enc : 5.67563e-06 	 AE : 2.19082e-05 	 MSE : 3.33004e-02
Training Epoch 440 finished, took current epoch 363.76s, cumulative time 163534.60s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 441, 25% 	 Loss : 1.5712e-02 	 Res : 2.9307e-03 	 Jac : 1.2755e-02 	 Enc : 5.6021e-06 	 AEnc : 2.1186e-05 	 MSE : 2.5863e-02
Epoch 441, 50% 	 Loss : 1.5790e-02 	 Res : 2.9369e-03 	 Jac : 1.2825e-02 	 Enc : 5.7562e-06 	 AEnc : 2.1743e-05 	 MSE : 2.6183e-02
Epoch 441, 75% 	 Loss : 1.5830e-02 	 Res : 2.9658e-03 	 Jac : 1.2838e-02 	 Enc : 5.8418e-06 	 AEnc : 2.0947e-05 	 MSE : 2.6267e-02
Training Epoch 441 : 	 Train : 1.57723e-02 	 Res : 2.95160e-03 	 Jac : 1.27934e-02 	 Enc : 5.76947e-06 	 AE : 2.15149e-05 	 MSE : 2.66150e-02
Validation Epoch 441 : 	 Train : 1.57632e-02 	 Res : 2.99760e-03 	 Jac : 1.27381e-02 	 Enc : 5.79184e-06 	 AE : 2.17159e-05 	 MSE : 3.29197e-02
Training Epoch 441 finished, took current epoch 363.51s, cumulative time 163898.09s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 442, 25% 	 Loss : 1.5801e-02 	 Res : 2.9756e-03 	 Jac : 1.2799e-02 	 Enc : 5.7431e-06 	 AEnc : 2.0972e-05 	 MSE : 4.0365e-02
Epoch 442, 50% 	 Loss : 1.5802e-02 	 Res : 2.9501e-03 	 Jac : 1.2825e-02 	 Enc : 5.7819e-06 	 AEnc : 2.0528e-05 	 MSE : 2.5004e-02
Epoch 442, 75% 	 Loss : 1.5869e-02 	 Res : 2.9883e-03 	 Jac : 1.2853e-02 	 Enc : 5.6509e-06 	 AEnc : 2.2708e-05 	 MSE : 3.4987e-02
Training Epoch 442 : 	 Train : 1.58243e-02 	 Res : 2.98171e-03 	 Jac : 1.28149e-02 	 Enc : 5.74581e-06 	 AE : 2.19660e-05 	 MSE : 3.51005e-02
Validation Epoch 442 : 	 Train : 1.58562e-02 	 Res : 3.06266e-03 	 Jac : 1.27599e-02 	 Enc : 6.21578e-06 	 AE : 2.74052e-05 	 MSE : 5.33426e-02
Training Epoch 442 finished, took current epoch 365.07s, cumulative time 164263.14s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 443, 25% 	 Loss : 1.5785e-02 	 Res : 3.0189e-03 	 Jac : 1.2733e-02 	 Enc : 6.1108e-06 	 AEnc : 2.6925e-05 	 MSE : 3.4489e-02
Epoch 443, 50% 	 Loss : 1.5728e-02 	 Res : 2.9292e-03 	 Jac : 1.2756e-02 	 Enc : 5.6571e-06 	 AEnc : 3.6462e-05 	 MSE : 2.5161e-02
Epoch 443, 75% 	 Loss : 1.5927e-02 	 Res : 2.9392e-03 	 Jac : 1.2836e-02 	 Enc : 6.3298e-06 	 AEnc : 1.4586e-04 	 MSE : 1.8237e-02
Training Epoch 443 : 	 Train : 1.58318e-02 	 Res : 2.96294e-03 	 Jac : 1.27757e-02 	 Enc : 6.12293e-06 	 AE : 8.70372e-05 	 MSE : 2.54109e-02
Validation Epoch 443 : 	 Train : 1.62406e-02 	 Res : 3.05026e-03 	 Jac : 1.27354e-02 	 Enc : 6.54206e-06 	 AE : 4.48466e-04 	 MSE : 1.97814e-02
Training Epoch 443 finished, took current epoch 365.90s, cumulative time 164629.00s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 444, 25% 	 Loss : 1.6190e-02 	 Res : 2.9775e-03 	 Jac : 1.2833e-02 	 Enc : 6.5514e-06 	 AEnc : 3.7328e-04 	 MSE : 2.5272e-02
Epoch 444, 50% 	 Loss : 1.5949e-02 	 Res : 3.0792e-03 	 Jac : 1.2788e-02 	 Enc : 6.0479e-06 	 AEnc : 7.6363e-05 	 MSE : 7.9283e-02
Epoch 444, 75% 	 Loss : 1.6055e-02 	 Res : 3.2035e-03 	 Jac : 1.2812e-02 	 Enc : 6.1359e-06 	 AEnc : 3.2997e-05 	 MSE : 1.2091e-01
Training Epoch 444 : 	 Train : 1.60086e-02 	 Res : 3.06889e-03 	 Jac : 1.28045e-02 	 Enc : 6.18698e-06 	 AE : 1.29103e-04 	 MSE : 6.37042e-02
Validation Epoch 444 : 	 Train : 1.57941e-02 	 Res : 3.00561e-03 	 Jac : 1.27621e-02 	 Enc : 6.01656e-06 	 AE : 2.03975e-05 	 MSE : 2.75299e-02
Training Epoch 444 finished, took current epoch 365.20s, cumulative time 164994.17s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 445, 25% 	 Loss : 1.5815e-02 	 Res : 2.9547e-03 	 Jac : 1.2833e-02 	 Enc : 5.9426e-06 	 AEnc : 2.0837e-05 	 MSE : 2.6678e-02
Epoch 445, 50% 	 Loss : 1.5778e-02 	 Res : 2.9834e-03 	 Jac : 1.2766e-02 	 Enc : 5.8939e-06 	 AEnc : 2.2136e-05 	 MSE : 3.4432e-02
Epoch 445, 75% 	 Loss : 1.5778e-02 	 Res : 2.9883e-03 	 Jac : 1.2733e-02 	 Enc : 5.8664e-06 	 AEnc : 5.1048e-05 	 MSE : 4.8531e-02
Training Epoch 445 : 	 Train : 1.58212e-02 	 Res : 2.97323e-03 	 Jac : 1.28051e-02 	 Enc : 5.91587e-06 	 AE : 3.69641e-05 	 MSE : 3.36612e-02
Validation Epoch 445 : 	 Train : 1.57210e-02 	 Res : 2.95428e-03 	 Jac : 1.27353e-02 	 Enc : 5.73376e-06 	 AE : 2.56928e-05 	 MSE : 1.67976e-02
Training Epoch 445 finished, took current epoch 362.82s, cumulative time 165356.98s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 446, 25% 	 Loss : 1.5790e-02 	 Res : 3.0144e-03 	 Jac : 1.2744e-02 	 Enc : 5.7300e-06 	 AEnc : 2.6064e-05 	 MSE : 2.9077e-02
Epoch 446, 50% 	 Loss : 1.5781e-02 	 Res : 3.0224e-03 	 Jac : 1.2696e-02 	 Enc : 5.7442e-06 	 AEnc : 5.6218e-05 	 MSE : 3.0722e-02
Epoch 446, 75% 	 Loss : 1.5663e-02 	 Res : 2.9021e-03 	 Jac : 1.2721e-02 	 Enc : 5.8535e-06 	 AEnc : 3.3090e-05 	 MSE : 2.6749e-02
Training Epoch 446 : 	 Train : 1.57413e-02 	 Res : 2.95909e-03 	 Jac : 1.27412e-02 	 Enc : 5.78340e-06 	 AE : 3.52574e-05 	 MSE : 2.82518e-02
Validation Epoch 446 : 	 Train : 1.56743e-02 	 Res : 2.95554e-03 	 Jac : 1.26926e-02 	 Enc : 5.93366e-06 	 AE : 2.02389e-05 	 MSE : 1.91830e-02
Training Epoch 446 finished, took current epoch 361.76s, cumulative time 165718.73s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 447, 25% 	 Loss : 1.5773e-02 	 Res : 2.9033e-03 	 Jac : 1.2843e-02 	 Enc : 5.9083e-06 	 AEnc : 2.0659e-05 	 MSE : 2.5757e-02
Epoch 447, 50% 	 Loss : 1.5582e-02 	 Res : 2.8685e-03 	 Jac : 1.2687e-02 	 Enc : 5.7409e-06 	 AEnc : 2.0836e-05 	 MSE : 2.8170e-02
Epoch 447, 75% 	 Loss : 1.6008e-02 	 Res : 3.1299e-03 	 Jac : 1.2851e-02 	 Enc : 5.6311e-06 	 AEnc : 2.2292e-05 	 MSE : 8.0043e-02
Training Epoch 447 : 	 Train : 1.58418e-02 	 Res : 3.03352e-03 	 Jac : 1.27812e-02 	 Enc : 5.76637e-06 	 AE : 2.13684e-05 	 MSE : 5.98275e-02
Validation Epoch 447 : 	 Train : 1.58082e-02 	 Res : 3.08939e-03 	 Jac : 1.26927e-02 	 Enc : 5.85998e-06 	 AE : 2.01918e-05 	 MSE : 6.86401e-02
Training Epoch 447 finished, took current epoch 363.33s, cumulative time 166082.04s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 448, 25% 	 Loss : 1.5918e-02 	 Res : 3.1039e-03 	 Jac : 1.2788e-02 	 Enc : 6.0215e-06 	 AEnc : 2.0074e-05 	 MSE : 1.0850e-01
Epoch 448, 50% 	 Loss : 1.5949e-02 	 Res : 3.1820e-03 	 Jac : 1.2741e-02 	 Enc : 6.0078e-06 	 AEnc : 2.0040e-05 	 MSE : 1.1022e-01
Epoch 448, 75% 	 Loss : 1.5941e-02 	 Res : 3.1875e-03 	 Jac : 1.2727e-02 	 Enc : 5.9893e-06 	 AEnc : 2.0573e-05 	 MSE : 1.0801e-01
Training Epoch 448 : 	 Train : 1.59276e-02 	 Res : 3.16072e-03 	 Jac : 1.27404e-02 	 Enc : 5.97552e-06 	 AE : 2.04920e-05 	 MSE : 1.09987e-01
Validation Epoch 448 : 	 Train : 1.59203e-02 	 Res : 3.04957e-03 	 Jac : 1.28433e-02 	 Enc : 5.87225e-06 	 AE : 2.15753e-05 	 MSE : 4.67182e-02
Training Epoch 448 finished, took current epoch 365.06s, cumulative time 166447.06s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 449, 25% 	 Loss : 1.5959e-02 	 Res : 3.1280e-03 	 Jac : 1.2801e-02 	 Enc : 5.9134e-06 	 AEnc : 2.3992e-05 	 MSE : 1.0715e-01
Epoch 449, 50% 	 Loss : 1.5893e-02 	 Res : 3.1875e-03 	 Jac : 1.2677e-02 	 Enc : 5.8904e-06 	 AEnc : 2.2358e-05 	 MSE : 1.1077e-01
Epoch 449, 75% 	 Loss : 1.5964e-02 	 Res : 3.1746e-03 	 Jac : 1.2764e-02 	 Enc : 5.9012e-06 	 AEnc : 2.0366e-05 	 MSE : 1.0960e-01
Training Epoch 449 : 	 Train : 1.59503e-02 	 Res : 3.15792e-03 	 Jac : 1.27645e-02 	 Enc : 5.93287e-06 	 AE : 2.19008e-05 	 MSE : 1.09471e-01
Validation Epoch 449 : 	 Train : 1.59222e-02 	 Res : 3.05155e-03 	 Jac : 1.28440e-02 	 Enc : 5.91667e-06 	 AE : 2.07590e-05 	 MSE : 5.44390e-02
Training Epoch 449 finished, took current epoch 364.36s, cumulative time 166811.41s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 450, 25% 	 Loss : 1.5958e-02 	 Res : 3.1216e-03 	 Jac : 1.2810e-02 	 Enc : 5.9116e-06 	 AEnc : 2.0552e-05 	 MSE : 1.0738e-01
Epoch 450, 50% 	 Loss : 1.5928e-02 	 Res : 3.1960e-03 	 Jac : 1.2706e-02 	 Enc : 6.0672e-06 	 AEnc : 2.0159e-05 	 MSE : 1.1134e-01
Epoch 450, 75% 	 Loss : 1.5953e-02 	 Res : 3.1581e-03 	 Jac : 1.2769e-02 	 Enc : 6.0155e-06 	 AEnc : 2.0109e-05 	 MSE : 1.0852e-01
Training Epoch 450 : 	 Train : 1.59616e-02 	 Res : 3.16540e-03 	 Jac : 1.27698e-02 	 Enc : 6.01200e-06 	 AE : 2.03865e-05 	 MSE : 1.12213e-01
Validation Epoch 450 : 	 Train : 1.57328e-02 	 Res : 2.95951e-03 	 Jac : 1.27469e-02 	 Enc : 6.04087e-06 	 AE : 2.03653e-05 	 MSE : 2.08401e-02
Training Epoch 450 finished, took current epoch 366.13s, cumulative time 167177.53s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 451, 25% 	 Loss : 1.5935e-02 	 Res : 3.1479e-03 	 Jac : 1.2761e-02 	 Enc : 5.9796e-06 	 AEnc : 2.0858e-05 	 MSE : 1.0557e-01
Epoch 451, 50% 	 Loss : 1.5960e-02 	 Res : 3.1377e-03 	 Jac : 1.2795e-02 	 Enc : 5.9238e-06 	 AEnc : 2.1339e-05 	 MSE : 1.0637e-01
Epoch 451, 75% 	 Loss : 1.5896e-02 	 Res : 3.1474e-03 	 Jac : 1.2722e-02 	 Enc : 6.1575e-06 	 AEnc : 2.0516e-05 	 MSE : 1.1012e-01
Training Epoch 451 : 	 Train : 1.59644e-02 	 Res : 3.15878e-03 	 Jac : 1.27786e-02 	 Enc : 6.06774e-06 	 AE : 2.08949e-05 	 MSE : 1.08126e-01
Validation Epoch 451 : 	 Train : 1.58221e-02 	 Res : 2.96293e-03 	 Jac : 1.28327e-02 	 Enc : 6.17662e-06 	 AE : 2.03714e-05 	 MSE : 2.43637e-02
Training Epoch 451 finished, took current epoch 361.64s, cumulative time 167539.16s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 452, 25% 	 Loss : 1.6033e-02 	 Res : 3.1591e-03 	 Jac : 1.2847e-02 	 Enc : 6.1576e-06 	 AEnc : 2.0852e-05 	 MSE : 1.0775e-01
Epoch 452, 50% 	 Loss : 1.5985e-02 	 Res : 3.1704e-03 	 Jac : 1.2789e-02 	 Enc : 6.0652e-06 	 AEnc : 2.0180e-05 	 MSE : 1.1000e-01
Epoch 452, 75% 	 Loss : 1.6035e-02 	 Res : 3.1564e-03 	 Jac : 1.2852e-02 	 Enc : 6.1837e-06 	 AEnc : 2.0389e-05 	 MSE : 1.0880e-01
Training Epoch 452 : 	 Train : 1.60007e-02 	 Res : 3.15707e-03 	 Jac : 1.28171e-02 	 Enc : 6.12521e-06 	 AE : 2.04388e-05 	 MSE : 1.09778e-01
Validation Epoch 452 : 	 Train : 1.57406e-02 	 Res : 2.95895e-03 	 Jac : 1.27562e-02 	 Enc : 6.10187e-06 	 AE : 1.93302e-05 	 MSE : 2.02133e-02
Training Epoch 452 finished, took current epoch 363.25s, cumulative time 167902.39s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 453, 25% 	 Loss : 1.5986e-02 	 Res : 3.2160e-03 	 Jac : 1.2743e-02 	 Enc : 6.2150e-06 	 AEnc : 2.0515e-05 	 MSE : 1.0520e-01
Epoch 453, 50% 	 Loss : 1.6010e-02 	 Res : 3.2112e-03 	 Jac : 1.2771e-02 	 Enc : 6.2576e-06 	 AEnc : 2.1477e-05 	 MSE : 1.1976e-01
Epoch 453, 75% 	 Loss : 1.5933e-02 	 Res : 3.1089e-03 	 Jac : 1.2798e-02 	 Enc : 6.1454e-06 	 AEnc : 1.9514e-05 	 MSE : 1.1091e-01
Training Epoch 453 : 	 Train : 1.59345e-02 	 Res : 3.13881e-03 	 Jac : 1.27691e-02 	 Enc : 6.16371e-06 	 AE : 2.04013e-05 	 MSE : 1.02055e-01
Validation Epoch 453 : 	 Train : 1.57090e-02 	 Res : 2.97625e-03 	 Jac : 1.27062e-02 	 Enc : 6.04594e-06 	 AE : 2.05265e-05 	 MSE : 2.78578e-02
Training Epoch 453 finished, took current epoch 362.85s, cumulative time 168265.20s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 454, 25% 	 Loss : 1.5838e-02 	 Res : 2.9951e-03 	 Jac : 1.2816e-02 	 Enc : 5.9088e-06 	 AEnc : 2.0975e-05 	 MSE : 2.7486e-02
Epoch 454, 50% 	 Loss : 1.5672e-02 	 Res : 2.9225e-03 	 Jac : 1.2724e-02 	 Enc : 5.8008e-06 	 AEnc : 1.9754e-05 	 MSE : 2.6219e-02
Epoch 454, 75% 	 Loss : 1.5680e-02 	 Res : 2.9370e-03 	 Jac : 1.2717e-02 	 Enc : 5.6910e-06 	 AEnc : 2.0216e-05 	 MSE : 2.6549e-02
Training Epoch 454 : 	 Train : 1.57354e-02 	 Res : 2.94592e-03 	 Jac : 1.27633e-02 	 Enc : 5.81269e-06 	 AE : 2.03267e-05 	 MSE : 2.69367e-02
Validation Epoch 454 : 	 Train : 1.57316e-02 	 Res : 2.95413e-03 	 Jac : 1.27534e-02 	 Enc : 5.84205e-06 	 AE : 1.82060e-05 	 MSE : 2.07668e-02
Training Epoch 454 finished, took current epoch 362.95s, cumulative time 168628.11s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 455, 25% 	 Loss : 1.5691e-02 	 Res : 2.9075e-03 	 Jac : 1.2756e-02 	 Enc : 5.8439e-06 	 AEnc : 2.1415e-05 	 MSE : 2.7848e-02
Epoch 455, 50% 	 Loss : 1.5852e-02 	 Res : 2.9988e-03 	 Jac : 1.2826e-02 	 Enc : 5.8977e-06 	 AEnc : 2.1583e-05 	 MSE : 2.9544e-02
Epoch 455, 75% 	 Loss : 1.5794e-02 	 Res : 2.9318e-03 	 Jac : 1.2830e-02 	 Enc : 5.7777e-06 	 AEnc : 2.6311e-05 	 MSE : 3.2740e-02
Training Epoch 455 : 	 Train : 1.57923e-02 	 Res : 2.95364e-03 	 Jac : 1.28028e-02 	 Enc : 5.88094e-06 	 AE : 2.99272e-05 	 MSE : 2.94543e-02
Validation Epoch 455 : 	 Train : 1.57607e-02 	 Res : 2.95298e-03 	 Jac : 1.27673e-02 	 Enc : 5.61123e-06 	 AE : 3.48215e-05 	 MSE : 1.70816e-02
Training Epoch 455 finished, took current epoch 365.07s, cumulative time 168993.14s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 456, 25% 	 Loss : 1.5727e-02 	 Res : 2.9667e-03 	 Jac : 1.2713e-02 	 Enc : 5.7038e-06 	 AEnc : 4.1161e-05 	 MSE : 3.1149e-02
Epoch 456, 50% 	 Loss : 1.5694e-02 	 Res : 2.9467e-03 	 Jac : 1.2712e-02 	 Enc : 5.8253e-06 	 AEnc : 2.9969e-05 	 MSE : 2.6602e-02
Epoch 456, 75% 	 Loss : 1.5758e-02 	 Res : 2.9735e-03 	 Jac : 1.2723e-02 	 Enc : 5.8005e-06 	 AEnc : 5.5888e-05 	 MSE : 2.9711e-02
Training Epoch 456 : 	 Train : 1.57704e-02 	 Res : 2.95959e-03 	 Jac : 1.27519e-02 	 Enc : 5.77614e-06 	 AE : 5.31006e-05 	 MSE : 2.96932e-02
Validation Epoch 456 : 	 Train : 1.58818e-02 	 Res : 3.03159e-03 	 Jac : 1.27151e-02 	 Enc : 5.95882e-06 	 AE : 1.29136e-04 	 MSE : 4.30592e-02
Training Epoch 456 finished, took current epoch 364.53s, cumulative time 169357.66s
Current Learning rate DEQ : 3.0223145490365776e-05
Current Learning rate AUTOENC : 0.00015111572745182887
Epoch 457, 25% 	 Loss : 1.5990e-02 	 Res : 2.9372e-03 	 Jac : 1.2792e-02 	 Enc : 5.7714e-06 	 AEnc : 2.5493e-04 	 MSE : 2.8001e-02
Epoch 457, 50% 	 Loss : 1.5791e-02 	 Res : 2.9663e-03 	 Jac : 1.2736e-02 	 Enc : 5.6343e-06 	 AEnc : 8.3365e-05 	 MSE : 2.7338e-02
Epoch 457, 75% 	 Loss : 1.5728e-02 	 Res : 2.9717e-03 	 Jac : 1.2724e-02 	 Enc : 5.8575e-06 	 AEnc : 2.6106e-05 	 MSE : 3.2530e-02
Training Epoch 457 : 	 Train : 1.58336e-02 	 Res : 2.96410e-03 	 Jac : 1.27654e-02 	 Enc : 5.77930e-06 	 AE : 9.83846e-05 	 MSE : 2.87793e-02
Validation Epoch 457 : 	 Train : 1.57612e-02 	 Res : 2.99799e-03 	 Jac : 1.27387e-02 	 Enc : 5.65321e-06 	 AE : 1.88834e-05 	 MSE : 3.87360e-02
Training Epoch 457 finished, took current epoch 366.92s, cumulative time 169724.56s
Current Learning rate DEQ : 2.4178516392292623e-05
Current Learning rate AUTOENC : 0.0001208925819614631
Epoch 458, 25% 	 Loss : 1.5778e-02 	 Res : 2.9413e-03 	 Jac : 1.2810e-02 	 Enc : 5.6816e-06 	 AEnc : 2.0528e-05 	 MSE : 2.3431e-02
Epoch 458, 50% 	 Loss : 1.5739e-02 	 Res : 2.9132e-03 	 Jac : 1.2784e-02 	 Enc : 5.5577e-06 	 AEnc : 3.6873e-05 	 MSE : 3.0670e-02
Epoch 458, 75% 	 Loss : 1.5790e-02 	 Res : 2.9463e-03 	 Jac : 1.2816e-02 	 Enc : 5.6722e-06 	 AEnc : 2.2483e-05 	 MSE : 1.6229e-02
Training Epoch 458 : 	 Train : 1.57732e-02 	 Res : 2.93862e-03 	 Jac : 1.28031e-02 	 Enc : 5.65447e-06 	 AE : 2.58926e-05 	 MSE : 2.36328e-02
Validation Epoch 458 : 	 Train : 1.57201e-02 	 Res : 2.93468e-03 	 Jac : 1.27492e-02 	 Enc : 5.47379e-06 	 AE : 3.07198e-05 	 MSE : 1.39641e-02
Training Epoch 458 finished, took current epoch 363.55s, cumulative time 170088.03s
Current Learning rate DEQ : 2.4178516392292623e-05
Current Learning rate AUTOENC : 0.0001208925819614631
MODEL SAVED
Epoch 459, 25% 	 Loss : 1.5632e-02 	 Res : 2.8870e-03 	 Jac : 1.2716e-02 	 Enc : 5.5663e-06 	 AEnc : 2.3780e-05 	 MSE : 2.3598e-02
Epoch 459, 50% 	 Loss : 1.5904e-02 	 Res : 3.0702e-03 	 Jac : 1.2774e-02 	 Enc : 5.8994e-06 	 AEnc : 5.4207e-05 	 MSE : 6.2256e-02
Epoch 459, 75% 	 Loss : 1.5842e-02 	 Res : 2.9969e-03 	 Jac : 1.2788e-02 	 Enc : 5.9210e-06 	 AEnc : 5.1295e-05 	 MSE : 4.1396e-02
Training Epoch 459 : 	 Train : 1.58080e-02 	 Res : 2.98805e-03 	 Jac : 1.27754e-02 	 Enc : 5.77320e-06 	 AE : 3.88075e-05 	 MSE : 4.16000e-02
Validation Epoch 459 : 	 Train : 1.58552e-02 	 Res : 3.00034e-03 	 Jac : 1.28313e-02 	 Enc : 5.64590e-06 	 AE : 1.79862e-05 	 MSE : 3.83818e-02
Training Epoch 459 finished, took current epoch 363.24s, cumulative time 170451.26s
Current Learning rate DEQ : 2.4178516392292623e-05
Current Learning rate AUTOENC : 0.0001208925819614631
Epoch 460, 25% 	 Loss : 1.5877e-02 	 Res : 3.1144e-03 	 Jac : 1.2734e-02 	 Enc : 5.8340e-06 	 AEnc : 2.2732e-05 	 MSE : 9.7606e-02
Epoch 460, 50% 	 Loss : 1.5674e-02 	 Res : 2.9361e-03 	 Jac : 1.2710e-02 	 Enc : 5.8605e-06 	 AEnc : 2.1663e-05 	 MSE : 4.1884e-02
Epoch 460, 75% 	 Loss : 1.5741e-02 	 Res : 2.9954e-03 	 Jac : 1.2719e-02 	 Enc : 5.6656e-06 	 AEnc : 2.0859e-05 	 MSE : 4.0047e-02
Training Epoch 460 : 	 Train : 1.57638e-02 	 Res : 3.01797e-03 	 Jac : 1.27186e-02 	 Enc : 5.79687e-06 	 AE : 2.14132e-05 	 MSE : 5.53317e-02
Validation Epoch 460 : 	 Train : 1.57164e-02 	 Res : 2.95485e-03 	 Jac : 1.27347e-02 	 Enc : 5.80319e-06 	 AE : 2.10410e-05 	 MSE : 2.22701e-02
Training Epoch 460 finished, took current epoch 364.38s, cumulative time 170815.60s
Current Learning rate DEQ : 2.4178516392292623e-05
Current Learning rate AUTOENC : 0.0001208925819614631
Epoch 461, 25% 	 Loss : 1.5721e-02 	 Res : 3.0160e-03 	 Jac : 1.2678e-02 	 Enc : 5.9418e-06 	 AEnc : 2.1083e-05 	 MSE : 4.3815e-02
Epoch 461, 50% 	 Loss : 1.5648e-02 	 Res : 2.9229e-03 	 Jac : 1.2699e-02 	 Enc : 5.7546e-06 	 AEnc : 2.0123e-05 	 MSE : 3.1603e-02
Epoch 461, 75% 	 Loss : 1.5699e-02 	 Res : 2.9098e-03 	 Jac : 1.2762e-02 	 Enc : 5.4735e-06 	 AEnc : 2.0966e-05 	 MSE : 1.4896e-02
Training Epoch 461 : 	 Train : 1.56793e-02 	 Res : 2.94270e-03 	 Jac : 1.27103e-02 	 Enc : 5.63991e-06 	 AE : 2.06169e-05 	 MSE : 2.85351e-02
Validation Epoch 461 : 	 Train : 1.57307e-02 	 Res : 2.96227e-03 	 Jac : 1.27375e-02 	 Enc : 5.33959e-06 	 AE : 2.56120e-05 	 MSE : 2.45475e-02
Training Epoch 461 finished, took current epoch 363.18s, cumulative time 171178.71s
Current Learning rate DEQ : 2.4178516392292623e-05
Current Learning rate AUTOENC : 0.0001208925819614631
Epoch 462, 25% 	 Loss : 1.5720e-02 	 Res : 2.9259e-03 	 Jac : 1.2767e-02 	 Enc : 5.5701e-06 	 AEnc : 2.1448e-05 	 MSE : 2.2141e-02
Epoch 462, 50% 	 Loss : 1.5718e-02 	 Res : 2.9163e-03 	 Jac : 1.2776e-02 	 Enc : 5.6828e-06 	 AEnc : 2.0664e-05 	 MSE : 2.1338e-02
Epoch 462, 75% 	 Loss : 1.5801e-02 	 Res : 2.9658e-03 	 Jac : 1.2809e-02 	 Enc : 5.5593e-06 	 AEnc : 2.1389e-05 	 MSE : 2.8639e-02
Training Epoch 462 : 	 Train : 1.57488e-02 	 Res : 2.93416e-03 	 Jac : 1.27851e-02 	 Enc : 5.56072e-06 	 AE : 2.39814e-05 	 MSE : 2.41974e-02
Validation Epoch 462 : 	 Train : 1.56663e-02 	 Res : 2.94971e-03 	 Jac : 1.26861e-02 	 Enc : 5.45594e-06 	 AE : 2.51088e-05 	 MSE : 1.54474e-02
Training Epoch 462 finished, took current epoch 365.08s, cumulative time 171543.75s
Current Learning rate DEQ : 2.4178516392292623e-05
Current Learning rate AUTOENC : 0.0001208925819614631
Epoch 463, 25% 	 Loss : 1.5824e-02 	 Res : 2.9494e-03 	 Jac : 1.2847e-02 	 Enc : 5.6664e-06 	 AEnc : 2.2326e-05 	 MSE : 2.3297e-02
Epoch 463, 50% 	 Loss : 1.5738e-02 	 Res : 2.9196e-03 	 Jac : 1.2746e-02 	 Enc : 5.7578e-06 	 AEnc : 6.6350e-05 	 MSE : 2.1843e-02
Epoch 463, 75% 	 Loss : 1.5762e-02 	 Res : 2.9088e-03 	 Jac : 1.2772e-02 	 Enc : 5.4578e-06 	 AEnc : 7.5015e-05 	 MSE : 2.4560e-02
Training Epoch 463 : 	 Train : 1.57780e-02 	 Res : 2.93372e-03 	 Jac : 1.27914e-02 	 Enc : 5.57018e-06 	 AE : 4.72281e-05 	 MSE : 2.26134e-02
Validation Epoch 463 : 	 Train : 1.57295e-02 	 Res : 2.94223e-03 	 Jac : 1.27640e-02 	 Enc : 5.38321e-06 	 AE : 1.79014e-05 	 MSE : 1.63627e-02
Training Epoch 463 finished, took current epoch 364.90s, cumulative time 171908.60s
Current Learning rate DEQ : 2.4178516392292623e-05
Current Learning rate AUTOENC : 0.0001208925819614631
Epoch 464, 25% 	 Loss : 1.5743e-02 	 Res : 2.8955e-03 	 Jac : 1.2821e-02 	 Enc : 5.5112e-06 	 AEnc : 2.1271e-05 	 MSE : 2.1321e-02
Epoch 464, 50% 	 Loss : 1.5732e-02 	 Res : 2.9587e-03 	 Jac : 1.2746e-02 	 Enc : 5.5705e-06 	 AEnc : 2.1591e-05 	 MSE : 2.2815e-02
Epoch 464, 75% 	 Loss : 1.5780e-02 	 Res : 2.9096e-03 	 Jac : 1.2845e-02 	 Enc : 5.5936e-06 	 AEnc : 1.9816e-05 	 MSE : 2.1174e-02
Training Epoch 464 : 	 Train : 1.57743e-02 	 Res : 2.92658e-03 	 Jac : 1.28213e-02 	 Enc : 5.55920e-06 	 AE : 2.08221e-05 	 MSE : 2.17833e-02
Validation Epoch 464 : 	 Train : 1.58262e-02 	 Res : 2.98311e-03 	 Jac : 1.28177e-02 	 Enc : 5.48121e-06 	 AE : 1.99095e-05 	 MSE : 3.30214e-02
Training Epoch 464 finished, took current epoch 365.12s, cumulative time 172273.68s
Current Learning rate DEQ : 2.4178516392292623e-05
Current Learning rate AUTOENC : 0.0001208925819614631
Epoch 465, 25% 	 Loss : 1.5683e-02 	 Res : 2.9494e-03 	 Jac : 1.2707e-02 	 Enc : 5.6140e-06 	 AEnc : 2.0501e-05 	 MSE : 2.2689e-02
Epoch 465, 50% 	 Loss : 1.5737e-02 	 Res : 2.9291e-03 	 Jac : 1.2781e-02 	 Enc : 5.6491e-06 	 AEnc : 2.1220e-05 	 MSE : 2.1755e-02
Epoch 465, 75% 	 Loss : 1.5664e-02 	 Res : 2.9429e-03 	 Jac : 1.2692e-02 	 Enc : 5.7444e-06 	 AEnc : 2.2667e-05 	 MSE : 2.3713e-02
Training Epoch 465 : 	 Train : 1.56989e-02 	 Res : 2.92866e-03 	 Jac : 1.27422e-02 	 Enc : 5.65721e-06 	 AE : 2.22952e-05 	 MSE : 2.32147e-02
Validation Epoch 465 : 	 Train : 1.57050e-02 	 Res : 2.93577e-03 	 Jac : 1.27439e-02 	 Enc : 5.47590e-06 	 AE : 1.98652e-05 	 MSE : 1.35967e-02
Training Epoch 465 finished, took current epoch 365.88s, cumulative time 172639.52s
Current Learning rate DEQ : 2.4178516392292623e-05
Current Learning rate AUTOENC : 0.0001208925819614631
Epoch 466, 25% 	 Loss : 1.5758e-02 	 Res : 2.9644e-03 	 Jac : 1.2734e-02 	 Enc : 5.6412e-06 	 AEnc : 5.4246e-05 	 MSE : 1.7320e-02
Epoch 466, 50% 	 Loss : 1.5833e-02 	 Res : 2.8789e-03 	 Jac : 1.2797e-02 	 Enc : 5.5081e-06 	 AEnc : 1.5142e-04 	 MSE : 1.6933e-02
Epoch 466, 75% 	 Loss : 1.5905e-02 	 Res : 2.9762e-03 	 Jac : 1.2785e-02 	 Enc : 5.4359e-06 	 AEnc : 1.3801e-04 	 MSE : 2.5930e-02
Training Epoch 466 : 	 Train : 1.59621e-02 	 Res : 3.06959e-03 	 Jac : 1.27684e-02 	 Enc : 5.50871e-06 	 AE : 1.18612e-04 	 MSE : 5.83082e-02
Validation Epoch 466 : 	 Train : 1.60223e-02 	 Res : 2.99514e-03 	 Jac : 1.27532e-02 	 Enc : 5.55537e-06 	 AE : 2.68314e-04 	 MSE : 2.34714e-02
Training Epoch 466 finished, took current epoch 362.97s, cumulative time 173002.43s
Current Learning rate DEQ : 2.4178516392292623e-05
Current Learning rate AUTOENC : 0.0001208925819614631
Epoch 467, 25% 	 Loss : 1.5833e-02 	 Res : 2.9755e-03 	 Jac : 1.2771e-02 	 Enc : 5.6299e-06 	 AEnc : 8.0974e-05 	 MSE : 1.9425e-02
Epoch 467, 50% 	 Loss : 1.5800e-02 	 Res : 2.9482e-03 	 Jac : 1.2819e-02 	 Enc : 5.5223e-06 	 AEnc : 2.7076e-05 	 MSE : 2.1851e-02
Epoch 467, 75% 	 Loss : 1.5671e-02 	 Res : 2.8950e-03 	 Jac : 1.2734e-02 	 Enc : 5.6227e-06 	 AEnc : 3.6531e-05 	 MSE : 2.5919e-02
Training Epoch 467 : 	 Train : 1.57573e-02 	 Res : 2.94182e-03 	 Jac : 1.27547e-02 	 Enc : 5.54715e-06 	 AE : 5.51917e-05 	 MSE : 2.50282e-02
Validation Epoch 467 : 	 Train : 1.57828e-02 	 Res : 2.93134e-03 	 Jac : 1.27862e-02 	 Enc : 5.51311e-06 	 AE : 5.97751e-05 	 MSE : 1.17236e-02
Training Epoch 467 finished, took current epoch 364.45s, cumulative time 173366.84s
Current Learning rate DEQ : 2.4178516392292623e-05
Current Learning rate AUTOENC : 0.0001208925819614631
MODEL SAVED
Epoch 468, 25% 	 Loss : 1.5918e-02 	 Res : 2.9454e-03 	 Jac : 1.2752e-02 	 Enc : 5.5701e-06 	 AEnc : 2.1461e-04 	 MSE : 3.1806e-02
Epoch 468, 50% 	 Loss : 1.5872e-02 	 Res : 3.0300e-03 	 Jac : 1.2767e-02 	 Enc : 5.6174e-06 	 AEnc : 6.9466e-05 	 MSE : 4.3414e-02
Epoch 468, 75% 	 Loss : 1.5786e-02 	 Res : 2.9650e-03 	 Jac : 1.2789e-02 	 Enc : 5.5801e-06 	 AEnc : 2.7242e-05 	 MSE : 4.0468e-02
Training Epoch 468 : 	 Train : 1.58299e-02 	 Res : 2.97635e-03 	 Jac : 1.27635e-02 	 Enc : 5.61846e-06 	 AE : 8.43888e-05 	 MSE : 3.83019e-02
Validation Epoch 468 : 	 Train : 1.59268e-02 	 Res : 3.07928e-03 	 Jac : 1.28208e-02 	 Enc : 5.63855e-06 	 AE : 2.10960e-05 	 MSE : 7.23271e-02
Training Epoch 468 finished, took current epoch 365.44s, cumulative time 173732.23s
Current Learning rate DEQ : 2.4178516392292623e-05
Current Learning rate AUTOENC : 0.0001208925819614631
Epoch 469, 25% 	 Loss : 1.5692e-02 	 Res : 2.9958e-03 	 Jac : 1.2670e-02 	 Enc : 5.6485e-06 	 AEnc : 2.0321e-05 	 MSE : 4.2879e-02
Epoch 469, 50% 	 Loss : 1.6034e-02 	 Res : 3.1741e-03 	 Jac : 1.2833e-02 	 Enc : 5.5740e-06 	 AEnc : 2.1546e-05 	 MSE : 1.1914e-01
Epoch 469, 75% 	 Loss : 1.5855e-02 	 Res : 3.0874e-03 	 Jac : 1.2729e-02 	 Enc : 5.7444e-06 	 AEnc : 3.3054e-05 	 MSE : 8.6118e-02
Training Epoch 469 : 	 Train : 1.58034e-02 	 Res : 3.04319e-03 	 Jac : 1.27255e-02 	 Enc : 5.64532e-06 	 AE : 2.90577e-05 	 MSE : 6.72269e-02
Validation Epoch 469 : 	 Train : 1.57637e-02 	 Res : 2.95046e-03 	 Jac : 1.27583e-02 	 Enc : 5.48503e-06 	 AE : 4.94708e-05 	 MSE : 1.91122e-02
Training Epoch 469 finished, took current epoch 362.83s, cumulative time 174095.04s
Current Learning rate DEQ : 2.4178516392292623e-05
Current Learning rate AUTOENC : 0.0001208925819614631
Epoch 470, 25% 	 Loss : 1.5732e-02 	 Res : 2.9263e-03 	 Jac : 1.2765e-02 	 Enc : 5.5650e-06 	 AEnc : 3.5770e-05 	 MSE : 2.3434e-02
Epoch 470, 50% 	 Loss : 1.5744e-02 	 Res : 3.0097e-03 	 Jac : 1.2708e-02 	 Enc : 5.5734e-06 	 AEnc : 2.0654e-05 	 MSE : 3.7338e-02
Epoch 470, 75% 	 Loss : 1.5751e-02 	 Res : 2.9218e-03 	 Jac : 1.2801e-02 	 Enc : 5.6598e-06 	 AEnc : 2.2444e-05 	 MSE : 2.2689e-02
Training Epoch 470 : 	 Train : 1.57449e-02 	 Res : 2.93995e-03 	 Jac : 1.27745e-02 	 Enc : 5.56311e-06 	 AE : 2.48888e-05 	 MSE : 2.61459e-02
Validation Epoch 470 : 	 Train : 1.57577e-02 	 Res : 2.93459e-03 	 Jac : 1.27980e-02 	 Enc : 5.49847e-06 	 AE : 1.96961e-05 	 MSE : 1.50466e-02
Training Epoch 470 finished, took current epoch 363.18s, cumulative time 174458.21s
Current Learning rate DEQ : 2.4178516392292623e-05
Current Learning rate AUTOENC : 0.0001208925819614631
Epoch 471, 25% 	 Loss : 1.5881e-02 	 Res : 2.9400e-03 	 Jac : 1.2915e-02 	 Enc : 5.5479e-06 	 AEnc : 2.0180e-05 	 MSE : 2.2430e-02
Epoch 471, 50% 	 Loss : 1.5767e-02 	 Res : 2.9126e-03 	 Jac : 1.2827e-02 	 Enc : 5.5154e-06 	 AEnc : 2.2007e-05 	 MSE : 4.2281e-02
Epoch 471, 75% 	 Loss : 1.5654e-02 	 Res : 2.8610e-03 	 Jac : 1.2766e-02 	 Enc : 5.6004e-06 	 AEnc : 2.1398e-05 	 MSE : 1.9676e-02
Training Epoch 471 : 	 Train : 1.57921e-02 	 Res : 2.93582e-03 	 Jac : 1.28238e-02 	 Enc : 5.54895e-06 	 AE : 2.69226e-05 	 MSE : 2.61909e-02
Validation Epoch 471 : 	 Train : 1.58135e-02 	 Res : 2.98192e-03 	 Jac : 1.27615e-02 	 Enc : 5.67733e-06 	 AE : 6.43966e-05 	 MSE : 2.98234e-02
Training Epoch 471 finished, took current epoch 361.94s, cumulative time 174820.10s
Current Learning rate DEQ : 2.4178516392292623e-05
Current Learning rate AUTOENC : 0.0001208925819614631
Epoch 472, 25% 	 Loss : 1.5779e-02 	 Res : 2.9413e-03 	 Jac : 1.2800e-02 	 Enc : 5.5924e-06 	 AEnc : 3.1963e-05 	 MSE : 2.3320e-02
Epoch 472, 50% 	 Loss : 1.5673e-02 	 Res : 2.8857e-03 	 Jac : 1.2756e-02 	 Enc : 5.8479e-06 	 AEnc : 2.5812e-05 	 MSE : 2.1093e-02
Epoch 472, 75% 	 Loss : 1.5691e-02 	 Res : 2.9209e-03 	 Jac : 1.2743e-02 	 Enc : 5.4242e-06 	 AEnc : 2.1965e-05 	 MSE : 2.0710e-02
Training Epoch 472 : 	 Train : 1.57012e-02 	 Res : 2.92237e-03 	 Jac : 1.27482e-02 	 Enc : 5.59932e-06 	 AE : 2.51018e-05 	 MSE : 2.15640e-02
Validation Epoch 472 : 	 Train : 1.57604e-02 	 Res : 2.93626e-03 	 Jac : 1.27990e-02 	 Enc : 5.55061e-06 	 AE : 1.95640e-05 	 MSE : 1.58460e-02
Training Epoch 472 finished, took current epoch 361.46s, cumulative time 175181.53s
Current Learning rate DEQ : 2.4178516392292623e-05
Current Learning rate AUTOENC : 0.0001208925819614631
Epoch 473, 25% 	 Loss : 1.5679e-02 	 Res : 2.9053e-03 	 Jac : 1.2748e-02 	 Enc : 5.5472e-06 	 AEnc : 2.0414e-05 	 MSE : 2.1201e-02
Epoch 473, 50% 	 Loss : 1.5817e-02 	 Res : 3.0457e-03 	 Jac : 1.2745e-02 	 Enc : 5.3259e-06 	 AEnc : 2.0108e-05 	 MSE : 4.8442e-02
Epoch 473, 75% 	 Loss : 1.5796e-02 	 Res : 3.0311e-03 	 Jac : 1.2739e-02 	 Enc : 5.5959e-06 	 AEnc : 1.9791e-05 	 MSE : 7.7792e-02
Training Epoch 473 : 	 Train : 1.57755e-02 	 Res : 3.00853e-03 	 Jac : 1.27413e-02 	 Enc : 5.54042e-06 	 AE : 2.00767e-05 	 MSE : 5.56915e-02
Validation Epoch 473 : 	 Train : 1.60601e-02 	 Res : 3.21850e-03 	 Jac : 1.28179e-02 	 Enc : 5.58657e-06 	 AE : 1.81150e-05 	 MSE : 1.22294e-01
Training Epoch 473 finished, took current epoch 360.23s, cumulative time 175541.74s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 474, 25% 	 Loss : 1.5750e-02 	 Res : 2.9988e-03 	 Jac : 1.2723e-02 	 Enc : 5.5224e-06 	 AEnc : 2.2072e-05 	 MSE : 5.0190e-02
Epoch 474, 50% 	 Loss : 1.5822e-02 	 Res : 2.9412e-03 	 Jac : 1.2855e-02 	 Enc : 5.5875e-06 	 AEnc : 1.9935e-05 	 MSE : 1.8023e-02
Epoch 474, 75% 	 Loss : 1.5655e-02 	 Res : 2.9114e-03 	 Jac : 1.2718e-02 	 Enc : 5.4855e-06 	 AEnc : 2.0316e-05 	 MSE : 1.7577e-02
Training Epoch 474 : 	 Train : 1.57054e-02 	 Res : 2.93247e-03 	 Jac : 1.27470e-02 	 Enc : 5.49471e-06 	 AE : 2.04891e-05 	 MSE : 2.60742e-02
Validation Epoch 474 : 	 Train : 1.56842e-02 	 Res : 2.93775e-03 	 Jac : 1.27200e-02 	 Enc : 5.49051e-06 	 AE : 2.09444e-05 	 MSE : 1.70362e-02
Training Epoch 474 finished, took current epoch 363.03s, cumulative time 175904.75s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 475, 25% 	 Loss : 1.5797e-02 	 Res : 2.9908e-03 	 Jac : 1.2779e-02 	 Enc : 5.6497e-06 	 AEnc : 2.2057e-05 	 MSE : 1.8848e-02
Epoch 475, 50% 	 Loss : 1.5788e-02 	 Res : 2.9432e-03 	 Jac : 1.2817e-02 	 Enc : 5.5270e-06 	 AEnc : 2.1845e-05 	 MSE : 3.1057e-02
Epoch 475, 75% 	 Loss : 1.5639e-02 	 Res : 2.8942e-03 	 Jac : 1.2719e-02 	 Enc : 5.3045e-06 	 AEnc : 2.0045e-05 	 MSE : 2.9234e-02
Training Epoch 475 : 	 Train : 1.57269e-02 	 Res : 2.93376e-03 	 Jac : 1.27530e-02 	 Enc : 5.47069e-06 	 AE : 3.46770e-05 	 MSE : 2.49875e-02
Validation Epoch 475 : 	 Train : 1.59428e-02 	 Res : 2.94413e-03 	 Jac : 1.28834e-02 	 Enc : 5.48918e-06 	 AE : 1.09789e-04 	 MSE : 1.18190e-02
Training Epoch 475 finished, took current epoch 364.83s, cumulative time 176269.54s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 476, 25% 	 Loss : 1.5642e-02 	 Res : 2.8757e-03 	 Jac : 1.2710e-02 	 Enc : 5.5080e-06 	 AEnc : 5.1626e-05 	 MSE : 1.8556e-02
Epoch 476, 50% 	 Loss : 1.5731e-02 	 Res : 2.9789e-03 	 Jac : 1.2719e-02 	 Enc : 5.8579e-06 	 AEnc : 2.7550e-05 	 MSE : 1.8682e-02
Epoch 476, 75% 	 Loss : 1.5689e-02 	 Res : 2.9278e-03 	 Jac : 1.2736e-02 	 Enc : 5.4375e-06 	 AEnc : 1.9901e-05 	 MSE : 2.0820e-02
Training Epoch 476 : 	 Train : 1.56829e-02 	 Res : 2.91587e-03 	 Jac : 1.27288e-02 	 Enc : 5.57486e-06 	 AE : 3.25900e-05 	 MSE : 1.89989e-02
Validation Epoch 476 : 	 Train : 1.59883e-02 	 Res : 3.20851e-03 	 Jac : 1.27483e-02 	 Enc : 5.48564e-06 	 AE : 2.59846e-05 	 MSE : 1.13072e-01
Training Epoch 476 finished, took current epoch 364.54s, cumulative time 176634.04s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 477, 25% 	 Loss : 1.5652e-02 	 Res : 2.8627e-03 	 Jac : 1.2752e-02 	 Enc : 5.5003e-06 	 AEnc : 3.2613e-05 	 MSE : 1.6812e-02
Epoch 477, 50% 	 Loss : 1.5765e-02 	 Res : 2.9149e-03 	 Jac : 1.2737e-02 	 Enc : 5.4349e-06 	 AEnc : 1.0716e-04 	 MSE : 1.8523e-02
Epoch 477, 75% 	 Loss : 1.5882e-02 	 Res : 2.9862e-03 	 Jac : 1.2843e-02 	 Enc : 5.5402e-06 	 AEnc : 4.6556e-05 	 MSE : 3.1079e-02
Training Epoch 477 : 	 Train : 1.57690e-02 	 Res : 2.93198e-03 	 Jac : 1.27763e-02 	 Enc : 5.51871e-06 	 AE : 5.51898e-05 	 MSE : 2.44078e-02
Validation Epoch 477 : 	 Train : 1.60414e-02 	 Res : 3.04425e-03 	 Jac : 1.28526e-02 	 Enc : 5.70711e-06 	 AE : 1.38932e-04 	 MSE : 4.95981e-02
Training Epoch 477 finished, took current epoch 364.48s, cumulative time 176998.44s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 478, 25% 	 Loss : 1.5862e-02 	 Res : 2.9767e-03 	 Jac : 1.2761e-02 	 Enc : 5.7575e-06 	 AEnc : 1.1815e-04 	 MSE : 2.9118e-02
Epoch 478, 50% 	 Loss : 1.5679e-02 	 Res : 2.9350e-03 	 Jac : 1.2714e-02 	 Enc : 5.5279e-06 	 AEnc : 2.3717e-05 	 MSE : 2.8249e-02
Epoch 478, 75% 	 Loss : 1.5686e-02 	 Res : 2.9110e-03 	 Jac : 1.2750e-02 	 Enc : 5.4985e-06 	 AEnc : 1.9630e-05 	 MSE : 1.6729e-02
Training Epoch 478 : 	 Train : 1.57074e-02 	 Res : 2.92838e-03 	 Jac : 1.27269e-02 	 Enc : 5.55874e-06 	 AE : 4.65732e-05 	 MSE : 2.34410e-02
Validation Epoch 478 : 	 Train : 1.56499e-02 	 Res : 2.97075e-03 	 Jac : 1.26540e-02 	 Enc : 5.32369e-06 	 AE : 1.98395e-05 	 MSE : 2.71396e-02
Training Epoch 478 finished, took current epoch 365.28s, cumulative time 177363.67s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 479, 25% 	 Loss : 1.5668e-02 	 Res : 2.8866e-03 	 Jac : 1.2753e-02 	 Enc : 5.3053e-06 	 AEnc : 2.3068e-05 	 MSE : 1.7846e-02
Epoch 479, 50% 	 Loss : 1.5810e-02 	 Res : 2.9405e-03 	 Jac : 1.2831e-02 	 Enc : 5.3960e-06 	 AEnc : 3.2453e-05 	 MSE : 1.7834e-02
Epoch 479, 75% 	 Loss : 1.5598e-02 	 Res : 2.8650e-03 	 Jac : 1.2703e-02 	 Enc : 5.5043e-06 	 AEnc : 2.3778e-05 	 MSE : 1.8320e-02
Training Epoch 479 : 	 Train : 1.57047e-02 	 Res : 2.91242e-03 	 Jac : 1.27618e-02 	 Enc : 5.38987e-06 	 AE : 2.50976e-05 	 MSE : 1.80425e-02
Validation Epoch 479 : 	 Train : 1.57162e-02 	 Res : 2.94058e-03 	 Jac : 1.27452e-02 	 Enc : 5.51899e-06 	 AE : 2.49682e-05 	 MSE : 1.77152e-02
Training Epoch 479 finished, took current epoch 363.08s, cumulative time 177726.72s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 480, 25% 	 Loss : 1.5681e-02 	 Res : 2.9403e-03 	 Jac : 1.2713e-02 	 Enc : 5.5503e-06 	 AEnc : 2.2146e-05 	 MSE : 1.9078e-02
Epoch 480, 50% 	 Loss : 1.5702e-02 	 Res : 2.9410e-03 	 Jac : 1.2736e-02 	 Enc : 5.5058e-06 	 AEnc : 1.9703e-05 	 MSE : 1.8745e-02
Epoch 480, 75% 	 Loss : 1.5668e-02 	 Res : 2.8678e-03 	 Jac : 1.2773e-02 	 Enc : 5.5009e-06 	 AEnc : 2.0891e-05 	 MSE : 1.6074e-02
Training Epoch 480 : 	 Train : 1.56918e-02 	 Res : 2.90962e-03 	 Jac : 1.27562e-02 	 Enc : 5.55061e-06 	 AE : 2.04511e-05 	 MSE : 1.80439e-02
Validation Epoch 480 : 	 Train : 1.57019e-02 	 Res : 2.96169e-03 	 Jac : 1.27136e-02 	 Enc : 5.64758e-06 	 AE : 2.09487e-05 	 MSE : 2.51506e-02
Training Epoch 480 finished, took current epoch 363.50s, cumulative time 178090.17s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 481, 25% 	 Loss : 1.5713e-02 	 Res : 2.8998e-03 	 Jac : 1.2788e-02 	 Enc : 5.5120e-06 	 AEnc : 1.9476e-05 	 MSE : 1.9020e-02
Epoch 481, 50% 	 Loss : 1.5686e-02 	 Res : 2.8963e-03 	 Jac : 1.2764e-02 	 Enc : 5.3602e-06 	 AEnc : 1.9916e-05 	 MSE : 1.8740e-02
Epoch 481, 75% 	 Loss : 1.5746e-02 	 Res : 2.9274e-03 	 Jac : 1.2790e-02 	 Enc : 5.5750e-06 	 AEnc : 2.2850e-05 	 MSE : 2.2733e-02
Training Epoch 481 : 	 Train : 1.57122e-02 	 Res : 2.91364e-03 	 Jac : 1.27716e-02 	 Enc : 5.54326e-06 	 AE : 2.14323e-05 	 MSE : 1.99007e-02
Validation Epoch 481 : 	 Train : 1.58189e-02 	 Res : 2.96251e-03 	 Jac : 1.27988e-02 	 Enc : 5.80188e-06 	 AE : 5.17703e-05 	 MSE : 2.34334e-02
Training Epoch 481 finished, took current epoch 364.42s, cumulative time 178454.57s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 482, 25% 	 Loss : 1.6054e-02 	 Res : 3.1289e-03 	 Jac : 1.2786e-02 	 Enc : 5.7903e-06 	 AEnc : 1.3345e-04 	 MSE : 6.6929e-02
Epoch 482, 50% 	 Loss : 1.5600e-02 	 Res : 2.9208e-03 	 Jac : 1.2646e-02 	 Enc : 5.6841e-06 	 AEnc : 2.7188e-05 	 MSE : 2.9145e-02
Epoch 482, 75% 	 Loss : 1.5744e-02 	 Res : 2.9688e-03 	 Jac : 1.2750e-02 	 Enc : 5.7528e-06 	 AEnc : 1.9872e-05 	 MSE : 2.9254e-02
Training Epoch 482 : 	 Train : 1.57804e-02 	 Res : 2.99204e-03 	 Jac : 1.27318e-02 	 Enc : 5.70932e-06 	 AE : 5.08489e-05 	 MSE : 3.93274e-02
Validation Epoch 482 : 	 Train : 1.57288e-02 	 Res : 2.93693e-03 	 Jac : 1.27644e-02 	 Enc : 5.52769e-06 	 AE : 2.20340e-05 	 MSE : 1.86379e-02
Training Epoch 482 finished, took current epoch 365.63s, cumulative time 178820.14s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 483, 25% 	 Loss : 1.5734e-02 	 Res : 2.9460e-03 	 Jac : 1.2763e-02 	 Enc : 5.5373e-06 	 AEnc : 1.9332e-05 	 MSE : 2.9101e-02
Epoch 483, 50% 	 Loss : 1.5701e-02 	 Res : 2.9129e-03 	 Jac : 1.2764e-02 	 Enc : 5.4264e-06 	 AEnc : 1.9141e-05 	 MSE : 3.0632e-02
Epoch 483, 75% 	 Loss : 1.5785e-02 	 Res : 2.9711e-03 	 Jac : 1.2780e-02 	 Enc : 5.5023e-06 	 AEnc : 2.7994e-05 	 MSE : 3.1497e-02
Training Epoch 483 : 	 Train : 1.57612e-02 	 Res : 2.94142e-03 	 Jac : 1.27898e-02 	 Enc : 5.47568e-06 	 AE : 2.45035e-05 	 MSE : 3.04614e-02
Validation Epoch 483 : 	 Train : 1.57292e-02 	 Res : 2.92971e-03 	 Jac : 1.27758e-02 	 Enc : 5.42344e-06 	 AE : 1.83474e-05 	 MSE : 1.41566e-02
Training Epoch 483 finished, took current epoch 362.66s, cumulative time 179182.71s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
MODEL SAVED
Epoch 484, 25% 	 Loss : 1.5651e-02 	 Res : 2.9292e-03 	 Jac : 1.2696e-02 	 Enc : 5.4936e-06 	 AEnc : 1.9897e-05 	 MSE : 2.8952e-02
Epoch 484, 50% 	 Loss : 1.5797e-02 	 Res : 3.0498e-03 	 Jac : 1.2720e-02 	 Enc : 5.4680e-06 	 AEnc : 2.0919e-05 	 MSE : 4.8792e-02
Epoch 484, 75% 	 Loss : 1.5781e-02 	 Res : 2.9743e-03 	 Jac : 1.2782e-02 	 Enc : 5.5066e-06 	 AEnc : 1.9637e-05 	 MSE : 2.9734e-02
Training Epoch 484 : 	 Train : 1.57290e-02 	 Res : 2.96225e-03 	 Jac : 1.27414e-02 	 Enc : 5.48326e-06 	 AE : 1.99288e-05 	 MSE : 3.45416e-02
Validation Epoch 484 : 	 Train : 1.55819e-02 	 Res : 2.92973e-03 	 Jac : 1.26294e-02 	 Enc : 5.38614e-06 	 AE : 1.73273e-05 	 MSE : 1.47496e-02
Training Epoch 484 finished, took current epoch 363.58s, cumulative time 179546.28s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 485, 25% 	 Loss : 1.5808e-02 	 Res : 2.9618e-03 	 Jac : 1.2822e-02 	 Enc : 5.3908e-06 	 AEnc : 1.9357e-05 	 MSE : 2.9139e-02
Epoch 485, 50% 	 Loss : 1.5582e-02 	 Res : 2.8786e-03 	 Jac : 1.2678e-02 	 Enc : 5.3277e-06 	 AEnc : 1.9595e-05 	 MSE : 2.9866e-02
Epoch 485, 75% 	 Loss : 1.5786e-02 	 Res : 2.9720e-03 	 Jac : 1.2787e-02 	 Enc : 5.3718e-06 	 AEnc : 2.0951e-05 	 MSE : 3.1002e-02
Training Epoch 485 : 	 Train : 1.57517e-02 	 Res : 2.93789e-03 	 Jac : 1.27887e-02 	 Enc : 5.40442e-06 	 AE : 1.97277e-05 	 MSE : 3.00932e-02
Validation Epoch 485 : 	 Train : 1.56490e-02 	 Res : 2.92601e-03 	 Jac : 1.26986e-02 	 Enc : 5.44190e-06 	 AE : 1.89076e-05 	 MSE : 1.35902e-02
Training Epoch 485 finished, took current epoch 365.00s, cumulative time 179911.21s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
MODEL SAVED
Epoch 486, 25% 	 Loss : 1.5814e-02 	 Res : 3.0183e-03 	 Jac : 1.2770e-02 	 Enc : 5.5233e-06 	 AEnc : 1.9437e-05 	 MSE : 2.9086e-02
Epoch 486, 50% 	 Loss : 1.5703e-02 	 Res : 2.9120e-03 	 Jac : 1.2766e-02 	 Enc : 5.4408e-06 	 AEnc : 1.9720e-05 	 MSE : 3.0703e-02
Epoch 486, 75% 	 Loss : 1.5753e-02 	 Res : 2.9254e-03 	 Jac : 1.2803e-02 	 Enc : 5.4709e-06 	 AEnc : 1.9426e-05 	 MSE : 3.2184e-02
Training Epoch 486 : 	 Train : 1.57302e-02 	 Res : 2.93999e-03 	 Jac : 1.27652e-02 	 Enc : 5.44924e-06 	 AE : 1.95954e-05 	 MSE : 3.07240e-02
Validation Epoch 486 : 	 Train : 1.56728e-02 	 Res : 2.93852e-03 	 Jac : 1.27070e-02 	 Enc : 5.44608e-06 	 AE : 2.18594e-05 	 MSE : 1.74786e-02
Training Epoch 486 finished, took current epoch 362.02s, cumulative time 180273.18s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 487, 25% 	 Loss : 1.5801e-02 	 Res : 3.0223e-03 	 Jac : 1.2746e-02 	 Enc : 5.5423e-06 	 AEnc : 2.7246e-05 	 MSE : 6.9258e-02
Epoch 487, 50% 	 Loss : 1.5885e-02 	 Res : 3.0694e-03 	 Jac : 1.2772e-02 	 Enc : 5.8066e-06 	 AEnc : 3.7763e-05 	 MSE : 5.8602e-02
Epoch 487, 75% 	 Loss : 1.5736e-02 	 Res : 2.9113e-03 	 Jac : 1.2796e-02 	 Enc : 5.6354e-06 	 AEnc : 2.2534e-05 	 MSE : 1.6762e-02
Training Epoch 487 : 	 Train : 1.57717e-02 	 Res : 2.97053e-03 	 Jac : 1.27681e-02 	 Enc : 5.63236e-06 	 AE : 2.73881e-05 	 MSE : 4.06550e-02
Validation Epoch 487 : 	 Train : 1.56117e-02 	 Res : 2.92711e-03 	 Jac : 1.26554e-02 	 Enc : 5.77996e-06 	 AE : 2.34493e-05 	 MSE : 1.30333e-02
Training Epoch 487 finished, took current epoch 361.77s, cumulative time 180634.91s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 488, 25% 	 Loss : 1.5767e-02 	 Res : 2.9417e-03 	 Jac : 1.2792e-02 	 Enc : 5.5894e-06 	 AEnc : 2.7761e-05 	 MSE : 2.3829e-02
Epoch 488, 50% 	 Loss : 1.5855e-02 	 Res : 2.9220e-03 	 Jac : 1.2782e-02 	 Enc : 5.6247e-06 	 AEnc : 1.4572e-04 	 MSE : 2.0008e-02
Epoch 488, 75% 	 Loss : 1.6010e-02 	 Res : 3.0496e-03 	 Jac : 1.2711e-02 	 Enc : 5.3557e-06 	 AEnc : 2.4490e-04 	 MSE : 6.2941e-02
Training Epoch 488 : 	 Train : 1.58771e-02 	 Res : 2.97474e-03 	 Jac : 1.27562e-02 	 Enc : 5.50779e-06 	 AE : 1.40656e-04 	 MSE : 3.34188e-02
Validation Epoch 488 : 	 Train : 1.57749e-02 	 Res : 2.93169e-03 	 Jac : 1.27976e-02 	 Enc : 5.37605e-06 	 AE : 4.01645e-05 	 MSE : 1.34278e-02
Training Epoch 488 finished, took current epoch 363.88s, cumulative time 180998.75s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 489, 25% 	 Loss : 1.5763e-02 	 Res : 2.9343e-03 	 Jac : 1.2775e-02 	 Enc : 5.3825e-06 	 AEnc : 4.8913e-05 	 MSE : 1.8367e-02
Epoch 489, 50% 	 Loss : 1.5623e-02 	 Res : 2.9053e-03 	 Jac : 1.2688e-02 	 Enc : 5.1983e-06 	 AEnc : 2.4448e-05 	 MSE : 2.1501e-02
Epoch 489, 75% 	 Loss : 1.5749e-02 	 Res : 2.9585e-03 	 Jac : 1.2766e-02 	 Enc : 5.3434e-06 	 AEnc : 1.9163e-05 	 MSE : 3.2174e-02
Training Epoch 489 : 	 Train : 1.57300e-02 	 Res : 2.92932e-03 	 Jac : 1.27672e-02 	 Enc : 5.33229e-06 	 AE : 2.81596e-05 	 MSE : 2.54531e-02
Validation Epoch 489 : 	 Train : 1.56891e-02 	 Res : 2.94797e-03 	 Jac : 1.27110e-02 	 Enc : 5.35764e-06 	 AE : 2.47834e-05 	 MSE : 2.29915e-02
Training Epoch 489 finished, took current epoch 365.54s, cumulative time 181364.24s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 490, 25% 	 Loss : 1.5798e-02 	 Res : 3.0105e-03 	 Jac : 1.2756e-02 	 Enc : 5.3338e-06 	 AEnc : 2.5902e-05 	 MSE : 5.6901e-02
Epoch 490, 50% 	 Loss : 1.5855e-02 	 Res : 2.9984e-03 	 Jac : 1.2767e-02 	 Enc : 5.5071e-06 	 AEnc : 8.4313e-05 	 MSE : 5.4241e-02
Epoch 490, 75% 	 Loss : 1.5858e-02 	 Res : 3.0501e-03 	 Jac : 1.2775e-02 	 Enc : 5.5864e-06 	 AEnc : 2.6999e-05 	 MSE : 5.5135e-02
Training Epoch 490 : 	 Train : 1.58025e-02 	 Res : 2.99867e-03 	 Jac : 1.27585e-02 	 Enc : 5.46768e-06 	 AE : 3.98346e-05 	 MSE : 5.11175e-02
Validation Epoch 490 : 	 Train : 1.57614e-02 	 Res : 2.93473e-03 	 Jac : 1.27905e-02 	 Enc : 5.52586e-06 	 AE : 3.06125e-05 	 MSE : 1.39725e-02
Training Epoch 490 finished, took current epoch 362.38s, cumulative time 181726.58s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 491, 25% 	 Loss : 1.5780e-02 	 Res : 2.9087e-03 	 Jac : 1.2845e-02 	 Enc : 5.5284e-06 	 AEnc : 2.0435e-05 	 MSE : 1.8416e-02
Epoch 491, 50% 	 Loss : 1.5639e-02 	 Res : 2.9032e-03 	 Jac : 1.2709e-02 	 Enc : 5.2794e-06 	 AEnc : 2.1468e-05 	 MSE : 2.8806e-02
Epoch 491, 75% 	 Loss : 1.5735e-02 	 Res : 2.9760e-03 	 Jac : 1.2734e-02 	 Enc : 5.3743e-06 	 AEnc : 1.9708e-05 	 MSE : 2.4577e-02
Training Epoch 491 : 	 Train : 1.57067e-02 	 Res : 2.92049e-03 	 Jac : 1.27604e-02 	 Enc : 5.34361e-06 	 AE : 2.04854e-05 	 MSE : 2.30370e-02
Validation Epoch 491 : 	 Train : 1.57368e-02 	 Res : 2.93819e-03 	 Jac : 1.27742e-02 	 Enc : 5.33911e-06 	 AE : 1.90645e-05 	 MSE : 1.99894e-02
Training Epoch 491 finished, took current epoch 362.85s, cumulative time 182089.37s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 492, 25% 	 Loss : 1.5573e-02 	 Res : 2.8459e-03 	 Jac : 1.2693e-02 	 Enc : 5.4811e-06 	 AEnc : 2.9103e-05 	 MSE : 1.7164e-02
Epoch 492, 50% 	 Loss : 1.5719e-02 	 Res : 2.9071e-03 	 Jac : 1.2772e-02 	 Enc : 5.5095e-06 	 AEnc : 3.3977e-05 	 MSE : 1.8197e-02
Epoch 492, 75% 	 Loss : 1.5782e-02 	 Res : 2.9349e-03 	 Jac : 1.2745e-02 	 Enc : 5.1965e-06 	 AEnc : 9.6883e-05 	 MSE : 1.7150e-02
Training Epoch 492 : 	 Train : 1.57015e-02 	 Res : 2.91259e-03 	 Jac : 1.27317e-02 	 Enc : 5.39761e-06 	 AE : 5.17487e-05 	 MSE : 1.79575e-02
Validation Epoch 492 : 	 Train : 1.56748e-02 	 Res : 2.92197e-03 	 Jac : 1.27112e-02 	 Enc : 5.46164e-06 	 AE : 3.61008e-05 	 MSE : 1.21494e-02
Training Epoch 492 finished, took current epoch 365.36s, cumulative time 182454.63s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
MODEL SAVED
Epoch 493, 25% 	 Loss : 1.5805e-02 	 Res : 2.9431e-03 	 Jac : 1.2790e-02 	 Enc : 5.3301e-06 	 AEnc : 6.6177e-05 	 MSE : 2.8345e-02
Epoch 493, 50% 	 Loss : 1.5905e-02 	 Res : 3.0455e-03 	 Jac : 1.2813e-02 	 Enc : 5.2419e-06 	 AEnc : 4.1187e-05 	 MSE : 4.0393e-02
Epoch 493, 75% 	 Loss : 1.5731e-02 	 Res : 2.9514e-03 	 Jac : 1.2746e-02 	 Enc : 5.2045e-06 	 AEnc : 2.8411e-05 	 MSE : 3.1083e-02
Training Epoch 493 : 	 Train : 1.57682e-02 	 Res : 2.95431e-03 	 Jac : 1.27675e-02 	 Enc : 5.29216e-06 	 AE : 4.11282e-05 	 MSE : 3.08717e-02
Validation Epoch 493 : 	 Train : 1.58332e-02 	 Res : 2.92833e-03 	 Jac : 1.28194e-02 	 Enc : 5.46825e-06 	 AE : 8.00493e-05 	 MSE : 1.07578e-02
Training Epoch 493 finished, took current epoch 361.42s, cumulative time 182815.99s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 494, 25% 	 Loss : 1.5731e-02 	 Res : 2.9239e-03 	 Jac : 1.2718e-02 	 Enc : 5.3698e-06 	 AEnc : 8.3005e-05 	 MSE : 2.1986e-02
Epoch 494, 50% 	 Loss : 1.5822e-02 	 Res : 2.9301e-03 	 Jac : 1.2809e-02 	 Enc : 5.5841e-06 	 AEnc : 7.7858e-05 	 MSE : 1.8245e-02
Epoch 494, 75% 	 Loss : 1.5752e-02 	 Res : 2.9499e-03 	 Jac : 1.2762e-02 	 Enc : 5.4109e-06 	 AEnc : 3.4504e-05 	 MSE : 1.4036e-02
Training Epoch 494 : 	 Train : 1.57273e-02 	 Res : 2.91503e-03 	 Jac : 1.27519e-02 	 Enc : 5.36685e-06 	 AE : 5.49810e-05 	 MSE : 1.87513e-02
Validation Epoch 494 : 	 Train : 1.55589e-02 	 Res : 2.96597e-03 	 Jac : 1.25634e-02 	 Enc : 5.05428e-06 	 AE : 2.44240e-05 	 MSE : 2.82011e-02
Training Epoch 494 finished, took current epoch 363.18s, cumulative time 183179.12s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 495, 25% 	 Loss : 1.5658e-02 	 Res : 2.8987e-03 	 Jac : 1.2734e-02 	 Enc : 5.2938e-06 	 AEnc : 1.9721e-05 	 MSE : 1.4875e-02
Epoch 495, 50% 	 Loss : 1.5773e-02 	 Res : 2.9308e-03 	 Jac : 1.2817e-02 	 Enc : 5.1400e-06 	 AEnc : 2.0582e-05 	 MSE : 2.1859e-02
Epoch 495, 75% 	 Loss : 1.5627e-02 	 Res : 2.9381e-03 	 Jac : 1.2665e-02 	 Enc : 5.2014e-06 	 AEnc : 1.9062e-05 	 MSE : 1.7020e-02
Training Epoch 495 : 	 Train : 1.56681e-02 	 Res : 2.90606e-03 	 Jac : 1.27374e-02 	 Enc : 5.18711e-06 	 AE : 1.94797e-05 	 MSE : 1.77934e-02
Validation Epoch 495 : 	 Train : 1.57167e-02 	 Res : 2.94410e-03 	 Jac : 1.27482e-02 	 Enc : 5.23784e-06 	 AE : 1.91941e-05 	 MSE : 2.16168e-02
Training Epoch 495 finished, took current epoch 363.25s, cumulative time 183542.34s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 496, 25% 	 Loss : 1.5749e-02 	 Res : 2.9748e-03 	 Jac : 1.2750e-02 	 Enc : 5.1776e-06 	 AEnc : 1.9548e-05 	 MSE : 1.8250e-02
Epoch 496, 50% 	 Loss : 1.5769e-02 	 Res : 2.9047e-03 	 Jac : 1.2840e-02 	 Enc : 5.3401e-06 	 AEnc : 1.8751e-05 	 MSE : 1.9338e-02
Epoch 496, 75% 	 Loss : 1.5599e-02 	 Res : 2.8803e-03 	 Jac : 1.2694e-02 	 Enc : 5.3392e-06 	 AEnc : 1.9505e-05 	 MSE : 1.7266e-02
Training Epoch 496 : 	 Train : 1.57010e-02 	 Res : 2.90412e-03 	 Jac : 1.27723e-02 	 Enc : 5.27756e-06 	 AE : 1.92675e-05 	 MSE : 1.80147e-02
Validation Epoch 496 : 	 Train : 1.56611e-02 	 Res : 2.92282e-03 	 Jac : 1.27153e-02 	 Enc : 5.21620e-06 	 AE : 1.77983e-05 	 MSE : 1.29925e-02
Training Epoch 496 finished, took current epoch 359.64s, cumulative time 183901.93s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 497, 25% 	 Loss : 1.5603e-02 	 Res : 2.8292e-03 	 Jac : 1.2750e-02 	 Enc : 5.2930e-06 	 AEnc : 1.8534e-05 	 MSE : 1.6852e-02
Epoch 497, 50% 	 Loss : 1.5658e-02 	 Res : 2.9562e-03 	 Jac : 1.2678e-02 	 Enc : 5.2040e-06 	 AEnc : 1.8623e-05 	 MSE : 1.7596e-02
Epoch 497, 75% 	 Loss : 1.5715e-02 	 Res : 2.9214e-03 	 Jac : 1.2769e-02 	 Enc : 5.2019e-06 	 AEnc : 1.9797e-05 	 MSE : 1.9722e-02
Training Epoch 497 : 	 Train : 1.56754e-02 	 Res : 2.91602e-03 	 Jac : 1.27335e-02 	 Enc : 5.23556e-06 	 AE : 2.06179e-05 	 MSE : 2.18084e-02
Validation Epoch 497 : 	 Train : 1.58601e-02 	 Res : 2.97793e-03 	 Jac : 1.28474e-02 	 Enc : 5.24341e-06 	 AE : 2.95133e-05 	 MSE : 3.18438e-02
Training Epoch 497 finished, took current epoch 362.18s, cumulative time 184264.07s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 498, 25% 	 Loss : 1.5727e-02 	 Res : 2.9384e-03 	 Jac : 1.2761e-02 	 Enc : 5.2944e-06 	 AEnc : 2.1889e-05 	 MSE : 3.2257e-02
Epoch 498, 50% 	 Loss : 1.5694e-02 	 Res : 2.9927e-03 	 Jac : 1.2676e-02 	 Enc : 5.3511e-06 	 AEnc : 1.9686e-05 	 MSE : 3.2596e-02
Epoch 498, 75% 	 Loss : 1.5774e-02 	 Res : 2.9246e-03 	 Jac : 1.2823e-02 	 Enc : 5.3952e-06 	 AEnc : 2.0577e-05 	 MSE : 2.6118e-02
Training Epoch 498 : 	 Train : 1.57183e-02 	 Res : 2.93622e-03 	 Jac : 1.27555e-02 	 Enc : 5.38485e-06 	 AE : 2.12017e-05 	 MSE : 2.78458e-02
Validation Epoch 498 : 	 Train : 1.57499e-02 	 Res : 2.97345e-03 	 Jac : 1.27520e-02 	 Enc : 5.46019e-06 	 AE : 1.90002e-05 	 MSE : 3.16866e-02
Training Epoch 498 finished, took current epoch 363.07s, cumulative time 184627.10s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 499, 25% 	 Loss : 1.5727e-02 	 Res : 2.9348e-03 	 Jac : 1.2760e-02 	 Enc : 5.4254e-06 	 AEnc : 2.7084e-05 	 MSE : 2.0677e-02
Epoch 499, 50% 	 Loss : 1.5824e-02 	 Res : 3.0755e-03 	 Jac : 1.2719e-02 	 Enc : 5.3993e-06 	 AEnc : 2.4000e-05 	 MSE : 6.4223e-02
Epoch 499, 75% 	 Loss : 1.5581e-02 	 Res : 2.8648e-03 	 Jac : 1.2690e-02 	 Enc : 5.5876e-06 	 AEnc : 2.0910e-05 	 MSE : 2.3277e-02
Training Epoch 499 : 	 Train : 1.56881e-02 	 Res : 2.94224e-03 	 Jac : 1.27151e-02 	 Enc : 5.46606e-06 	 AE : 2.52317e-05 	 MSE : 3.05164e-02
Validation Epoch 499 : 	 Train : 1.57673e-02 	 Res : 2.92442e-03 	 Jac : 1.28135e-02 	 Enc : 5.35701e-06 	 AE : 2.40685e-05 	 MSE : 1.26063e-02
Training Epoch 499 finished, took current epoch 363.10s, cumulative time 184990.16s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 500, 25% 	 Loss : 1.5718e-02 	 Res : 2.9498e-03 	 Jac : 1.2736e-02 	 Enc : 5.3362e-06 	 AEnc : 2.6924e-05 	 MSE : 1.5146e-02
Epoch 500, 50% 	 Loss : 1.5708e-02 	 Res : 2.9658e-03 	 Jac : 1.2714e-02 	 Enc : 5.7686e-06 	 AEnc : 2.2944e-05 	 MSE : 2.2090e-02
Epoch 500, 75% 	 Loss : 1.5631e-02 	 Res : 2.8725e-03 	 Jac : 1.2727e-02 	 Enc : 5.4341e-06 	 AEnc : 2.5366e-05 	 MSE : 1.7063e-02
Training Epoch 500 : 	 Train : 1.56666e-02 	 Res : 2.90735e-03 	 Jac : 1.27278e-02 	 Enc : 5.42748e-06 	 AE : 2.60501e-05 	 MSE : 1.82568e-02
Validation Epoch 500 : 	 Train : 1.57137e-02 	 Res : 2.91997e-03 	 Jac : 1.27452e-02 	 Enc : 5.19634e-06 	 AE : 4.34082e-05 	 MSE : 1.03804e-02
Training Epoch 500 finished, took current epoch 364.37s, cumulative time 185354.42s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
MODEL SAVED
Epoch 501, 25% 	 Loss : 1.5687e-02 	 Res : 2.8955e-03 	 Jac : 1.2714e-02 	 Enc : 5.2339e-06 	 AEnc : 7.2375e-05 	 MSE : 1.5033e-02
Epoch 501, 50% 	 Loss : 1.5684e-02 	 Res : 2.9294e-03 	 Jac : 1.2697e-02 	 Enc : 5.3574e-06 	 AEnc : 5.1758e-05 	 MSE : 1.4644e-02
Epoch 501, 75% 	 Loss : 1.5710e-02 	 Res : 2.9353e-03 	 Jac : 1.2701e-02 	 Enc : 5.3607e-06 	 AEnc : 6.8090e-05 	 MSE : 2.4237e-02
Training Epoch 501 : 	 Train : 1.56909e-02 	 Res : 2.92013e-03 	 Jac : 1.27068e-02 	 Enc : 5.24719e-06 	 AE : 5.87233e-05 	 MSE : 2.10710e-02
Validation Epoch 501 : 	 Train : 1.56740e-02 	 Res : 2.92593e-03 	 Jac : 1.27230e-02 	 Enc : 5.10502e-06 	 AE : 1.99577e-05 	 MSE : 1.58747e-02
Training Epoch 501 finished, took current epoch 361.25s, cumulative time 185715.63s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 502, 25% 	 Loss : 1.5689e-02 	 Res : 2.9322e-03 	 Jac : 1.2732e-02 	 Enc : 5.1799e-06 	 AEnc : 1.9841e-05 	 MSE : 3.1260e-02
Epoch 502, 50% 	 Loss : 1.5623e-02 	 Res : 2.9051e-03 	 Jac : 1.2693e-02 	 Enc : 5.3506e-06 	 AEnc : 1.9337e-05 	 MSE : 2.9659e-02
Epoch 502, 75% 	 Loss : 1.5790e-02 	 Res : 3.0363e-03 	 Jac : 1.2728e-02 	 Enc : 5.4606e-06 	 AEnc : 1.9300e-05 	 MSE : 6.4737e-02
Training Epoch 502 : 	 Train : 1.57010e-02 	 Res : 2.96521e-03 	 Jac : 1.27109e-02 	 Enc : 5.36934e-06 	 AE : 1.94881e-05 	 MSE : 3.94215e-02
Validation Epoch 502 : 	 Train : 1.57664e-02 	 Res : 2.92696e-03 	 Jac : 1.28160e-02 	 Enc : 5.47237e-06 	 AE : 1.79718e-05 	 MSE : 1.51622e-02
Training Epoch 502 finished, took current epoch 364.24s, cumulative time 186079.84s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 503, 25% 	 Loss : 1.6178e-02 	 Res : 3.3834e-03 	 Jac : 1.2769e-02 	 Enc : 5.4621e-06 	 AEnc : 1.9500e-05 	 MSE : 1.4443e-01
Epoch 503, 50% 	 Loss : 1.5566e-02 	 Res : 2.8931e-03 	 Jac : 1.2648e-02 	 Enc : 5.4357e-06 	 AEnc : 1.9154e-05 	 MSE : 3.0241e-02
Epoch 503, 75% 	 Loss : 1.5633e-02 	 Res : 2.8965e-03 	 Jac : 1.2710e-02 	 Enc : 5.5511e-06 	 AEnc : 2.0092e-05 	 MSE : 3.1770e-02
Training Epoch 503 : 	 Train : 1.58085e-02 	 Res : 3.04271e-03 	 Jac : 1.27409e-02 	 Enc : 5.53285e-06 	 AE : 1.93183e-05 	 MSE : 6.07841e-02
Validation Epoch 503 : 	 Train : 1.57216e-02 	 Res : 2.93787e-03 	 Jac : 1.27592e-02 	 Enc : 5.54420e-06 	 AE : 1.90652e-05 	 MSE : 1.94106e-02
Training Epoch 503 finished, took current epoch 362.54s, cumulative time 186442.34s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 504, 25% 	 Loss : 1.5658e-02 	 Res : 2.9045e-03 	 Jac : 1.2729e-02 	 Enc : 5.5534e-06 	 AEnc : 1.9518e-05 	 MSE : 3.1447e-02
Epoch 504, 50% 	 Loss : 1.5710e-02 	 Res : 2.9466e-03 	 Jac : 1.2739e-02 	 Enc : 5.3873e-06 	 AEnc : 1.9534e-05 	 MSE : 3.0832e-02
Epoch 504, 75% 	 Loss : 1.5729e-02 	 Res : 2.9198e-03 	 Jac : 1.2785e-02 	 Enc : 5.4911e-06 	 AEnc : 1.9220e-05 	 MSE : 3.2060e-02
Training Epoch 504 : 	 Train : 1.57260e-02 	 Res : 2.93692e-03 	 Jac : 1.27644e-02 	 Enc : 5.46840e-06 	 AE : 1.92660e-05 	 MSE : 3.16665e-02
Validation Epoch 504 : 	 Train : 1.56304e-02 	 Res : 2.92072e-03 	 Jac : 1.26856e-02 	 Enc : 5.38946e-06 	 AE : 1.86709e-05 	 MSE : 1.35858e-02
Training Epoch 504 finished, took current epoch 361.32s, cumulative time 186803.63s
Current Learning rate DEQ : 1.93428131138341e-05
Current Learning rate AUTOENC : 9.671406556917049e-05
Epoch 505, 25% 	 Loss : 1.5673e-02 	 Res : 2.9229e-03 	 Jac : 1.2727e-02 	 Enc : 5.3631e-06 	 AEnc : 1.8463e-05 	 MSE : 3.1922e-02
Epoch 505, 50% 	 Loss : 1.5728e-02 	 Res : 2.9607e-03 	 Jac : 1.2743e-02 	 Enc : 5.4305e-06 	 AEnc : 1.9650e-05 	 MSE : 3.0985e-02
Epoch 505, 75% 	 Loss : 1.5744e-02 	 Res : 2.9203e-03 	 Jac : 1.2799e-02 	 Enc : 5.5231e-06 	 AEnc : 1.9203e-05 	 MSE : 3.0296e-02
Training Epoch 505 : 	 Train : 1.57026e-02 	 Res : 2.93720e-03 	 Jac : 1.27408e-02 	 Enc : 5.43002e-06 	 AE : 1.91052e-05 	 MSE : 3.11610e-02
Validation Epoch 505 : 	 Train : 1.57101e-02 	 Res : 2.92602e-03 	 Jac : 1.27604e-02 	 Enc : 5.33524e-06 	 AE : 1.83403e-05 	 MSE : 1.63335e-02
Training Epoch 505 finished, took current epoch 364.40s, cumulative time 187167.99s
Current Learning rate DEQ : 1.547425049106728e-05
Current Learning rate AUTOENC : 7.73712524553364e-05
Epoch 506, 25% 	 Loss : 1.5651e-02 	 Res : 2.9372e-03 	 Jac : 1.2689e-02 	 Enc : 5.3665e-06 	 AEnc : 1.8853e-05 	 MSE : 2.3385e-02
Epoch 506, 50% 	 Loss : 1.5746e-02 	 Res : 2.9325e-03 	 Jac : 1.2785e-02 	 Enc : 5.4536e-06 	 AEnc : 2.3291e-05 	 MSE : 2.3108e-02
Epoch 506, 75% 	 Loss : 1.5647e-02 	 Res : 2.8941e-03 	 Jac : 1.2717e-02 	 Enc : 5.4543e-06 	 AEnc : 3.0416e-05 	 MSE : 2.4545e-02
Training Epoch 506 : 	 Train : 1.56866e-02 	 Res : 2.91778e-03 	 Jac : 1.27399e-02 	 Enc : 5.41018e-06 	 AE : 2.34682e-05 	 MSE : 2.37766e-02
Validation Epoch 506 : 	 Train : 1.56135e-02 	 Res : 2.92097e-03 	 Jac : 1.26678e-02 	 Enc : 5.36347e-06 	 AE : 1.93721e-05 	 MSE : 1.34707e-02
Training Epoch 506 finished, took current epoch 361.92s, cumulative time 187529.89s
Current Learning rate DEQ : 1.547425049106728e-05
Current Learning rate AUTOENC : 7.73712524553364e-05
Epoch 507, 25% 	 Loss : 1.5749e-02 	 Res : 2.9555e-03 	 Jac : 1.2768e-02 	 Enc : 5.4164e-06 	 AEnc : 1.9348e-05 	 MSE : 2.3954e-02
Epoch 507, 50% 	 Loss : 1.5767e-02 	 Res : 2.9398e-03 	 Jac : 1.2803e-02 	 Enc : 5.2178e-06 	 AEnc : 1.9652e-05 	 MSE : 1.6819e-02
Epoch 507, 75% 	 Loss : 1.5550e-02 	 Res : 2.8166e-03 	 Jac : 1.2707e-02 	 Enc : 5.4495e-06 	 AEnc : 2.1043e-05 	 MSE : 1.3256e-02
Training Epoch 507 : 	 Train : 1.57055e-02 	 Res : 2.91579e-03 	 Jac : 1.27629e-02 	 Enc : 5.33763e-06 	 AE : 2.14300e-05 	 MSE : 2.02428e-02
Validation Epoch 507 : 	 Train : 1.57513e-02 	 Res : 2.92545e-03 	 Jac : 1.27993e-02 	 Enc : 5.37082e-06 	 AE : 2.11903e-05 	 MSE : 1.50676e-02
Training Epoch 507 finished, took current epoch 362.72s, cumulative time 187892.60s
Current Learning rate DEQ : 1.547425049106728e-05
Current Learning rate AUTOENC : 7.73712524553364e-05
Epoch 508, 25% 	 Loss : 1.5726e-02 	 Res : 2.9014e-03 	 Jac : 1.2746e-02 	 Enc : 5.2756e-06 	 AEnc : 7.2700e-05 	 MSE : 1.7204e-02
Epoch 508, 50% 	 Loss : 1.5614e-02 	 Res : 2.8799e-03 	 Jac : 1.2701e-02 	 Enc : 5.3862e-06 	 AEnc : 2.7118e-05 	 MSE : 1.8725e-02
Epoch 508, 75% 	 Loss : 1.5738e-02 	 Res : 2.9679e-03 	 Jac : 1.2743e-02 	 Enc : 5.3895e-06 	 AEnc : 2.1752e-05 	 MSE : 1.8496e-02
Training Epoch 508 : 	 Train : 1.57916e-02 	 Res : 3.01977e-03 	 Jac : 1.27302e-02 	 Enc : 5.38066e-06 	 AE : 3.62046e-05 	 MSE : 4.66547e-02
Validation Epoch 508 : 	 Train : 1.57045e-02 	 Res : 2.91629e-03 	 Jac : 1.27606e-02 	 Enc : 5.35236e-06 	 AE : 2.22898e-05 	 MSE : 1.14074e-02
Training Epoch 508 finished, took current epoch 365.17s, cumulative time 188257.71s
Current Learning rate DEQ : 1.547425049106728e-05
Current Learning rate AUTOENC : 7.73712524553364e-05
MODEL SAVED
Epoch 509, 25% 	 Loss : 1.5676e-02 	 Res : 2.9160e-03 	 Jac : 1.2721e-02 	 Enc : 5.3847e-06 	 AEnc : 3.3514e-05 	 MSE : 1.9452e-02
Epoch 509, 50% 	 Loss : 1.5716e-02 	 Res : 2.8609e-03 	 Jac : 1.2807e-02 	 Enc : 5.3667e-06 	 AEnc : 4.2352e-05 	 MSE : 1.7314e-02
Epoch 509, 75% 	 Loss : 1.5738e-02 	 Res : 2.9055e-03 	 Jac : 1.2807e-02 	 Enc : 5.4497e-06 	 AEnc : 2.0854e-05 	 MSE : 1.3420e-02
Training Epoch 509 : 	 Train : 1.56950e-02 	 Res : 2.90171e-03 	 Jac : 1.27583e-02 	 Enc : 5.41646e-06 	 AE : 2.95865e-05 	 MSE : 1.64581e-02
Validation Epoch 509 : 	 Train : 1.56570e-02 	 Res : 2.91584e-03 	 Jac : 1.27063e-02 	 Enc : 5.42377e-06 	 AE : 2.94343e-05 	 MSE : 9.37693e-03
Training Epoch 509 finished, took current epoch 364.19s, cumulative time 188621.79s
Current Learning rate DEQ : 1.547425049106728e-05
Current Learning rate AUTOENC : 7.73712524553364e-05
MODEL SAVED
Epoch 510, 25% 	 Loss : 1.5628e-02 	 Res : 2.9086e-03 	 Jac : 1.2676e-02 	 Enc : 5.5002e-06 	 AEnc : 3.7913e-05 	 MSE : 1.5599e-02
Epoch 510, 50% 	 Loss : 1.5696e-02 	 Res : 2.9106e-03 	 Jac : 1.2756e-02 	 Enc : 5.5371e-06 	 AEnc : 2.4005e-05 	 MSE : 2.4377e-02
Epoch 510, 75% 	 Loss : 1.5649e-02 	 Res : 2.9124e-03 	 Jac : 1.2710e-02 	 Enc : 5.5856e-06 	 AEnc : 2.1122e-05 	 MSE : 3.9745e-02
Training Epoch 510 : 	 Train : 1.56661e-02 	 Res : 2.92788e-03 	 Jac : 1.27068e-02 	 Enc : 5.53293e-06 	 AE : 2.58860e-05 	 MSE : 2.73419e-02
Validation Epoch 510 : 	 Train : 1.56494e-02 	 Res : 2.94066e-03 	 Jac : 1.26850e-02 	 Enc : 5.33136e-06 	 AE : 1.83757e-05 	 MSE : 1.72984e-02
Training Epoch 510 finished, took current epoch 362.85s, cumulative time 188984.61s
Current Learning rate DEQ : 1.547425049106728e-05
Current Learning rate AUTOENC : 7.73712524553364e-05
Epoch 511, 25% 	 Loss : 1.5768e-02 	 Res : 2.9895e-03 	 Jac : 1.2747e-02 	 Enc : 5.2506e-06 	 AEnc : 2.6864e-05 	 MSE : 5.4771e-02
Epoch 511, 50% 	 Loss : 1.5756e-02 	 Res : 2.9633e-03 	 Jac : 1.2762e-02 	 Enc : 5.2862e-06 	 AEnc : 2.5855e-05 	 MSE : 3.5370e-02
Epoch 511, 75% 	 Loss : 1.5668e-02 	 Res : 2.9367e-03 	 Jac : 1.2693e-02 	 Enc : 5.5436e-06 	 AEnc : 3.2375e-05 	 MSE : 2.2555e-02
Training Epoch 511 : 	 Train : 1.57200e-02 	 Res : 2.94774e-03 	 Jac : 1.27314e-02 	 Enc : 5.46213e-06 	 AE : 3.54439e-05 	 MSE : 3.39532e-02
Validation Epoch 511 : 	 Train : 1.56743e-02 	 Res : 2.91408e-03 	 Jac : 1.27325e-02 	 Enc : 5.82020e-06 	 AE : 2.19083e-05 	 MSE : 9.99295e-03
Training Epoch 511 finished, took current epoch 361.45s, cumulative time 189346.00s
Current Learning rate DEQ : 1.547425049106728e-05
Current Learning rate AUTOENC : 7.73712524553364e-05
MODEL SAVED
Epoch 512, 25% 	 Loss : 1.5658e-02 	 Res : 2.9045e-03 	 Jac : 1.2724e-02 	 Enc : 5.5643e-06 	 AEnc : 2.3909e-05 	 MSE : 2.0155e-02
Epoch 512, 50% 	 Loss : 1.5642e-02 	 Res : 2.8750e-03 	 Jac : 1.2741e-02 	 Enc : 5.4422e-06 	 AEnc : 2.1009e-05 	 MSE : 4.5192e-02
Epoch 512, 75% 	 Loss : 1.5784e-02 	 Res : 3.0352e-03 	 Jac : 1.2722e-02 	 Enc : 5.5974e-06 	 AEnc : 2.0879e-05 	 MSE : 2.2748e-02
Training Epoch 512 : 	 Train : 1.56735e-02 	 Res : 2.92995e-03 	 Jac : 1.27162e-02 	 Enc : 5.53336e-06 	 AE : 2.18138e-05 	 MSE : 2.67341e-02
Validation Epoch 512 : 	 Train : 1.56466e-02 	 Res : 2.91080e-03 	 Jac : 1.27071e-02 	 Enc : 5.44668e-06 	 AE : 2.32082e-05 	 MSE : 8.80547e-03
Training Epoch 512 finished, took current epoch 364.80s, cumulative time 189710.69s
Current Learning rate DEQ : 1.547425049106728e-05
Current Learning rate AUTOENC : 7.73712524553364e-05
MODEL SAVED
Epoch 513, 25% 	 Loss : 1.5720e-02 	 Res : 2.8978e-03 	 Jac : 1.2793e-02 	 Enc : 5.3734e-06 	 AEnc : 2.3649e-05 	 MSE : 1.4998e-02
Epoch 513, 50% 	 Loss : 1.5696e-02 	 Res : 2.9295e-03 	 Jac : 1.2742e-02 	 Enc : 5.6988e-06 	 AEnc : 1.9200e-05 	 MSE : 1.8903e-02
Epoch 513, 75% 	 Loss : 1.5642e-02 	 Res : 2.9026e-03 	 Jac : 1.2715e-02 	 Enc : 5.6887e-06 	 AEnc : 1.9034e-05 	 MSE : 2.1910e-02
Training Epoch 513 : 	 Train : 1.56795e-02 	 Res : 2.90353e-03 	 Jac : 1.27496e-02 	 Enc : 5.55535e-06 	 AE : 2.08052e-05 	 MSE : 1.73435e-02
Validation Epoch 513 : 	 Train : 1.56906e-02 	 Res : 2.93185e-03 	 Jac : 1.27359e-02 	 Enc : 5.46314e-06 	 AE : 1.74307e-05 	 MSE : 1.33132e-02
Training Epoch 513 finished, took current epoch 364.95s, cumulative time 190075.60s
Current Learning rate DEQ : 1.547425049106728e-05
Current Learning rate AUTOENC : 7.73712524553364e-05
Epoch 514, 25% 	 Loss : 1.5625e-02 	 Res : 2.9037e-03 	 Jac : 1.2665e-02 	 Enc : 5.5157e-06 	 AEnc : 5.1015e-05 	 MSE : 1.8340e-02
Epoch 514, 50% 	 Loss : 1.5754e-02 	 Res : 2.9281e-03 	 Jac : 1.2652e-02 	 Enc : 5.4723e-06 	 AEnc : 1.6841e-04 	 MSE : 1.4025e-02
Epoch 514, 75% 	 Loss : 1.5905e-02 	 Res : 2.9076e-03 	 Jac : 1.2769e-02 	 Enc : 5.2982e-06 	 AEnc : 2.2309e-04 	 MSE : 1.8417e-02
Training Epoch 514 : 	 Train : 1.57673e-02 	 Res : 2.94124e-03 	 Jac : 1.26995e-02 	 Enc : 5.35375e-06 	 AE : 1.21137e-04 	 MSE : 2.67184e-02
Validation Epoch 514 : 	 Train : 1.56548e-02 	 Res : 2.91905e-03 	 Jac : 1.27136e-02 	 Enc : 5.20021e-06 	 AE : 1.69582e-05 	 MSE : 1.16513e-02
Training Epoch 514 finished, took current epoch 364.37s, cumulative time 190439.96s
Current Learning rate DEQ : 1.547425049106728e-05
Current Learning rate AUTOENC : 7.73712524553364e-05
Epoch 515, 25% 	 Loss : 1.5733e-02 	 Res : 2.9141e-03 	 Jac : 1.2790e-02 	 Enc : 5.2821e-06 	 AEnc : 2.3214e-05 	 MSE : 1.5237e-02
Epoch 515, 50% 	 Loss : 1.5631e-02 	 Res : 2.8849e-03 	 Jac : 1.2722e-02 	 Enc : 5.3510e-06 	 AEnc : 1.9308e-05 	 MSE : 1.0904e-02
Epoch 515, 75% 	 Loss : 1.5647e-02 	 Res : 2.8377e-03 	 Jac : 1.2784e-02 	 Enc : 5.3025e-06 	 AEnc : 1.9342e-05 	 MSE : 1.6038e-02
Training Epoch 515 : 	 Train : 1.56732e-02 	 Res : 2.89316e-03 	 Jac : 1.27546e-02 	 Enc : 5.30738e-06 	 AE : 2.01661e-05 	 MSE : 1.45209e-02
Validation Epoch 515 : 	 Train : 1.56351e-02 	 Res : 2.91068e-03 	 Jac : 1.27013e-02 	 Enc : 5.25308e-06 	 AE : 1.79199e-05 	 MSE : 9.00056e-03
Training Epoch 515 finished, took current epoch 366.01s, cumulative time 190805.92s
Current Learning rate DEQ : 1.547425049106728e-05
Current Learning rate AUTOENC : 7.73712524553364e-05
MODEL SAVED
Epoch 516, 25% 	 Loss : 1.5593e-02 	 Res : 2.9212e-03 	 Jac : 1.2647e-02 	 Enc : 5.2250e-06 	 AEnc : 2.0332e-05 	 MSE : 2.2550e-02
Epoch 516, 50% 	 Loss : 1.5713e-02 	 Res : 2.8957e-03 	 Jac : 1.2786e-02 	 Enc : 5.4936e-06 	 AEnc : 2.5761e-05 	 MSE : 2.3891e-02
Epoch 516, 75% 	 Loss : 1.5660e-02 	 Res : 2.8962e-03 	 Jac : 1.2735e-02 	 Enc : 5.2402e-06 	 AEnc : 2.3684e-05 	 MSE : 1.8923e-02
Training Epoch 516 : 	 Train : 1.56759e-02 	 Res : 2.91763e-03 	 Jac : 1.27310e-02 	 Enc : 5.26282e-06 	 AE : 2.20020e-05 	 MSE : 2.32749e-02
Validation Epoch 516 : 	 Train : 1.56653e-02 	 Res : 2.93053e-03 	 Jac : 1.27092e-02 	 Enc : 5.08478e-06 	 AE : 2.04569e-05 	 MSE : 1.73882e-02
Training Epoch 516 finished, took current epoch 364.10s, cumulative time 191169.98s
Current Learning rate DEQ : 1.2379400392853824e-05
Current Learning rate AUTOENC : 6.189700196426911e-05
Epoch 517, 25% 	 Loss : 1.5688e-02 	 Res : 2.9264e-03 	 Jac : 1.2735e-02 	 Enc : 5.3118e-06 	 AEnc : 2.1496e-05 	 MSE : 1.6641e-02
Epoch 517, 50% 	 Loss : 1.5592e-02 	 Res : 2.8493e-03 	 Jac : 1.2721e-02 	 Enc : 5.2727e-06 	 AEnc : 1.7316e-05 	 MSE : 1.1725e-02
Epoch 517, 75% 	 Loss : 1.5694e-02 	 Res : 2.9194e-03 	 Jac : 1.2693e-02 	 Enc : 5.4612e-06 	 AEnc : 7.5569e-05 	 MSE : 1.2577e-02
Training Epoch 517 : 	 Train : 1.56519e-02 	 Res : 2.91081e-03 	 Jac : 1.26990e-02 	 Enc : 5.42670e-06 	 AE : 3.66821e-05 	 MSE : 2.07621e-02
Validation Epoch 517 : 	 Train : 1.57368e-02 	 Res : 2.93590e-03 	 Jac : 1.27744e-02 	 Enc : 5.58090e-06 	 AE : 2.09194e-05 	 MSE : 1.88569e-02
Training Epoch 517 finished, took current epoch 363.74s, cumulative time 191533.68s
Current Learning rate DEQ : 1.2379400392853824e-05
Current Learning rate AUTOENC : 6.189700196426911e-05
Epoch 518, 25% 	 Loss : 1.5633e-02 	 Res : 2.8915e-03 	 Jac : 1.2713e-02 	 Enc : 5.6212e-06 	 AEnc : 2.2823e-05 	 MSE : 1.6242e-02
Epoch 518, 50% 	 Loss : 1.5675e-02 	 Res : 2.9167e-03 	 Jac : 1.2733e-02 	 Enc : 5.5529e-06 	 AEnc : 1.9320e-05 	 MSE : 1.4064e-02
Epoch 518, 75% 	 Loss : 1.5608e-02 	 Res : 2.8544e-03 	 Jac : 1.2730e-02 	 Enc : 5.3025e-06 	 AEnc : 1.8416e-05 	 MSE : 1.8428e-02
Training Epoch 518 : 	 Train : 1.56596e-02 	 Res : 2.90003e-03 	 Jac : 1.27339e-02 	 Enc : 5.42760e-06 	 AE : 2.02184e-05 	 MSE : 1.69329e-02
Validation Epoch 518 : 	 Train : 1.56501e-02 	 Res : 2.91235e-03 	 Jac : 1.27132e-02 	 Enc : 5.38717e-06 	 AE : 1.91272e-05 	 MSE : 1.04797e-02
Training Epoch 518 finished, took current epoch 364.87s, cumulative time 191898.53s
Current Learning rate DEQ : 1.2379400392853824e-05
Current Learning rate AUTOENC : 6.189700196426911e-05
Epoch 519, 25% 	 Loss : 1.5688e-02 	 Res : 2.8975e-03 	 Jac : 1.2765e-02 	 Enc : 5.5479e-06 	 AEnc : 1.9634e-05 	 MSE : 2.0478e-02
Epoch 519, 50% 	 Loss : 1.5609e-02 	 Res : 2.9047e-03 	 Jac : 1.2679e-02 	 Enc : 5.6702e-06 	 AEnc : 1.9972e-05 	 MSE : 1.1443e-02
Epoch 519, 75% 	 Loss : 1.5663e-02 	 Res : 2.9090e-03 	 Jac : 1.2728e-02 	 Enc : 5.3439e-06 	 AEnc : 2.0798e-05 	 MSE : 1.5340e-02
Training Epoch 519 : 	 Train : 1.56509e-02 	 Res : 2.89426e-03 	 Jac : 1.27311e-02 	 Enc : 5.45833e-06 	 AE : 2.01745e-05 	 MSE : 1.52240e-02
Validation Epoch 519 : 	 Train : 1.56687e-02 	 Res : 2.91987e-03 	 Jac : 1.27225e-02 	 Enc : 5.25334e-06 	 AE : 2.10935e-05 	 MSE : 1.00821e-02
Training Epoch 519 finished, took current epoch 362.91s, cumulative time 192261.42s
Current Learning rate DEQ : 1.2379400392853824e-05
Current Learning rate AUTOENC : 6.189700196426911e-05
Epoch 520, 25% 	 Loss : 1.5673e-02 	 Res : 2.8618e-03 	 Jac : 1.2775e-02 	 Enc : 5.2491e-06 	 AEnc : 3.0773e-05 	 MSE : 1.3987e-02
Epoch 520, 50% 	 Loss : 1.5645e-02 	 Res : 2.8935e-03 	 Jac : 1.2714e-02 	 Enc : 5.2867e-06 	 AEnc : 3.2046e-05 	 MSE : 1.3433e-02
Epoch 520, 75% 	 Loss : 1.5567e-02 	 Res : 2.8939e-03 	 Jac : 1.2647e-02 	 Enc : 5.2456e-06 	 AEnc : 2.1085e-05 	 MSE : 1.2799e-02
Training Epoch 520 : 	 Train : 1.56346e-02 	 Res : 2.89229e-03 	 Jac : 1.27111e-02 	 Enc : 5.28621e-06 	 AE : 2.58844e-05 	 MSE : 1.34812e-02
Validation Epoch 520 : 	 Train : 1.56169e-02 	 Res : 2.91638e-03 	 Jac : 1.26780e-02 	 Enc : 5.37737e-06 	 AE : 1.71263e-05 	 MSE : 1.22461e-02
Training Epoch 520 finished, took current epoch 362.86s, cumulative time 192624.24s
Current Learning rate DEQ : 1.2379400392853824e-05
Current Learning rate AUTOENC : 6.189700196426911e-05
Epoch 521, 25% 	 Loss : 1.5766e-02 	 Res : 2.9456e-03 	 Jac : 1.2796e-02 	 Enc : 5.5295e-06 	 AEnc : 1.8445e-05 	 MSE : 1.5774e-02
Epoch 521, 50% 	 Loss : 1.5698e-02 	 Res : 2.8964e-03 	 Jac : 1.2776e-02 	 Enc : 5.3357e-06 	 AEnc : 1.9365e-05 	 MSE : 1.4896e-02
Epoch 521, 75% 	 Loss : 1.5522e-02 	 Res : 2.8393e-03 	 Jac : 1.2653e-02 	 Enc : 5.2621e-06 	 AEnc : 2.4426e-05 	 MSE : 1.4061e-02
Training Epoch 521 : 	 Train : 1.56768e-02 	 Res : 2.89367e-03 	 Jac : 1.27566e-02 	 Enc : 5.34492e-06 	 AE : 2.12428e-05 	 MSE : 1.42164e-02
Validation Epoch 521 : 	 Train : 1.56352e-02 	 Res : 2.90956e-03 	 Jac : 1.27037e-02 	 Enc : 5.12236e-06 	 AE : 1.68913e-05 	 MSE : 9.86704e-03
Training Epoch 521 finished, took current epoch 360.99s, cumulative time 192985.20s
Current Learning rate DEQ : 1.2379400392853824e-05
Current Learning rate AUTOENC : 6.189700196426911e-05
MODEL SAVED
Epoch 522, 25% 	 Loss : 1.5737e-02 	 Res : 2.9360e-03 	 Jac : 1.2772e-02 	 Enc : 5.2435e-06 	 AEnc : 2.3870e-05 	 MSE : 1.4392e-02
Epoch 522, 50% 	 Loss : 1.5618e-02 	 Res : 2.8396e-03 	 Jac : 1.2752e-02 	 Enc : 5.3096e-06 	 AEnc : 2.1517e-05 	 MSE : 2.1232e-02
Epoch 522, 75% 	 Loss : 1.5638e-02 	 Res : 2.9003e-03 	 Jac : 1.2712e-02 	 Enc : 5.6594e-06 	 AEnc : 2.0071e-05 	 MSE : 1.6362e-02
Training Epoch 522 : 	 Train : 1.56441e-02 	 Res : 2.89765e-03 	 Jac : 1.27198e-02 	 Enc : 5.44433e-06 	 AE : 2.12306e-05 	 MSE : 1.64862e-02
Validation Epoch 522 : 	 Train : 1.56567e-02 	 Res : 2.91280e-03 	 Jac : 1.27165e-02 	 Enc : 5.48949e-06 	 AE : 2.18976e-05 	 MSE : 9.44052e-03
Training Epoch 522 finished, took current epoch 363.08s, cumulative time 193348.23s
Current Learning rate DEQ : 1.2379400392853824e-05
Current Learning rate AUTOENC : 6.189700196426911e-05
Epoch 523, 25% 	 Loss : 1.5686e-02 	 Res : 2.8668e-03 	 Jac : 1.2759e-02 	 Enc : 5.2745e-06 	 AEnc : 5.5482e-05 	 MSE : 1.2171e-02
Epoch 523, 50% 	 Loss : 1.5660e-02 	 Res : 2.8877e-03 	 Jac : 1.2745e-02 	 Enc : 5.1217e-06 	 AEnc : 2.1690e-05 	 MSE : 1.2345e-02
Epoch 523, 75% 	 Loss : 1.5684e-02 	 Res : 2.9117e-03 	 Jac : 1.2748e-02 	 Enc : 5.1331e-06 	 AEnc : 1.9274e-05 	 MSE : 1.5237e-02
Training Epoch 523 : 	 Train : 1.56610e-02 	 Res : 2.89387e-03 	 Jac : 1.27328e-02 	 Enc : 5.20612e-06 	 AE : 2.91264e-05 	 MSE : 1.45464e-02
Validation Epoch 523 : 	 Train : 1.57794e-02 	 Res : 2.96081e-03 	 Jac : 1.27953e-02 	 Enc : 5.29519e-06 	 AE : 1.80255e-05 	 MSE : 3.01464e-02
Training Epoch 523 finished, took current epoch 361.42s, cumulative time 193709.64s
Current Learning rate DEQ : 1.2379400392853824e-05
Current Learning rate AUTOENC : 6.189700196426911e-05
Epoch 524, 25% 	 Loss : 1.5589e-02 	 Res : 2.8920e-03 	 Jac : 1.2672e-02 	 Enc : 5.2850e-06 	 AEnc : 1.9405e-05 	 MSE : 1.9189e-02
Epoch 524, 50% 	 Loss : 1.5611e-02 	 Res : 2.8913e-03 	 Jac : 1.2696e-02 	 Enc : 5.2811e-06 	 AEnc : 1.8342e-05 	 MSE : 1.9235e-02
Epoch 524, 75% 	 Loss : 1.5571e-02 	 Res : 2.9031e-03 	 Jac : 1.2644e-02 	 Enc : 5.4972e-06 	 AEnc : 1.8493e-05 	 MSE : 1.3747e-02
Training Epoch 524 : 	 Train : 1.56127e-02 	 Res : 2.89708e-03 	 Jac : 1.26901e-02 	 Enc : 5.36780e-06 	 AE : 2.00615e-05 	 MSE : 1.71084e-02
Validation Epoch 524 : 	 Train : 1.56433e-02 	 Res : 2.91717e-03 	 Jac : 1.27027e-02 	 Enc : 5.30416e-06 	 AE : 1.82077e-05 	 MSE : 1.07145e-02
Training Epoch 524 finished, took current epoch 367.29s, cumulative time 194076.87s
Current Learning rate DEQ : 1.2379400392853824e-05
Current Learning rate AUTOENC : 6.189700196426911e-05
Epoch 525, 25% 	 Loss : 1.5660e-02 	 Res : 2.9053e-03 	 Jac : 1.2731e-02 	 Enc : 5.3313e-06 	 AEnc : 1.8834e-05 	 MSE : 1.6307e-02
Epoch 525, 50% 	 Loss : 1.5593e-02 	 Res : 2.8846e-03 	 Jac : 1.2684e-02 	 Enc : 5.3079e-06 	 AEnc : 1.8914e-05 	 MSE : 1.6289e-02
Epoch 525, 75% 	 Loss : 1.5492e-02 	 Res : 2.8577e-03 	 Jac : 1.2607e-02 	 Enc : 5.4742e-06 	 AEnc : 2.2356e-05 	 MSE : 1.5710e-02
Training Epoch 525 : 	 Train : 1.55900e-02 	 Res : 2.89570e-03 	 Jac : 1.26686e-02 	 Enc : 5.35908e-06 	 AE : 2.03452e-05 	 MSE : 1.55313e-02
Validation Epoch 525 : 	 Train : 1.57288e-02 	 Res : 2.91545e-03 	 Jac : 1.27574e-02 	 Enc : 5.38190e-06 	 AE : 5.05562e-05 	 MSE : 8.80252e-03
Training Epoch 525 finished, took current epoch 364.07s, cumulative time 194440.89s
Current Learning rate DEQ : 1.2379400392853824e-05
Current Learning rate AUTOENC : 6.189700196426911e-05
Epoch 526, 25% 	 Loss : 1.5666e-02 	 Res : 2.8528e-03 	 Jac : 1.2778e-02 	 Enc : 5.5674e-06 	 AEnc : 3.0331e-05 	 MSE : 1.6152e-02
Epoch 526, 50% 	 Loss : 1.5635e-02 	 Res : 2.8770e-03 	 Jac : 1.2727e-02 	 Enc : 5.4547e-06 	 AEnc : 2.5068e-05 	 MSE : 1.7855e-02
Epoch 526, 75% 	 Loss : 1.5691e-02 	 Res : 2.9115e-03 	 Jac : 1.2743e-02 	 Enc : 5.3166e-06 	 AEnc : 3.1173e-05 	 MSE : 1.1067e-02
Training Epoch 526 : 	 Train : 1.56738e-02 	 Res : 2.89525e-03 	 Jac : 1.27439e-02 	 Enc : 5.45175e-06 	 AE : 2.92802e-05 	 MSE : 1.47769e-02
Validation Epoch 526 : 	 Train : 1.57627e-02 	 Res : 2.98859e-03 	 Jac : 1.27363e-02 	 Enc : 5.35992e-06 	 AE : 3.24877e-05 	 MSE : 3.79952e-02
Training Epoch 526 finished, took current epoch 364.92s, cumulative time 194805.75s
Current Learning rate DEQ : 1.2379400392853824e-05
Current Learning rate AUTOENC : 6.189700196426911e-05
Epoch 527, 25% 	 Loss : 1.5704e-02 	 Res : 2.8997e-03 	 Jac : 1.2776e-02 	 Enc : 5.3551e-06 	 AEnc : 2.2874e-05 	 MSE : 1.3550e-02
Epoch 527, 50% 	 Loss : 1.5766e-02 	 Res : 2.9796e-03 	 Jac : 1.2755e-02 	 Enc : 5.3852e-06 	 AEnc : 2.6063e-05 	 MSE : 2.2968e-02
Epoch 527, 75% 	 Loss : 1.5660e-02 	 Res : 2.8636e-03 	 Jac : 1.2764e-02 	 Enc : 5.2635e-06 	 AEnc : 2.7061e-05 	 MSE : 3.2216e-02
Training Epoch 527 : 	 Train : 1.57269e-02 	 Res : 2.91820e-03 	 Jac : 1.27795e-02 	 Enc : 5.30614e-06 	 AE : 2.39073e-05 	 MSE : 2.46672e-02
Validation Epoch 527 : 	 Train : 1.56678e-02 	 Res : 2.91099e-03 	 Jac : 1.27319e-02 	 Enc : 5.21999e-06 	 AE : 1.96906e-05 	 MSE : 1.09765e-02
Training Epoch 527 finished, took current epoch 365.56s, cumulative time 195171.25s
Current Learning rate DEQ : 9.90352031428306e-06
Current Learning rate AUTOENC : 4.9517601571415295e-05
Epoch 528, 25% 	 Loss : 1.5640e-02 	 Res : 2.9171e-03 	 Jac : 1.2698e-02 	 Enc : 5.2155e-06 	 AEnc : 2.0636e-05 	 MSE : 1.3598e-02
Epoch 528, 50% 	 Loss : 1.5782e-02 	 Res : 2.9473e-03 	 Jac : 1.2798e-02 	 Enc : 5.3032e-06 	 AEnc : 3.1335e-05 	 MSE : 1.9017e-02
Epoch 528, 75% 	 Loss : 1.5673e-02 	 Res : 2.8559e-03 	 Jac : 1.2788e-02 	 Enc : 5.2232e-06 	 AEnc : 2.3112e-05 	 MSE : 1.4501e-02
Training Epoch 528 : 	 Train : 1.56572e-02 	 Res : 2.89665e-03 	 Jac : 1.27316e-02 	 Enc : 5.28345e-06 	 AE : 2.36427e-05 	 MSE : 1.62771e-02
Validation Epoch 528 : 	 Train : 1.56395e-02 	 Res : 2.92220e-03 	 Jac : 1.26918e-02 	 Enc : 5.44329e-06 	 AE : 2.00480e-05 	 MSE : 1.31350e-02
Training Epoch 528 finished, took current epoch 361.96s, cumulative time 195533.17s
Current Learning rate DEQ : 9.90352031428306e-06
Current Learning rate AUTOENC : 4.9517601571415295e-05
Epoch 529, 25% 	 Loss : 1.5638e-02 	 Res : 2.8878e-03 	 Jac : 1.2722e-02 	 Enc : 5.4982e-06 	 AEnc : 2.2369e-05 	 MSE : 1.2119e-02
Epoch 529, 50% 	 Loss : 1.5690e-02 	 Res : 2.9151e-03 	 Jac : 1.2718e-02 	 Enc : 5.4837e-06 	 AEnc : 5.1274e-05 	 MSE : 1.9511e-02
Epoch 529, 75% 	 Loss : 1.5726e-02 	 Res : 2.9513e-03 	 Jac : 1.2745e-02 	 Enc : 5.5063e-06 	 AEnc : 2.4112e-05 	 MSE : 1.8667e-02
Training Epoch 529 : 	 Train : 1.56697e-02 	 Res : 2.89727e-03 	 Jac : 1.27312e-02 	 Enc : 5.48717e-06 	 AE : 3.56676e-05 	 MSE : 1.57422e-02
Validation Epoch 529 : 	 Train : 1.56816e-02 	 Res : 2.91347e-03 	 Jac : 1.27447e-02 	 Enc : 5.39747e-06 	 AE : 1.79551e-05 	 MSE : 1.00879e-02
Training Epoch 529 finished, took current epoch 363.67s, cumulative time 195896.82s
Current Learning rate DEQ : 9.90352031428306e-06
Current Learning rate AUTOENC : 4.9517601571415295e-05
Epoch 530, 25% 	 Loss : 1.5708e-02 	 Res : 2.8947e-03 	 Jac : 1.2775e-02 	 Enc : 5.3017e-06 	 AEnc : 3.3380e-05 	 MSE : 1.3729e-02
Epoch 530, 50% 	 Loss : 1.5694e-02 	 Res : 2.9262e-03 	 Jac : 1.2743e-02 	 Enc : 5.3922e-06 	 AEnc : 2.0057e-05 	 MSE : 2.7288e-02
Epoch 530, 75% 	 Loss : 1.5688e-02 	 Res : 2.9304e-03 	 Jac : 1.2731e-02 	 Enc : 5.4246e-06 	 AEnc : 2.1395e-05 	 MSE : 3.7846e-02
Training Epoch 530 : 	 Train : 1.57069e-02 	 Res : 2.91591e-03 	 Jac : 1.27618e-02 	 Enc : 5.38865e-06 	 AE : 2.37858e-05 	 MSE : 2.41284e-02
Validation Epoch 530 : 	 Train : 1.56538e-02 	 Res : 2.91447e-03 	 Jac : 1.27160e-02 	 Enc : 5.35926e-06 	 AE : 1.79210e-05 	 MSE : 1.06407e-02
Training Epoch 530 finished, took current epoch 362.47s, cumulative time 196259.27s
Current Learning rate DEQ : 9.90352031428306e-06
Current Learning rate AUTOENC : 4.9517601571415295e-05
Epoch 531, 25% 	 Loss : 1.5557e-02 	 Res : 2.9005e-03 	 Jac : 1.2633e-02 	 Enc : 5.2780e-06 	 AEnc : 1.8276e-05 	 MSE : 1.3884e-02
Epoch 531, 50% 	 Loss : 1.5531e-02 	 Res : 2.8819e-03 	 Jac : 1.2625e-02 	 Enc : 5.1447e-06 	 AEnc : 1.8783e-05 	 MSE : 1.3993e-02
Epoch 531, 75% 	 Loss : 1.5645e-02 	 Res : 2.8951e-03 	 Jac : 1.2724e-02 	 Enc : 5.3652e-06 	 AEnc : 2.0869e-05 	 MSE : 1.2195e-02
Training Epoch 531 : 	 Train : 1.56007e-02 	 Res : 2.88822e-03 	 Jac : 1.26879e-02 	 Enc : 5.27199e-06 	 AE : 1.93530e-05 	 MSE : 1.33714e-02
Validation Epoch 531 : 	 Train : 1.56924e-02 	 Res : 2.91324e-03 	 Jac : 1.27562e-02 	 Enc : 5.25454e-06 	 AE : 1.77492e-05 	 MSE : 1.10797e-02
Training Epoch 531 finished, took current epoch 361.37s, cumulative time 196620.63s
Current Learning rate DEQ : 9.90352031428306e-06
Current Learning rate AUTOENC : 4.9517601571415295e-05
Epoch 532, 25% 	 Loss : 1.5654e-02 	 Res : 2.9035e-03 	 Jac : 1.2700e-02 	 Enc : 5.5055e-06 	 AEnc : 4.4773e-05 	 MSE : 1.3938e-02
Epoch 532, 50% 	 Loss : 1.5720e-02 	 Res : 2.9135e-03 	 Jac : 1.2741e-02 	 Enc : 5.3155e-06 	 AEnc : 6.0843e-05 	 MSE : 1.8896e-02
Epoch 532, 75% 	 Loss : 1.5653e-02 	 Res : 2.8833e-03 	 Jac : 1.2715e-02 	 Enc : 5.3077e-06 	 AEnc : 4.9638e-05 	 MSE : 1.3695e-02
Training Epoch 532 : 	 Train : 1.56753e-02 	 Res : 2.89705e-03 	 Jac : 1.27287e-02 	 Enc : 5.32481e-06 	 AE : 4.42814e-05 	 MSE : 1.55011e-02
Validation Epoch 532 : 	 Train : 1.56628e-02 	 Res : 2.90826e-03 	 Jac : 1.27307e-02 	 Enc : 5.18176e-06 	 AE : 1.86703e-05 	 MSE : 8.90003e-03
Training Epoch 532 finished, took current epoch 361.23s, cumulative time 196981.82s
Current Learning rate DEQ : 9.90352031428306e-06
Current Learning rate AUTOENC : 4.9517601571415295e-05
MODEL SAVED
Epoch 533, 25% 	 Loss : 1.5661e-02 	 Res : 2.8924e-03 	 Jac : 1.2741e-02 	 Enc : 5.2914e-06 	 AEnc : 2.2564e-05 	 MSE : 1.0947e-02
Epoch 533, 50% 	 Loss : 1.5672e-02 	 Res : 2.8909e-03 	 Jac : 1.2755e-02 	 Enc : 5.2587e-06 	 AEnc : 2.1193e-05 	 MSE : 1.1921e-02
Epoch 533, 75% 	 Loss : 1.5635e-02 	 Res : 2.8690e-03 	 Jac : 1.2741e-02 	 Enc : 5.3729e-06 	 AEnc : 1.9403e-05 	 MSE : 1.1621e-02
Training Epoch 533 : 	 Train : 1.56533e-02 	 Res : 2.88400e-03 	 Jac : 1.27426e-02 	 Enc : 5.33767e-06 	 AE : 2.13058e-05 	 MSE : 1.20235e-02
Validation Epoch 533 : 	 Train : 1.56759e-02 	 Res : 2.91969e-03 	 Jac : 1.27343e-02 	 Enc : 5.33939e-06 	 AE : 1.66265e-05 	 MSE : 1.40857e-02
Training Epoch 533 finished, took current epoch 366.01s, cumulative time 197347.82s
Current Learning rate DEQ : 9.90352031428306e-06
Current Learning rate AUTOENC : 4.9517601571415295e-05
Epoch 534, 25% 	 Loss : 1.5819e-02 	 Res : 2.8722e-03 	 Jac : 1.2914e-02 	 Enc : 5.3271e-06 	 AEnc : 2.7983e-05 	 MSE : 1.3311e-02
Epoch 534, 50% 	 Loss : 1.5639e-02 	 Res : 2.8859e-03 	 Jac : 1.2719e-02 	 Enc : 5.4174e-06 	 AEnc : 2.8791e-05 	 MSE : 1.1665e-02
Epoch 534, 75% 	 Loss : 1.5655e-02 	 Res : 2.8772e-03 	 Jac : 1.2748e-02 	 Enc : 5.3933e-06 	 AEnc : 2.5221e-05 	 MSE : 1.2928e-02
Training Epoch 534 : 	 Train : 1.57155e-02 	 Res : 2.89026e-03 	 Jac : 1.27942e-02 	 Enc : 5.36081e-06 	 AE : 2.56285e-05 	 MSE : 1.40392e-02
Validation Epoch 534 : 	 Train : 1.57662e-02 	 Res : 3.00274e-03 	 Jac : 1.27408e-02 	 Enc : 5.13843e-06 	 AE : 1.75205e-05 	 MSE : 3.02269e-02
Training Epoch 534 finished, took current epoch 365.34s, cumulative time 197713.13s
Current Learning rate DEQ : 9.90352031428306e-06
Current Learning rate AUTOENC : 4.9517601571415295e-05
Epoch 535, 25% 	 Loss : 1.5623e-02 	 Res : 2.8619e-03 	 Jac : 1.2737e-02 	 Enc : 5.1924e-06 	 AEnc : 1.8897e-05 	 MSE : 1.2698e-02
Epoch 535, 50% 	 Loss : 1.5647e-02 	 Res : 2.9092e-03 	 Jac : 1.2713e-02 	 Enc : 5.1288e-06 	 AEnc : 1.9380e-05 	 MSE : 1.4073e-02
Epoch 535, 75% 	 Loss : 1.5648e-02 	 Res : 2.9177e-03 	 Jac : 1.2705e-02 	 Enc : 5.1595e-06 	 AEnc : 2.0799e-05 	 MSE : 1.4013e-02
Training Epoch 535 : 	 Train : 1.56380e-02 	 Res : 2.88820e-03 	 Jac : 1.27246e-02 	 Enc : 5.17547e-06 	 AE : 2.00323e-05 	 MSE : 1.32317e-02
Validation Epoch 535 : 	 Train : 1.56978e-02 	 Res : 2.92601e-03 	 Jac : 1.27471e-02 	 Enc : 5.26445e-06 	 AE : 1.94503e-05 	 MSE : 1.26919e-02
Training Epoch 535 finished, took current epoch 361.45s, cumulative time 198074.57s
Current Learning rate DEQ : 9.90352031428306e-06
Current Learning rate AUTOENC : 4.9517601571415295e-05
Epoch 536, 25% 	 Loss : 1.5747e-02 	 Res : 2.9122e-03 	 Jac : 1.2797e-02 	 Enc : 5.2144e-06 	 AEnc : 3.2157e-05 	 MSE : 1.5043e-02
Epoch 536, 50% 	 Loss : 1.5768e-02 	 Res : 2.9596e-03 	 Jac : 1.2698e-02 	 Enc : 5.4887e-06 	 AEnc : 1.0499e-04 	 MSE : 1.3754e-02
Epoch 536, 75% 	 Loss : 1.5596e-02 	 Res : 2.7852e-03 	 Jac : 1.2779e-02 	 Enc : 5.2804e-06 	 AEnc : 2.7030e-05 	 MSE : 1.6890e-02
Training Epoch 536 : 	 Train : 1.57161e-02 	 Res : 2.89844e-03 	 Jac : 1.27655e-02 	 Enc : 5.35180e-06 	 AE : 4.67535e-05 	 MSE : 1.56273e-02
Validation Epoch 536 : 	 Train : 1.57482e-02 	 Res : 2.91423e-03 	 Jac : 1.28103e-02 	 Enc : 5.31365e-06 	 AE : 1.83825e-05 	 MSE : 1.01348e-02
Training Epoch 536 finished, took current epoch 362.39s, cumulative time 198436.94s
Current Learning rate DEQ : 9.90352031428306e-06
Current Learning rate AUTOENC : 4.9517601571415295e-05
Epoch 537, 25% 	 Loss : 1.5649e-02 	 Res : 2.9170e-03 	 Jac : 1.2705e-02 	 Enc : 5.4298e-06 	 AEnc : 2.1760e-05 	 MSE : 2.0329e-02
Epoch 537, 50% 	 Loss : 1.5612e-02 	 Res : 2.8404e-03 	 Jac : 1.2747e-02 	 Enc : 5.3126e-06 	 AEnc : 1.9436e-05 	 MSE : 1.3015e-02
Epoch 537, 75% 	 Loss : 1.5706e-02 	 Res : 2.9866e-03 	 Jac : 1.2656e-02 	 Enc : 5.3965e-06 	 AEnc : 5.8042e-05 	 MSE : 1.3372e-02
Training Epoch 537 : 	 Train : 1.56458e-02 	 Res : 2.89660e-03 	 Jac : 1.27075e-02 	 Enc : 5.35316e-06 	 AE : 3.63294e-05 	 MSE : 1.56001e-02
Validation Epoch 537 : 	 Train : 1.56630e-02 	 Res : 2.91253e-03 	 Jac : 1.27186e-02 	 Enc : 5.31702e-06 	 AE : 2.65188e-05 	 MSE : 1.16365e-02
Training Epoch 537 finished, took current epoch 362.79s, cumulative time 198799.69s
Current Learning rate DEQ : 9.90352031428306e-06
Current Learning rate AUTOENC : 4.9517601571415295e-05
Epoch 538, 25% 	 Loss : 1.5698e-02 	 Res : 2.9010e-03 	 Jac : 1.2771e-02 	 Enc : 5.3325e-06 	 AEnc : 2.0799e-05 	 MSE : 1.5699e-02
Epoch 538, 50% 	 Loss : 1.5629e-02 	 Res : 2.8946e-03 	 Jac : 1.2709e-02 	 Enc : 5.3023e-06 	 AEnc : 1.9601e-05 	 MSE : 1.5289e-02
Epoch 538, 75% 	 Loss : 1.5691e-02 	 Res : 2.9279e-03 	 Jac : 1.2738e-02 	 Enc : 5.2318e-06 	 AEnc : 1.9580e-05 	 MSE : 1.4385e-02
Training Epoch 538 : 	 Train : 1.56708e-02 	 Res : 2.89061e-03 	 Jac : 1.27545e-02 	 Enc : 5.32191e-06 	 AE : 2.04379e-05 	 MSE : 1.43915e-02
Validation Epoch 538 : 	 Train : 1.56744e-02 	 Res : 2.93074e-03 	 Jac : 1.27165e-02 	 Enc : 5.14348e-06 	 AE : 2.20142e-05 	 MSE : 1.68483e-02
Training Epoch 538 finished, took current epoch 364.19s, cumulative time 199163.87s
Current Learning rate DEQ : 7.922816251426448e-06
Current Learning rate AUTOENC : 3.961408125713224e-05
Epoch 539, 25% 	 Loss : 1.5611e-02 	 Res : 2.9003e-03 	 Jac : 1.2684e-02 	 Enc : 5.1288e-06 	 AEnc : 2.1895e-05 	 MSE : 1.2760e-02
Epoch 539, 50% 	 Loss : 1.5649e-02 	 Res : 2.8889e-03 	 Jac : 1.2736e-02 	 Enc : 5.1295e-06 	 AEnc : 1.8239e-05 	 MSE : 1.5553e-02
Epoch 539, 75% 	 Loss : 1.5644e-02 	 Res : 2.8452e-03 	 Jac : 1.2773e-02 	 Enc : 5.2353e-06 	 AEnc : 2.0912e-05 	 MSE : 1.3233e-02
Training Epoch 539 : 	 Train : 1.56456e-02 	 Res : 2.88931e-03 	 Jac : 1.27312e-02 	 Enc : 5.20198e-06 	 AE : 1.99289e-05 	 MSE : 1.36438e-02
Validation Epoch 539 : 	 Train : 1.56519e-02 	 Res : 2.92058e-03 	 Jac : 1.27078e-02 	 Enc : 5.22959e-06 	 AE : 1.83485e-05 	 MSE : 1.38724e-02
Training Epoch 539 finished, took current epoch 364.15s, cumulative time 199528.00s
Current Learning rate DEQ : 7.922816251426448e-06
Current Learning rate AUTOENC : 3.961408125713224e-05
Epoch 540, 25% 	 Loss : 1.5683e-02 	 Res : 2.8883e-03 	 Jac : 1.2771e-02 	 Enc : 5.1698e-06 	 AEnc : 1.8732e-05 	 MSE : 1.1741e-02
Epoch 540, 50% 	 Loss : 1.5707e-02 	 Res : 2.8722e-03 	 Jac : 1.2811e-02 	 Enc : 5.3117e-06 	 AEnc : 1.8556e-05 	 MSE : 1.0502e-02
Epoch 540, 75% 	 Loss : 1.5598e-02 	 Res : 2.8793e-03 	 Jac : 1.2694e-02 	 Enc : 5.4787e-06 	 AEnc : 1.9287e-05 	 MSE : 1.1477e-02
Training Epoch 540 : 	 Train : 1.56726e-02 	 Res : 2.88299e-03 	 Jac : 1.27649e-02 	 Enc : 5.31773e-06 	 AE : 1.94060e-05 	 MSE : 1.15358e-02
Validation Epoch 540 : 	 Train : 1.57388e-02 	 Res : 2.91618e-03 	 Jac : 1.27690e-02 	 Enc : 5.42670e-06 	 AE : 4.81875e-05 	 MSE : 1.11397e-02
Training Epoch 540 finished, took current epoch 363.21s, cumulative time 199891.20s
Current Learning rate DEQ : 7.922816251426448e-06
Current Learning rate AUTOENC : 3.961408125713224e-05
Epoch 541, 25% 	 Loss : 1.5640e-02 	 Res : 2.8579e-03 	 Jac : 1.2744e-02 	 Enc : 5.2841e-06 	 AEnc : 3.3029e-05 	 MSE : 1.1112e-02
Epoch 541, 50% 	 Loss : 1.5606e-02 	 Res : 2.8648e-03 	 Jac : 1.2699e-02 	 Enc : 5.2678e-06 	 AEnc : 3.7092e-05 	 MSE : 1.1601e-02
Epoch 541, 75% 	 Loss : 1.5692e-02 	 Res : 2.9133e-03 	 Jac : 1.2753e-02 	 Enc : 5.5665e-06 	 AEnc : 2.0313e-05 	 MSE : 1.4223e-02
Training Epoch 541 : 	 Train : 1.56642e-02 	 Res : 2.88701e-03 	 Jac : 1.27441e-02 	 Enc : 5.40188e-06 	 AE : 2.76640e-05 	 MSE : 1.25647e-02
Validation Epoch 541 : 	 Train : 1.57039e-02 	 Res : 2.92048e-03 	 Jac : 1.27590e-02 	 Enc : 5.35818e-06 	 AE : 1.90516e-05 	 MSE : 1.48079e-02
Training Epoch 541 finished, took current epoch 361.38s, cumulative time 200252.57s
Current Learning rate DEQ : 7.922816251426448e-06
Current Learning rate AUTOENC : 3.961408125713224e-05
Epoch 542, 25% 	 Loss : 1.5660e-02 	 Res : 2.9106e-03 	 Jac : 1.2726e-02 	 Enc : 5.2815e-06 	 AEnc : 1.8531e-05 	 MSE : 1.5667e-02
Epoch 542, 50% 	 Loss : 1.5621e-02 	 Res : 2.8341e-03 	 Jac : 1.2763e-02 	 Enc : 5.4158e-06 	 AEnc : 1.8880e-05 	 MSE : 1.1862e-02
Epoch 542, 75% 	 Loss : 1.5657e-02 	 Res : 2.8992e-03 	 Jac : 1.2734e-02 	 Enc : 5.2649e-06 	 AEnc : 1.9302e-05 	 MSE : 1.5274e-02
Training Epoch 542 : 	 Train : 1.56480e-02 	 Res : 2.88921e-03 	 Jac : 1.27347e-02 	 Enc : 5.30081e-06 	 AE : 1.88425e-05 	 MSE : 1.40642e-02
Validation Epoch 542 : 	 Train : 1.56615e-02 	 Res : 2.91024e-03 	 Jac : 1.27267e-02 	 Enc : 5.21726e-06 	 AE : 1.93211e-05 	 MSE : 1.10220e-02
Training Epoch 542 finished, took current epoch 360.92s, cumulative time 200613.47s
Current Learning rate DEQ : 7.922816251426448e-06
Current Learning rate AUTOENC : 3.961408125713224e-05
Epoch 543, 25% 	 Loss : 1.5708e-02 	 Res : 2.8740e-03 	 Jac : 1.2808e-02 	 Enc : 5.2923e-06 	 AEnc : 2.0289e-05 	 MSE : 1.2058e-02
Epoch 543, 50% 	 Loss : 1.5740e-02 	 Res : 2.9238e-03 	 Jac : 1.2786e-02 	 Enc : 5.3058e-06 	 AEnc : 2.4475e-05 	 MSE : 1.4874e-02
Epoch 543, 75% 	 Loss : 1.5631e-02 	 Res : 2.8496e-03 	 Jac : 1.2756e-02 	 Enc : 5.4909e-06 	 AEnc : 1.9996e-05 	 MSE : 1.2002e-02
Training Epoch 543 : 	 Train : 1.56933e-02 	 Res : 2.89869e-03 	 Jac : 1.27684e-02 	 Enc : 5.33875e-06 	 AE : 2.08151e-05 	 MSE : 1.69483e-02
Validation Epoch 543 : 	 Train : 1.56643e-02 	 Res : 2.92414e-03 	 Jac : 1.27147e-02 	 Enc : 5.26213e-06 	 AE : 2.02310e-05 	 MSE : 1.45368e-02
Training Epoch 543 finished, took current epoch 358.95s, cumulative time 200972.40s
Current Learning rate DEQ : 7.922816251426448e-06
Current Learning rate AUTOENC : 3.961408125713224e-05
Epoch 544, 25% 	 Loss : 1.5743e-02 	 Res : 2.9178e-03 	 Jac : 1.2801e-02 	 Enc : 5.2812e-06 	 AEnc : 1.8466e-05 	 MSE : 1.8416e-02
Epoch 544, 50% 	 Loss : 1.5732e-02 	 Res : 2.8906e-03 	 Jac : 1.2816e-02 	 Enc : 5.2737e-06 	 AEnc : 1.9998e-05 	 MSE : 1.5550e-02
Epoch 544, 75% 	 Loss : 1.5687e-02 	 Res : 2.8694e-03 	 Jac : 1.2793e-02 	 Enc : 5.4407e-06 	 AEnc : 1.9376e-05 	 MSE : 1.3706e-02
Training Epoch 544 : 	 Train : 1.57208e-02 	 Res : 2.89562e-03 	 Jac : 1.27765e-02 	 Enc : 5.34769e-06 	 AE : 4.34169e-05 	 MSE : 1.55525e-02
Validation Epoch 544 : 	 Train : 1.55954e-02 	 Res : 2.93861e-03 	 Jac : 1.26313e-02 	 Enc : 5.45280e-06 	 AE : 2.00258e-05 	 MSE : 1.70737e-02
Training Epoch 544 finished, took current epoch 358.67s, cumulative time 201331.04s
Current Learning rate DEQ : 7.922816251426448e-06
Current Learning rate AUTOENC : 3.961408125713224e-05
Epoch 545, 25% 	 Loss : 1.5669e-02 	 Res : 2.8878e-03 	 Jac : 1.2711e-02 	 Enc : 5.4476e-06 	 AEnc : 6.5252e-05 	 MSE : 1.3189e-02
Epoch 545, 50% 	 Loss : 1.5511e-02 	 Res : 2.8084e-03 	 Jac : 1.2670e-02 	 Enc : 5.2930e-06 	 AEnc : 2.6832e-05 	 MSE : 1.2943e-02
Epoch 545, 75% 	 Loss : 1.5798e-02 	 Res : 2.9571e-03 	 Jac : 1.2815e-02 	 Enc : 5.3066e-06 	 AEnc : 2.0851e-05 	 MSE : 1.3262e-02
Training Epoch 545 : 	 Train : 1.56519e-02 	 Res : 2.88864e-03 	 Jac : 1.27244e-02 	 Enc : 5.37427e-06 	 AE : 3.34928e-05 	 MSE : 1.34359e-02
Validation Epoch 545 : 	 Train : 1.56652e-02 	 Res : 2.92191e-03 	 Jac : 1.27156e-02 	 Enc : 5.43989e-06 	 AE : 2.22399e-05 	 MSE : 1.44681e-02
Training Epoch 545 finished, took current epoch 353.40s, cumulative time 201684.42s
Current Learning rate DEQ : 7.922816251426448e-06
Current Learning rate AUTOENC : 3.961408125713224e-05
Epoch 546, 25% 	 Loss : 1.5669e-02 	 Res : 2.9430e-03 	 Jac : 1.2701e-02 	 Enc : 5.5338e-06 	 AEnc : 1.9455e-05 	 MSE : 1.3134e-02
Epoch 546, 50% 	 Loss : 1.5518e-02 	 Res : 2.8950e-03 	 Jac : 1.2598e-02 	 Enc : 5.3255e-06 	 AEnc : 1.9277e-05 	 MSE : 1.7817e-02
Epoch 546, 75% 	 Loss : 1.5482e-02 	 Res : 2.8426e-03 	 Jac : 1.2615e-02 	 Enc : 5.3022e-06 	 AEnc : 1.9497e-05 	 MSE : 1.1649e-02
Training Epoch 546 : 	 Train : 1.55841e-02 	 Res : 2.89235e-03 	 Jac : 1.26674e-02 	 Enc : 5.41675e-06 	 AE : 1.89407e-05 	 MSE : 1.52742e-02
Validation Epoch 546 : 	 Train : 1.56096e-02 	 Res : 2.90823e-03 	 Jac : 1.26784e-02 	 Enc : 5.43682e-06 	 AE : 1.75402e-05 	 MSE : 9.39086e-03
Training Epoch 546 finished, took current epoch 358.20s, cumulative time 202042.56s
Current Learning rate DEQ : 7.922816251426448e-06
Current Learning rate AUTOENC : 3.961408125713224e-05
MODEL SAVED
Epoch 547, 25% 	 Loss : 1.5608e-02 	 Res : 2.8823e-03 	 Jac : 1.2702e-02 	 Enc : 5.4643e-06 	 AEnc : 1.8223e-05 	 MSE : 1.5480e-02
Epoch 547, 50% 	 Loss : 1.5658e-02 	 Res : 2.9010e-03 	 Jac : 1.2732e-02 	 Enc : 5.3213e-06 	 AEnc : 1.9546e-05 	 MSE : 1.3295e-02
Epoch 547, 75% 	 Loss : 1.5665e-02 	 Res : 2.9023e-03 	 Jac : 1.2737e-02 	 Enc : 5.2275e-06 	 AEnc : 2.0099e-05 	 MSE : 1.5493e-02
Training Epoch 547 : 	 Train : 1.56326e-02 	 Res : 2.88787e-03 	 Jac : 1.27203e-02 	 Enc : 5.38713e-06 	 AE : 1.90631e-05 	 MSE : 1.43998e-02
Validation Epoch 547 : 	 Train : 1.56789e-02 	 Res : 2.91747e-03 	 Jac : 1.27388e-02 	 Enc : 5.33381e-06 	 AE : 1.72938e-05 	 MSE : 1.24794e-02
Training Epoch 547 finished, took current epoch 356.73s, cumulative time 202399.28s
Current Learning rate DEQ : 7.922816251426448e-06
Current Learning rate AUTOENC : 3.961408125713224e-05
Epoch 548, 25% 	 Loss : 1.5583e-02 	 Res : 2.8654e-03 	 Jac : 1.2693e-02 	 Enc : 5.3385e-06 	 AEnc : 1.9861e-05 	 MSE : 1.3967e-02
Epoch 548, 50% 	 Loss : 1.5604e-02 	 Res : 2.9073e-03 	 Jac : 1.2672e-02 	 Enc : 5.3686e-06 	 AEnc : 1.9393e-05 	 MSE : 1.3820e-02
Epoch 548, 75% 	 Loss : 1.5637e-02 	 Res : 2.8805e-03 	 Jac : 1.2733e-02 	 Enc : 5.2986e-06 	 AEnc : 1.8058e-05 	 MSE : 1.6160e-02
Training Epoch 548 : 	 Train : 1.56229e-02 	 Res : 2.89405e-03 	 Jac : 1.27042e-02 	 Enc : 5.36544e-06 	 AE : 1.93025e-05 	 MSE : 1.57418e-02
Validation Epoch 548 : 	 Train : 1.56997e-02 	 Res : 2.90938e-03 	 Jac : 1.27594e-02 	 Enc : 5.35372e-06 	 AE : 2.56156e-05 	 MSE : 9.80913e-03
Training Epoch 548 finished, took current epoch 356.19s, cumulative time 202755.46s
Current Learning rate DEQ : 7.922816251426448e-06
Current Learning rate AUTOENC : 3.961408125713224e-05
Epoch 549, 25% 	 Loss : 1.5571e-02 	 Res : 2.8995e-03 	 Jac : 1.2645e-02 	 Enc : 5.4076e-06 	 AEnc : 2.1452e-05 	 MSE : 1.6291e-02
Epoch 549, 50% 	 Loss : 1.5750e-02 	 Res : 2.9549e-03 	 Jac : 1.2771e-02 	 Enc : 5.3601e-06 	 AEnc : 1.8387e-05 	 MSE : 2.3249e-02
Epoch 549, 75% 	 Loss : 1.5621e-02 	 Res : 2.8257e-03 	 Jac : 1.2768e-02 	 Enc : 5.2840e-06 	 AEnc : 2.2623e-05 	 MSE : 1.1489e-02
Training Epoch 549 : 	 Train : 1.56507e-02 	 Res : 2.89397e-03 	 Jac : 1.27310e-02 	 Enc : 5.31505e-06 	 AE : 2.04285e-05 	 MSE : 1.59429e-02
Validation Epoch 549 : 	 Train : 1.57533e-02 	 Res : 2.91776e-03 	 Jac : 1.28115e-02 	 Enc : 5.29938e-06 	 AE : 1.87051e-05 	 MSE : 1.44970e-02
Training Epoch 549 finished, took current epoch 356.45s, cumulative time 203111.89s
Current Learning rate DEQ : 6.338253001141159e-06
Current Learning rate AUTOENC : 3.1691265005705794e-05
Epoch 550, 25% 	 Loss : 1.5625e-02 	 Res : 2.8965e-03 	 Jac : 1.2704e-02 	 Enc : 5.2150e-06 	 AEnc : 1.9420e-05 	 MSE : 1.1179e-02
Epoch 550, 50% 	 Loss : 1.5677e-02 	 Res : 2.8729e-03 	 Jac : 1.2779e-02 	 Enc : 5.4121e-06 	 AEnc : 1.9645e-05 	 MSE : 1.0372e-02
Epoch 550, 75% 	 Loss : 1.5697e-02 	 Res : 2.9002e-03 	 Jac : 1.2772e-02 	 Enc : 5.3614e-06 	 AEnc : 1.9425e-05 	 MSE : 1.1089e-02
Training Epoch 550 : 	 Train : 1.56417e-02 	 Res : 2.88219e-03 	 Jac : 1.27350e-02 	 Enc : 5.35921e-06 	 AE : 1.92099e-05 	 MSE : 1.14059e-02
Validation Epoch 550 : 	 Train : 1.55859e-02 	 Res : 2.91874e-03 	 Jac : 1.26423e-02 	 Enc : 5.53469e-06 	 AE : 1.92938e-05 	 MSE : 1.40975e-02
Training Epoch 550 finished, took current epoch 352.99s, cumulative time 203464.87s
Current Learning rate DEQ : 6.338253001141159e-06
Current Learning rate AUTOENC : 3.1691265005705794e-05
Epoch 551, 25% 	 Loss : 1.5623e-02 	 Res : 2.8649e-03 	 Jac : 1.2730e-02 	 Enc : 5.4997e-06 	 AEnc : 2.2470e-05 	 MSE : 1.1576e-02
Epoch 551, 50% 	 Loss : 1.5587e-02 	 Res : 2.8430e-03 	 Jac : 1.2717e-02 	 Enc : 5.3573e-06 	 AEnc : 2.1663e-05 	 MSE : 1.2081e-02
Epoch 551, 75% 	 Loss : 1.5611e-02 	 Res : 2.9408e-03 	 Jac : 1.2645e-02 	 Enc : 5.4208e-06 	 AEnc : 1.9904e-05 	 MSE : 1.2498e-02
Training Epoch 551 : 	 Train : 1.56238e-02 	 Res : 2.88295e-03 	 Jac : 1.27147e-02 	 Enc : 5.36475e-06 	 AE : 2.07680e-05 	 MSE : 1.21886e-02
Validation Epoch 551 : 	 Train : 1.56208e-02 	 Res : 2.90864e-03 	 Jac : 1.26866e-02 	 Enc : 5.29821e-06 	 AE : 2.02373e-05 	 MSE : 1.06779e-02
Training Epoch 551 finished, took current epoch 355.49s, cumulative time 203820.34s
Current Learning rate DEQ : 6.338253001141159e-06
Current Learning rate AUTOENC : 3.1691265005705794e-05
Epoch 552, 25% 	 Loss : 1.5684e-02 	 Res : 2.8717e-03 	 Jac : 1.2787e-02 	 Enc : 5.3182e-06 	 AEnc : 1.9607e-05 	 MSE : 1.2468e-02
Epoch 552, 50% 	 Loss : 1.5749e-02 	 Res : 2.8911e-03 	 Jac : 1.2834e-02 	 Enc : 5.3676e-06 	 AEnc : 1.8327e-05 	 MSE : 1.4465e-02
Epoch 552, 75% 	 Loss : 1.5569e-02 	 Res : 2.8524e-03 	 Jac : 1.2693e-02 	 Enc : 5.3043e-06 	 AEnc : 1.8835e-05 	 MSE : 1.2113e-02
Training Epoch 552 : 	 Train : 1.56748e-02 	 Res : 2.88340e-03 	 Jac : 1.27671e-02 	 Enc : 5.34983e-06 	 AE : 1.89551e-05 	 MSE : 1.25196e-02
Validation Epoch 552 : 	 Train : 1.56790e-02 	 Res : 2.90603e-03 	 Jac : 1.27482e-02 	 Enc : 5.40991e-06 	 AE : 1.93377e-05 	 MSE : 9.29380e-03
Training Epoch 552 finished, took current epoch 358.53s, cumulative time 204178.84s
Current Learning rate DEQ : 6.338253001141159e-06
Current Learning rate AUTOENC : 3.1691265005705794e-05
MODEL SAVED
Epoch 553, 25% 	 Loss : 1.5581e-02 	 Res : 2.8718e-03 	 Jac : 1.2685e-02 	 Enc : 5.4855e-06 	 AEnc : 1.9016e-05 	 MSE : 1.2782e-02
Epoch 553, 50% 	 Loss : 1.5609e-02 	 Res : 2.8610e-03 	 Jac : 1.2724e-02 	 Enc : 5.3994e-06 	 AEnc : 1.8769e-05 	 MSE : 1.0995e-02
Epoch 553, 75% 	 Loss : 1.5929e-02 	 Res : 3.0944e-03 	 Jac : 1.2792e-02 	 Enc : 5.1814e-06 	 AEnc : 3.7859e-05 	 MSE : 4.6940e-02
Training Epoch 553 : 	 Train : 1.56633e-02 	 Res : 2.92500e-03 	 Jac : 1.27064e-02 	 Enc : 5.33967e-06 	 AE : 2.65634e-05 	 MSE : 2.08922e-02
Validation Epoch 553 : 	 Train : 1.57669e-02 	 Res : 2.91626e-03 	 Jac : 1.28045e-02 	 Enc : 5.20541e-06 	 AE : 4.09044e-05 	 MSE : 1.07616e-02
Training Epoch 553 finished, took current epoch 352.08s, cumulative time 204530.91s
Current Learning rate DEQ : 6.338253001141159e-06
Current Learning rate AUTOENC : 3.1691265005705794e-05
Epoch 554, 25% 	 Loss : 1.5601e-02 	 Res : 2.8094e-03 	 Jac : 1.2763e-02 	 Enc : 5.2872e-06 	 AEnc : 2.2726e-05 	 MSE : 1.1411e-02
Epoch 554, 50% 	 Loss : 1.5663e-02 	 Res : 2.8826e-03 	 Jac : 1.2754e-02 	 Enc : 5.2099e-06 	 AEnc : 2.1083e-05 	 MSE : 1.0343e-02
Epoch 554, 75% 	 Loss : 1.5620e-02 	 Res : 2.8781e-03 	 Jac : 1.2717e-02 	 Enc : 5.3639e-06 	 AEnc : 1.9771e-05 	 MSE : 1.3519e-02
Training Epoch 554 : 	 Train : 1.56400e-02 	 Res : 2.88065e-03 	 Jac : 1.27334e-02 	 Enc : 5.32374e-06 	 AE : 2.05625e-05 	 MSE : 1.14936e-02
Validation Epoch 554 : 	 Train : 1.56953e-02 	 Res : 2.90609e-03 	 Jac : 1.27612e-02 	 Enc : 5.31987e-06 	 AE : 2.27802e-05 	 MSE : 9.00469e-03
Training Epoch 554 finished, took current epoch 358.51s, cumulative time 204889.41s
Current Learning rate DEQ : 6.338253001141159e-06
Current Learning rate AUTOENC : 3.1691265005705794e-05
Epoch 555, 25% 	 Loss : 1.5601e-02 	 Res : 2.8604e-03 	 Jac : 1.2714e-02 	 Enc : 5.3461e-06 	 AEnc : 2.1035e-05 	 MSE : 1.1300e-02
Epoch 555, 50% 	 Loss : 1.5614e-02 	 Res : 2.8521e-03 	 Jac : 1.2737e-02 	 Enc : 5.3582e-06 	 AEnc : 2.0140e-05 	 MSE : 1.1877e-02
Epoch 555, 75% 	 Loss : 1.5661e-02 	 Res : 2.9023e-03 	 Jac : 1.2735e-02 	 Enc : 5.3526e-06 	 AEnc : 1.8609e-05 	 MSE : 1.3547e-02
Training Epoch 555 : 	 Train : 1.56613e-02 	 Res : 2.88260e-03 	 Jac : 1.27527e-02 	 Enc : 5.33793e-06 	 AE : 2.06695e-05 	 MSE : 1.22780e-02
Validation Epoch 555 : 	 Train : 1.56531e-02 	 Res : 2.91735e-03 	 Jac : 1.27090e-02 	 Enc : 5.45691e-06 	 AE : 2.12730e-05 	 MSE : 1.10421e-02
Training Epoch 555 finished, took current epoch 358.44s, cumulative time 205247.83s
Current Learning rate DEQ : 6.338253001141159e-06
Current Learning rate AUTOENC : 3.1691265005705794e-05
Epoch 556, 25% 	 Loss : 1.5579e-02 	 Res : 2.9057e-03 	 Jac : 1.2646e-02 	 Enc : 5.4954e-06 	 AEnc : 2.1691e-05 	 MSE : 1.3768e-02
Epoch 556, 50% 	 Loss : 1.5685e-02 	 Res : 2.9017e-03 	 Jac : 1.2757e-02 	 Enc : 5.2493e-06 	 AEnc : 2.1543e-05 	 MSE : 1.2129e-02
Epoch 556, 75% 	 Loss : 1.5555e-02 	 Res : 2.8196e-03 	 Jac : 1.2711e-02 	 Enc : 5.4808e-06 	 AEnc : 1.8992e-05 	 MSE : 1.3154e-02
Training Epoch 556 : 	 Train : 1.56424e-02 	 Res : 2.88526e-03 	 Jac : 1.27314e-02 	 Enc : 5.40383e-06 	 AE : 2.03277e-05 	 MSE : 1.34972e-02
Validation Epoch 556 : 	 Train : 1.56999e-02 	 Res : 2.90985e-03 	 Jac : 1.27637e-02 	 Enc : 5.29662e-06 	 AE : 2.10437e-05 	 MSE : 8.99369e-03
Training Epoch 556 finished, took current epoch 359.80s, cumulative time 205607.62s
Current Learning rate DEQ : 6.338253001141159e-06
Current Learning rate AUTOENC : 3.1691265005705794e-05
Epoch 557, 25% 	 Loss : 1.5542e-02 	 Res : 2.8485e-03 	 Jac : 1.2669e-02 	 Enc : 5.2537e-06 	 AEnc : 1.9117e-05 	 MSE : 1.4943e-02
Epoch 557, 50% 	 Loss : 1.5616e-02 	 Res : 2.9462e-03 	 Jac : 1.2646e-02 	 Enc : 5.2889e-06 	 AEnc : 1.8950e-05 	 MSE : 1.8433e-02
Epoch 557, 75% 	 Loss : 1.5644e-02 	 Res : 2.8514e-03 	 Jac : 1.2768e-02 	 Enc : 5.2687e-06 	 AEnc : 1.9552e-05 	 MSE : 1.1150e-02
Training Epoch 557 : 	 Train : 1.56188e-02 	 Res : 2.88808e-03 	 Jac : 1.27040e-02 	 Enc : 5.25645e-06 	 AE : 2.14218e-05 	 MSE : 1.42505e-02
Validation Epoch 557 : 	 Train : 1.55862e-02 	 Res : 2.90472e-03 	 Jac : 1.26547e-02 	 Enc : 5.14694e-06 	 AE : 2.16546e-05 	 MSE : 9.07908e-03
Training Epoch 557 finished, took current epoch 356.00s, cumulative time 205963.60s
Current Learning rate DEQ : 6.338253001141159e-06
Current Learning rate AUTOENC : 3.1691265005705794e-05
MODEL SAVED
Epoch 558, 25% 	 Loss : 1.5594e-02 	 Res : 2.8838e-03 	 Jac : 1.2679e-02 	 Enc : 5.1031e-06 	 AEnc : 2.6385e-05 	 MSE : 1.2653e-02
Epoch 558, 50% 	 Loss : 1.5571e-02 	 Res : 2.8800e-03 	 Jac : 1.2643e-02 	 Enc : 5.1580e-06 	 AEnc : 4.1966e-05 	 MSE : 1.6372e-02
Epoch 558, 75% 	 Loss : 1.5729e-02 	 Res : 2.9246e-03 	 Jac : 1.2749e-02 	 Enc : 5.3751e-06 	 AEnc : 5.0632e-05 	 MSE : 1.3610e-02
Training Epoch 558 : 	 Train : 1.56181e-02 	 Res : 2.88701e-03 	 Jac : 1.26899e-02 	 Enc : 5.26143e-06 	 AE : 3.59219e-05 	 MSE : 1.32882e-02
Validation Epoch 558 : 	 Train : 1.57365e-02 	 Res : 2.90862e-03 	 Jac : 1.27814e-02 	 Enc : 5.28161e-06 	 AE : 4.11520e-05 	 MSE : 8.85403e-03
Training Epoch 558 finished, took current epoch 357.89s, cumulative time 206321.48s
Current Learning rate DEQ : 6.338253001141159e-06
Current Learning rate AUTOENC : 3.1691265005705794e-05
Epoch 559, 25% 	 Loss : 1.5695e-02 	 Res : 2.8998e-03 	 Jac : 1.2769e-02 	 Enc : 5.2253e-06 	 AEnc : 2.1682e-05 	 MSE : 1.1015e-02
Epoch 559, 50% 	 Loss : 1.5616e-02 	 Res : 2.8644e-03 	 Jac : 1.2727e-02 	 Enc : 5.1999e-06 	 AEnc : 1.8841e-05 	 MSE : 1.2204e-02
Epoch 559, 75% 	 Loss : 1.5665e-02 	 Res : 2.9000e-03 	 Jac : 1.2741e-02 	 Enc : 5.1526e-06 	 AEnc : 1.8670e-05 	 MSE : 1.1395e-02
Training Epoch 559 : 	 Train : 1.56448e-02 	 Res : 2.88221e-03 	 Jac : 1.27380e-02 	 Enc : 5.18788e-06 	 AE : 1.94290e-05 	 MSE : 1.20367e-02
Validation Epoch 559 : 	 Train : 1.56739e-02 	 Res : 2.91008e-03 	 Jac : 1.27358e-02 	 Enc : 5.23810e-06 	 AE : 2.28249e-05 	 MSE : 1.07319e-02
Training Epoch 559 finished, took current epoch 358.69s, cumulative time 206680.16s
Current Learning rate DEQ : 6.338253001141159e-06
Current Learning rate AUTOENC : 3.1691265005705794e-05
Epoch 560, 25% 	 Loss : 1.5677e-02 	 Res : 2.9355e-03 	 Jac : 1.2716e-02 	 Enc : 5.2501e-06 	 AEnc : 2.0695e-05 	 MSE : 1.1112e-02
Epoch 560, 50% 	 Loss : 1.5683e-02 	 Res : 2.8893e-03 	 Jac : 1.2771e-02 	 Enc : 5.2262e-06 	 AEnc : 1.8106e-05 	 MSE : 1.2467e-02
Epoch 560, 75% 	 Loss : 1.5625e-02 	 Res : 2.8697e-03 	 Jac : 1.2728e-02 	 Enc : 5.3129e-06 	 AEnc : 2.1843e-05 	 MSE : 1.9974e-02
Training Epoch 560 : 	 Train : 1.56520e-02 	 Res : 2.88761e-03 	 Jac : 1.27393e-02 	 Enc : 5.26409e-06 	 AE : 1.97509e-05 	 MSE : 1.41970e-02
Validation Epoch 560 : 	 Train : 1.56173e-02 	 Res : 2.91237e-03 	 Jac : 1.26807e-02 	 Enc : 5.38149e-06 	 AE : 1.88111e-05 	 MSE : 1.09516e-02
Training Epoch 560 finished, took current epoch 361.08s, cumulative time 207041.22s
Current Learning rate DEQ : 5.0706024009129275e-06
Current Learning rate AUTOENC : 2.5353012004564636e-05
Epoch 561, 25% 	 Loss : 1.5575e-02 	 Res : 2.8478e-03 	 Jac : 1.2704e-02 	 Enc : 5.3342e-06 	 AEnc : 1.8400e-05 	 MSE : 1.1302e-02
Epoch 561, 50% 	 Loss : 1.5565e-02 	 Res : 2.9132e-03 	 Jac : 1.2629e-02 	 Enc : 5.0995e-06 	 AEnc : 1.8332e-05 	 MSE : 9.6814e-03
Epoch 561, 75% 	 Loss : 1.5598e-02 	 Res : 2.8436e-03 	 Jac : 1.2730e-02 	 Enc : 5.4364e-06 	 AEnc : 1.9417e-05 	 MSE : 1.2187e-02
Training Epoch 561 : 	 Train : 1.56677e-02 	 Res : 2.93056e-03 	 Jac : 1.27127e-02 	 Enc : 5.29270e-06 	 AE : 1.91212e-05 	 MSE : 2.58830e-02
Validation Epoch 561 : 	 Train : 1.56707e-02 	 Res : 2.91648e-03 	 Jac : 1.27306e-02 	 Enc : 5.35689e-06 	 AE : 1.81943e-05 	 MSE : 1.25407e-02
Training Epoch 561 finished, took current epoch 356.96s, cumulative time 207398.17s
Current Learning rate DEQ : 5.0706024009129275e-06
Current Learning rate AUTOENC : 2.5353012004564636e-05
Epoch 562, 25% 	 Loss : 1.5728e-02 	 Res : 2.8709e-03 	 Jac : 1.2833e-02 	 Enc : 5.6052e-06 	 AEnc : 1.8914e-05 	 MSE : 1.2219e-02
Epoch 562, 50% 	 Loss : 1.5728e-02 	 Res : 2.8697e-03 	 Jac : 1.2834e-02 	 Enc : 5.2599e-06 	 AEnc : 1.9343e-05 	 MSE : 1.3244e-02
Epoch 562, 75% 	 Loss : 1.5514e-02 	 Res : 2.9036e-03 	 Jac : 1.2585e-02 	 Enc : 5.3947e-06 	 AEnc : 1.9905e-05 	 MSE : 1.0954e-02
Training Epoch 562 : 	 Train : 1.56770e-02 	 Res : 2.88243e-03 	 Jac : 1.27698e-02 	 Enc : 5.39708e-06 	 AE : 1.94472e-05 	 MSE : 1.24930e-02
Validation Epoch 562 : 	 Train : 1.56429e-02 	 Res : 2.91048e-03 	 Jac : 1.27101e-02 	 Enc : 5.23451e-06 	 AE : 1.70988e-05 	 MSE : 1.08674e-02
Training Epoch 562 finished, took current epoch 357.30s, cumulative time 207755.46s
Current Learning rate DEQ : 5.0706024009129275e-06
Current Learning rate AUTOENC : 2.5353012004564636e-05
Epoch 563, 25% 	 Loss : 1.5572e-02 	 Res : 2.8910e-03 	 Jac : 1.2657e-02 	 Enc : 5.1543e-06 	 AEnc : 1.8933e-05 	 MSE : 1.0717e-02
Epoch 563, 50% 	 Loss : 1.5568e-02 	 Res : 2.8636e-03 	 Jac : 1.2679e-02 	 Enc : 5.5331e-06 	 AEnc : 1.9792e-05 	 MSE : 1.2477e-02
Epoch 563, 75% 	 Loss : 1.5690e-02 	 Res : 2.8958e-03 	 Jac : 1.2771e-02 	 Enc : 5.1978e-06 	 AEnc : 1.8782e-05 	 MSE : 1.3142e-02
Training Epoch 563 : 	 Train : 1.55823e-02 	 Res : 2.88034e-03 	 Jac : 1.26776e-02 	 Enc : 5.30777e-06 	 AE : 1.90427e-05 	 MSE : 1.19033e-02
Validation Epoch 563 : 	 Train : 1.56147e-02 	 Res : 2.90450e-03 	 Jac : 1.26855e-02 	 Enc : 5.30473e-06 	 AE : 1.93474e-05 	 MSE : 8.75764e-03
Training Epoch 563 finished, took current epoch 363.21s, cumulative time 208118.64s
Current Learning rate DEQ : 5.0706024009129275e-06
Current Learning rate AUTOENC : 2.5353012004564636e-05
MODEL SAVED
Epoch 564, 25% 	 Loss : 1.5718e-02 	 Res : 2.9663e-03 	 Jac : 1.2726e-02 	 Enc : 5.4423e-06 	 AEnc : 1.9314e-05 	 MSE : 1.0266e-02
Epoch 564, 50% 	 Loss : 1.5655e-02 	 Res : 2.8673e-03 	 Jac : 1.2762e-02 	 Enc : 5.4298e-06 	 AEnc : 1.9623e-05 	 MSE : 1.4819e-02
Epoch 564, 75% 	 Loss : 1.5601e-02 	 Res : 2.8594e-03 	 Jac : 1.2717e-02 	 Enc : 5.4188e-06 	 AEnc : 1.9169e-05 	 MSE : 1.1528e-02
Training Epoch 564 : 	 Train : 1.56495e-02 	 Res : 2.87900e-03 	 Jac : 1.27457e-02 	 Enc : 5.42347e-06 	 AE : 1.93803e-05 	 MSE : 1.17669e-02
Validation Epoch 564 : 	 Train : 1.56760e-02 	 Res : 2.91044e-03 	 Jac : 1.27379e-02 	 Enc : 5.26772e-06 	 AE : 2.24265e-05 	 MSE : 1.05826e-02
Training Epoch 564 finished, took current epoch 358.46s, cumulative time 208477.06s
Current Learning rate DEQ : 5.0706024009129275e-06
Current Learning rate AUTOENC : 2.5353012004564636e-05
Epoch 565, 25% 	 Loss : 1.5578e-02 	 Res : 2.8291e-03 	 Jac : 1.2724e-02 	 Enc : 5.4430e-06 	 AEnc : 1.8860e-05 	 MSE : 1.0826e-02
Epoch 565, 50% 	 Loss : 1.5659e-02 	 Res : 2.9090e-03 	 Jac : 1.2725e-02 	 Enc : 5.0234e-06 	 AEnc : 2.0045e-05 	 MSE : 1.0350e-02
Epoch 565, 75% 	 Loss : 1.5636e-02 	 Res : 2.9100e-03 	 Jac : 1.2699e-02 	 Enc : 5.2600e-06 	 AEnc : 2.1066e-05 	 MSE : 1.1230e-02
Training Epoch 565 : 	 Train : 1.56175e-02 	 Res : 2.87830e-03 	 Jac : 1.27137e-02 	 Enc : 5.22220e-06 	 AE : 2.02777e-05 	 MSE : 1.07950e-02
Validation Epoch 565 : 	 Train : 1.56415e-02 	 Res : 2.90715e-03 	 Jac : 1.27078e-02 	 Enc : 5.26060e-06 	 AE : 2.12638e-05 	 MSE : 9.47058e-03
Training Epoch 565 finished, took current epoch 362.32s, cumulative time 208839.37s
Current Learning rate DEQ : 5.0706024009129275e-06
Current Learning rate AUTOENC : 2.5353012004564636e-05
Epoch 566, 25% 	 Loss : 1.5710e-02 	 Res : 2.9278e-03 	 Jac : 1.2758e-02 	 Enc : 5.3077e-06 	 AEnc : 1.8958e-05 	 MSE : 1.0411e-02
Epoch 566, 50% 	 Loss : 1.5602e-02 	 Res : 2.8095e-03 	 Jac : 1.2768e-02 	 Enc : 5.3797e-06 	 AEnc : 1.9019e-05 	 MSE : 1.0450e-02
Epoch 566, 75% 	 Loss : 1.5708e-02 	 Res : 2.9290e-03 	 Jac : 1.2752e-02 	 Enc : 5.2070e-06 	 AEnc : 2.1129e-05 	 MSE : 1.1654e-02
Training Epoch 566 : 	 Train : 1.56496e-02 	 Res : 2.88047e-03 	 Jac : 1.27443e-02 	 Enc : 5.29643e-06 	 AE : 1.95308e-05 	 MSE : 1.12490e-02
Validation Epoch 566 : 	 Train : 1.56242e-02 	 Res : 2.91009e-03 	 Jac : 1.26837e-02 	 Enc : 5.32906e-06 	 AE : 2.50376e-05 	 MSE : 1.04824e-02
Training Epoch 566 finished, took current epoch 358.77s, cumulative time 209198.13s
Current Learning rate DEQ : 5.0706024009129275e-06
Current Learning rate AUTOENC : 2.5353012004564636e-05
Epoch 567, 25% 	 Loss : 1.5704e-02 	 Res : 2.9164e-03 	 Jac : 1.2759e-02 	 Enc : 5.3811e-06 	 AEnc : 2.2788e-05 	 MSE : 1.0348e-02
Epoch 567, 50% 	 Loss : 1.5600e-02 	 Res : 2.8699e-03 	 Jac : 1.2704e-02 	 Enc : 5.5187e-06 	 AEnc : 2.0664e-05 	 MSE : 1.2474e-02
Epoch 567, 75% 	 Loss : 1.5615e-02 	 Res : 2.8828e-03 	 Jac : 1.2694e-02 	 Enc : 5.2470e-06 	 AEnc : 3.3010e-05 	 MSE : 9.4369e-03
Training Epoch 567 : 	 Train : 1.56340e-02 	 Res : 2.88059e-03 	 Jac : 1.27192e-02 	 Enc : 5.35507e-06 	 AE : 2.88173e-05 	 MSE : 1.12402e-02
Validation Epoch 567 : 	 Train : 1.57163e-02 	 Res : 2.91744e-03 	 Jac : 1.27612e-02 	 Enc : 5.22793e-06 	 AE : 3.24544e-05 	 MSE : 1.24848e-02
Training Epoch 567 finished, took current epoch 359.13s, cumulative time 209557.25s
Current Learning rate DEQ : 5.0706024009129275e-06
Current Learning rate AUTOENC : 2.5353012004564636e-05
Epoch 568, 25% 	 Loss : 1.5555e-02 	 Res : 2.9160e-03 	 Jac : 1.2609e-02 	 Enc : 5.2994e-06 	 AEnc : 2.4690e-05 	 MSE : 1.2558e-02
Epoch 568, 50% 	 Loss : 1.5544e-02 	 Res : 2.8468e-03 	 Jac : 1.2669e-02 	 Enc : 5.2754e-06 	 AEnc : 2.2457e-05 	 MSE : 1.4183e-02
Epoch 568, 75% 	 Loss : 1.5659e-02 	 Res : 2.8945e-03 	 Jac : 1.2739e-02 	 Enc : 5.3634e-06 	 AEnc : 1.9921e-05 	 MSE : 1.2798e-02
Training Epoch 568 : 	 Train : 1.55821e-02 	 Res : 2.88364e-03 	 Jac : 1.26711e-02 	 Enc : 5.34528e-06 	 AE : 2.19560e-05 	 MSE : 1.28028e-02
Validation Epoch 568 : 	 Train : 1.56702e-02 	 Res : 2.91137e-03 	 Jac : 1.27363e-02 	 Enc : 5.40553e-06 	 AE : 1.70918e-05 	 MSE : 1.04366e-02
Training Epoch 568 finished, took current epoch 357.79s, cumulative time 209915.03s
Current Learning rate DEQ : 5.0706024009129275e-06
Current Learning rate AUTOENC : 2.5353012004564636e-05
Epoch 569, 25% 	 Loss : 1.5550e-02 	 Res : 2.8417e-03 	 Jac : 1.2684e-02 	 Enc : 5.2580e-06 	 AEnc : 1.8412e-05 	 MSE : 1.3986e-02
Epoch 569, 50% 	 Loss : 1.5479e-02 	 Res : 2.7730e-03 	 Jac : 1.2682e-02 	 Enc : 5.2810e-06 	 AEnc : 1.8455e-05 	 MSE : 1.0179e-02
Epoch 569, 75% 	 Loss : 1.5681e-02 	 Res : 2.9276e-03 	 Jac : 1.2729e-02 	 Enc : 5.4862e-06 	 AEnc : 1.9408e-05 	 MSE : 1.1978e-02
Training Epoch 569 : 	 Train : 1.56030e-02 	 Res : 2.88173e-03 	 Jac : 1.26973e-02 	 Enc : 5.33775e-06 	 AE : 1.86452e-05 	 MSE : 1.20113e-02
Validation Epoch 569 : 	 Train : 1.56709e-02 	 Res : 2.90819e-03 	 Jac : 1.27402e-02 	 Enc : 5.32193e-06 	 AE : 1.72517e-05 	 MSE : 1.00632e-02
Training Epoch 569 finished, took current epoch 360.02s, cumulative time 210275.03s
Current Learning rate DEQ : 5.0706024009129275e-06
Current Learning rate AUTOENC : 2.5353012004564636e-05
Epoch 570, 25% 	 Loss : 1.5626e-02 	 Res : 2.8897e-03 	 Jac : 1.2712e-02 	 Enc : 5.3786e-06 	 AEnc : 1.8796e-05 	 MSE : 1.0922e-02
Epoch 570, 50% 	 Loss : 1.5525e-02 	 Res : 2.8583e-03 	 Jac : 1.2642e-02 	 Enc : 5.2149e-06 	 AEnc : 1.8862e-05 	 MSE : 1.0771e-02
Epoch 570, 75% 	 Loss : 1.5652e-02 	 Res : 2.8356e-03 	 Jac : 1.2793e-02 	 Enc : 5.2675e-06 	 AEnc : 1.8400e-05 	 MSE : 9.8218e-03
Training Epoch 570 : 	 Train : 1.56164e-02 	 Res : 2.88033e-03 	 Jac : 1.27113e-02 	 Enc : 5.31779e-06 	 AE : 1.94487e-05 	 MSE : 1.17215e-02
Validation Epoch 570 : 	 Train : 1.57458e-02 	 Res : 2.94895e-03 	 Jac : 1.27736e-02 	 Enc : 5.32944e-06 	 AE : 1.79950e-05 	 MSE : 2.50158e-02
Training Epoch 570 finished, took current epoch 359.01s, cumulative time 210634.03s
Current Learning rate DEQ : 5.0706024009129275e-06
Current Learning rate AUTOENC : 2.5353012004564636e-05
Epoch 571, 25% 	 Loss : 1.5638e-02 	 Res : 2.9184e-03 	 Jac : 1.2694e-02 	 Enc : 5.2471e-06 	 AEnc : 2.0223e-05 	 MSE : 1.2275e-02
Epoch 571, 50% 	 Loss : 1.5572e-02 	 Res : 2.8838e-03 	 Jac : 1.2652e-02 	 Enc : 5.4701e-06 	 AEnc : 3.1131e-05 	 MSE : 1.0138e-02
Epoch 571, 75% 	 Loss : 1.5592e-02 	 Res : 2.8663e-03 	 Jac : 1.2699e-02 	 Enc : 5.3022e-06 	 AEnc : 2.1594e-05 	 MSE : 1.0324e-02
Training Epoch 571 : 	 Train : 1.56075e-02 	 Res : 2.87930e-03 	 Jac : 1.26995e-02 	 Enc : 5.37081e-06 	 AE : 2.32846e-05 	 MSE : 1.11292e-02
Validation Epoch 571 : 	 Train : 1.57170e-02 	 Res : 2.92523e-03 	 Jac : 1.27579e-02 	 Enc : 5.39043e-06 	 AE : 2.84816e-05 	 MSE : 1.51301e-02
Training Epoch 571 finished, took current epoch 362.57s, cumulative time 210996.59s
Current Learning rate DEQ : 4.056481920730342e-06
Current Learning rate AUTOENC : 2.028240960365171e-05
Epoch 572, 25% 	 Loss : 1.5612e-02 	 Res : 2.8522e-03 	 Jac : 1.2733e-02 	 Enc : 5.3797e-06 	 AEnc : 2.1346e-05 	 MSE : 1.1822e-02
Epoch 572, 50% 	 Loss : 1.5614e-02 	 Res : 2.9360e-03 	 Jac : 1.2653e-02 	 Enc : 5.4175e-06 	 AEnc : 1.9776e-05 	 MSE : 1.2625e-02
Epoch 572, 75% 	 Loss : 1.5619e-02 	 Res : 2.8344e-03 	 Jac : 1.2760e-02 	 Enc : 5.3736e-06 	 AEnc : 1.8620e-05 	 MSE : 9.8505e-03
Training Epoch 572 : 	 Train : 1.56162e-02 	 Res : 2.87848e-03 	 Jac : 1.27125e-02 	 Enc : 5.41235e-06 	 AE : 1.98430e-05 	 MSE : 1.14181e-02
Validation Epoch 572 : 	 Train : 1.56070e-02 	 Res : 2.91233e-03 	 Jac : 1.26695e-02 	 Enc : 5.39554e-06 	 AE : 1.97837e-05 	 MSE : 1.23282e-02
Training Epoch 572 finished, took current epoch 359.32s, cumulative time 211355.90s
Current Learning rate DEQ : 4.056481920730342e-06
Current Learning rate AUTOENC : 2.028240960365171e-05
Epoch 573, 25% 	 Loss : 1.5563e-02 	 Res : 2.8700e-03 	 Jac : 1.2668e-02 	 Enc : 5.5003e-06 	 AEnc : 1.9748e-05 	 MSE : 1.2182e-02
Epoch 573, 50% 	 Loss : 1.5731e-02 	 Res : 2.9054e-03 	 Jac : 1.2800e-02 	 Enc : 5.4111e-06 	 AEnc : 2.0149e-05 	 MSE : 1.5173e-02
Epoch 573, 75% 	 Loss : 1.5559e-02 	 Res : 2.9001e-03 	 Jac : 1.2635e-02 	 Enc : 5.4309e-06 	 AEnc : 1.8298e-05 	 MSE : 1.9285e-02
Training Epoch 573 : 	 Train : 1.56195e-02 	 Res : 2.88704e-03 	 Jac : 1.27078e-02 	 Enc : 5.40271e-06 	 AE : 1.92356e-05 	 MSE : 1.47110e-02
Validation Epoch 573 : 	 Train : 1.56531e-02 	 Res : 2.91063e-03 	 Jac : 1.27190e-02 	 Enc : 5.35479e-06 	 AE : 1.81378e-05 	 MSE : 1.11351e-02
Training Epoch 573 finished, took current epoch 357.31s, cumulative time 211713.19s
Current Learning rate DEQ : 4.056481920730342e-06
Current Learning rate AUTOENC : 2.028240960365171e-05
Epoch 574, 25% 	 Loss : 1.5599e-02 	 Res : 2.9192e-03 	 Jac : 1.2656e-02 	 Enc : 5.4176e-06 	 AEnc : 1.8921e-05 	 MSE : 1.1226e-02
Epoch 574, 50% 	 Loss : 1.5663e-02 	 Res : 2.9189e-03 	 Jac : 1.2720e-02 	 Enc : 5.2860e-06 	 AEnc : 1.9083e-05 	 MSE : 1.1732e-02
Epoch 574, 75% 	 Loss : 1.5558e-02 	 Res : 2.8744e-03 	 Jac : 1.2659e-02 	 Enc : 5.5493e-06 	 AEnc : 1.9167e-05 	 MSE : 1.0307e-02
Training Epoch 574 : 	 Train : 1.55944e-02 	 Res : 2.87898e-03 	 Jac : 1.26908e-02 	 Enc : 5.41730e-06 	 AE : 1.91768e-05 	 MSE : 1.10805e-02
Validation Epoch 574 : 	 Train : 1.55969e-02 	 Res : 2.90554e-03 	 Jac : 1.26675e-02 	 Enc : 5.35358e-06 	 AE : 1.85148e-05 	 MSE : 9.21587e-03
Training Epoch 574 finished, took current epoch 358.63s, cumulative time 212071.80s
Current Learning rate DEQ : 4.056481920730342e-06
Current Learning rate AUTOENC : 2.028240960365171e-05
Epoch 575, 25% 	 Loss : 1.5671e-02 	 Res : 2.9293e-03 	 Jac : 1.2712e-02 	 Enc : 5.3485e-06 	 AEnc : 2.4420e-05 	 MSE : 1.0506e-02
Epoch 575, 50% 	 Loss : 1.5719e-02 	 Res : 2.8772e-03 	 Jac : 1.2815e-02 	 Enc : 5.3756e-06 	 AEnc : 2.1714e-05 	 MSE : 9.7382e-03
Epoch 575, 75% 	 Loss : 1.5641e-02 	 Res : 2.8669e-03 	 Jac : 1.2749e-02 	 Enc : 5.1771e-06 	 AEnc : 1.9884e-05 	 MSE : 1.0068e-02
Training Epoch 575 : 	 Train : 1.56413e-02 	 Res : 2.87701e-03 	 Jac : 1.27374e-02 	 Enc : 5.27075e-06 	 AE : 2.15509e-05 	 MSE : 1.01970e-02
Validation Epoch 575 : 	 Train : 1.56674e-02 	 Res : 2.91618e-03 	 Jac : 1.27265e-02 	 Enc : 5.21185e-06 	 AE : 1.95072e-05 	 MSE : 1.25829e-02
Training Epoch 575 finished, took current epoch 364.65s, cumulative time 212436.41s
Current Learning rate DEQ : 4.056481920730342e-06
Current Learning rate AUTOENC : 2.028240960365171e-05
Epoch 576, 25% 	 Loss : 1.5699e-02 	 Res : 2.8660e-03 	 Jac : 1.2807e-02 	 Enc : 5.3141e-06 	 AEnc : 2.0624e-05 	 MSE : 1.1149e-02
Epoch 576, 50% 	 Loss : 1.5603e-02 	 Res : 2.9580e-03 	 Jac : 1.2621e-02 	 Enc : 5.2351e-06 	 AEnc : 1.9330e-05 	 MSE : 1.1833e-02
Epoch 576, 75% 	 Loss : 1.5645e-02 	 Res : 2.8483e-03 	 Jac : 1.2772e-02 	 Enc : 5.3145e-06 	 AEnc : 1.9299e-05 	 MSE : 1.0347e-02
Training Epoch 576 : 	 Train : 1.56469e-02 	 Res : 2.87954e-03 	 Jac : 1.27424e-02 	 Enc : 5.32379e-06 	 AE : 1.95767e-05 	 MSE : 1.17522e-02
Validation Epoch 576 : 	 Train : 1.55669e-02 	 Res : 2.90408e-03 	 Jac : 1.26401e-02 	 Enc : 5.34657e-06 	 AE : 1.73355e-05 	 MSE : 8.85394e-03
Training Epoch 576 finished, took current epoch 361.69s, cumulative time 212798.05s
Current Learning rate DEQ : 4.056481920730342e-06
Current Learning rate AUTOENC : 2.028240960365171e-05
MODEL SAVED
Epoch 577, 25% 	 Loss : 1.5619e-02 	 Res : 2.8784e-03 	 Jac : 1.2716e-02 	 Enc : 5.3743e-06 	 AEnc : 1.8619e-05 	 MSE : 1.1487e-02
Epoch 577, 50% 	 Loss : 1.5648e-02 	 Res : 2.9332e-03 	 Jac : 1.2689e-02 	 Enc : 5.3324e-06 	 AEnc : 1.9673e-05 	 MSE : 1.0771e-02
Epoch 577, 75% 	 Loss : 1.5673e-02 	 Res : 2.8419e-03 	 Jac : 1.2806e-02 	 Enc : 5.4807e-06 	 AEnc : 1.9629e-05 	 MSE : 1.0044e-02
Training Epoch 577 : 	 Train : 1.56099e-02 	 Res : 2.87682e-03 	 Jac : 1.27086e-02 	 Enc : 5.43253e-06 	 AE : 1.90313e-05 	 MSE : 1.06038e-02
Validation Epoch 577 : 	 Train : 1.56318e-02 	 Res : 2.90499e-03 	 Jac : 1.27034e-02 	 Enc : 5.40293e-06 	 AE : 1.79953e-05 	 MSE : 9.39224e-03
Training Epoch 577 finished, took current epoch 360.40s, cumulative time 213158.40s
Current Learning rate DEQ : 4.056481920730342e-06
Current Learning rate AUTOENC : 2.028240960365171e-05
Epoch 578, 25% 	 Loss : 1.5628e-02 	 Res : 2.8970e-03 	 Jac : 1.2706e-02 	 Enc : 5.4121e-06 	 AEnc : 1.9279e-05 	 MSE : 1.0506e-02
Epoch 578, 50% 	 Loss : 1.5715e-02 	 Res : 2.9630e-03 	 Jac : 1.2728e-02 	 Enc : 5.5452e-06 	 AEnc : 1.9117e-05 	 MSE : 2.0190e-02
Epoch 578, 75% 	 Loss : 1.5638e-02 	 Res : 2.8842e-03 	 Jac : 1.2729e-02 	 Enc : 5.4291e-06 	 AEnc : 1.8807e-05 	 MSE : 1.4262e-02
Training Epoch 578 : 	 Train : 1.56502e-02 	 Res : 2.89239e-03 	 Jac : 1.27331e-02 	 Enc : 5.38139e-06 	 AE : 1.93307e-05 	 MSE : 1.45594e-02
Validation Epoch 578 : 	 Train : 1.56982e-02 	 Res : 2.91981e-03 	 Jac : 1.27549e-02 	 Enc : 5.32103e-06 	 AE : 1.81402e-05 	 MSE : 1.47997e-02
Training Epoch 578 finished, took current epoch 360.44s, cumulative time 213518.83s
Current Learning rate DEQ : 4.056481920730342e-06
Current Learning rate AUTOENC : 2.028240960365171e-05
Epoch 579, 25% 	 Loss : 1.5698e-02 	 Res : 2.8920e-03 	 Jac : 1.2781e-02 	 Enc : 5.3215e-06 	 AEnc : 2.0146e-05 	 MSE : 1.0852e-02
Epoch 579, 50% 	 Loss : 1.5663e-02 	 Res : 2.8928e-03 	 Jac : 1.2746e-02 	 Enc : 5.4936e-06 	 AEnc : 1.8703e-05 	 MSE : 1.1023e-02
Epoch 579, 75% 	 Loss : 1.5579e-02 	 Res : 2.8666e-03 	 Jac : 1.2687e-02 	 Enc : 5.5540e-06 	 AEnc : 1.9946e-05 	 MSE : 1.0687e-02
Training Epoch 579 : 	 Train : 1.56240e-02 	 Res : 2.87777e-03 	 Jac : 1.27214e-02 	 Enc : 5.45294e-06 	 AE : 1.93816e-05 	 MSE : 1.08744e-02
Validation Epoch 579 : 	 Train : 1.56562e-02 	 Res : 2.90616e-03 	 Jac : 1.27260e-02 	 Enc : 5.41180e-06 	 AE : 1.86080e-05 	 MSE : 9.56003e-03
Training Epoch 579 finished, took current epoch 361.34s, cumulative time 213880.12s
Current Learning rate DEQ : 4.056481920730342e-06
Current Learning rate AUTOENC : 2.028240960365171e-05
Epoch 580, 25% 	 Loss : 1.5671e-02 	 Res : 2.8787e-03 	 Jac : 1.2768e-02 	 Enc : 5.3655e-06 	 AEnc : 1.8360e-05 	 MSE : 1.0524e-02
Epoch 580, 50% 	 Loss : 1.5622e-02 	 Res : 2.8699e-03 	 Jac : 1.2728e-02 	 Enc : 5.4578e-06 	 AEnc : 1.8730e-05 	 MSE : 1.1940e-02
Epoch 580, 75% 	 Loss : 1.5662e-02 	 Res : 2.8809e-03 	 Jac : 1.2757e-02 	 Enc : 5.2998e-06 	 AEnc : 1.8637e-05 	 MSE : 1.0864e-02
Training Epoch 580 : 	 Train : 1.56683e-02 	 Res : 2.87764e-03 	 Jac : 1.27667e-02 	 Enc : 5.40679e-06 	 AE : 1.85545e-05 	 MSE : 1.09667e-02
Validation Epoch 580 : 	 Train : 1.56244e-02 	 Res : 2.90350e-03 	 Jac : 1.26981e-02 	 Enc : 5.35162e-06 	 AE : 1.74252e-05 	 MSE : 8.79670e-03
Training Epoch 580 finished, took current epoch 359.03s, cumulative time 214239.11s
Current Learning rate DEQ : 4.056481920730342e-06
Current Learning rate AUTOENC : 2.028240960365171e-05
MODEL SAVED
Epoch 581, 25% 	 Loss : 1.5677e-02 	 Res : 2.9162e-03 	 Jac : 1.2736e-02 	 Enc : 5.3157e-06 	 AEnc : 2.0036e-05 	 MSE : 1.0171e-02
Epoch 581, 50% 	 Loss : 1.5519e-02 	 Res : 2.7741e-03 	 Jac : 1.2721e-02 	 Enc : 5.3413e-06 	 AEnc : 1.7921e-05 	 MSE : 9.5480e-03
Epoch 581, 75% 	 Loss : 1.5676e-02 	 Res : 2.9169e-03 	 Jac : 1.2734e-02 	 Enc : 5.5167e-06 	 AEnc : 1.9706e-05 	 MSE : 1.0502e-02
Training Epoch 581 : 	 Train : 1.56078e-02 	 Res : 2.87524e-03 	 Jac : 1.27081e-02 	 Enc : 5.39247e-06 	 AE : 1.91029e-05 	 MSE : 1.01670e-02
Validation Epoch 581 : 	 Train : 1.56107e-02 	 Res : 2.91109e-03 	 Jac : 1.26760e-02 	 Enc : 5.26718e-06 	 AE : 1.83616e-05 	 MSE : 9.50662e-03
Training Epoch 581 finished, took current epoch 358.00s, cumulative time 214597.07s
Current Learning rate DEQ : 4.056481920730342e-06
Current Learning rate AUTOENC : 2.028240960365171e-05
Epoch 582, 25% 	 Loss : 1.5596e-02 	 Res : 2.8935e-03 	 Jac : 1.2679e-02 	 Enc : 5.3021e-06 	 AEnc : 1.8118e-05 	 MSE : 1.7425e-02
Epoch 582, 50% 	 Loss : 1.5707e-02 	 Res : 2.9088e-03 	 Jac : 1.2774e-02 	 Enc : 5.2472e-06 	 AEnc : 1.8349e-05 	 MSE : 1.1008e-02
Epoch 582, 75% 	 Loss : 1.5535e-02 	 Res : 2.8507e-03 	 Jac : 1.2659e-02 	 Enc : 5.4159e-06 	 AEnc : 1.9852e-05 	 MSE : 1.1711e-02
Training Epoch 582 : 	 Train : 1.56154e-02 	 Res : 2.88271e-03 	 Jac : 1.27087e-02 	 Enc : 5.37091e-06 	 AE : 1.86037e-05 	 MSE : 1.30470e-02
Validation Epoch 582 : 	 Train : 1.56856e-02 	 Res : 2.90663e-03 	 Jac : 1.27564e-02 	 Enc : 5.42940e-06 	 AE : 1.72013e-05 	 MSE : 9.84393e-03
Training Epoch 582 finished, took current epoch 359.70s, cumulative time 214956.76s
Current Learning rate DEQ : 3.245185536584274e-06
Current Learning rate AUTOENC : 1.6225927682921368e-05
Epoch 583, 25% 	 Loss : 1.5662e-02 	 Res : 2.8746e-03 	 Jac : 1.2763e-02 	 Enc : 5.5101e-06 	 AEnc : 1.8406e-05 	 MSE : 1.0699e-02
Epoch 583, 50% 	 Loss : 1.5707e-02 	 Res : 2.9495e-03 	 Jac : 1.2730e-02 	 Enc : 5.5607e-06 	 AEnc : 2.0996e-05 	 MSE : 1.1486e-02
Epoch 583, 75% 	 Loss : 1.5481e-02 	 Res : 2.8321e-03 	 Jac : 1.2625e-02 	 Enc : 5.4016e-06 	 AEnc : 1.8861e-05 	 MSE : 1.1710e-02
Training Epoch 583 : 	 Train : 1.56161e-02 	 Res : 2.87575e-03 	 Jac : 1.27155e-02 	 Enc : 5.44941e-06 	 AE : 1.94195e-05 	 MSE : 1.07383e-02
Validation Epoch 583 : 	 Train : 1.55448e-02 	 Res : 2.90460e-03 	 Jac : 1.26164e-02 	 Enc : 5.38586e-06 	 AE : 1.84706e-05 	 MSE : 8.57090e-03
Training Epoch 583 finished, took current epoch 362.42s, cumulative time 215319.17s
Current Learning rate DEQ : 3.245185536584274e-06
Current Learning rate AUTOENC : 1.6225927682921368e-05
Epoch 584, 25% 	 Loss : 1.5614e-02 	 Res : 2.8897e-03 	 Jac : 1.2700e-02 	 Enc : 5.3476e-06 	 AEnc : 1.8953e-05 	 MSE : 9.2504e-03
Epoch 584, 50% 	 Loss : 1.5635e-02 	 Res : 2.8896e-03 	 Jac : 1.2723e-02 	 Enc : 5.4956e-06 	 AEnc : 1.7927e-05 	 MSE : 9.9932e-03
Epoch 584, 75% 	 Loss : 1.5626e-02 	 Res : 2.8545e-03 	 Jac : 1.2741e-02 	 Enc : 5.5063e-06 	 AEnc : 2.5025e-05 	 MSE : 1.2427e-02
Training Epoch 584 : 	 Train : 1.56415e-02 	 Res : 2.87752e-03 	 Jac : 1.27380e-02 	 Enc : 5.41217e-06 	 AE : 2.06064e-05 	 MSE : 1.08237e-02
Validation Epoch 584 : 	 Train : 1.56813e-02 	 Res : 2.90927e-03 	 Jac : 1.27466e-02 	 Enc : 5.36658e-06 	 AE : 2.00725e-05 	 MSE : 9.92681e-03
Training Epoch 584 finished, took current epoch 359.13s, cumulative time 215678.29s
Current Learning rate DEQ : 3.245185536584274e-06
Current Learning rate AUTOENC : 1.6225927682921368e-05
Epoch 585, 25% 	 Loss : 1.5701e-02 	 Res : 2.9158e-03 	 Jac : 1.2759e-02 	 Enc : 5.5118e-06 	 AEnc : 2.0586e-05 	 MSE : 1.0729e-02
Epoch 585, 50% 	 Loss : 1.5569e-02 	 Res : 2.8562e-03 	 Jac : 1.2690e-02 	 Enc : 5.2966e-06 	 AEnc : 1.8270e-05 	 MSE : 1.0054e-02
Epoch 585, 75% 	 Loss : 1.5744e-02 	 Res : 2.9273e-03 	 Jac : 1.2792e-02 	 Enc : 5.5178e-06 	 AEnc : 1.9142e-05 	 MSE : 1.2163e-02
Training Epoch 585 : 	 Train : 1.56359e-02 	 Res : 2.87657e-03 	 Jac : 1.27348e-02 	 Enc : 5.43170e-06 	 AE : 1.91838e-05 	 MSE : 1.07498e-02
Validation Epoch 585 : 	 Train : 1.58174e-02 	 Res : 3.05179e-03 	 Jac : 1.27422e-02 	 Enc : 5.47055e-06 	 AE : 1.79441e-05 	 MSE : 4.40520e-02
Training Epoch 585 finished, took current epoch 360.19s, cumulative time 216038.46s
Current Learning rate DEQ : 3.245185536584274e-06
Current Learning rate AUTOENC : 1.6225927682921368e-05
Epoch 586, 25% 	 Loss : 1.5632e-02 	 Res : 2.9380e-03 	 Jac : 1.2669e-02 	 Enc : 5.5194e-06 	 AEnc : 1.9554e-05 	 MSE : 1.1409e-02
Epoch 586, 50% 	 Loss : 1.5502e-02 	 Res : 2.8307e-03 	 Jac : 1.2628e-02 	 Enc : 5.3844e-06 	 AEnc : 3.6998e-05 	 MSE : 1.2242e-02
Epoch 586, 75% 	 Loss : 1.5705e-02 	 Res : 2.8803e-03 	 Jac : 1.2787e-02 	 Enc : 5.4861e-06 	 AEnc : 3.2381e-05 	 MSE : 1.0146e-02
Training Epoch 586 : 	 Train : 1.56381e-02 	 Res : 2.87869e-03 	 Jac : 1.27269e-02 	 Enc : 5.43957e-06 	 AE : 2.70567e-05 	 MSE : 1.11916e-02
Validation Epoch 586 : 	 Train : 1.55649e-02 	 Res : 2.90465e-03 	 Jac : 1.26358e-02 	 Enc : 5.44711e-06 	 AE : 1.89242e-05 	 MSE : 7.69059e-03
Training Epoch 586 finished, took current epoch 360.75s, cumulative time 216399.20s
Current Learning rate DEQ : 3.245185536584274e-06
Current Learning rate AUTOENC : 1.6225927682921368e-05
Epoch 587, 25% 	 Loss : 1.5686e-02 	 Res : 2.9080e-03 	 Jac : 1.2753e-02 	 Enc : 5.4479e-06 	 AEnc : 1.9647e-05 	 MSE : 8.8967e-03
Epoch 587, 50% 	 Loss : 1.5611e-02 	 Res : 2.8335e-03 	 Jac : 1.2753e-02 	 Enc : 5.6555e-06 	 AEnc : 1.8685e-05 	 MSE : 1.0557e-02
Epoch 587, 75% 	 Loss : 1.5688e-02 	 Res : 2.8570e-03 	 Jac : 1.2806e-02 	 Enc : 5.5220e-06 	 AEnc : 1.9266e-05 	 MSE : 1.2505e-02
Training Epoch 587 : 	 Train : 1.56717e-02 	 Res : 2.87665e-03 	 Jac : 1.27705e-02 	 Enc : 5.50776e-06 	 AE : 1.89597e-05 	 MSE : 1.05702e-02
Validation Epoch 587 : 	 Train : 1.56115e-02 	 Res : 2.90438e-03 	 Jac : 1.26819e-02 	 Enc : 5.37415e-06 	 AE : 1.98035e-05 	 MSE : 8.91955e-03
Training Epoch 587 finished, took current epoch 359.42s, cumulative time 216758.59s
Current Learning rate DEQ : 3.245185536584274e-06
Current Learning rate AUTOENC : 1.6225927682921368e-05
Epoch 588, 25% 	 Loss : 1.5572e-02 	 Res : 2.8734e-03 	 Jac : 1.2673e-02 	 Enc : 5.4452e-06 	 AEnc : 1.9830e-05 	 MSE : 1.0675e-02
Epoch 588, 50% 	 Loss : 1.5640e-02 	 Res : 2.8927e-03 	 Jac : 1.2723e-02 	 Enc : 5.4164e-06 	 AEnc : 1.8656e-05 	 MSE : 1.1866e-02
Epoch 588, 75% 	 Loss : 1.5574e-02 	 Res : 2.8782e-03 	 Jac : 1.2671e-02 	 Enc : 5.3601e-06 	 AEnc : 1.8999e-05 	 MSE : 1.1891e-02
Training Epoch 588 : 	 Train : 1.55999e-02 	 Res : 2.90549e-03 	 Jac : 1.26700e-02 	 Enc : 5.41946e-06 	 AE : 1.89257e-05 	 MSE : 2.03906e-02
Validation Epoch 588 : 	 Train : 1.56578e-02 	 Res : 2.90696e-03 	 Jac : 1.27281e-02 	 Enc : 5.44635e-06 	 AE : 1.72747e-05 	 MSE : 9.69616e-03
Training Epoch 588 finished, took current epoch 359.68s, cumulative time 217118.26s
Current Learning rate DEQ : 3.245185536584274e-06
Current Learning rate AUTOENC : 1.6225927682921368e-05
Epoch 589, 25% 	 Loss : 1.5524e-02 	 Res : 2.8694e-03 	 Jac : 1.2631e-02 	 Enc : 5.5281e-06 	 AEnc : 1.7961e-05 	 MSE : 9.3940e-03
Epoch 589, 50% 	 Loss : 1.5683e-02 	 Res : 2.9989e-03 	 Jac : 1.2659e-02 	 Enc : 5.4786e-06 	 AEnc : 1.8822e-05 	 MSE : 5.6302e-02
Epoch 589, 75% 	 Loss : 1.5651e-02 	 Res : 2.8817e-03 	 Jac : 1.2746e-02 	 Enc : 5.3765e-06 	 AEnc : 1.8211e-05 	 MSE : 9.7376e-03
Training Epoch 589 : 	 Train : 1.56198e-02 	 Res : 2.90594e-03 	 Jac : 1.26898e-02 	 Enc : 5.46268e-06 	 AE : 1.85132e-05 	 MSE : 2.14196e-02
Validation Epoch 589 : 	 Train : 1.57265e-02 	 Res : 2.91346e-03 	 Jac : 1.27779e-02 	 Enc : 5.41101e-06 	 AE : 2.97725e-05 	 MSE : 1.22724e-02
Training Epoch 589 finished, took current epoch 364.64s, cumulative time 217482.89s
Current Learning rate DEQ : 3.245185536584274e-06
Current Learning rate AUTOENC : 1.6225927682921368e-05
Epoch 590, 25% 	 Loss : 1.5585e-02 	 Res : 2.8641e-03 	 Jac : 1.2692e-02 	 Enc : 5.3327e-06 	 AEnc : 2.3468e-05 	 MSE : 1.1715e-02
Epoch 590, 50% 	 Loss : 1.5656e-02 	 Res : 2.8618e-03 	 Jac : 1.2771e-02 	 Enc : 5.3461e-06 	 AEnc : 1.8449e-05 	 MSE : 1.0871e-02
Epoch 590, 75% 	 Loss : 1.5693e-02 	 Res : 2.9087e-03 	 Jac : 1.2760e-02 	 Enc : 5.4314e-06 	 AEnc : 1.8518e-05 	 MSE : 1.2476e-02
Training Epoch 590 : 	 Train : 1.56404e-02 	 Res : 2.88071e-03 	 Jac : 1.27343e-02 	 Enc : 5.36756e-06 	 AE : 2.00835e-05 	 MSE : 1.19082e-02
Validation Epoch 590 : 	 Train : 1.55747e-02 	 Res : 2.90339e-03 	 Jac : 1.26434e-02 	 Enc : 5.33821e-06 	 AE : 2.26082e-05 	 MSE : 8.97490e-03
Training Epoch 590 finished, took current epoch 360.71s, cumulative time 217843.54s
Current Learning rate DEQ : 3.245185536584274e-06
Current Learning rate AUTOENC : 1.6225927682921368e-05
MODEL SAVED
Epoch 591, 25% 	 Loss : 1.5580e-02 	 Res : 2.8771e-03 	 Jac : 1.2679e-02 	 Enc : 5.4684e-06 	 AEnc : 1.8326e-05 	 MSE : 1.0211e-02
Epoch 591, 50% 	 Loss : 1.5558e-02 	 Res : 2.7898e-03 	 Jac : 1.2744e-02 	 Enc : 5.2705e-06 	 AEnc : 1.9053e-05 	 MSE : 1.0953e-02
Epoch 591, 75% 	 Loss : 1.5734e-02 	 Res : 2.9787e-03 	 Jac : 1.2732e-02 	 Enc : 5.5509e-06 	 AEnc : 1.7565e-05 	 MSE : 1.0438e-02
Training Epoch 591 : 	 Train : 1.56129e-02 	 Res : 2.87568e-03 	 Jac : 1.27134e-02 	 Enc : 5.36459e-06 	 AE : 1.84743e-05 	 MSE : 1.05170e-02
Validation Epoch 591 : 	 Train : 1.56165e-02 	 Res : 2.90832e-03 	 Jac : 1.26823e-02 	 Enc : 5.31475e-06 	 AE : 2.05646e-05 	 MSE : 9.68268e-03
Training Epoch 591 finished, took current epoch 361.47s, cumulative time 218204.98s
Current Learning rate DEQ : 3.245185536584274e-06
Current Learning rate AUTOENC : 1.6225927682921368e-05
Epoch 592, 25% 	 Loss : 1.5476e-02 	 Res : 2.8564e-03 	 Jac : 1.2595e-02 	 Enc : 5.3256e-06 	 AEnc : 1.8940e-05 	 MSE : 9.7340e-03
Epoch 592, 50% 	 Loss : 1.5605e-02 	 Res : 2.8602e-03 	 Jac : 1.2720e-02 	 Enc : 5.2919e-06 	 AEnc : 1.8610e-05 	 MSE : 9.6230e-03
Epoch 592, 75% 	 Loss : 1.5742e-02 	 Res : 2.9407e-03 	 Jac : 1.2778e-02 	 Enc : 5.4362e-06 	 AEnc : 1.8193e-05 	 MSE : 1.1700e-02
Training Epoch 592 : 	 Train : 1.56137e-02 	 Res : 2.87483e-03 	 Jac : 1.27151e-02 	 Enc : 5.36424e-06 	 AE : 1.84710e-05 	 MSE : 1.03834e-02
Validation Epoch 592 : 	 Train : 1.55952e-02 	 Res : 2.90559e-03 	 Jac : 1.26674e-02 	 Enc : 5.38845e-06 	 AE : 1.69071e-05 	 MSE : 9.85901e-03
Training Epoch 592 finished, took current epoch 363.36s, cumulative time 218568.32s
Current Learning rate DEQ : 3.245185536584274e-06
Current Learning rate AUTOENC : 1.6225927682921368e-05
Epoch 593, 25% 	 Loss : 1.5468e-02 	 Res : 2.8506e-03 	 Jac : 1.2594e-02 	 Enc : 5.3289e-06 	 AEnc : 1.8662e-05 	 MSE : 9.8407e-03
Epoch 593, 50% 	 Loss : 1.5670e-02 	 Res : 2.8827e-03 	 Jac : 1.2763e-02 	 Enc : 5.3048e-06 	 AEnc : 1.8606e-05 	 MSE : 1.0468e-02
Epoch 593, 75% 	 Loss : 1.5629e-02 	 Res : 2.9011e-03 	 Jac : 1.2704e-02 	 Enc : 5.3800e-06 	 AEnc : 1.9290e-05 	 MSE : 9.1667e-03
Training Epoch 593 : 	 Train : 1.55877e-02 	 Res : 2.87371e-03 	 Jac : 1.26898e-02 	 Enc : 5.39902e-06 	 AE : 1.87489e-05 	 MSE : 9.70651e-03
Validation Epoch 593 : 	 Train : 1.56520e-02 	 Res : 2.90503e-03 	 Jac : 1.27240e-02 	 Enc : 5.52943e-06 	 AE : 1.74178e-05 	 MSE : 9.27455e-03
Training Epoch 593 finished, took current epoch 364.07s, cumulative time 218932.34s
Current Learning rate DEQ : 3.245185536584274e-06
Current Learning rate AUTOENC : 1.6225927682921368e-05
Epoch 594, 25% 	 Loss : 1.5621e-02 	 Res : 2.8673e-03 	 Jac : 1.2729e-02 	 Enc : 5.6512e-06 	 AEnc : 1.9263e-05 	 MSE : 9.9475e-03
Epoch 594, 50% 	 Loss : 1.5522e-02 	 Res : 2.8149e-03 	 Jac : 1.2682e-02 	 Enc : 5.4385e-06 	 AEnc : 1.9594e-05 	 MSE : 1.1061e-02
Epoch 594, 75% 	 Loss : 1.5631e-02 	 Res : 2.9113e-03 	 Jac : 1.2692e-02 	 Enc : 5.5273e-06 	 AEnc : 2.2091e-05 	 MSE : 1.0291e-02
Training Epoch 594 : 	 Train : 1.55968e-02 	 Res : 2.87586e-03 	 Jac : 1.26954e-02 	 Enc : 5.51421e-06 	 AE : 1.99696e-05 	 MSE : 1.04340e-02
Validation Epoch 594 : 	 Train : 1.57434e-02 	 Res : 2.91152e-03 	 Jac : 1.28084e-02 	 Enc : 5.45304e-06 	 AE : 1.80642e-05 	 MSE : 1.19606e-02
Training Epoch 594 finished, took current epoch 359.43s, cumulative time 219291.71s
Current Learning rate DEQ : 2.596148429267419e-06
Current Learning rate AUTOENC : 1.2980742146337096e-05
Epoch 595, 25% 	 Loss : 1.5622e-02 	 Res : 2.9327e-03 	 Jac : 1.2665e-02 	 Enc : 5.4187e-06 	 AEnc : 1.8425e-05 	 MSE : 1.0474e-02
Epoch 595, 50% 	 Loss : 1.5529e-02 	 Res : 2.8351e-03 	 Jac : 1.2670e-02 	 Enc : 5.4640e-06 	 AEnc : 1.8283e-05 	 MSE : 1.0205e-02
Epoch 595, 75% 	 Loss : 1.5675e-02 	 Res : 2.9316e-03 	 Jac : 1.2719e-02 	 Enc : 5.3806e-06 	 AEnc : 1.9109e-05 	 MSE : 9.5413e-03
Training Epoch 595 : 	 Train : 1.55471e-02 	 Res : 2.87371e-03 	 Jac : 1.26495e-02 	 Enc : 5.46105e-06 	 AE : 1.83892e-05 	 MSE : 1.01497e-02
Validation Epoch 595 : 	 Train : 1.57600e-02 	 Res : 2.90599e-03 	 Jac : 1.28310e-02 	 Enc : 5.39150e-06 	 AE : 1.75986e-05 	 MSE : 8.51327e-03
Training Epoch 595 finished, took current epoch 359.82s, cumulative time 219651.50s
Current Learning rate DEQ : 2.596148429267419e-06
Current Learning rate AUTOENC : 1.2980742146337096e-05
Epoch 596, 25% 	 Loss : 1.5723e-02 	 Res : 2.9578e-03 	 Jac : 1.2741e-02 	 Enc : 5.4692e-06 	 AEnc : 1.9247e-05 	 MSE : 1.0678e-02
Epoch 596, 50% 	 Loss : 1.5547e-02 	 Res : 2.8105e-03 	 Jac : 1.2712e-02 	 Enc : 5.3638e-06 	 AEnc : 1.8827e-05 	 MSE : 1.1131e-02
Epoch 596, 75% 	 Loss : 1.5583e-02 	 Res : 2.8552e-03 	 Jac : 1.2704e-02 	 Enc : 5.3265e-06 	 AEnc : 1.8440e-05 	 MSE : 1.2455e-02
Training Epoch 596 : 	 Train : 1.56265e-02 	 Res : 2.87686e-03 	 Jac : 1.27252e-02 	 Enc : 5.37356e-06 	 AE : 1.90420e-05 	 MSE : 1.07249e-02
Validation Epoch 596 : 	 Train : 1.56418e-02 	 Res : 2.90676e-03 	 Jac : 1.27120e-02 	 Enc : 5.32247e-06 	 AE : 1.76485e-05 	 MSE : 1.01586e-02
Training Epoch 596 finished, took current epoch 360.53s, cumulative time 220011.98s
Current Learning rate DEQ : 2.596148429267419e-06
Current Learning rate AUTOENC : 1.2980742146337096e-05
Epoch 597, 25% 	 Loss : 1.5677e-02 	 Res : 2.9066e-03 	 Jac : 1.2746e-02 	 Enc : 5.4142e-06 	 AEnc : 1.8778e-05 	 MSE : 9.6948e-03
Epoch 597, 50% 	 Loss : 1.5666e-02 	 Res : 2.8929e-03 	 Jac : 1.2749e-02 	 Enc : 5.4459e-06 	 AEnc : 1.8680e-05 	 MSE : 9.1179e-03
Epoch 597, 75% 	 Loss : 1.5541e-02 	 Res : 2.7645e-03 	 Jac : 1.2752e-02 	 Enc : 5.3883e-06 	 AEnc : 1.8677e-05 	 MSE : 9.5628e-03
Training Epoch 597 : 	 Train : 1.56369e-02 	 Res : 2.88081e-03 	 Jac : 1.27324e-02 	 Enc : 5.43140e-06 	 AE : 1.83194e-05 	 MSE : 1.14945e-02
Validation Epoch 597 : 	 Train : 1.56702e-02 	 Res : 2.90425e-03 	 Jac : 1.27436e-02 	 Enc : 5.43632e-06 	 AE : 1.69818e-05 	 MSE : 9.80300e-03
Training Epoch 597 finished, took current epoch 358.99s, cumulative time 220370.95s
Current Learning rate DEQ : 2.596148429267419e-06
Current Learning rate AUTOENC : 1.2980742146337096e-05
Epoch 598, 25% 	 Loss : 1.5662e-02 	 Res : 2.9127e-03 	 Jac : 1.2725e-02 	 Enc : 5.5397e-06 	 AEnc : 1.8533e-05 	 MSE : 1.4660e-02
Epoch 598, 50% 	 Loss : 1.5616e-02 	 Res : 2.8747e-03 	 Jac : 1.2718e-02 	 Enc : 5.4048e-06 	 AEnc : 1.7718e-05 	 MSE : 1.3302e-02
Epoch 598, 75% 	 Loss : 1.5603e-02 	 Res : 2.8689e-03 	 Jac : 1.2710e-02 	 Enc : 5.3738e-06 	 AEnc : 1.8451e-05 	 MSE : 1.2517e-02
Training Epoch 598 : 	 Train : 1.56203e-02 	 Res : 2.88262e-03 	 Jac : 1.27140e-02 	 Enc : 5.41895e-06 	 AE : 1.82497e-05 	 MSE : 1.28126e-02
Validation Epoch 598 : 	 Train : 1.58013e-02 	 Res : 2.95565e-03 	 Jac : 1.28199e-02 	 Enc : 5.37395e-06 	 AE : 2.03465e-05 	 MSE : 1.51393e-02
Training Epoch 598 finished, took current epoch 359.36s, cumulative time 220730.29s
Current Learning rate DEQ : 2.596148429267419e-06
Current Learning rate AUTOENC : 1.2980742146337096e-05
Epoch 599, 25% 	 Loss : 1.5659e-02 	 Res : 2.8723e-03 	 Jac : 1.2763e-02 	 Enc : 5.4375e-06 	 AEnc : 1.8215e-05 	 MSE : 1.1542e-02
Epoch 599, 50% 	 Loss : 1.5541e-02 	 Res : 2.8953e-03 	 Jac : 1.2621e-02 	 Enc : 5.3769e-06 	 AEnc : 1.9304e-05 	 MSE : 1.0470e-02
Epoch 599, 75% 	 Loss : 1.5470e-02 	 Res : 2.7894e-03 	 Jac : 1.2656e-02 	 Enc : 5.3874e-06 	 AEnc : 1.8535e-05 	 MSE : 9.1992e-03
Training Epoch 599 : 	 Train : 1.56323e-02 	 Res : 2.92031e-03 	 Jac : 1.26882e-02 	 Enc : 5.42823e-06 	 AE : 1.83665e-05 	 MSE : 1.78914e-02
Validation Epoch 599 : 	 Train : 1.56890e-02 	 Res : 2.92053e-03 	 Jac : 1.27454e-02 	 Enc : 5.41539e-06 	 AE : 1.75593e-05 	 MSE : 1.23235e-02
Training Epoch 599 finished, took current epoch 358.12s, cumulative time 221088.35s
Current Learning rate DEQ : 2.596148429267419e-06
Current Learning rate AUTOENC : 1.2980742146337096e-05
Epoch 600, 25% 	 Loss : 1.5587e-02 	 Res : 2.8498e-03 	 Jac : 1.2713e-02 	 Enc : 5.4595e-06 	 AEnc : 1.8830e-05 	 MSE : 1.1545e-02
Epoch 600, 50% 	 Loss : 1.5642e-02 	 Res : 2.9073e-03 	 Jac : 1.2710e-02 	 Enc : 5.5735e-06 	 AEnc : 1.8645e-05 	 MSE : 1.0193e-02
Epoch 600, 75% 	 Loss : 1.5537e-02 	 Res : 2.8415e-03 	 Jac : 1.2670e-02 	 Enc : 5.3445e-06 	 AEnc : 1.9765e-05 	 MSE : 9.9283e-03
Training Epoch 600 : 	 Train : 1.56232e-02 	 Res : 2.87516e-03 	 Jac : 1.27236e-02 	 Enc : 5.45981e-06 	 AE : 1.89896e-05 	 MSE : 1.06662e-02
Validation Epoch 600 : 	 Train : 1.56169e-02 	 Res : 2.90766e-03 	 Jac : 1.26858e-02 	 Enc : 5.39543e-06 	 AE : 1.80915e-05 	 MSE : 1.01602e-02
Training Epoch 600 finished, took current epoch 361.32s, cumulative time 221449.62s
Current Learning rate DEQ : 2.596148429267419e-06
Current Learning rate AUTOENC : 1.2980742146337096e-05
Epoch 601, 25% 	 Loss : 1.5690e-02 	 Res : 2.9256e-03 	 Jac : 1.2740e-02 	 Enc : 5.4970e-06 	 AEnc : 1.8319e-05 	 MSE : 1.0317e-02
Epoch 601, 50% 	 Loss : 1.5621e-02 	 Res : 2.9208e-03 	 Jac : 1.2676e-02 	 Enc : 5.4107e-06 	 AEnc : 1.8893e-05 	 MSE : 1.1075e-02
Epoch 601, 75% 	 Loss : 1.5631e-02 	 Res : 2.8184e-03 	 Jac : 1.2789e-02 	 Enc : 5.4934e-06 	 AEnc : 1.8326e-05 	 MSE : 9.9884e-03
Training Epoch 601 : 	 Train : 1.56518e-02 	 Res : 2.87586e-03 	 Jac : 1.27522e-02 	 Enc : 5.41502e-06 	 AE : 1.83816e-05 	 MSE : 1.06363e-02
Validation Epoch 601 : 	 Train : 1.56455e-02 	 Res : 2.91389e-03 	 Jac : 1.27083e-02 	 Enc : 5.36016e-06 	 AE : 1.79752e-05 	 MSE : 1.13874e-02
Training Epoch 601 finished, took current epoch 360.56s, cumulative time 221810.17s
Current Learning rate DEQ : 2.596148429267419e-06
Current Learning rate AUTOENC : 1.2980742146337096e-05
Epoch 602, 25% 	 Loss : 1.5569e-02 	 Res : 2.9163e-03 	 Jac : 1.2629e-02 	 Enc : 5.3535e-06 	 AEnc : 1.8319e-05 	 MSE : 9.7507e-03
Epoch 602, 50% 	 Loss : 1.5522e-02 	 Res : 2.8917e-03 	 Jac : 1.2607e-02 	 Enc : 5.3938e-06 	 AEnc : 1.7877e-05 	 MSE : 1.1083e-02
Epoch 602, 75% 	 Loss : 1.5601e-02 	 Res : 2.8654e-03 	 Jac : 1.2712e-02 	 Enc : 5.4036e-06 	 AEnc : 1.8095e-05 	 MSE : 9.0853e-03
Training Epoch 602 : 	 Train : 1.55624e-02 	 Res : 2.87343e-03 	 Jac : 1.26653e-02 	 Enc : 5.42983e-06 	 AE : 1.81989e-05 	 MSE : 9.91815e-03
Validation Epoch 602 : 	 Train : 1.56881e-02 	 Res : 2.90996e-03 	 Jac : 1.27546e-02 	 Enc : 5.39631e-06 	 AE : 1.82257e-05 	 MSE : 1.05909e-02
Training Epoch 602 finished, took current epoch 363.12s, cumulative time 222173.26s
Current Learning rate DEQ : 2.596148429267419e-06
Current Learning rate AUTOENC : 1.2980742146337096e-05
Epoch 603, 25% 	 Loss : 1.5626e-02 	 Res : 2.8858e-03 	 Jac : 1.2716e-02 	 Enc : 5.4344e-06 	 AEnc : 1.8892e-05 	 MSE : 9.7464e-03
Epoch 603, 50% 	 Loss : 1.5559e-02 	 Res : 2.8420e-03 	 Jac : 1.2693e-02 	 Enc : 5.3544e-06 	 AEnc : 1.8239e-05 	 MSE : 1.0147e-02
Epoch 603, 75% 	 Loss : 1.5713e-02 	 Res : 2.9157e-03 	 Jac : 1.2773e-02 	 Enc : 5.4808e-06 	 AEnc : 1.8709e-05 	 MSE : 1.0487e-02
Training Epoch 603 : 	 Train : 1.56302e-02 	 Res : 2.87469e-03 	 Jac : 1.27314e-02 	 Enc : 5.42311e-06 	 AE : 1.86778e-05 	 MSE : 1.00972e-02
Validation Epoch 603 : 	 Train : 1.57023e-02 	 Res : 2.90337e-03 	 Jac : 1.27761e-02 	 Enc : 5.43652e-06 	 AE : 1.74154e-05 	 MSE : 8.77877e-03
Training Epoch 603 finished, took current epoch 361.38s, cumulative time 222534.58s
Current Learning rate DEQ : 2.596148429267419e-06
Current Learning rate AUTOENC : 1.2980742146337096e-05
MODEL SAVED
Epoch 604, 25% 	 Loss : 1.5602e-02 	 Res : 2.8771e-03 	 Jac : 1.2701e-02 	 Enc : 5.4293e-06 	 AEnc : 1.8692e-05 	 MSE : 1.0119e-02
Epoch 604, 50% 	 Loss : 1.5566e-02 	 Res : 2.8663e-03 	 Jac : 1.2677e-02 	 Enc : 5.4414e-06 	 AEnc : 1.7764e-05 	 MSE : 1.0602e-02
Epoch 604, 75% 	 Loss : 1.5668e-02 	 Res : 2.8473e-03 	 Jac : 1.2797e-02 	 Enc : 5.5094e-06 	 AEnc : 1.7836e-05 	 MSE : 1.0420e-02
Training Epoch 604 : 	 Train : 1.56263e-02 	 Res : 2.87357e-03 	 Jac : 1.27290e-02 	 Enc : 5.42888e-06 	 AE : 1.83553e-05 	 MSE : 1.01962e-02
Validation Epoch 604 : 	 Train : 1.56420e-02 	 Res : 2.90667e-03 	 Jac : 1.27088e-02 	 Enc : 5.43482e-06 	 AE : 2.10937e-05 	 MSE : 9.14990e-03
Training Epoch 604 finished, took current epoch 362.76s, cumulative time 222897.33s
Current Learning rate DEQ : 2.596148429267419e-06
Current Learning rate AUTOENC : 1.2980742146337096e-05
Epoch 605, 25% 	 Loss : 1.5630e-02 	 Res : 2.8629e-03 	 Jac : 1.2743e-02 	 Enc : 5.5203e-06 	 AEnc : 1.8341e-05 	 MSE : 9.7929e-03
Epoch 605, 50% 	 Loss : 1.5664e-02 	 Res : 2.9411e-03 	 Jac : 1.2698e-02 	 Enc : 5.4553e-06 	 AEnc : 1.8929e-05 	 MSE : 1.1183e-02
Epoch 605, 75% 	 Loss : 1.5654e-02 	 Res : 2.8319e-03 	 Jac : 1.2797e-02 	 Enc : 5.4608e-06 	 AEnc : 1.9450e-05 	 MSE : 9.4204e-03
Training Epoch 605 : 	 Train : 1.56344e-02 	 Res : 2.87425e-03 	 Jac : 1.27357e-02 	 Enc : 5.49773e-06 	 AE : 1.89116e-05 	 MSE : 1.00741e-02
Validation Epoch 605 : 	 Train : 1.57269e-02 	 Res : 2.90284e-03 	 Jac : 1.28020e-02 	 Enc : 5.46739e-06 	 AE : 1.65713e-05 	 MSE : 9.41232e-03
Training Epoch 605 finished, took current epoch 363.48s, cumulative time 223260.77s
Current Learning rate DEQ : 2.0769187434139356e-06
Current Learning rate AUTOENC : 1.0384593717069677e-05
MODEL SAVED
Epoch 606, 25% 	 Loss : 1.5598e-02 	 Res : 2.8682e-03 	 Jac : 1.2706e-02 	 Enc : 5.4163e-06 	 AEnc : 1.8205e-05 	 MSE : 1.0518e-02
Epoch 606, 50% 	 Loss : 1.5682e-02 	 Res : 2.9035e-03 	 Jac : 1.2756e-02 	 Enc : 5.5781e-06 	 AEnc : 1.7329e-05 	 MSE : 1.0674e-02
Epoch 606, 75% 	 Loss : 1.5653e-02 	 Res : 2.8573e-03 	 Jac : 1.2772e-02 	 Enc : 5.4419e-06 	 AEnc : 1.8773e-05 	 MSE : 1.0346e-02
Training Epoch 606 : 	 Train : 1.56248e-02 	 Res : 2.87384e-03 	 Jac : 1.27276e-02 	 Enc : 5.44637e-06 	 AE : 1.79966e-05 	 MSE : 1.03301e-02
Validation Epoch 606 : 	 Train : 1.56590e-02 	 Res : 2.90693e-03 	 Jac : 1.27274e-02 	 Enc : 5.37979e-06 	 AE : 1.93067e-05 	 MSE : 9.20781e-03
Training Epoch 606 finished, took current epoch 361.35s, cumulative time 223622.08s
Current Learning rate DEQ : 2.0769187434139356e-06
Current Learning rate AUTOENC : 1.0384593717069677e-05
Epoch 607, 25% 	 Loss : 1.5620e-02 	 Res : 2.8633e-03 	 Jac : 1.2732e-02 	 Enc : 5.5033e-06 	 AEnc : 1.8891e-05 	 MSE : 9.6321e-03
Epoch 607, 50% 	 Loss : 1.5582e-02 	 Res : 2.8352e-03 	 Jac : 1.2722e-02 	 Enc : 5.4287e-06 	 AEnc : 1.8477e-05 	 MSE : 9.3598e-03
Epoch 607, 75% 	 Loss : 1.5653e-02 	 Res : 2.8429e-03 	 Jac : 1.2787e-02 	 Enc : 5.3028e-06 	 AEnc : 1.8066e-05 	 MSE : 9.7413e-03
Training Epoch 607 : 	 Train : 1.56141e-02 	 Res : 2.87361e-03 	 Jac : 1.27161e-02 	 Enc : 5.42271e-06 	 AE : 1.89187e-05 	 MSE : 9.58081e-03
Validation Epoch 607 : 	 Train : 1.56089e-02 	 Res : 2.90589e-03 	 Jac : 1.26793e-02 	 Enc : 5.39773e-06 	 AE : 1.83275e-05 	 MSE : 9.21592e-03
Training Epoch 607 finished, took current epoch 362.52s, cumulative time 223984.55s
Current Learning rate DEQ : 2.0769187434139356e-06
Current Learning rate AUTOENC : 1.0384593717069677e-05
Epoch 608, 25% 	 Loss : 1.5539e-02 	 Res : 2.8268e-03 	 Jac : 1.2690e-02 	 Enc : 5.3724e-06 	 AEnc : 1.7301e-05 	 MSE : 9.4642e-03
Epoch 608, 50% 	 Loss : 1.5580e-02 	 Res : 2.8671e-03 	 Jac : 1.2689e-02 	 Enc : 5.2643e-06 	 AEnc : 1.8649e-05 	 MSE : 9.6846e-03
Epoch 608, 75% 	 Loss : 1.5596e-02 	 Res : 2.9022e-03 	 Jac : 1.2670e-02 	 Enc : 5.3837e-06 	 AEnc : 1.8153e-05 	 MSE : 9.8831e-03
Training Epoch 608 : 	 Train : 1.55769e-02 	 Res : 2.87305e-03 	 Jac : 1.26803e-02 	 Enc : 5.37057e-06 	 AE : 1.82086e-05 	 MSE : 9.65812e-03
Validation Epoch 608 : 	 Train : 1.56288e-02 	 Res : 2.90845e-03 	 Jac : 1.26978e-02 	 Enc : 5.34576e-06 	 AE : 1.72114e-05 	 MSE : 1.03800e-02
Training Epoch 608 finished, took current epoch 361.37s, cumulative time 224345.89s
Current Learning rate DEQ : 2.0769187434139356e-06
Current Learning rate AUTOENC : 1.0384593717069677e-05
Epoch 609, 25% 	 Loss : 1.5668e-02 	 Res : 2.9072e-03 	 Jac : 1.2737e-02 	 Enc : 5.4153e-06 	 AEnc : 1.8399e-05 	 MSE : 1.0104e-02
Epoch 609, 50% 	 Loss : 1.5607e-02 	 Res : 2.8452e-03 	 Jac : 1.2737e-02 	 Enc : 5.4626e-06 	 AEnc : 1.8823e-05 	 MSE : 1.0330e-02
Epoch 609, 75% 	 Loss : 1.5618e-02 	 Res : 2.8676e-03 	 Jac : 1.2727e-02 	 Enc : 5.5467e-06 	 AEnc : 1.8045e-05 	 MSE : 1.2221e-02
Training Epoch 609 : 	 Train : 1.56156e-02 	 Res : 2.87478e-03 	 Jac : 1.27170e-02 	 Enc : 5.43323e-06 	 AE : 1.84248e-05 	 MSE : 1.06648e-02
Validation Epoch 609 : 	 Train : 1.56193e-02 	 Res : 2.91038e-03 	 Jac : 1.26865e-02 	 Enc : 5.41005e-06 	 AE : 1.69983e-05 	 MSE : 1.11443e-02
Training Epoch 609 finished, took current epoch 364.83s, cumulative time 224710.70s
Current Learning rate DEQ : 2.0769187434139356e-06
Current Learning rate AUTOENC : 1.0384593717069677e-05
Epoch 610, 25% 	 Loss : 1.5634e-02 	 Res : 2.8522e-03 	 Jac : 1.2759e-02 	 Enc : 5.5206e-06 	 AEnc : 1.7798e-05 	 MSE : 9.9773e-03
Epoch 610, 50% 	 Loss : 1.5611e-02 	 Res : 2.8905e-03 	 Jac : 1.2697e-02 	 Enc : 5.3732e-06 	 AEnc : 1.8683e-05 	 MSE : 1.0076e-02
Epoch 610, 75% 	 Loss : 1.5634e-02 	 Res : 2.8677e-03 	 Jac : 1.2743e-02 	 Enc : 5.3109e-06 	 AEnc : 1.7119e-05 	 MSE : 9.4224e-03
Training Epoch 610 : 	 Train : 1.56228e-02 	 Res : 2.87407e-03 	 Jac : 1.27253e-02 	 Enc : 5.44232e-06 	 AE : 1.80353e-05 	 MSE : 1.00772e-02
Validation Epoch 610 : 	 Train : 1.56138e-02 	 Res : 2.91848e-03 	 Jac : 1.26690e-02 	 Enc : 5.42261e-06 	 AE : 2.08893e-05 	 MSE : 1.38935e-02
Training Epoch 610 finished, took current epoch 363.38s, cumulative time 225074.05s
Current Learning rate DEQ : 2.0769187434139356e-06
Current Learning rate AUTOENC : 1.0384593717069677e-05
Epoch 611, 25% 	 Loss : 1.5682e-02 	 Res : 2.8515e-03 	 Jac : 1.2806e-02 	 Enc : 5.3339e-06 	 AEnc : 1.9758e-05 	 MSE : 9.9858e-03
Epoch 611, 50% 	 Loss : 1.5518e-02 	 Res : 2.8723e-03 	 Jac : 1.2621e-02 	 Enc : 5.3879e-06 	 AEnc : 1.8576e-05 	 MSE : 2.1033e-02
Epoch 611, 75% 	 Loss : 1.5693e-02 	 Res : 2.9405e-03 	 Jac : 1.2728e-02 	 Enc : 5.6200e-06 	 AEnc : 1.9493e-05 	 MSE : 1.0310e-02
Training Epoch 611 : 	 Train : 1.56359e-02 	 Res : 2.88638e-03 	 Jac : 1.27241e-02 	 Enc : 5.46119e-06 	 AE : 1.99104e-05 	 MSE : 1.28240e-02
Validation Epoch 611 : 	 Train : 1.55764e-02 	 Res : 2.90573e-03 	 Jac : 1.26477e-02 	 Enc : 5.43504e-06 	 AE : 1.75672e-05 	 MSE : 9.82328e-03
Training Epoch 611 finished, took current epoch 362.13s, cumulative time 225436.15s
Current Learning rate DEQ : 2.0769187434139356e-06
Current Learning rate AUTOENC : 1.0384593717069677e-05
Epoch 612, 25% 	 Loss : 1.5665e-02 	 Res : 2.8499e-03 	 Jac : 1.2790e-02 	 Enc : 5.4728e-06 	 AEnc : 1.9074e-05 	 MSE : 9.8430e-03
Epoch 612, 50% 	 Loss : 1.5672e-02 	 Res : 2.9141e-03 	 Jac : 1.2734e-02 	 Enc : 5.5030e-06 	 AEnc : 1.8370e-05 	 MSE : 1.0283e-02
Epoch 612, 75% 	 Loss : 1.5523e-02 	 Res : 2.8539e-03 	 Jac : 1.2645e-02 	 Enc : 5.3188e-06 	 AEnc : 1.8622e-05 	 MSE : 1.0131e-02
Training Epoch 612 : 	 Train : 1.56170e-02 	 Res : 2.87285e-03 	 Jac : 1.27202e-02 	 Enc : 5.41141e-06 	 AE : 1.84685e-05 	 MSE : 9.88249e-03
Validation Epoch 612 : 	 Train : 1.56430e-02 	 Res : 2.90733e-03 	 Jac : 1.27122e-02 	 Enc : 5.38108e-06 	 AE : 1.80997e-05 	 MSE : 9.94404e-03
Training Epoch 612 finished, took current epoch 359.83s, cumulative time 225795.97s
Current Learning rate DEQ : 2.0769187434139356e-06
Current Learning rate AUTOENC : 1.0384593717069677e-05
Epoch 613, 25% 	 Loss : 1.5604e-02 	 Res : 2.9082e-03 	 Jac : 1.2672e-02 	 Enc : 5.3876e-06 	 AEnc : 1.7891e-05 	 MSE : 1.0840e-02
Epoch 613, 50% 	 Loss : 1.5621e-02 	 Res : 2.9142e-03 	 Jac : 1.2683e-02 	 Enc : 5.4162e-06 	 AEnc : 1.8322e-05 	 MSE : 9.5804e-03
Epoch 613, 75% 	 Loss : 1.5530e-02 	 Res : 2.8538e-03 	 Jac : 1.2652e-02 	 Enc : 5.5413e-06 	 AEnc : 1.8853e-05 	 MSE : 1.0336e-02
Training Epoch 613 : 	 Train : 1.55994e-02 	 Res : 2.87401e-03 	 Jac : 1.27015e-02 	 Enc : 5.41742e-06 	 AE : 1.84720e-05 	 MSE : 1.01704e-02
Validation Epoch 613 : 	 Train : 1.56388e-02 	 Res : 2.91454e-03 	 Jac : 1.27019e-02 	 Enc : 5.37351e-06 	 AE : 1.70158e-05 	 MSE : 1.34120e-02
Training Epoch 613 finished, took current epoch 360.96s, cumulative time 226156.89s
Current Learning rate DEQ : 2.0769187434139356e-06
Current Learning rate AUTOENC : 1.0384593717069677e-05
Epoch 614, 25% 	 Loss : 1.5714e-02 	 Res : 2.8704e-03 	 Jac : 1.2820e-02 	 Enc : 5.4550e-06 	 AEnc : 1.7870e-05 	 MSE : 1.1770e-02
Epoch 614, 50% 	 Loss : 1.5568e-02 	 Res : 2.8670e-03 	 Jac : 1.2678e-02 	 Enc : 5.2063e-06 	 AEnc : 1.7892e-05 	 MSE : 1.0480e-02
Epoch 614, 75% 	 Loss : 1.5594e-02 	 Res : 2.8929e-03 	 Jac : 1.2678e-02 	 Enc : 5.3673e-06 	 AEnc : 1.7962e-05 	 MSE : 1.0316e-02
Training Epoch 614 : 	 Train : 1.56470e-02 	 Res : 2.87558e-03 	 Jac : 1.27481e-02 	 Enc : 5.39291e-06 	 AE : 1.79775e-05 	 MSE : 1.07684e-02
Validation Epoch 614 : 	 Train : 1.56345e-02 	 Res : 2.90362e-03 	 Jac : 1.27074e-02 	 Enc : 5.36902e-06 	 AE : 1.81252e-05 	 MSE : 8.83086e-03
Training Epoch 614 finished, took current epoch 359.84s, cumulative time 226516.70s
Current Learning rate DEQ : 2.0769187434139356e-06
Current Learning rate AUTOENC : 1.0384593717069677e-05
Epoch 615, 25% 	 Loss : 1.5643e-02 	 Res : 2.9121e-03 	 Jac : 1.2707e-02 	 Enc : 5.3896e-06 	 AEnc : 1.8634e-05 	 MSE : 1.0250e-02
Epoch 615, 50% 	 Loss : 1.5598e-02 	 Res : 2.8385e-03 	 Jac : 1.2736e-02 	 Enc : 5.4179e-06 	 AEnc : 1.7753e-05 	 MSE : 9.9567e-03
Epoch 615, 75% 	 Loss : 1.5558e-02 	 Res : 2.8692e-03 	 Jac : 1.2664e-02 	 Enc : 5.5056e-06 	 AEnc : 1.8778e-05 	 MSE : 9.3408e-03
Training Epoch 615 : 	 Train : 1.56051e-02 	 Res : 2.87305e-03 	 Jac : 1.27083e-02 	 Enc : 5.44435e-06 	 AE : 1.82961e-05 	 MSE : 9.83349e-03
Validation Epoch 615 : 	 Train : 1.56690e-02 	 Res : 2.93586e-03 	 Jac : 1.27065e-02 	 Enc : 5.43665e-06 	 AE : 2.11694e-05 	 MSE : 1.57224e-02
Training Epoch 615 finished, took current epoch 360.98s, cumulative time 226877.64s
Current Learning rate DEQ : 2.0769187434139356e-06
Current Learning rate AUTOENC : 1.0384593717069677e-05
Epoch 616, 25% 	 Loss : 1.5664e-02 	 Res : 2.8879e-03 	 Jac : 1.2752e-02 	 Enc : 5.6046e-06 	 AEnc : 1.8269e-05 	 MSE : 9.9397e-03
Epoch 616, 50% 	 Loss : 1.5682e-02 	 Res : 2.8826e-03 	 Jac : 1.2775e-02 	 Enc : 5.3639e-06 	 AEnc : 1.8720e-05 	 MSE : 1.1191e-02
Epoch 616, 75% 	 Loss : 1.5622e-02 	 Res : 2.8744e-03 	 Jac : 1.2723e-02 	 Enc : 5.3230e-06 	 AEnc : 1.9030e-05 	 MSE : 1.0062e-02
Training Epoch 616 : 	 Train : 1.56465e-02 	 Res : 2.87346e-03 	 Jac : 1.27483e-02 	 Enc : 5.44974e-06 	 AE : 1.92263e-05 	 MSE : 1.01622e-02
Validation Epoch 616 : 	 Train : 1.56142e-02 	 Res : 2.90905e-03 	 Jac : 1.26794e-02 	 Enc : 5.43881e-06 	 AE : 2.03853e-05 	 MSE : 1.04069e-02
Training Epoch 616 finished, took current epoch 361.00s, cumulative time 227238.63s
Current Learning rate DEQ : 1.6615349947311485e-06
Current Learning rate AUTOENC : 8.307674973655742e-06
Epoch 617, 25% 	 Loss : 1.5625e-02 	 Res : 3.0082e-03 	 Jac : 1.2592e-02 	 Enc : 5.3732e-06 	 AEnc : 1.8893e-05 	 MSE : 2.8801e-02
Epoch 617, 50% 	 Loss : 1.5624e-02 	 Res : 2.8539e-03 	 Jac : 1.2746e-02 	 Enc : 5.4298e-06 	 AEnc : 1.8519e-05 	 MSE : 9.6510e-03
Epoch 617, 75% 	 Loss : 1.5770e-02 	 Res : 2.9169e-03 	 Jac : 1.2828e-02 	 Enc : 5.5685e-06 	 AEnc : 1.9688e-05 	 MSE : 1.1023e-02
Training Epoch 617 : 	 Train : 1.56360e-02 	 Res : 2.89261e-03 	 Jac : 1.27193e-02 	 Enc : 5.47175e-06 	 AE : 1.86041e-05 	 MSE : 1.50361e-02
Validation Epoch 617 : 	 Train : 1.56219e-02 	 Res : 2.90480e-03 	 Jac : 1.26941e-02 	 Enc : 5.48329e-06 	 AE : 1.75695e-05 	 MSE : 9.49102e-03
Training Epoch 617 finished, took current epoch 359.42s, cumulative time 227598.03s
Current Learning rate DEQ : 1.6615349947311485e-06
Current Learning rate AUTOENC : 8.307674973655742e-06
Epoch 618, 25% 	 Loss : 1.5656e-02 	 Res : 2.8561e-03 	 Jac : 1.2776e-02 	 Enc : 5.4176e-06 	 AEnc : 1.8327e-05 	 MSE : 1.0865e-02
Epoch 618, 50% 	 Loss : 1.5493e-02 	 Res : 2.8101e-03 	 Jac : 1.2660e-02 	 Enc : 5.5021e-06 	 AEnc : 1.8075e-05 	 MSE : 9.3352e-03
Epoch 618, 75% 	 Loss : 1.5820e-02 	 Res : 2.9854e-03 	 Jac : 1.2810e-02 	 Enc : 5.5399e-06 	 AEnc : 1.9379e-05 	 MSE : 9.9037e-03
Training Epoch 618 : 	 Train : 1.56220e-02 	 Res : 2.87344e-03 	 Jac : 1.27245e-02 	 Enc : 5.48713e-06 	 AE : 1.86085e-05 	 MSE : 1.00616e-02
Validation Epoch 618 : 	 Train : 1.55762e-02 	 Res : 2.90378e-03 	 Jac : 1.26509e-02 	 Enc : 5.45229e-06 	 AE : 1.61004e-05 	 MSE : 8.95071e-03
Training Epoch 618 finished, took current epoch 358.02s, cumulative time 227956.01s
Current Learning rate DEQ : 1.6615349947311485e-06
Current Learning rate AUTOENC : 8.307674973655742e-06
Epoch 619, 25% 	 Loss : 1.5560e-02 	 Res : 2.8298e-03 	 Jac : 1.2706e-02 	 Enc : 5.3434e-06 	 AEnc : 1.8432e-05 	 MSE : 9.5479e-03
Epoch 619, 50% 	 Loss : 1.5659e-02 	 Res : 2.8685e-03 	 Jac : 1.2767e-02 	 Enc : 5.4896e-06 	 AEnc : 1.8053e-05 	 MSE : 8.8041e-03
Epoch 619, 75% 	 Loss : 1.5662e-02 	 Res : 2.9187e-03 	 Jac : 1.2719e-02 	 Enc : 5.6312e-06 	 AEnc : 1.8622e-05 	 MSE : 1.0542e-02
Training Epoch 619 : 	 Train : 1.56509e-02 	 Res : 2.87255e-03 	 Jac : 1.27544e-02 	 Enc : 5.50072e-06 	 AE : 1.84915e-05 	 MSE : 9.57808e-03
Validation Epoch 619 : 	 Train : 1.56566e-02 	 Res : 2.90289e-03 	 Jac : 1.27312e-02 	 Enc : 5.46711e-06 	 AE : 1.70624e-05 	 MSE : 8.61186e-03
Training Epoch 619 finished, took current epoch 357.88s, cumulative time 228313.86s
Current Learning rate DEQ : 1.6615349947311485e-06
Current Learning rate AUTOENC : 8.307674973655742e-06
Epoch 620, 25% 	 Loss : 1.5620e-02 	 Res : 2.8657e-03 	 Jac : 1.2730e-02 	 Enc : 5.5828e-06 	 AEnc : 1.8754e-05 	 MSE : 9.1542e-03
Epoch 620, 50% 	 Loss : 1.5645e-02 	 Res : 2.8823e-03 	 Jac : 1.2739e-02 	 Enc : 5.3247e-06 	 AEnc : 1.8804e-05 	 MSE : 8.9887e-03
Epoch 620, 75% 	 Loss : 1.5612e-02 	 Res : 2.8573e-03 	 Jac : 1.2732e-02 	 Enc : 5.4354e-06 	 AEnc : 1.7504e-05 	 MSE : 9.9182e-03
Training Epoch 620 : 	 Train : 1.56384e-02 	 Res : 2.87225e-03 	 Jac : 1.27422e-02 	 Enc : 5.45059e-06 	 AE : 1.84990e-05 	 MSE : 9.62732e-03
Validation Epoch 620 : 	 Train : 1.56093e-02 	 Res : 2.90410e-03 	 Jac : 1.26831e-02 	 Enc : 5.40733e-06 	 AE : 1.66928e-05 	 MSE : 9.04065e-03
Training Epoch 620 finished, took current epoch 363.94s, cumulative time 228677.79s
Current Learning rate DEQ : 1.6615349947311485e-06
Current Learning rate AUTOENC : 8.307674973655742e-06
Epoch 621, 25% 	 Loss : 1.5614e-02 	 Res : 2.8757e-03 	 Jac : 1.2714e-02 	 Enc : 5.3228e-06 	 AEnc : 1.9154e-05 	 MSE : 9.5415e-03
Epoch 621, 50% 	 Loss : 1.5640e-02 	 Res : 2.8632e-03 	 Jac : 1.2753e-02 	 Enc : 5.5381e-06 	 AEnc : 1.8085e-05 	 MSE : 8.6884e-03
Epoch 621, 75% 	 Loss : 1.5716e-02 	 Res : 2.9067e-03 	 Jac : 1.2785e-02 	 Enc : 5.6147e-06 	 AEnc : 1.8657e-05 	 MSE : 9.7754e-03
Training Epoch 621 : 	 Train : 1.56469e-02 	 Res : 2.87154e-03 	 Jac : 1.27514e-02 	 Enc : 5.46954e-06 	 AE : 1.85420e-05 	 MSE : 9.28482e-03
Validation Epoch 621 : 	 Train : 1.57194e-02 	 Res : 2.90394e-03 	 Jac : 1.27913e-02 	 Enc : 5.43187e-06 	 AE : 1.86637e-05 	 MSE : 8.67919e-03
Training Epoch 621 finished, took current epoch 367.09s, cumulative time 229044.87s
Current Learning rate DEQ : 1.6615349947311485e-06
Current Learning rate AUTOENC : 8.307674973655742e-06
Epoch 622, 25% 	 Loss : 1.5770e-02 	 Res : 2.9107e-03 	 Jac : 1.2834e-02 	 Enc : 5.4968e-06 	 AEnc : 1.9447e-05 	 MSE : 9.4456e-03
Epoch 622, 50% 	 Loss : 1.5562e-02 	 Res : 2.8139e-03 	 Jac : 1.2724e-02 	 Enc : 5.4797e-06 	 AEnc : 1.8198e-05 	 MSE : 9.5968e-03
Epoch 622, 75% 	 Loss : 1.5656e-02 	 Res : 2.9115e-03 	 Jac : 1.2719e-02 	 Enc : 5.4984e-06 	 AEnc : 1.9304e-05 	 MSE : 9.1452e-03
Training Epoch 622 : 	 Train : 1.56513e-02 	 Res : 2.87246e-03 	 Jac : 1.27545e-02 	 Enc : 5.47803e-06 	 AE : 1.88388e-05 	 MSE : 9.52591e-03
Validation Epoch 622 : 	 Train : 1.57413e-02 	 Res : 2.90345e-03 	 Jac : 1.28147e-02 	 Enc : 5.44141e-06 	 AE : 1.76903e-05 	 MSE : 8.86120e-03
Training Epoch 622 finished, took current epoch 358.87s, cumulative time 229403.73s
Current Learning rate DEQ : 1.6615349947311485e-06
Current Learning rate AUTOENC : 8.307674973655742e-06
Epoch 623, 25% 	 Loss : 1.5631e-02 	 Res : 2.9451e-03 	 Jac : 1.2662e-02 	 Enc : 5.5970e-06 	 AEnc : 1.8494e-05 	 MSE : 9.7153e-03
Epoch 623, 50% 	 Loss : 1.5590e-02 	 Res : 2.8554e-03 	 Jac : 1.2711e-02 	 Enc : 5.4730e-06 	 AEnc : 1.7935e-05 	 MSE : 1.0281e-02
Epoch 623, 75% 	 Loss : 1.5591e-02 	 Res : 2.8508e-03 	 Jac : 1.2717e-02 	 Enc : 5.4764e-06 	 AEnc : 1.8150e-05 	 MSE : 1.0568e-02
Training Epoch 623 : 	 Train : 1.56278e-02 	 Res : 2.87271e-03 	 Jac : 1.27314e-02 	 Enc : 5.49426e-06 	 AE : 1.81894e-05 	 MSE : 9.97991e-03
Validation Epoch 623 : 	 Train : 1.56604e-02 	 Res : 2.90488e-03 	 Jac : 1.27323e-02 	 Enc : 5.44358e-06 	 AE : 1.77773e-05 	 MSE : 9.21297e-03
Training Epoch 623 finished, took current epoch 363.33s, cumulative time 229767.04s
Current Learning rate DEQ : 1.6615349947311485e-06
Current Learning rate AUTOENC : 8.307674973655742e-06
Epoch 624, 25% 	 Loss : 1.5716e-02 	 Res : 2.8757e-03 	 Jac : 1.2816e-02 	 Enc : 5.4686e-06 	 AEnc : 1.8475e-05 	 MSE : 9.4068e-03
Epoch 624, 50% 	 Loss : 1.5745e-02 	 Res : 2.9251e-03 	 Jac : 1.2796e-02 	 Enc : 5.4874e-06 	 AEnc : 1.8084e-05 	 MSE : 9.6403e-03
Epoch 624, 75% 	 Loss : 1.5500e-02 	 Res : 2.8409e-03 	 Jac : 1.2636e-02 	 Enc : 5.5658e-06 	 AEnc : 1.8017e-05 	 MSE : 9.1891e-03
Training Epoch 624 : 	 Train : 1.56258e-02 	 Res : 2.87220e-03 	 Jac : 1.27300e-02 	 Enc : 5.49024e-06 	 AE : 1.81593e-05 	 MSE : 9.47255e-03
Validation Epoch 624 : 	 Train : 1.56732e-02 	 Res : 2.90491e-03 	 Jac : 1.27456e-02 	 Enc : 5.44231e-06 	 AE : 1.72159e-05 	 MSE : 8.89882e-03
Training Epoch 624 finished, took current epoch 361.70s, cumulative time 230128.72s
Current Learning rate DEQ : 1.6615349947311485e-06
Current Learning rate AUTOENC : 8.307674973655742e-06
Epoch 625, 25% 	 Loss : 1.5576e-02 	 Res : 2.8193e-03 	 Jac : 1.2732e-02 	 Enc : 5.3841e-06 	 AEnc : 1.9293e-05 	 MSE : 1.0905e-02
Epoch 625, 50% 	 Loss : 1.5606e-02 	 Res : 2.8958e-03 	 Jac : 1.2686e-02 	 Enc : 5.5737e-06 	 AEnc : 1.8659e-05 	 MSE : 9.4520e-03
Epoch 625, 75% 	 Loss : 1.5641e-02 	 Res : 2.9134e-03 	 Jac : 1.2704e-02 	 Enc : 5.5498e-06 	 AEnc : 1.7991e-05 	 MSE : 1.0280e-02
Training Epoch 625 : 	 Train : 1.56215e-02 	 Res : 2.87298e-03 	 Jac : 1.27245e-02 	 Enc : 5.48416e-06 	 AE : 1.85885e-05 	 MSE : 9.99424e-03
Validation Epoch 625 : 	 Train : 1.55522e-02 	 Res : 2.90313e-03 	 Jac : 1.26247e-02 	 Enc : 5.45606e-06 	 AE : 1.89517e-05 	 MSE : 8.67798e-03
Training Epoch 625 finished, took current epoch 361.96s, cumulative time 230490.65s
Current Learning rate DEQ : 1.6615349947311485e-06
Current Learning rate AUTOENC : 8.307674973655742e-06
Epoch 626, 25% 	 Loss : 1.5615e-02 	 Res : 2.8388e-03 	 Jac : 1.2752e-02 	 Enc : 5.5458e-06 	 AEnc : 1.8481e-05 	 MSE : 9.5779e-03
Epoch 626, 50% 	 Loss : 1.5749e-02 	 Res : 2.9025e-03 	 Jac : 1.2822e-02 	 Enc : 5.4414e-06 	 AEnc : 1.8718e-05 	 MSE : 1.0479e-02
Epoch 626, 75% 	 Loss : 1.5485e-02 	 Res : 2.8514e-03 	 Jac : 1.2610e-02 	 Enc : 5.5352e-06 	 AEnc : 1.7770e-05 	 MSE : 9.4546e-03
Training Epoch 626 : 	 Train : 1.56211e-02 	 Res : 2.87339e-03 	 Jac : 1.27237e-02 	 Enc : 5.49999e-06 	 AE : 1.84483e-05 	 MSE : 9.80777e-03
Validation Epoch 626 : 	 Train : 1.56991e-02 	 Res : 2.90508e-03 	 Jac : 1.27707e-02 	 Enc : 5.47852e-06 	 AE : 1.77926e-05 	 MSE : 9.81711e-03
Training Epoch 626 finished, took current epoch 360.59s, cumulative time 230851.23s
Current Learning rate DEQ : 1.6615349947311485e-06
Current Learning rate AUTOENC : 8.307674973655742e-06
Epoch 627, 25% 	 Loss : 1.5559e-02 	 Res : 2.8593e-03 	 Jac : 1.2676e-02 	 Enc : 5.4337e-06 	 AEnc : 1.8614e-05 	 MSE : 9.9332e-03
Epoch 627, 50% 	 Loss : 1.5731e-02 	 Res : 2.8535e-03 	 Jac : 1.2854e-02 	 Enc : 5.4629e-06 	 AEnc : 1.8840e-05 	 MSE : 1.0850e-02
Epoch 627, 75% 	 Loss : 1.5762e-02 	 Res : 2.8934e-03 	 Jac : 1.2845e-02 	 Enc : 5.6030e-06 	 AEnc : 1.7777e-05 	 MSE : 1.0279e-02
Training Epoch 627 : 	 Train : 1.56625e-02 	 Res : 2.87403e-03 	 Jac : 1.27647e-02 	 Enc : 5.48002e-06 	 AE : 1.82880e-05 	 MSE : 1.03869e-02
Validation Epoch 627 : 	 Train : 1.56602e-02 	 Res : 2.91088e-03 	 Jac : 1.27269e-02 	 Enc : 5.43477e-06 	 AE : 1.69935e-05 	 MSE : 1.13905e-02
Training Epoch 627 finished, took current epoch 359.49s, cumulative time 231210.66s
Current Learning rate DEQ : 1.3292279957849189e-06
Current Learning rate AUTOENC : 6.646139978924594e-06
Epoch 628, 25% 	 Loss : 1.5567e-02 	 Res : 2.7992e-03 	 Jac : 1.2744e-02 	 Enc : 5.4591e-06 	 AEnc : 1.8411e-05 	 MSE : 8.9935e-03
Epoch 628, 50% 	 Loss : 1.5598e-02 	 Res : 2.8841e-03 	 Jac : 1.2690e-02 	 Enc : 5.4966e-06 	 AEnc : 1.8733e-05 	 MSE : 9.4290e-03
Epoch 628, 75% 	 Loss : 1.5674e-02 	 Res : 2.8894e-03 	 Jac : 1.2761e-02 	 Enc : 5.4171e-06 	 AEnc : 1.8399e-05 	 MSE : 9.0636e-03
Training Epoch 628 : 	 Train : 1.56030e-02 	 Res : 2.87251e-03 	 Jac : 1.27066e-02 	 Enc : 5.45346e-06 	 AE : 1.84182e-05 	 MSE : 9.42688e-03
Validation Epoch 628 : 	 Train : 1.56985e-02 	 Res : 2.90397e-03 	 Jac : 1.27699e-02 	 Enc : 5.42336e-06 	 AE : 1.92201e-05 	 MSE : 8.92836e-03
Training Epoch 628 finished, took current epoch 361.37s, cumulative time 231572.00s
Current Learning rate DEQ : 1.3292279957849189e-06
Current Learning rate AUTOENC : 6.646139978924594e-06
Epoch 629, 25% 	 Loss : 1.5682e-02 	 Res : 2.9605e-03 	 Jac : 1.2697e-02 	 Enc : 5.4161e-06 	 AEnc : 1.8910e-05 	 MSE : 9.0626e-03
Epoch 629, 50% 	 Loss : 1.5606e-02 	 Res : 2.7677e-03 	 Jac : 1.2815e-02 	 Enc : 5.3377e-06 	 AEnc : 1.8199e-05 	 MSE : 9.8102e-03
Epoch 629, 75% 	 Loss : 1.5600e-02 	 Res : 2.8928e-03 	 Jac : 1.2684e-02 	 Enc : 5.5636e-06 	 AEnc : 1.8204e-05 	 MSE : 9.3729e-03
Training Epoch 629 : 	 Train : 1.56540e-02 	 Res : 2.87213e-03 	 Jac : 1.27578e-02 	 Enc : 5.47235e-06 	 AE : 1.86069e-05 	 MSE : 9.36186e-03
Validation Epoch 629 : 	 Train : 1.56465e-02 	 Res : 2.90462e-03 	 Jac : 1.27201e-02 	 Enc : 5.44269e-06 	 AE : 1.63665e-05 	 MSE : 9.05305e-03
Training Epoch 629 finished, took current epoch 362.51s, cumulative time 231934.49s
Current Learning rate DEQ : 1.3292279957849189e-06
Current Learning rate AUTOENC : 6.646139978924594e-06
Epoch 630, 25% 	 Loss : 1.5519e-02 	 Res : 2.8741e-03 	 Jac : 1.2620e-02 	 Enc : 5.5218e-06 	 AEnc : 1.9302e-05 	 MSE : 9.6008e-03
Epoch 630, 50% 	 Loss : 1.5571e-02 	 Res : 2.8420e-03 	 Jac : 1.2705e-02 	 Enc : 5.4052e-06 	 AEnc : 1.8555e-05 	 MSE : 9.2651e-03
Epoch 630, 75% 	 Loss : 1.5694e-02 	 Res : 2.8892e-03 	 Jac : 1.2781e-02 	 Enc : 5.4771e-06 	 AEnc : 1.8825e-05 	 MSE : 1.0198e-02
Training Epoch 630 : 	 Train : 1.55994e-02 	 Res : 2.87248e-03 	 Jac : 1.27026e-02 	 Enc : 5.48586e-06 	 AE : 1.88325e-05 	 MSE : 9.70650e-03
Validation Epoch 630 : 	 Train : 1.57231e-02 	 Res : 2.90400e-03 	 Jac : 1.27970e-02 	 Enc : 5.48244e-06 	 AE : 1.66629e-05 	 MSE : 8.84168e-03
Training Epoch 630 finished, took current epoch 362.29s, cumulative time 232296.76s
Current Learning rate DEQ : 1.3292279957849189e-06
Current Learning rate AUTOENC : 6.646139978924594e-06
Epoch 631, 25% 	 Loss : 1.5508e-02 	 Res : 2.8648e-03 	 Jac : 1.2619e-02 	 Enc : 5.5266e-06 	 AEnc : 1.8662e-05 	 MSE : 9.6228e-03
Epoch 631, 50% 	 Loss : 1.5640e-02 	 Res : 2.8760e-03 	 Jac : 1.2740e-02 	 Enc : 5.5934e-06 	 AEnc : 1.8463e-05 	 MSE : 9.4556e-03
Epoch 631, 75% 	 Loss : 1.5552e-02 	 Res : 2.8732e-03 	 Jac : 1.2656e-02 	 Enc : 5.3466e-06 	 AEnc : 1.7726e-05 	 MSE : 9.1280e-03
Training Epoch 631 : 	 Train : 1.55807e-02 	 Res : 2.87183e-03 	 Jac : 1.26852e-02 	 Enc : 5.50422e-06 	 AE : 1.82123e-05 	 MSE : 9.39158e-03
Validation Epoch 631 : 	 Train : 1.55811e-02 	 Res : 2.90501e-03 	 Jac : 1.26530e-02 	 Enc : 5.48156e-06 	 AE : 1.76347e-05 	 MSE : 9.36150e-03
Training Epoch 631 finished, took current epoch 364.18s, cumulative time 232660.93s
Current Learning rate DEQ : 1.3292279957849189e-06
Current Learning rate AUTOENC : 6.646139978924594e-06
Epoch 632, 25% 	 Loss : 1.5704e-02 	 Res : 2.9201e-03 	 Jac : 1.2760e-02 	 Enc : 5.4108e-06 	 AEnc : 1.8542e-05 	 MSE : 1.7224e-02
Epoch 632, 50% 	 Loss : 1.5610e-02 	 Res : 2.8416e-03 	 Jac : 1.2745e-02 	 Enc : 5.4730e-06 	 AEnc : 1.7993e-05 	 MSE : 9.4802e-03
Epoch 632, 75% 	 Loss : 1.5574e-02 	 Res : 2.8510e-03 	 Jac : 1.2699e-02 	 Enc : 5.4936e-06 	 AEnc : 1.8039e-05 	 MSE : 9.1751e-03
Training Epoch 632 : 	 Train : 1.56433e-02 	 Res : 2.87762e-03 	 Jac : 1.27419e-02 	 Enc : 5.51895e-06 	 AE : 1.82166e-05 	 MSE : 1.14605e-02
Validation Epoch 632 : 	 Train : 1.57146e-02 	 Res : 2.90434e-03 	 Jac : 1.27887e-02 	 Enc : 5.49206e-06 	 AE : 1.60840e-05 	 MSE : 9.28640e-03
Training Epoch 632 finished, took current epoch 363.21s, cumulative time 233024.12s
Current Learning rate DEQ : 1.3292279957849189e-06
Current Learning rate AUTOENC : 6.646139978924594e-06
Epoch 633, 25% 	 Loss : 1.5582e-02 	 Res : 2.9057e-03 	 Jac : 1.2653e-02 	 Enc : 5.4192e-06 	 AEnc : 1.8268e-05 	 MSE : 9.2564e-03
Epoch 633, 50% 	 Loss : 1.5528e-02 	 Res : 2.8407e-03 	 Jac : 1.2663e-02 	 Enc : 5.5851e-06 	 AEnc : 1.7973e-05 	 MSE : 9.6605e-03
Epoch 633, 75% 	 Loss : 1.5681e-02 	 Res : 2.9375e-03 	 Jac : 1.2720e-02 	 Enc : 5.6262e-06 	 AEnc : 1.7842e-05 	 MSE : 9.6317e-03
Training Epoch 633 : 	 Train : 1.55842e-02 	 Res : 2.87189e-03 	 Jac : 1.26889e-02 	 Enc : 5.52653e-06 	 AE : 1.78999e-05 	 MSE : 9.45230e-03
Validation Epoch 633 : 	 Train : 1.56746e-02 	 Res : 2.90254e-03 	 Jac : 1.27475e-02 	 Enc : 5.52401e-06 	 AE : 1.89628e-05 	 MSE : 8.48196e-03
Training Epoch 633 finished, took current epoch 362.34s, cumulative time 233386.36s
Current Learning rate DEQ : 1.3292279957849189e-06
Current Learning rate AUTOENC : 6.646139978924594e-06
MODEL SAVED
Epoch 634, 25% 	 Loss : 1.5485e-02 	 Res : 2.8234e-03 	 Jac : 1.2638e-02 	 Enc : 5.4377e-06 	 AEnc : 1.8138e-05 	 MSE : 8.9028e-03
Epoch 634, 50% 	 Loss : 1.5563e-02 	 Res : 2.8783e-03 	 Jac : 1.2662e-02 	 Enc : 5.3878e-06 	 AEnc : 1.8031e-05 	 MSE : 9.8802e-03
Epoch 634, 75% 	 Loss : 1.5548e-02 	 Res : 2.8517e-03 	 Jac : 1.2672e-02 	 Enc : 5.5451e-06 	 AEnc : 1.8713e-05 	 MSE : 1.0040e-02
Training Epoch 634 : 	 Train : 1.55980e-02 	 Res : 2.90041e-03 	 Jac : 1.26736e-02 	 Enc : 5.51825e-06 	 AE : 1.84180e-05 	 MSE : 1.90322e-02
Validation Epoch 634 : 	 Train : 1.55478e-02 	 Res : 2.90267e-03 	 Jac : 1.26223e-02 	 Enc : 5.49275e-06 	 AE : 1.73376e-05 	 MSE : 8.93901e-03
Training Epoch 634 finished, took current epoch 360.84s, cumulative time 233747.18s
Current Learning rate DEQ : 1.3292279957849189e-06
Current Learning rate AUTOENC : 6.646139978924594e-06
Epoch 635, 25% 	 Loss : 1.5616e-02 	 Res : 2.8658e-03 	 Jac : 1.2726e-02 	 Enc : 5.5977e-06 	 AEnc : 1.8254e-05 	 MSE : 9.6802e-03
Epoch 635, 50% 	 Loss : 1.5665e-02 	 Res : 2.8638e-03 	 Jac : 1.2776e-02 	 Enc : 5.4115e-06 	 AEnc : 1.9250e-05 	 MSE : 1.0068e-02
Epoch 635, 75% 	 Loss : 1.5634e-02 	 Res : 2.8935e-03 	 Jac : 1.2717e-02 	 Enc : 5.5784e-06 	 AEnc : 1.7703e-05 	 MSE : 1.0529e-02
Training Epoch 635 : 	 Train : 1.56354e-02 	 Res : 2.87307e-03 	 Jac : 1.27384e-02 	 Enc : 5.52629e-06 	 AE : 1.83859e-05 	 MSE : 9.77779e-03
Validation Epoch 635 : 	 Train : 1.56865e-02 	 Res : 2.90587e-03 	 Jac : 1.27569e-02 	 Enc : 5.47747e-06 	 AE : 1.82169e-05 	 MSE : 1.00356e-02
Training Epoch 635 finished, took current epoch 364.83s, cumulative time 234111.97s
Current Learning rate DEQ : 1.3292279957849189e-06
Current Learning rate AUTOENC : 6.646139978924594e-06
Epoch 636, 25% 	 Loss : 1.5683e-02 	 Res : 2.8870e-03 	 Jac : 1.2772e-02 	 Enc : 5.5114e-06 	 AEnc : 1.8164e-05 	 MSE : 9.9465e-03
Epoch 636, 50% 	 Loss : 1.5549e-02 	 Res : 2.7942e-03 	 Jac : 1.2731e-02 	 Enc : 5.5402e-06 	 AEnc : 1.8051e-05 	 MSE : 9.0930e-03
Epoch 636, 75% 	 Loss : 1.5697e-02 	 Res : 2.9514e-03 	 Jac : 1.2721e-02 	 Enc : 5.4623e-06 	 AEnc : 1.8618e-05 	 MSE : 9.2707e-03
Training Epoch 636 : 	 Train : 1.56399e-02 	 Res : 2.87193e-03 	 Jac : 1.27443e-02 	 Enc : 5.47898e-06 	 AE : 1.81956e-05 	 MSE : 9.48519e-03
Validation Epoch 636 : 	 Train : 1.56403e-02 	 Res : 2.90369e-03 	 Jac : 1.27126e-02 	 Enc : 5.43454e-06 	 AE : 1.85075e-05 	 MSE : 8.92923e-03
Training Epoch 636 finished, took current epoch 359.33s, cumulative time 234471.25s
Current Learning rate DEQ : 1.3292279957849189e-06
Current Learning rate AUTOENC : 6.646139978924594e-06
Epoch 637, 25% 	 Loss : 1.5655e-02 	 Res : 2.8880e-03 	 Jac : 1.2744e-02 	 Enc : 5.3967e-06 	 AEnc : 1.8034e-05 	 MSE : 9.1341e-03
Epoch 637, 50% 	 Loss : 1.5663e-02 	 Res : 2.8357e-03 	 Jac : 1.2803e-02 	 Enc : 5.4625e-06 	 AEnc : 1.8228e-05 	 MSE : 9.1478e-03
Epoch 637, 75% 	 Loss : 1.5616e-02 	 Res : 2.8597e-03 	 Jac : 1.2732e-02 	 Enc : 5.5858e-06 	 AEnc : 1.8402e-05 	 MSE : 1.0003e-02
Training Epoch 637 : 	 Train : 1.56579e-02 	 Res : 2.87197e-03 	 Jac : 1.27622e-02 	 Enc : 5.44768e-06 	 AE : 1.83758e-05 	 MSE : 9.57549e-03
Validation Epoch 637 : 	 Train : 1.56366e-02 	 Res : 2.90292e-03 	 Jac : 1.27100e-02 	 Enc : 5.41406e-06 	 AE : 1.82802e-05 	 MSE : 8.99720e-03
Training Epoch 637 finished, took current epoch 362.18s, cumulative time 234833.42s
Current Learning rate DEQ : 1.3292279957849189e-06
Current Learning rate AUTOENC : 6.646139978924594e-06
Epoch 638, 25% 	 Loss : 1.5692e-02 	 Res : 2.8913e-03 	 Jac : 1.2777e-02 	 Enc : 5.3544e-06 	 AEnc : 1.8538e-05 	 MSE : 9.3989e-03
Epoch 638, 50% 	 Loss : 1.5650e-02 	 Res : 2.8814e-03 	 Jac : 1.2745e-02 	 Enc : 5.4229e-06 	 AEnc : 1.7766e-05 	 MSE : 9.3887e-03
Epoch 638, 75% 	 Loss : 1.5616e-02 	 Res : 2.8291e-03 	 Jac : 1.2762e-02 	 Enc : 5.4817e-06 	 AEnc : 1.8621e-05 	 MSE : 9.0607e-03
Training Epoch 638 : 	 Train : 1.56462e-02 	 Res : 2.87196e-03 	 Jac : 1.27505e-02 	 Enc : 5.45725e-06 	 AE : 1.82977e-05 	 MSE : 9.29275e-03
Validation Epoch 638 : 	 Train : 1.56420e-02 	 Res : 2.90383e-03 	 Jac : 1.27157e-02 	 Enc : 5.43404e-06 	 AE : 1.69401e-05 	 MSE : 9.01645e-03
Training Epoch 638 finished, took current epoch 363.38s, cumulative time 235196.79s
Current Learning rate DEQ : 1.0633823966279351e-06
Current Learning rate AUTOENC : 5.3169119831396756e-06
Epoch 639, 25% 	 Loss : 1.5529e-02 	 Res : 2.8380e-03 	 Jac : 1.2667e-02 	 Enc : 5.5451e-06 	 AEnc : 1.8413e-05 	 MSE : 9.3592e-03
Epoch 639, 50% 	 Loss : 1.5637e-02 	 Res : 2.8549e-03 	 Jac : 1.2759e-02 	 Enc : 5.4824e-06 	 AEnc : 1.7561e-05 	 MSE : 9.2195e-03
Epoch 639, 75% 	 Loss : 1.5572e-02 	 Res : 2.8637e-03 	 Jac : 1.2685e-02 	 Enc : 5.4664e-06 	 AEnc : 1.8099e-05 	 MSE : 9.5370e-03
Training Epoch 639 : 	 Train : 1.56120e-02 	 Res : 2.87155e-03 	 Jac : 1.27168e-02 	 Enc : 5.46596e-06 	 AE : 1.81422e-05 	 MSE : 9.38405e-03
Validation Epoch 639 : 	 Train : 1.55986e-02 	 Res : 2.90241e-03 	 Jac : 1.26722e-02 	 Enc : 5.43600e-06 	 AE : 1.84607e-05 	 MSE : 8.34789e-03
Training Epoch 639 finished, took current epoch 363.58s, cumulative time 235560.35s
Current Learning rate DEQ : 1.0633823966279351e-06
Current Learning rate AUTOENC : 5.3169119831396756e-06
MODEL SAVED
Epoch 640, 25% 	 Loss : 1.5585e-02 	 Res : 2.8364e-03 	 Jac : 1.2725e-02 	 Enc : 5.4954e-06 	 AEnc : 1.8626e-05 	 MSE : 8.8414e-03
Epoch 640, 50% 	 Loss : 1.5866e-02 	 Res : 3.1448e-03 	 Jac : 1.2697e-02 	 Enc : 5.5419e-06 	 AEnc : 1.8655e-05 	 MSE : 9.5438e-02
Epoch 640, 75% 	 Loss : 1.5642e-02 	 Res : 2.9881e-03 	 Jac : 1.2629e-02 	 Enc : 5.4626e-06 	 AEnc : 1.8458e-05 	 MSE : 9.4414e-03
Training Epoch 640 : 	 Train : 1.56717e-02 	 Res : 2.94449e-03 	 Jac : 1.27032e-02 	 Enc : 5.49293e-06 	 AE : 1.85420e-05 	 MSE : 3.06806e-02
Validation Epoch 640 : 	 Train : 1.56256e-02 	 Res : 2.90567e-03 	 Jac : 1.26971e-02 	 Enc : 5.46515e-06 	 AE : 1.73994e-05 	 MSE : 9.83313e-03
Training Epoch 640 finished, took current epoch 361.92s, cumulative time 235922.25s
Current Learning rate DEQ : 1.0633823966279351e-06
Current Learning rate AUTOENC : 5.3169119831396756e-06
Epoch 641, 25% 	 Loss : 1.5650e-02 	 Res : 2.9045e-03 	 Jac : 1.2722e-02 	 Enc : 5.4291e-06 	 AEnc : 1.8108e-05 	 MSE : 9.6321e-03
Epoch 641, 50% 	 Loss : 1.5636e-02 	 Res : 2.8778e-03 	 Jac : 1.2734e-02 	 Enc : 5.5117e-06 	 AEnc : 1.8361e-05 	 MSE : 9.6906e-03
Epoch 641, 75% 	 Loss : 1.5585e-02 	 Res : 2.8512e-03 	 Jac : 1.2710e-02 	 Enc : 5.5899e-06 	 AEnc : 1.8414e-05 	 MSE : 9.4238e-03
Training Epoch 641 : 	 Train : 1.55894e-02 	 Res : 2.87180e-03 	 Jac : 1.26939e-02 	 Enc : 5.53125e-06 	 AE : 1.82147e-05 	 MSE : 9.43232e-03
Validation Epoch 641 : 	 Train : 1.56933e-02 	 Res : 2.92674e-03 	 Jac : 1.27425e-02 	 Enc : 5.50745e-06 	 AE : 1.84812e-05 	 MSE : 1.12298e-02
Training Epoch 641 finished, took current epoch 361.18s, cumulative time 236283.41s
Current Learning rate DEQ : 1.0633823966279351e-06
Current Learning rate AUTOENC : 5.3169119831396756e-06
Epoch 642, 25% 	 Loss : 1.5604e-02 	 Res : 2.8294e-03 	 Jac : 1.2751e-02 	 Enc : 5.5470e-06 	 AEnc : 1.8169e-05 	 MSE : 8.9180e-03
Epoch 642, 50% 	 Loss : 1.5618e-02 	 Res : 2.9060e-03 	 Jac : 1.2689e-02 	 Enc : 5.6084e-06 	 AEnc : 1.7732e-05 	 MSE : 9.5594e-03
Epoch 642, 75% 	 Loss : 1.5533e-02 	 Res : 2.8490e-03 	 Jac : 1.2660e-02 	 Enc : 5.4866e-06 	 AEnc : 1.8743e-05 	 MSE : 9.2506e-03
Training Epoch 642 : 	 Train : 1.56150e-02 	 Res : 2.87160e-03 	 Jac : 1.27195e-02 	 Enc : 5.53299e-06 	 AE : 1.83888e-05 	 MSE : 9.58452e-03
Validation Epoch 642 : 	 Train : 1.57036e-02 	 Res : 2.90834e-03 	 Jac : 1.27717e-02 	 Enc : 5.49653e-06 	 AE : 1.80548e-05 	 MSE : 1.11672e-02
Training Epoch 642 finished, took current epoch 361.80s, cumulative time 236645.19s
Current Learning rate DEQ : 1.0633823966279351e-06
Current Learning rate AUTOENC : 5.3169119831396756e-06
Epoch 643, 25% 	 Loss : 1.5589e-02 	 Res : 2.8698e-03 	 Jac : 1.2695e-02 	 Enc : 5.4987e-06 	 AEnc : 1.8241e-05 	 MSE : 1.0571e-02
Epoch 643, 50% 	 Loss : 1.5575e-02 	 Res : 2.8527e-03 	 Jac : 1.2697e-02 	 Enc : 5.5232e-06 	 AEnc : 1.9415e-05 	 MSE : 9.5921e-03
Epoch 643, 75% 	 Loss : 1.5710e-02 	 Res : 2.9212e-03 	 Jac : 1.2765e-02 	 Enc : 5.4799e-06 	 AEnc : 1.8479e-05 	 MSE : 9.0823e-03
Training Epoch 643 : 	 Train : 1.56334e-02 	 Res : 2.87190e-03 	 Jac : 1.27375e-02 	 Enc : 5.50196e-06 	 AE : 1.84794e-05 	 MSE : 9.53089e-03
Validation Epoch 643 : 	 Train : 1.57052e-02 	 Res : 2.90233e-03 	 Jac : 1.27803e-02 	 Enc : 5.47673e-06 	 AE : 1.70972e-05 	 MSE : 8.80181e-03
Training Epoch 643 finished, took current epoch 361.67s, cumulative time 237006.82s
Current Learning rate DEQ : 1.0633823966279351e-06
Current Learning rate AUTOENC : 5.3169119831396756e-06
MODEL SAVED
Epoch 644, 25% 	 Loss : 1.5607e-02 	 Res : 2.8820e-03 	 Jac : 1.2702e-02 	 Enc : 5.4860e-06 	 AEnc : 1.7870e-05 	 MSE : 9.0757e-03
Epoch 644, 50% 	 Loss : 1.5589e-02 	 Res : 2.8371e-03 	 Jac : 1.2728e-02 	 Enc : 5.6222e-06 	 AEnc : 1.7817e-05 	 MSE : 9.6936e-03
Epoch 644, 75% 	 Loss : 1.5614e-02 	 Res : 2.8964e-03 	 Jac : 1.2694e-02 	 Enc : 5.4714e-06 	 AEnc : 1.7707e-05 	 MSE : 8.9420e-03
Training Epoch 644 : 	 Train : 1.55960e-02 	 Res : 2.87113e-03 	 Jac : 1.27015e-02 	 Enc : 5.51777e-06 	 AE : 1.78179e-05 	 MSE : 9.25686e-03
Validation Epoch 644 : 	 Train : 1.55957e-02 	 Res : 2.90403e-03 	 Jac : 1.26684e-02 	 Enc : 5.48025e-06 	 AE : 1.78528e-05 	 MSE : 8.71926e-03
Training Epoch 644 finished, took current epoch 362.08s, cumulative time 237368.89s
Current Learning rate DEQ : 1.0633823966279351e-06
Current Learning rate AUTOENC : 5.3169119831396756e-06
Epoch 645, 25% 	 Loss : 1.5639e-02 	 Res : 2.8613e-03 	 Jac : 1.2754e-02 	 Enc : 5.4619e-06 	 AEnc : 1.8558e-05 	 MSE : 9.8859e-03
Epoch 645, 50% 	 Loss : 1.5657e-02 	 Res : 2.9204e-03 	 Jac : 1.2712e-02 	 Enc : 5.5036e-06 	 AEnc : 1.8201e-05 	 MSE : 9.1511e-03
Epoch 645, 75% 	 Loss : 1.5494e-02 	 Res : 2.8188e-03 	 Jac : 1.2652e-02 	 Enc : 5.4990e-06 	 AEnc : 1.8044e-05 	 MSE : 8.7533e-03
Training Epoch 645 : 	 Train : 1.56193e-02 	 Res : 2.87191e-03 	 Jac : 1.27236e-02 	 Enc : 5.52512e-06 	 AE : 1.82657e-05 	 MSE : 9.30155e-03
Validation Epoch 645 : 	 Train : 1.57158e-02 	 Res : 2.90401e-03 	 Jac : 1.27882e-02 	 Enc : 5.48750e-06 	 AE : 1.81283e-05 	 MSE : 9.28496e-03
Training Epoch 645 finished, took current epoch 361.49s, cumulative time 237730.34s
Current Learning rate DEQ : 1.0633823966279351e-06
Current Learning rate AUTOENC : 5.3169119831396756e-06
Epoch 646, 25% 	 Loss : 1.5600e-02 	 Res : 2.8728e-03 	 Jac : 1.2704e-02 	 Enc : 5.4670e-06 	 AEnc : 1.8184e-05 	 MSE : 9.7778e-03
Epoch 646, 50% 	 Loss : 1.5556e-02 	 Res : 2.9127e-03 	 Jac : 1.2619e-02 	 Enc : 5.5679e-06 	 AEnc : 1.8248e-05 	 MSE : 9.3354e-03
Epoch 646, 75% 	 Loss : 1.5539e-02 	 Res : 2.8336e-03 	 Jac : 1.2681e-02 	 Enc : 5.5884e-06 	 AEnc : 1.7945e-05 	 MSE : 8.8720e-03
Training Epoch 646 : 	 Train : 1.55636e-02 	 Res : 2.87091e-03 	 Jac : 1.26691e-02 	 Enc : 5.52036e-06 	 AE : 1.80865e-05 	 MSE : 9.24453e-03
Validation Epoch 646 : 	 Train : 1.56584e-02 	 Res : 2.90386e-03 	 Jac : 1.27315e-02 	 Enc : 5.46213e-06 	 AE : 1.75945e-05 	 MSE : 8.89489e-03
Training Epoch 646 finished, took current epoch 363.16s, cumulative time 238093.46s
Current Learning rate DEQ : 1.0633823966279351e-06
Current Learning rate AUTOENC : 5.3169119831396756e-06
Epoch 647, 25% 	 Loss : 1.5694e-02 	 Res : 2.8731e-03 	 Jac : 1.2797e-02 	 Enc : 5.4997e-06 	 AEnc : 1.8589e-05 	 MSE : 9.3934e-03
Epoch 647, 50% 	 Loss : 1.5639e-02 	 Res : 2.8528e-03 	 Jac : 1.2762e-02 	 Enc : 5.5279e-06 	 AEnc : 1.8728e-05 	 MSE : 8.7542e-03
Epoch 647, 75% 	 Loss : 1.5651e-02 	 Res : 2.8822e-03 	 Jac : 1.2745e-02 	 Enc : 5.5260e-06 	 AEnc : 1.8200e-05 	 MSE : 8.7778e-03
Training Epoch 647 : 	 Train : 1.56424e-02 	 Res : 2.87122e-03 	 Jac : 1.27473e-02 	 Enc : 5.50267e-06 	 AE : 1.83956e-05 	 MSE : 9.11619e-03
Validation Epoch 647 : 	 Train : 1.56117e-02 	 Res : 2.90406e-03 	 Jac : 1.26846e-02 	 Enc : 5.45494e-06 	 AE : 1.75167e-05 	 MSE : 8.92527e-03
Training Epoch 647 finished, took current epoch 362.87s, cumulative time 238456.31s
Current Learning rate DEQ : 1.0633823966279351e-06
Current Learning rate AUTOENC : 5.3169119831396756e-06
Epoch 648, 25% 	 Loss : 1.5649e-02 	 Res : 2.8617e-03 	 Jac : 1.2763e-02 	 Enc : 5.4214e-06 	 AEnc : 1.8745e-05 	 MSE : 9.3992e-03
Epoch 648, 50% 	 Loss : 1.5539e-02 	 Res : 2.8586e-03 	 Jac : 1.2656e-02 	 Enc : 5.6283e-06 	 AEnc : 1.7998e-05 	 MSE : 9.1343e-03
Epoch 648, 75% 	 Loss : 1.5607e-02 	 Res : 2.8715e-03 	 Jac : 1.2712e-02 	 Enc : 5.5142e-06 	 AEnc : 1.8077e-05 	 MSE : 9.0531e-03
Training Epoch 648 : 	 Train : 1.56068e-02 	 Res : 2.87139e-03 	 Jac : 1.27117e-02 	 Enc : 5.50257e-06 	 AE : 1.82028e-05 	 MSE : 9.33796e-03
Validation Epoch 648 : 	 Train : 1.57378e-02 	 Res : 2.92863e-03 	 Jac : 1.27839e-02 	 Enc : 5.46825e-06 	 AE : 1.98042e-05 	 MSE : 1.26862e-02
Training Epoch 648 finished, took current epoch 364.50s, cumulative time 238820.79s
Current Learning rate DEQ : 1.0633823966279351e-06
Current Learning rate AUTOENC : 5.3169119831396756e-06
Epoch 649, 25% 	 Loss : 1.5589e-02 	 Res : 2.8250e-03 	 Jac : 1.2740e-02 	 Enc : 5.6131e-06 	 AEnc : 1.8282e-05 	 MSE : 9.5739e-03
Epoch 649, 50% 	 Loss : 1.5625e-02 	 Res : 2.9066e-03 	 Jac : 1.2695e-02 	 Enc : 5.4902e-06 	 AEnc : 1.8086e-05 	 MSE : 8.8604e-03
Epoch 649, 75% 	 Loss : 1.5681e-02 	 Res : 2.8491e-03 	 Jac : 1.2808e-02 	 Enc : 5.5296e-06 	 AEnc : 1.8798e-05 	 MSE : 9.8623e-03
Training Epoch 649 : 	 Train : 1.56498e-02 	 Res : 2.87200e-03 	 Jac : 1.27539e-02 	 Enc : 5.56179e-06 	 AE : 1.83697e-05 	 MSE : 9.69899e-03
Validation Epoch 649 : 	 Train : 1.56004e-02 	 Res : 2.90477e-03 	 Jac : 1.26720e-02 	 Enc : 5.54900e-06 	 AE : 1.79877e-05 	 MSE : 9.06034e-03
Training Epoch 649 finished, took current epoch 361.36s, cumulative time 239182.11s
Current Learning rate DEQ : 8.507059173023481e-07
Current Learning rate AUTOENC : 4.2535295865117404e-06
Epoch 650, 25% 	 Loss : 1.5463e-02 	 Res : 2.8212e-03 	 Jac : 1.2617e-02 	 Enc : 5.6105e-06 	 AEnc : 1.8459e-05 	 MSE : 8.6559e-03
Epoch 650, 50% 	 Loss : 1.5683e-02 	 Res : 2.9450e-03 	 Jac : 1.2714e-02 	 Enc : 5.6474e-06 	 AEnc : 1.8246e-05 	 MSE : 9.1161e-03
Epoch 650, 75% 	 Loss : 1.5631e-02 	 Res : 2.8696e-03 	 Jac : 1.2739e-02 	 Enc : 5.6705e-06 	 AEnc : 1.7245e-05 	 MSE : 9.3236e-03
Training Epoch 650 : 	 Train : 1.56020e-02 	 Res : 2.87090e-03 	 Jac : 1.27075e-02 	 Enc : 5.57328e-06 	 AE : 1.80087e-05 	 MSE : 9.10169e-03
Validation Epoch 650 : 	 Train : 1.55285e-02 	 Res : 2.90364e-03 	 Jac : 1.26008e-02 	 Enc : 5.50685e-06 	 AE : 1.85915e-05 	 MSE : 8.51650e-03
Training Epoch 650 finished, took current epoch 364.64s, cumulative time 239546.73s
Current Learning rate DEQ : 8.507059173023481e-07
Current Learning rate AUTOENC : 4.2535295865117404e-06
Epoch 651, 25% 	 Loss : 1.5579e-02 	 Res : 2.8749e-03 	 Jac : 1.2681e-02 	 Enc : 5.4348e-06 	 AEnc : 1.7791e-05 	 MSE : 8.8746e-03
Epoch 651, 50% 	 Loss : 1.5540e-02 	 Res : 2.8868e-03 	 Jac : 1.2630e-02 	 Enc : 5.5009e-06 	 AEnc : 1.7514e-05 	 MSE : 1.4692e-02
Epoch 651, 75% 	 Loss : 1.5639e-02 	 Res : 2.8661e-03 	 Jac : 1.2749e-02 	 Enc : 5.4701e-06 	 AEnc : 1.8078e-05 	 MSE : 8.9881e-03
Training Epoch 651 : 	 Train : 1.56119e-02 	 Res : 2.87737e-03 	 Jac : 1.27112e-02 	 Enc : 5.53329e-06 	 AE : 1.78013e-05 	 MSE : 1.04118e-02
Validation Epoch 651 : 	 Train : 1.55768e-02 	 Res : 2.90415e-03 	 Jac : 1.26503e-02 	 Enc : 5.50231e-06 	 AE : 1.68660e-05 	 MSE : 9.01777e-03
Training Epoch 651 finished, took current epoch 360.09s, cumulative time 239906.78s
Current Learning rate DEQ : 8.507059173023481e-07
Current Learning rate AUTOENC : 4.2535295865117404e-06
Epoch 652, 25% 	 Loss : 1.5676e-02 	 Res : 2.8348e-03 	 Jac : 1.2818e-02 	 Enc : 5.5863e-06 	 AEnc : 1.7697e-05 	 MSE : 9.1487e-03
Epoch 652, 50% 	 Loss : 1.5700e-02 	 Res : 2.8936e-03 	 Jac : 1.2783e-02 	 Enc : 5.5244e-06 	 AEnc : 1.7500e-05 	 MSE : 1.0040e-02
Epoch 652, 75% 	 Loss : 1.5539e-02 	 Res : 2.8304e-03 	 Jac : 1.2684e-02 	 Enc : 5.4565e-06 	 AEnc : 1.8465e-05 	 MSE : 9.1710e-03
Training Epoch 652 : 	 Train : 1.56444e-02 	 Res : 2.87228e-03 	 Jac : 1.27486e-02 	 Enc : 5.52133e-06 	 AE : 1.80065e-05 	 MSE : 9.44057e-03
Validation Epoch 652 : 	 Train : 1.56470e-02 	 Res : 2.90508e-03 	 Jac : 1.27189e-02 	 Enc : 5.46080e-06 	 AE : 1.76346e-05 	 MSE : 9.10874e-03
Training Epoch 652 finished, took current epoch 360.48s, cumulative time 240267.22s
Current Learning rate DEQ : 8.507059173023481e-07
Current Learning rate AUTOENC : 4.2535295865117404e-06
Epoch 653, 25% 	 Loss : 1.5651e-02 	 Res : 2.8854e-03 	 Jac : 1.2742e-02 	 Enc : 5.4757e-06 	 AEnc : 1.8127e-05 	 MSE : 9.1596e-03
Epoch 653, 50% 	 Loss : 1.5708e-02 	 Res : 2.9894e-03 	 Jac : 1.2696e-02 	 Enc : 5.6840e-06 	 AEnc : 1.7711e-05 	 MSE : 9.5209e-03
Epoch 653, 75% 	 Loss : 1.5527e-02 	 Res : 2.7675e-03 	 Jac : 1.2736e-02 	 Enc : 5.4318e-06 	 AEnc : 1.7649e-05 	 MSE : 8.6059e-03
Training Epoch 653 : 	 Train : 1.56301e-02 	 Res : 2.87746e-03 	 Jac : 1.27293e-02 	 Enc : 5.52058e-06 	 AE : 1.77675e-05 	 MSE : 1.01100e-02
Validation Epoch 653 : 	 Train : 1.56174e-02 	 Res : 2.90374e-03 	 Jac : 1.26909e-02 	 Enc : 5.46779e-06 	 AE : 1.72971e-05 	 MSE : 8.99382e-03
Training Epoch 653 finished, took current epoch 362.19s, cumulative time 240629.40s
Current Learning rate DEQ : 8.507059173023481e-07
Current Learning rate AUTOENC : 4.2535295865117404e-06
Epoch 654, 25% 	 Loss : 1.5567e-02 	 Res : 2.8570e-03 	 Jac : 1.2687e-02 	 Enc : 5.5660e-06 	 AEnc : 1.7548e-05 	 MSE : 8.5603e-03
Epoch 654, 50% 	 Loss : 1.5506e-02 	 Res : 2.8247e-03 	 Jac : 1.2659e-02 	 Enc : 5.4916e-06 	 AEnc : 1.7335e-05 	 MSE : 9.1750e-03
Epoch 654, 75% 	 Loss : 1.5724e-02 	 Res : 2.9454e-03 	 Jac : 1.2755e-02 	 Enc : 5.4257e-06 	 AEnc : 1.8155e-05 	 MSE : 9.4526e-03
Training Epoch 654 : 	 Train : 1.55906e-02 	 Res : 2.87067e-03 	 Jac : 1.26968e-02 	 Enc : 5.50967e-06 	 AE : 1.76437e-05 	 MSE : 9.10592e-03
Validation Epoch 654 : 	 Train : 1.56086e-02 	 Res : 2.90427e-03 	 Jac : 1.26815e-02 	 Enc : 5.49066e-06 	 AE : 1.72700e-05 	 MSE : 9.13269e-03
Training Epoch 654 finished, took current epoch 362.41s, cumulative time 240991.76s
Current Learning rate DEQ : 8.507059173023481e-07
Current Learning rate AUTOENC : 4.2535295865117404e-06
Epoch 655, 25% 	 Loss : 1.5627e-02 	 Res : 2.8731e-03 	 Jac : 1.2731e-02 	 Enc : 5.6257e-06 	 AEnc : 1.7850e-05 	 MSE : 9.4139e-03
Epoch 655, 50% 	 Loss : 1.5564e-02 	 Res : 2.8938e-03 	 Jac : 1.2647e-02 	 Enc : 5.4347e-06 	 AEnc : 1.7405e-05 	 MSE : 8.8754e-03
Epoch 655, 75% 	 Loss : 1.5661e-02 	 Res : 2.8623e-03 	 Jac : 1.2775e-02 	 Enc : 5.4189e-06 	 AEnc : 1.8368e-05 	 MSE : 1.0103e-02
Training Epoch 655 : 	 Train : 1.55967e-02 	 Res : 2.87150e-03 	 Jac : 1.27017e-02 	 Enc : 5.50872e-06 	 AE : 1.80347e-05 	 MSE : 9.54134e-03
Validation Epoch 655 : 	 Train : 1.57016e-02 	 Res : 2.90807e-03 	 Jac : 1.27707e-02 	 Enc : 5.46302e-06 	 AE : 1.74536e-05 	 MSE : 1.03293e-02
Training Epoch 655 finished, took current epoch 362.13s, cumulative time 241353.87s
Current Learning rate DEQ : 8.507059173023481e-07
Current Learning rate AUTOENC : 4.2535295865117404e-06
Epoch 656, 25% 	 Loss : 1.5545e-02 	 Res : 2.8653e-03 	 Jac : 1.2656e-02 	 Enc : 5.4456e-06 	 AEnc : 1.7869e-05 	 MSE : 9.6352e-03
Epoch 656, 50% 	 Loss : 1.5568e-02 	 Res : 2.8827e-03 	 Jac : 1.2662e-02 	 Enc : 5.4165e-06 	 AEnc : 1.8100e-05 	 MSE : 9.3012e-03
Epoch 656, 75% 	 Loss : 1.5570e-02 	 Res : 2.8836e-03 	 Jac : 1.2662e-02 	 Enc : 5.6457e-06 	 AEnc : 1.8211e-05 	 MSE : 9.3947e-03
Training Epoch 656 : 	 Train : 1.55816e-02 	 Res : 2.87124e-03 	 Jac : 1.26867e-02 	 Enc : 5.52753e-06 	 AE : 1.81439e-05 	 MSE : 9.39163e-03
Validation Epoch 656 : 	 Train : 1.56894e-02 	 Res : 2.94319e-03 	 Jac : 1.27233e-02 	 Enc : 5.48477e-06 	 AE : 1.74539e-05 	 MSE : 1.79662e-02
Training Epoch 656 finished, took current epoch 360.37s, cumulative time 241714.19s
Current Learning rate DEQ : 8.507059173023481e-07
Current Learning rate AUTOENC : 4.2535295865117404e-06
Epoch 657, 25% 	 Loss : 1.5742e-02 	 Res : 2.9164e-03 	 Jac : 1.2802e-02 	 Enc : 5.6567e-06 	 AEnc : 1.7729e-05 	 MSE : 9.3123e-03
Epoch 657, 50% 	 Loss : 1.5702e-02 	 Res : 2.8301e-03 	 Jac : 1.2848e-02 	 Enc : 5.4300e-06 	 AEnc : 1.7850e-05 	 MSE : 8.8515e-03
Epoch 657, 75% 	 Loss : 1.5661e-02 	 Res : 2.8735e-03 	 Jac : 1.2764e-02 	 Enc : 5.5481e-06 	 AEnc : 1.7758e-05 	 MSE : 8.7951e-03
Training Epoch 657 : 	 Train : 1.56941e-02 	 Res : 2.87110e-03 	 Jac : 1.27995e-02 	 Enc : 5.51236e-06 	 AE : 1.79677e-05 	 MSE : 9.16533e-03
Validation Epoch 657 : 	 Train : 1.55398e-02 	 Res : 2.90267e-03 	 Jac : 1.26131e-02 	 Enc : 5.48433e-06 	 AE : 1.85520e-05 	 MSE : 8.59636e-03
Training Epoch 657 finished, took current epoch 362.10s, cumulative time 242076.25s
Current Learning rate DEQ : 8.507059173023481e-07
Current Learning rate AUTOENC : 4.2535295865117404e-06
Epoch 658, 25% 	 Loss : 1.5633e-02 	 Res : 2.8685e-03 	 Jac : 1.2740e-02 	 Enc : 5.7539e-06 	 AEnc : 1.8527e-05 	 MSE : 9.4731e-03
Epoch 658, 50% 	 Loss : 1.5622e-02 	 Res : 2.8340e-03 	 Jac : 1.2765e-02 	 Enc : 5.5043e-06 	 AEnc : 1.8033e-05 	 MSE : 9.4091e-03
Epoch 658, 75% 	 Loss : 1.5645e-02 	 Res : 2.8948e-03 	 Jac : 1.2726e-02 	 Enc : 5.4021e-06 	 AEnc : 1.8538e-05 	 MSE : 9.3233e-03
Training Epoch 658 : 	 Train : 1.56289e-02 	 Res : 2.87099e-03 	 Jac : 1.27343e-02 	 Enc : 5.50375e-06 	 AE : 1.81678e-05 	 MSE : 9.39333e-03
Validation Epoch 658 : 	 Train : 1.56993e-02 	 Res : 2.90286e-03 	 Jac : 1.27727e-02 	 Enc : 5.45283e-06 	 AE : 1.82700e-05 	 MSE : 8.51034e-03
Training Epoch 658 finished, took current epoch 359.26s, cumulative time 242435.49s
Current Learning rate DEQ : 8.507059173023481e-07
Current Learning rate AUTOENC : 4.2535295865117404e-06
Epoch 659, 25% 	 Loss : 1.5547e-02 	 Res : 2.8337e-03 	 Jac : 1.2690e-02 	 Enc : 5.3635e-06 	 AEnc : 1.8084e-05 	 MSE : 9.3142e-03
Epoch 659, 50% 	 Loss : 1.5600e-02 	 Res : 2.8583e-03 	 Jac : 1.2719e-02 	 Enc : 5.4112e-06 	 AEnc : 1.8205e-05 	 MSE : 8.3558e-03
Epoch 659, 75% 	 Loss : 1.5681e-02 	 Res : 2.9067e-03 	 Jac : 1.2751e-02 	 Enc : 5.5120e-06 	 AEnc : 1.7797e-05 	 MSE : 9.3098e-03
Training Epoch 659 : 	 Train : 1.56264e-02 	 Res : 2.87114e-03 	 Jac : 1.27317e-02 	 Enc : 5.47494e-06 	 AE : 1.80826e-05 	 MSE : 9.27504e-03
Validation Epoch 659 : 	 Train : 1.55760e-02 	 Res : 2.90273e-03 	 Jac : 1.26503e-02 	 Enc : 5.44896e-06 	 AE : 1.75686e-05 	 MSE : 8.73702e-03
Training Epoch 659 finished, took current epoch 360.75s, cumulative time 242796.22s
Current Learning rate DEQ : 8.507059173023481e-07
Current Learning rate AUTOENC : 4.2535295865117404e-06
Epoch 660, 25% 	 Loss : 1.5557e-02 	 Res : 2.8235e-03 	 Jac : 1.2711e-02 	 Enc : 5.4619e-06 	 AEnc : 1.7720e-05 	 MSE : 8.8460e-03
Epoch 660, 50% 	 Loss : 1.5667e-02 	 Res : 2.9390e-03 	 Jac : 1.2704e-02 	 Enc : 5.5968e-06 	 AEnc : 1.7728e-05 	 MSE : 8.7871e-03
Epoch 660, 75% 	 Loss : 1.5541e-02 	 Res : 2.8391e-03 	 Jac : 1.2678e-02 	 Enc : 5.3914e-06 	 AEnc : 1.8158e-05 	 MSE : 9.2917e-03
Training Epoch 660 : 	 Train : 1.56247e-02 	 Res : 2.87131e-03 	 Jac : 1.27299e-02 	 Enc : 5.48046e-06 	 AE : 1.80463e-05 	 MSE : 9.10022e-03
Validation Epoch 660 : 	 Train : 1.55966e-02 	 Res : 2.90353e-03 	 Jac : 1.26674e-02 	 Enc : 5.45246e-06 	 AE : 2.01576e-05 	 MSE : 8.71119e-03
Training Epoch 660 finished, took current epoch 363.22s, cumulative time 243159.41s
Current Learning rate DEQ : 8.507059173023481e-07
Current Learning rate AUTOENC : 4.2535295865117404e-06
Epoch 661, 25% 	 Loss : 1.5664e-02 	 Res : 2.9094e-03 	 Jac : 1.2731e-02 	 Enc : 5.4570e-06 	 AEnc : 1.7944e-05 	 MSE : 1.2723e-02
Epoch 661, 50% 	 Loss : 1.5595e-02 	 Res : 2.8832e-03 	 Jac : 1.2688e-02 	 Enc : 5.5653e-06 	 AEnc : 1.8039e-05 	 MSE : 9.1384e-03
Epoch 661, 75% 	 Loss : 1.5548e-02 	 Res : 2.8528e-03 	 Jac : 1.2671e-02 	 Enc : 5.4908e-06 	 AEnc : 1.8080e-05 	 MSE : 9.2886e-03
Training Epoch 661 : 	 Train : 1.55952e-02 	 Res : 2.87589e-03 	 Jac : 1.26958e-02 	 Enc : 5.49980e-06 	 AE : 1.80062e-05 	 MSE : 1.01768e-02
Validation Epoch 661 : 	 Train : 1.55701e-02 	 Res : 2.90288e-03 	 Jac : 1.26445e-02 	 Enc : 5.46990e-06 	 AE : 1.72641e-05 	 MSE : 8.61234e-03
Training Epoch 661 finished, took current epoch 363.66s, cumulative time 243523.05s
Current Learning rate DEQ : 6.805647338418785e-07
Current Learning rate AUTOENC : 3.4028236692093925e-06
Epoch 662, 25% 	 Loss : 1.5656e-02 	 Res : 2.8727e-03 	 Jac : 1.2760e-02 	 Enc : 5.5274e-06 	 AEnc : 1.8258e-05 	 MSE : 9.4709e-03
Epoch 662, 50% 	 Loss : 1.5577e-02 	 Res : 2.8508e-03 	 Jac : 1.2703e-02 	 Enc : 5.4383e-06 	 AEnc : 1.7927e-05 	 MSE : 8.9910e-03
Epoch 662, 75% 	 Loss : 1.5632e-02 	 Res : 2.8466e-03 	 Jac : 1.2762e-02 	 Enc : 5.5647e-06 	 AEnc : 1.7638e-05 	 MSE : 8.9876e-03
Training Epoch 662 : 	 Train : 1.56213e-02 	 Res : 2.87093e-03 	 Jac : 1.27269e-02 	 Enc : 5.51123e-06 	 AE : 1.80010e-05 	 MSE : 9.14619e-03
Validation Epoch 662 : 	 Train : 1.56745e-02 	 Res : 2.90361e-03 	 Jac : 1.27481e-02 	 Enc : 5.44946e-06 	 AE : 1.74210e-05 	 MSE : 8.62125e-03
Training Epoch 662 finished, took current epoch 359.20s, cumulative time 243882.21s
Current Learning rate DEQ : 6.805647338418785e-07
Current Learning rate AUTOENC : 3.4028236692093925e-06
Epoch 663, 25% 	 Loss : 1.5598e-02 	 Res : 2.8958e-03 	 Jac : 1.2678e-02 	 Enc : 5.4757e-06 	 AEnc : 1.8191e-05 	 MSE : 9.4385e-03
Epoch 663, 50% 	 Loss : 1.5582e-02 	 Res : 2.8560e-03 	 Jac : 1.2702e-02 	 Enc : 5.4988e-06 	 AEnc : 1.8020e-05 	 MSE : 9.1203e-03
Epoch 663, 75% 	 Loss : 1.5513e-02 	 Res : 2.8256e-03 	 Jac : 1.2665e-02 	 Enc : 5.4211e-06 	 AEnc : 1.7509e-05 	 MSE : 9.1243e-03
Training Epoch 663 : 	 Train : 1.55937e-02 	 Res : 2.87116e-03 	 Jac : 1.26989e-02 	 Enc : 5.46844e-06 	 AE : 1.80926e-05 	 MSE : 9.25325e-03
Validation Epoch 663 : 	 Train : 1.55724e-02 	 Res : 2.90347e-03 	 Jac : 1.26463e-02 	 Enc : 5.43902e-06 	 AE : 1.72084e-05 	 MSE : 8.98221e-03
Training Epoch 663 finished, took current epoch 360.85s, cumulative time 244243.01s
Current Learning rate DEQ : 6.805647338418785e-07
Current Learning rate AUTOENC : 3.4028236692093925e-06
Epoch 664, 25% 	 Loss : 1.5749e-02 	 Res : 2.9138e-03 	 Jac : 1.2812e-02 	 Enc : 5.5246e-06 	 AEnc : 1.7512e-05 	 MSE : 9.0433e-03
Epoch 664, 50% 	 Loss : 1.5662e-02 	 Res : 2.8638e-03 	 Jac : 1.2775e-02 	 Enc : 5.5640e-06 	 AEnc : 1.7682e-05 	 MSE : 9.3809e-03
Epoch 664, 75% 	 Loss : 1.5585e-02 	 Res : 2.8350e-03 	 Jac : 1.2727e-02 	 Enc : 5.4680e-06 	 AEnc : 1.7882e-05 	 MSE : 9.2328e-03
Training Epoch 664 : 	 Train : 1.56623e-02 	 Res : 2.87084e-03 	 Jac : 1.27683e-02 	 Enc : 5.51170e-06 	 AE : 1.76436e-05 	 MSE : 9.17405e-03
Validation Epoch 664 : 	 Train : 1.55857e-02 	 Res : 2.90308e-03 	 Jac : 1.26583e-02 	 Enc : 5.47569e-06 	 AE : 1.88891e-05 	 MSE : 8.77794e-03
Training Epoch 664 finished, took current epoch 361.19s, cumulative time 244604.14s
Current Learning rate DEQ : 6.805647338418785e-07
Current Learning rate AUTOENC : 3.4028236692093925e-06
Epoch 665, 25% 	 Loss : 1.5585e-02 	 Res : 2.9097e-03 	 Jac : 1.2652e-02 	 Enc : 5.5362e-06 	 AEnc : 1.7740e-05 	 MSE : 8.9603e-03
Epoch 665, 50% 	 Loss : 1.5675e-02 	 Res : 2.8784e-03 	 Jac : 1.2772e-02 	 Enc : 5.5131e-06 	 AEnc : 1.8775e-05 	 MSE : 9.7739e-03
Epoch 665, 75% 	 Loss : 1.5620e-02 	 Res : 2.8571e-03 	 Jac : 1.2739e-02 	 Enc : 5.4311e-06 	 AEnc : 1.8748e-05 	 MSE : 8.9680e-03
Training Epoch 665 : 	 Train : 1.56076e-02 	 Res : 2.87099e-03 	 Jac : 1.27130e-02 	 Enc : 5.50156e-06 	 AE : 1.80756e-05 	 MSE : 9.20083e-03
Validation Epoch 665 : 	 Train : 1.56130e-02 	 Res : 2.90375e-03 	 Jac : 1.26862e-02 	 Enc : 5.45176e-06 	 AE : 1.76371e-05 	 MSE : 8.77349e-03
Training Epoch 665 finished, took current epoch 363.06s, cumulative time 244967.18s
Current Learning rate DEQ : 6.805647338418785e-07
Current Learning rate AUTOENC : 3.4028236692093925e-06
Epoch 666, 25% 	 Loss : 1.5658e-02 	 Res : 2.8990e-03 	 Jac : 1.2735e-02 	 Enc : 5.5689e-06 	 AEnc : 1.7693e-05 	 MSE : 9.1573e-03
Epoch 666, 50% 	 Loss : 1.5594e-02 	 Res : 2.8496e-03 	 Jac : 1.2721e-02 	 Enc : 5.4198e-06 	 AEnc : 1.7857e-05 	 MSE : 9.2963e-03
Epoch 666, 75% 	 Loss : 1.5503e-02 	 Res : 2.8509e-03 	 Jac : 1.2629e-02 	 Enc : 5.4398e-06 	 AEnc : 1.7734e-05 	 MSE : 8.9630e-03
Training Epoch 666 : 	 Train : 1.55979e-02 	 Res : 2.87113e-03 	 Jac : 1.27033e-02 	 Enc : 5.49962e-06 	 AE : 1.79886e-05 	 MSE : 9.17956e-03
Validation Epoch 666 : 	 Train : 1.56072e-02 	 Res : 2.90338e-03 	 Jac : 1.26812e-02 	 Enc : 5.47319e-06 	 AE : 1.71835e-05 	 MSE : 8.61766e-03
Training Epoch 666 finished, took current epoch 364.86s, cumulative time 245331.97s
Current Learning rate DEQ : 6.805647338418785e-07
Current Learning rate AUTOENC : 3.4028236692093925e-06
Epoch 667, 25% 	 Loss : 1.5688e-02 	 Res : 2.9292e-03 	 Jac : 1.2735e-02 	 Enc : 5.6060e-06 	 AEnc : 1.7913e-05 	 MSE : 9.0741e-03
Epoch 667, 50% 	 Loss : 1.5432e-02 	 Res : 2.7940e-03 	 Jac : 1.2614e-02 	 Enc : 5.4693e-06 	 AEnc : 1.8529e-05 	 MSE : 9.5250e-03
Epoch 667, 75% 	 Loss : 1.5582e-02 	 Res : 2.8532e-03 	 Jac : 1.2705e-02 	 Enc : 5.5421e-06 	 AEnc : 1.7564e-05 	 MSE : 9.4071e-03
Training Epoch 667 : 	 Train : 1.55782e-02 	 Res : 2.87090e-03 	 Jac : 1.26839e-02 	 Enc : 5.52313e-06 	 AE : 1.78893e-05 	 MSE : 9.27635e-03
Validation Epoch 667 : 	 Train : 1.56546e-02 	 Res : 2.90382e-03 	 Jac : 1.27261e-02 	 Enc : 5.49569e-06 	 AE : 1.91468e-05 	 MSE : 8.96185e-03
Training Epoch 667 finished, took current epoch 360.87s, cumulative time 245692.82s
Current Learning rate DEQ : 6.805647338418785e-07
Current Learning rate AUTOENC : 3.4028236692093925e-06
Epoch 668, 25% 	 Loss : 1.5538e-02 	 Res : 2.8626e-03 	 Jac : 1.2651e-02 	 Enc : 5.4616e-06 	 AEnc : 1.8735e-05 	 MSE : 9.1571e-03
Epoch 668, 50% 	 Loss : 1.5589e-02 	 Res : 2.8660e-03 	 Jac : 1.2699e-02 	 Enc : 5.5557e-06 	 AEnc : 1.7922e-05 	 MSE : 9.3030e-03
Epoch 668, 75% 	 Loss : 1.5578e-02 	 Res : 2.8858e-03 	 Jac : 1.2669e-02 	 Enc : 5.5113e-06 	 AEnc : 1.7877e-05 	 MSE : 9.2843e-03
Training Epoch 668 : 	 Train : 1.55706e-02 	 Res : 2.87088e-03 	 Jac : 1.26761e-02 	 Enc : 5.53426e-06 	 AE : 1.80959e-05 	 MSE : 9.21533e-03
Validation Epoch 668 : 	 Train : 1.55916e-02 	 Res : 2.90264e-03 	 Jac : 1.26654e-02 	 Enc : 5.50237e-06 	 AE : 1.80212e-05 	 MSE : 8.70783e-03
Training Epoch 668 finished, took current epoch 361.30s, cumulative time 246054.10s
Current Learning rate DEQ : 6.805647338418785e-07
Current Learning rate AUTOENC : 3.4028236692093925e-06
Epoch 669, 25% 	 Loss : 1.5597e-02 	 Res : 2.8798e-03 	 Jac : 1.2694e-02 	 Enc : 5.3776e-06 	 AEnc : 1.8050e-05 	 MSE : 9.3721e-03
Epoch 669, 50% 	 Loss : 1.5596e-02 	 Res : 2.8745e-03 	 Jac : 1.2698e-02 	 Enc : 5.6128e-06 	 AEnc : 1.7968e-05 	 MSE : 9.1340e-03
Epoch 669, 75% 	 Loss : 1.5681e-02 	 Res : 2.8763e-03 	 Jac : 1.2781e-02 	 Enc : 5.6770e-06 	 AEnc : 1.8268e-05 	 MSE : 8.9240e-03
Training Epoch 669 : 	 Train : 1.56355e-02 	 Res : 2.87021e-03 	 Jac : 1.27416e-02 	 Enc : 5.54736e-06 	 AE : 1.80463e-05 	 MSE : 9.05084e-03
Validation Epoch 669 : 	 Train : 1.55983e-02 	 Res : 2.90364e-03 	 Jac : 1.26718e-02 	 Enc : 5.51587e-06 	 AE : 1.73834e-05 	 MSE : 8.91198e-03
Training Epoch 669 finished, took current epoch 365.72s, cumulative time 246419.77s
Current Learning rate DEQ : 6.805647338418785e-07
Current Learning rate AUTOENC : 3.4028236692093925e-06
Epoch 670, 25% 	 Loss : 1.5726e-02 	 Res : 3.0032e-03 	 Jac : 1.2698e-02 	 Enc : 5.6135e-06 	 AEnc : 1.9210e-05 	 MSE : 6.3079e-02
Epoch 670, 50% 	 Loss : 1.5556e-02 	 Res : 2.8985e-03 	 Jac : 1.2634e-02 	 Enc : 5.5639e-06 	 AEnc : 1.8225e-05 	 MSE : 9.5258e-03
Epoch 670, 75% 	 Loss : 1.5795e-02 	 Res : 2.9855e-03 	 Jac : 1.2787e-02 	 Enc : 5.4306e-06 	 AEnc : 1.7155e-05 	 MSE : 3.7875e-02
Training Epoch 670 : 	 Train : 1.56463e-02 	 Res : 2.93876e-03 	 Jac : 1.26839e-02 	 Enc : 5.54119e-06 	 AE : 1.80399e-05 	 MSE : 3.05271e-02
Validation Epoch 670 : 	 Train : 1.56327e-02 	 Res : 2.90277e-03 	 Jac : 1.27071e-02 	 Enc : 5.52740e-06 	 AE : 1.73062e-05 	 MSE : 8.60983e-03
Training Epoch 670 finished, took current epoch 362.11s, cumulative time 246781.80s
Current Learning rate DEQ : 6.805647338418785e-07
Current Learning rate AUTOENC : 3.4028236692093925e-06
Epoch 671, 25% 	 Loss : 1.5698e-02 	 Res : 2.8744e-03 	 Jac : 1.2801e-02 	 Enc : 5.5568e-06 	 AEnc : 1.7349e-05 	 MSE : 9.2701e-03
Epoch 671, 50% 	 Loss : 1.5703e-02 	 Res : 2.8931e-03 	 Jac : 1.2787e-02 	 Enc : 5.5780e-06 	 AEnc : 1.7772e-05 	 MSE : 8.9239e-03
Epoch 671, 75% 	 Loss : 1.5550e-02 	 Res : 2.8490e-03 	 Jac : 1.2677e-02 	 Enc : 5.5891e-06 	 AEnc : 1.7827e-05 	 MSE : 9.5098e-03
Training Epoch 671 : 	 Train : 1.56520e-02 	 Res : 2.87082e-03 	 Jac : 1.27577e-02 	 Enc : 5.55196e-06 	 AE : 1.79710e-05 	 MSE : 9.24799e-03
Validation Epoch 671 : 	 Train : 1.56492e-02 	 Res : 2.90481e-03 	 Jac : 1.27220e-02 	 Enc : 5.50249e-06 	 AE : 1.68653e-05 	 MSE : 9.24615e-03
Training Epoch 671 finished, took current epoch 362.63s, cumulative time 247144.41s
Current Learning rate DEQ : 6.805647338418785e-07
Current Learning rate AUTOENC : 3.4028236692093925e-06
Epoch 672, 25% 	 Loss : 1.5702e-02 	 Res : 2.8973e-03 	 Jac : 1.2781e-02 	 Enc : 5.5195e-06 	 AEnc : 1.8071e-05 	 MSE : 9.0133e-03
Epoch 672, 50% 	 Loss : 1.5425e-02 	 Res : 2.7982e-03 	 Jac : 1.2604e-02 	 Enc : 5.6069e-06 	 AEnc : 1.8012e-05 	 MSE : 9.4209e-03
Epoch 672, 75% 	 Loss : 1.5734e-02 	 Res : 2.9293e-03 	 Jac : 1.2781e-02 	 Enc : 5.5987e-06 	 AEnc : 1.8741e-05 	 MSE : 1.1277e-02
Training Epoch 672 : 	 Train : 1.55873e-02 	 Res : 2.87416e-03 	 Jac : 1.26893e-02 	 Enc : 5.54834e-06 	 AE : 1.82498e-05 	 MSE : 9.75191e-03
Validation Epoch 672 : 	 Train : 1.56476e-02 	 Res : 2.90296e-03 	 Jac : 1.27213e-02 	 Enc : 5.50628e-06 	 AE : 1.78628e-05 	 MSE : 8.70531e-03
Training Epoch 672 finished, took current epoch 361.21s, cumulative time 247505.61s
Current Learning rate DEQ : 5.444517870735028e-07
Current Learning rate AUTOENC : 2.722258935367514e-06
Epoch 673, 25% 	 Loss : 1.5493e-02 	 Res : 2.8670e-03 	 Jac : 1.2602e-02 	 Enc : 5.5437e-06 	 AEnc : 1.7938e-05 	 MSE : 9.2295e-03
Epoch 673, 50% 	 Loss : 1.5452e-02 	 Res : 2.8224e-03 	 Jac : 1.2606e-02 	 Enc : 5.6538e-06 	 AEnc : 1.7944e-05 	 MSE : 9.4092e-03
Epoch 673, 75% 	 Loss : 1.5652e-02 	 Res : 2.9093e-03 	 Jac : 1.2720e-02 	 Enc : 5.4486e-06 	 AEnc : 1.7560e-05 	 MSE : 8.9616e-03
Training Epoch 673 : 	 Train : 1.55476e-02 	 Res : 2.87082e-03 	 Jac : 1.26533e-02 	 Enc : 5.54447e-06 	 AE : 1.79516e-05 	 MSE : 9.25088e-03
Validation Epoch 673 : 	 Train : 1.56859e-02 	 Res : 2.90317e-03 	 Jac : 1.27602e-02 	 Enc : 5.50856e-06 	 AE : 1.70857e-05 	 MSE : 8.92110e-03
Training Epoch 673 finished, took current epoch 361.83s, cumulative time 247867.42s
Current Learning rate DEQ : 5.444517870735028e-07
Current Learning rate AUTOENC : 2.722258935367514e-06
Epoch 674, 25% 	 Loss : 1.5625e-02 	 Res : 2.8974e-03 	 Jac : 1.2705e-02 	 Enc : 5.5418e-06 	 AEnc : 1.7861e-05 	 MSE : 9.9420e-03
Epoch 674, 50% 	 Loss : 1.5639e-02 	 Res : 2.8403e-03 	 Jac : 1.2776e-02 	 Enc : 5.7205e-06 	 AEnc : 1.7474e-05 	 MSE : 9.1933e-03
Epoch 674, 75% 	 Loss : 1.5693e-02 	 Res : 2.8830e-03 	 Jac : 1.2786e-02 	 Enc : 5.4437e-06 	 AEnc : 1.8503e-05 	 MSE : 9.0325e-03
Training Epoch 674 : 	 Train : 1.56203e-02 	 Res : 2.87106e-03 	 Jac : 1.27257e-02 	 Enc : 5.53073e-06 	 AE : 1.80463e-05 	 MSE : 9.26554e-03
Validation Epoch 674 : 	 Train : 1.57564e-02 	 Res : 2.94128e-03 	 Jac : 1.27915e-02 	 Enc : 5.48759e-06 	 AE : 1.80616e-05 	 MSE : 2.04686e-02
Training Epoch 674 finished, took current epoch 362.88s, cumulative time 248230.28s
Current Learning rate DEQ : 5.444517870735028e-07
Current Learning rate AUTOENC : 2.722258935367514e-06
Epoch 675, 25% 	 Loss : 1.5634e-02 	 Res : 2.8835e-03 	 Jac : 1.2728e-02 	 Enc : 5.5253e-06 	 AEnc : 1.7643e-05 	 MSE : 8.9159e-03
Epoch 675, 50% 	 Loss : 1.5701e-02 	 Res : 2.8656e-03 	 Jac : 1.2812e-02 	 Enc : 5.5217e-06 	 AEnc : 1.7722e-05 	 MSE : 8.9741e-03
Epoch 675, 75% 	 Loss : 1.5533e-02 	 Res : 2.8464e-03 	 Jac : 1.2662e-02 	 Enc : 5.5692e-06 	 AEnc : 1.8609e-05 	 MSE : 9.0170e-03
Training Epoch 675 : 	 Train : 1.56460e-02 	 Res : 2.87004e-03 	 Jac : 1.27524e-02 	 Enc : 5.52142e-06 	 AE : 1.80135e-05 	 MSE : 8.97551e-03
Validation Epoch 675 : 	 Train : 1.55341e-02 	 Res : 2.90267e-03 	 Jac : 1.26084e-02 	 Enc : 5.49809e-06 	 AE : 1.75658e-05 	 MSE : 8.45705e-03
Training Epoch 675 finished, took current epoch 359.84s, cumulative time 248590.09s
Current Learning rate DEQ : 5.444517870735028e-07
Current Learning rate AUTOENC : 2.722258935367514e-06
Epoch 676, 25% 	 Loss : 1.5595e-02 	 Res : 2.8932e-03 	 Jac : 1.2678e-02 	 Enc : 5.4808e-06 	 AEnc : 1.8263e-05 	 MSE : 9.0749e-03
Epoch 676, 50% 	 Loss : 1.5589e-02 	 Res : 2.8228e-03 	 Jac : 1.2743e-02 	 Enc : 5.5816e-06 	 AEnc : 1.7564e-05 	 MSE : 9.2475e-03
Epoch 676, 75% 	 Loss : 1.5599e-02 	 Res : 2.8854e-03 	 Jac : 1.2691e-02 	 Enc : 5.6199e-06 	 AEnc : 1.7525e-05 	 MSE : 8.7712e-03
Training Epoch 676 : 	 Train : 1.56065e-02 	 Res : 2.87038e-03 	 Jac : 1.27128e-02 	 Enc : 5.53089e-06 	 AE : 1.77987e-05 	 MSE : 9.09307e-03
Validation Epoch 676 : 	 Train : 1.55905e-02 	 Res : 2.90265e-03 	 Jac : 1.26644e-02 	 Enc : 5.50593e-06 	 AE : 1.80078e-05 	 MSE : 8.50723e-03
Training Epoch 676 finished, took current epoch 362.49s, cumulative time 248952.56s
Current Learning rate DEQ : 5.444517870735028e-07
Current Learning rate AUTOENC : 2.722258935367514e-06
Epoch 677, 25% 	 Loss : 1.5628e-02 	 Res : 2.9263e-03 	 Jac : 1.2678e-02 	 Enc : 5.6244e-06 	 AEnc : 1.8177e-05 	 MSE : 9.0332e-03
Epoch 677, 50% 	 Loss : 1.5657e-02 	 Res : 2.8817e-03 	 Jac : 1.2752e-02 	 Enc : 5.4932e-06 	 AEnc : 1.7828e-05 	 MSE : 9.1399e-03
Epoch 677, 75% 	 Loss : 1.5671e-02 	 Res : 2.8618e-03 	 Jac : 1.2785e-02 	 Enc : 5.5180e-06 	 AEnc : 1.8167e-05 	 MSE : 8.8266e-03
Training Epoch 677 : 	 Train : 1.56397e-02 	 Res : 2.87061e-03 	 Jac : 1.27454e-02 	 Enc : 5.54471e-06 	 AE : 1.81129e-05 	 MSE : 9.09110e-03
Validation Epoch 677 : 	 Train : 1.56210e-02 	 Res : 2.90275e-03 	 Jac : 1.26943e-02 	 Enc : 5.50621e-06 	 AE : 1.84179e-05 	 MSE : 8.41633e-03
Training Epoch 677 finished, took current epoch 362.48s, cumulative time 249315.02s
Current Learning rate DEQ : 5.444517870735028e-07
Current Learning rate AUTOENC : 2.722258935367514e-06
Epoch 678, 25% 	 Loss : 1.5567e-02 	 Res : 2.9076e-03 	 Jac : 1.2636e-02 	 Enc : 5.4572e-06 	 AEnc : 1.7953e-05 	 MSE : 9.1820e-03
Epoch 678, 50% 	 Loss : 1.5577e-02 	 Res : 2.8177e-03 	 Jac : 1.2736e-02 	 Enc : 5.5878e-06 	 AEnc : 1.7593e-05 	 MSE : 8.7660e-03
Epoch 678, 75% 	 Loss : 1.5614e-02 	 Res : 2.8953e-03 	 Jac : 1.2695e-02 	 Enc : 5.5708e-06 	 AEnc : 1.8005e-05 	 MSE : 8.7981e-03
Training Epoch 678 : 	 Train : 1.55800e-02 	 Res : 2.87211e-03 	 Jac : 1.26845e-02 	 Enc : 5.52870e-06 	 AE : 1.79388e-05 	 MSE : 9.19316e-03
Validation Epoch 678 : 	 Train : 1.56838e-02 	 Res : 2.90286e-03 	 Jac : 1.27580e-02 	 Enc : 5.48155e-06 	 AE : 1.74715e-05 	 MSE : 8.80077e-03
Training Epoch 678 finished, took current epoch 363.90s, cumulative time 249678.88s
Current Learning rate DEQ : 5.444517870735028e-07
Current Learning rate AUTOENC : 2.722258935367514e-06
Epoch 679, 25% 	 Loss : 1.5637e-02 	 Res : 2.8714e-03 	 Jac : 1.2743e-02 	 Enc : 5.5194e-06 	 AEnc : 1.7527e-05 	 MSE : 9.1851e-03
Epoch 679, 50% 	 Loss : 1.5708e-02 	 Res : 2.9054e-03 	 Jac : 1.2778e-02 	 Enc : 5.5688e-06 	 AEnc : 1.8582e-05 	 MSE : 9.2309e-03
Epoch 679, 75% 	 Loss : 1.5568e-02 	 Res : 2.8423e-03 	 Jac : 1.2702e-02 	 Enc : 5.4695e-06 	 AEnc : 1.8041e-05 	 MSE : 9.3290e-03
Training Epoch 679 : 	 Train : 1.56113e-02 	 Res : 2.87032e-03 	 Jac : 1.27174e-02 	 Enc : 5.51327e-06 	 AE : 1.80262e-05 	 MSE : 9.16847e-03
Validation Epoch 679 : 	 Train : 1.58775e-02 	 Res : 3.20553e-03 	 Jac : 1.26492e-02 	 Enc : 5.46734e-06 	 AE : 1.73366e-05 	 MSE : 9.60734e-02
Training Epoch 679 finished, took current epoch 362.61s, cumulative time 250041.45s
Current Learning rate DEQ : 5.444517870735028e-07
Current Learning rate AUTOENC : 2.722258935367514e-06
Epoch 680, 25% 	 Loss : 1.5673e-02 	 Res : 2.8715e-03 	 Jac : 1.2779e-02 	 Enc : 5.5151e-06 	 AEnc : 1.7828e-05 	 MSE : 9.4185e-03
Epoch 680, 50% 	 Loss : 1.5538e-02 	 Res : 2.8382e-03 	 Jac : 1.2676e-02 	 Enc : 5.4326e-06 	 AEnc : 1.7687e-05 	 MSE : 8.6775e-03
Epoch 680, 75% 	 Loss : 1.5619e-02 	 Res : 2.9090e-03 	 Jac : 1.2687e-02 	 Enc : 5.5512e-06 	 AEnc : 1.7624e-05 	 MSE : 9.3189e-03
Training Epoch 680 : 	 Train : 1.56083e-02 	 Res : 2.87061e-03 	 Jac : 1.27144e-02 	 Enc : 5.52292e-06 	 AE : 1.77320e-05 	 MSE : 9.18213e-03
Validation Epoch 680 : 	 Train : 1.55878e-02 	 Res : 2.90302e-03 	 Jac : 1.26614e-02 	 Enc : 5.47316e-06 	 AE : 1.79109e-05 	 MSE : 8.64458e-03
Training Epoch 680 finished, took current epoch 357.52s, cumulative time 250398.94s
Current Learning rate DEQ : 5.444517870735028e-07
Current Learning rate AUTOENC : 2.722258935367514e-06
Epoch 681, 25% 	 Loss : 1.5668e-02 	 Res : 2.8114e-03 	 Jac : 1.2833e-02 	 Enc : 5.4576e-06 	 AEnc : 1.7991e-05 	 MSE : 9.0854e-03
Epoch 681, 50% 	 Loss : 1.5669e-02 	 Res : 2.8564e-03 	 Jac : 1.2789e-02 	 Enc : 5.6475e-06 	 AEnc : 1.7308e-05 	 MSE : 9.2968e-03
Epoch 681, 75% 	 Loss : 1.5665e-02 	 Res : 2.9034e-03 	 Jac : 1.2738e-02 	 Enc : 5.5203e-06 	 AEnc : 1.7650e-05 	 MSE : 8.7448e-03
Training Epoch 681 : 	 Train : 1.56726e-02 	 Res : 2.87025e-03 	 Jac : 1.27790e-02 	 Enc : 5.53042e-06 	 AE : 1.77912e-05 	 MSE : 9.07200e-03
Validation Epoch 681 : 	 Train : 1.56325e-02 	 Res : 2.90244e-03 	 Jac : 1.27071e-02 	 Enc : 5.49793e-06 	 AE : 1.75339e-05 	 MSE : 8.53579e-03
Training Epoch 681 finished, took current epoch 362.17s, cumulative time 250761.08s
Current Learning rate DEQ : 5.444517870735028e-07
Current Learning rate AUTOENC : 2.722258935367514e-06
Epoch 682, 25% 	 Loss : 1.5718e-02 	 Res : 2.9321e-03 	 Jac : 1.2762e-02 	 Enc : 5.4212e-06 	 AEnc : 1.8560e-05 	 MSE : 8.7939e-03
Epoch 682, 50% 	 Loss : 1.5492e-02 	 Res : 2.8466e-03 	 Jac : 1.2622e-02 	 Enc : 5.5070e-06 	 AEnc : 1.7900e-05 	 MSE : 9.0340e-03
Epoch 682, 75% 	 Loss : 1.5566e-02 	 Res : 2.8333e-03 	 Jac : 1.2709e-02 	 Enc : 5.6438e-06 	 AEnc : 1.7696e-05 	 MSE : 8.8535e-03
Training Epoch 682 : 	 Train : 1.56081e-02 	 Res : 2.87001e-03 	 Jac : 1.27146e-02 	 Enc : 5.53186e-06 	 AE : 1.79436e-05 	 MSE : 8.96499e-03
Validation Epoch 682 : 	 Train : 1.55666e-02 	 Res : 2.91222e-03 	 Jac : 1.26315e-02 	 Enc : 5.50514e-06 	 AE : 1.74044e-05 	 MSE : 9.94023e-03
Training Epoch 682 finished, took current epoch 362.35s, cumulative time 251123.39s
Current Learning rate DEQ : 5.444517870735028e-07
Current Learning rate AUTOENC : 2.722258935367514e-06
Epoch 683, 25% 	 Loss : 1.5582e-02 	 Res : 2.8708e-03 	 Jac : 1.2688e-02 	 Enc : 5.5336e-06 	 AEnc : 1.7793e-05 	 MSE : 9.1928e-03
Epoch 683, 50% 	 Loss : 1.5562e-02 	 Res : 2.8897e-03 	 Jac : 1.2649e-02 	 Enc : 5.5957e-06 	 AEnc : 1.7842e-05 	 MSE : 8.9283e-03
Epoch 683, 75% 	 Loss : 1.5550e-02 	 Res : 2.8808e-03 	 Jac : 1.2646e-02 	 Enc : 5.5918e-06 	 AEnc : 1.8115e-05 	 MSE : 1.2254e-02
Training Epoch 683 : 	 Train : 1.55759e-02 	 Res : 2.87398e-03 	 Jac : 1.26785e-02 	 Enc : 5.52586e-06 	 AE : 1.79797e-05 	 MSE : 9.85153e-03
Validation Epoch 683 : 	 Train : 1.56537e-02 	 Res : 2.90322e-03 	 Jac : 1.27277e-02 	 Enc : 5.49152e-06 	 AE : 1.72913e-05 	 MSE : 8.69264e-03
Training Epoch 683 finished, took current epoch 362.17s, cumulative time 251485.53s
Current Learning rate DEQ : 4.355614296588023e-07
Current Learning rate AUTOENC : 2.1778071482940113e-06
Epoch 684, 25% 	 Loss : 1.5591e-02 	 Res : 2.9242e-03 	 Jac : 1.2643e-02 	 Enc : 5.4222e-06 	 AEnc : 1.8377e-05 	 MSE : 9.1413e-03
Epoch 684, 50% 	 Loss : 1.5807e-02 	 Res : 3.0651e-03 	 Jac : 1.2719e-02 	 Enc : 5.6705e-06 	 AEnc : 1.7501e-05 	 MSE : 3.2874e-02
Epoch 684, 75% 	 Loss : 1.5584e-02 	 Res : 2.8512e-03 	 Jac : 1.2710e-02 	 Enc : 5.5289e-06 	 AEnc : 1.7582e-05 	 MSE : 8.7985e-03
Training Epoch 684 : 	 Train : 1.56186e-02 	 Res : 2.91243e-03 	 Jac : 1.26827e-02 	 Enc : 5.55152e-06 	 AE : 1.78955e-05 	 MSE : 1.72498e-02
Validation Epoch 684 : 	 Train : 1.57325e-02 	 Res : 2.90231e-03 	 Jac : 1.28072e-02 	 Enc : 5.51787e-06 	 AE : 1.74574e-05 	 MSE : 8.74972e-03
Training Epoch 684 finished, took current epoch 358.95s, cumulative time 251844.35s
Current Learning rate DEQ : 4.355614296588023e-07
Current Learning rate AUTOENC : 2.1778071482940113e-06
MODEL SAVED
Epoch 685, 25% 	 Loss : 1.5671e-02 	 Res : 2.9404e-03 	 Jac : 1.2707e-02 	 Enc : 5.6177e-06 	 AEnc : 1.7895e-05 	 MSE : 9.3027e-03
Epoch 685, 50% 	 Loss : 1.5586e-02 	 Res : 2.8418e-03 	 Jac : 1.2720e-02 	 Enc : 5.5253e-06 	 AEnc : 1.7889e-05 	 MSE : 9.7077e-03
Epoch 685, 75% 	 Loss : 1.5571e-02 	 Res : 2.8505e-03 	 Jac : 1.2697e-02 	 Enc : 5.5773e-06 	 AEnc : 1.8048e-05 	 MSE : 8.9726e-03
Training Epoch 685 : 	 Train : 1.56010e-02 	 Res : 2.87047e-03 	 Jac : 1.27069e-02 	 Enc : 5.55308e-06 	 AE : 1.80296e-05 	 MSE : 9.34298e-03
Validation Epoch 685 : 	 Train : 1.56338e-02 	 Res : 2.90235e-03 	 Jac : 1.27078e-02 	 Enc : 5.51849e-06 	 AE : 1.81712e-05 	 MSE : 8.68290e-03
Training Epoch 685 finished, took current epoch 362.57s, cumulative time 252206.91s
Current Learning rate DEQ : 4.355614296588023e-07
Current Learning rate AUTOENC : 2.1778071482940113e-06
Epoch 686, 25% 	 Loss : 1.5658e-02 	 Res : 2.8836e-03 	 Jac : 1.2751e-02 	 Enc : 5.6280e-06 	 AEnc : 1.7838e-05 	 MSE : 9.4517e-03
Epoch 686, 50% 	 Loss : 1.5670e-02 	 Res : 2.9088e-03 	 Jac : 1.2738e-02 	 Enc : 5.4418e-06 	 AEnc : 1.8392e-05 	 MSE : 9.2132e-03
Epoch 686, 75% 	 Loss : 1.5556e-02 	 Res : 2.8568e-03 	 Jac : 1.2675e-02 	 Enc : 5.6128e-06 	 AEnc : 1.8553e-05 	 MSE : 9.0257e-03
Training Epoch 686 : 	 Train : 1.56079e-02 	 Res : 2.87038e-03 	 Jac : 1.27138e-02 	 Enc : 5.56380e-06 	 AE : 1.81887e-05 	 MSE : 9.15632e-03
Validation Epoch 686 : 	 Train : 1.55788e-02 	 Res : 2.90266e-03 	 Jac : 1.26534e-02 	 Enc : 5.52646e-06 	 AE : 1.72326e-05 	 MSE : 8.67069e-03
Training Epoch 686 finished, took current epoch 362.39s, cumulative time 252569.28s
Current Learning rate DEQ : 4.355614296588023e-07
Current Learning rate AUTOENC : 2.1778071482940113e-06
Epoch 687, 25% 	 Loss : 1.5523e-02 	 Res : 2.8593e-03 	 Jac : 1.2640e-02 	 Enc : 5.6624e-06 	 AEnc : 1.8075e-05 	 MSE : 9.0306e-03
Epoch 687, 50% 	 Loss : 1.5528e-02 	 Res : 2.8486e-03 	 Jac : 1.2656e-02 	 Enc : 5.5506e-06 	 AEnc : 1.7665e-05 	 MSE : 8.8392e-03
Epoch 687, 75% 	 Loss : 1.5510e-02 	 Res : 2.8646e-03 	 Jac : 1.2622e-02 	 Enc : 5.4793e-06 	 AEnc : 1.7869e-05 	 MSE : 8.7789e-03
Training Epoch 687 : 	 Train : 1.55427e-02 	 Res : 2.87011e-03 	 Jac : 1.26490e-02 	 Enc : 5.55400e-06 	 AE : 1.79979e-05 	 MSE : 8.88093e-03
Validation Epoch 687 : 	 Train : 1.57133e-02 	 Res : 3.01077e-03 	 Jac : 1.26801e-02 	 Enc : 5.51062e-06 	 AE : 1.69433e-05 	 MSE : 4.15381e-02
Training Epoch 687 finished, took current epoch 361.74s, cumulative time 252930.97s
Current Learning rate DEQ : 4.355614296588023e-07
Current Learning rate AUTOENC : 2.1778071482940113e-06
Epoch 688, 25% 	 Loss : 1.5674e-02 	 Res : 2.8916e-03 	 Jac : 1.2759e-02 	 Enc : 5.6130e-06 	 AEnc : 1.7753e-05 	 MSE : 8.6748e-03
Epoch 688, 50% 	 Loss : 1.5945e-02 	 Res : 3.2623e-03 	 Jac : 1.2659e-02 	 Enc : 5.5002e-06 	 AEnc : 1.7532e-05 	 MSE : 1.8850e-01
Epoch 688, 75% 	 Loss : 1.5660e-02 	 Res : 2.8890e-03 	 Jac : 1.2748e-02 	 Enc : 5.6018e-06 	 AEnc : 1.7878e-05 	 MSE : 8.9640e-03
Training Epoch 688 : 	 Train : 1.57075e-02 	 Res : 2.98029e-03 	 Jac : 1.27038e-02 	 Enc : 5.54905e-06 	 AE : 1.79269e-05 	 MSE : 5.37719e-02
Validation Epoch 688 : 	 Train : 1.56680e-02 	 Res : 2.90255e-03 	 Jac : 1.27420e-02 	 Enc : 5.51737e-06 	 AE : 1.79151e-05 	 MSE : 8.57431e-03
Training Epoch 688 finished, took current epoch 361.68s, cumulative time 253292.64s
Current Learning rate DEQ : 4.355614296588023e-07
Current Learning rate AUTOENC : 2.1778071482940113e-06
Epoch 689, 25% 	 Loss : 1.5585e-02 	 Res : 2.8268e-03 	 Jac : 1.2735e-02 	 Enc : 5.5648e-06 	 AEnc : 1.7827e-05 	 MSE : 8.9668e-03
Epoch 689, 50% 	 Loss : 1.5597e-02 	 Res : 2.9119e-03 	 Jac : 1.2662e-02 	 Enc : 5.6504e-06 	 AEnc : 1.7989e-05 	 MSE : 9.2760e-03
Epoch 689, 75% 	 Loss : 1.5651e-02 	 Res : 2.9133e-03 	 Jac : 1.2714e-02 	 Enc : 5.4787e-06 	 AEnc : 1.8228e-05 	 MSE : 9.1025e-03
Training Epoch 689 : 	 Train : 1.55998e-02 	 Res : 2.87090e-03 	 Jac : 1.27053e-02 	 Enc : 5.55754e-06 	 AE : 1.80561e-05 	 MSE : 9.26997e-03
Validation Epoch 689 : 	 Train : 1.57311e-02 	 Res : 2.90295e-03 	 Jac : 1.28040e-02 	 Enc : 5.52354e-06 	 AE : 1.86158e-05 	 MSE : 8.57978e-03
Training Epoch 689 finished, took current epoch 360.55s, cumulative time 253653.12s
Current Learning rate DEQ : 4.355614296588023e-07
Current Learning rate AUTOENC : 2.1778071482940113e-06
Epoch 690, 25% 	 Loss : 1.5611e-02 	 Res : 2.8524e-03 	 Jac : 1.2735e-02 	 Enc : 5.5809e-06 	 AEnc : 1.8095e-05 	 MSE : 9.4734e-03
Epoch 690, 50% 	 Loss : 1.5680e-02 	 Res : 2.8911e-03 	 Jac : 1.2766e-02 	 Enc : 5.5572e-06 	 AEnc : 1.7868e-05 	 MSE : 9.2144e-03
Epoch 690, 75% 	 Loss : 1.5635e-02 	 Res : 2.8600e-03 	 Jac : 1.2751e-02 	 Enc : 5.6071e-06 	 AEnc : 1.7982e-05 	 MSE : 8.7354e-03
Training Epoch 690 : 	 Train : 1.56414e-02 	 Res : 2.87003e-03 	 Jac : 1.27478e-02 	 Enc : 5.56603e-06 	 AE : 1.80390e-05 	 MSE : 9.19409e-03
Validation Epoch 690 : 	 Train : 1.56199e-02 	 Res : 2.90218e-03 	 Jac : 1.26940e-02 	 Enc : 5.51632e-06 	 AE : 1.81128e-05 	 MSE : 8.53182e-03
Training Epoch 690 finished, took current epoch 361.68s, cumulative time 254014.73s
Current Learning rate DEQ : 4.355614296588023e-07
Current Learning rate AUTOENC : 2.1778071482940113e-06
MODEL SAVED
Epoch 691, 25% 	 Loss : 1.5609e-02 	 Res : 2.8855e-03 	 Jac : 1.2700e-02 	 Enc : 5.5553e-06 	 AEnc : 1.7664e-05 	 MSE : 9.1986e-03
Epoch 691, 50% 	 Loss : 1.5617e-02 	 Res : 2.8766e-03 	 Jac : 1.2717e-02 	 Enc : 5.5695e-06 	 AEnc : 1.7976e-05 	 MSE : 9.2896e-03
Epoch 691, 75% 	 Loss : 1.5555e-02 	 Res : 2.8805e-03 	 Jac : 1.2650e-02 	 Enc : 5.5659e-06 	 AEnc : 1.8495e-05 	 MSE : 9.2528e-03
Training Epoch 691 : 	 Train : 1.56033e-02 	 Res : 2.86973e-03 	 Jac : 1.27100e-02 	 Enc : 5.55078e-06 	 AE : 1.79566e-05 	 MSE : 9.12264e-03
Validation Epoch 691 : 	 Train : 1.56309e-02 	 Res : 2.90277e-03 	 Jac : 1.27053e-02 	 Enc : 5.51528e-06 	 AE : 1.72769e-05 	 MSE : 8.56380e-03
Training Epoch 691 finished, took current epoch 361.97s, cumulative time 254376.67s
Current Learning rate DEQ : 4.355614296588023e-07
Current Learning rate AUTOENC : 2.1778071482940113e-06
Epoch 692, 25% 	 Loss : 1.5577e-02 	 Res : 2.8506e-03 	 Jac : 1.2703e-02 	 Enc : 5.4323e-06 	 AEnc : 1.7941e-05 	 MSE : 8.7443e-03
Epoch 692, 50% 	 Loss : 1.5574e-02 	 Res : 2.8434e-03 	 Jac : 1.2707e-02 	 Enc : 5.7035e-06 	 AEnc : 1.7839e-05 	 MSE : 8.9473e-03
Epoch 692, 75% 	 Loss : 1.5661e-02 	 Res : 2.8761e-03 	 Jac : 1.2761e-02 	 Enc : 5.4883e-06 	 AEnc : 1.8095e-05 	 MSE : 9.1407e-03
Training Epoch 692 : 	 Train : 1.56264e-02 	 Res : 2.86985e-03 	 Jac : 1.27331e-02 	 Enc : 5.53219e-06 	 AE : 1.78623e-05 	 MSE : 9.04497e-03
Validation Epoch 692 : 	 Train : 1.55910e-02 	 Res : 2.90295e-03 	 Jac : 1.26648e-02 	 Enc : 5.49036e-06 	 AE : 1.77582e-05 	 MSE : 8.52625e-03
Training Epoch 692 finished, took current epoch 359.62s, cumulative time 254736.23s
Current Learning rate DEQ : 4.355614296588023e-07
Current Learning rate AUTOENC : 2.1778071482940113e-06
Epoch 693, 25% 	 Loss : 1.5643e-02 	 Res : 2.8775e-03 	 Jac : 1.2741e-02 	 Enc : 5.4963e-06 	 AEnc : 1.8208e-05 	 MSE : 8.6332e-03
Epoch 693, 50% 	 Loss : 1.5629e-02 	 Res : 2.8629e-03 	 Jac : 1.2743e-02 	 Enc : 5.4349e-06 	 AEnc : 1.7957e-05 	 MSE : 9.1075e-03
Epoch 693, 75% 	 Loss : 1.5530e-02 	 Res : 2.8681e-03 	 Jac : 1.2639e-02 	 Enc : 5.7347e-06 	 AEnc : 1.7296e-05 	 MSE : 8.9896e-03
Training Epoch 693 : 	 Train : 1.56133e-02 	 Res : 2.87000e-03 	 Jac : 1.27198e-02 	 Enc : 5.55452e-06 	 AE : 1.79482e-05 	 MSE : 8.91620e-03
Validation Epoch 693 : 	 Train : 1.56671e-02 	 Res : 2.90305e-03 	 Jac : 1.27406e-02 	 Enc : 5.52140e-06 	 AE : 1.79249e-05 	 MSE : 8.67550e-03
Training Epoch 693 finished, took current epoch 362.75s, cumulative time 255098.97s
Current Learning rate DEQ : 4.355614296588023e-07
Current Learning rate AUTOENC : 2.1778071482940113e-06
Epoch 694, 25% 	 Loss : 1.5621e-02 	 Res : 2.8503e-03 	 Jac : 1.2747e-02 	 Enc : 5.6535e-06 	 AEnc : 1.7754e-05 	 MSE : 8.7759e-03
Epoch 694, 50% 	 Loss : 1.5662e-02 	 Res : 2.8732e-03 	 Jac : 1.2765e-02 	 Enc : 5.5472e-06 	 AEnc : 1.8375e-05 	 MSE : 8.7790e-03
Epoch 694, 75% 	 Loss : 1.5628e-02 	 Res : 2.8884e-03 	 Jac : 1.2716e-02 	 Enc : 5.4912e-06 	 AEnc : 1.7702e-05 	 MSE : 9.0125e-03
Training Epoch 694 : 	 Train : 1.56328e-02 	 Res : 2.87015e-03 	 Jac : 1.27391e-02 	 Enc : 5.55918e-06 	 AE : 1.80171e-05 	 MSE : 9.09499e-03
Validation Epoch 694 : 	 Train : 1.56488e-02 	 Res : 2.90350e-03 	 Jac : 1.27211e-02 	 Enc : 5.51512e-06 	 AE : 1.86609e-05 	 MSE : 8.81854e-03
Training Epoch 694 finished, took current epoch 361.59s, cumulative time 255460.54s
Current Learning rate DEQ : 3.484491437270418e-07
Current Learning rate AUTOENC : 1.7422457186352091e-06
Epoch 695, 25% 	 Loss : 1.5589e-02 	 Res : 2.8760e-03 	 Jac : 1.2690e-02 	 Enc : 5.6294e-06 	 AEnc : 1.7977e-05 	 MSE : 8.8849e-03
Epoch 695, 50% 	 Loss : 1.5650e-02 	 Res : 2.8888e-03 	 Jac : 1.2738e-02 	 Enc : 5.6612e-06 	 AEnc : 1.8419e-05 	 MSE : 9.2591e-03
Epoch 695, 75% 	 Loss : 1.5525e-02 	 Res : 2.8257e-03 	 Jac : 1.2675e-02 	 Enc : 5.3289e-06 	 AEnc : 1.8298e-05 	 MSE : 9.1350e-03
Training Epoch 695 : 	 Train : 1.55846e-02 	 Res : 2.86967e-03 	 Jac : 1.26913e-02 	 Enc : 5.55680e-06 	 AE : 1.80267e-05 	 MSE : 9.01505e-03
Validation Epoch 695 : 	 Train : 1.55884e-02 	 Res : 2.90281e-03 	 Jac : 1.26627e-02 	 Enc : 5.52175e-06 	 AE : 1.73798e-05 	 MSE : 8.72096e-03
Training Epoch 695 finished, took current epoch 357.75s, cumulative time 255818.24s
Current Learning rate DEQ : 3.484491437270418e-07
Current Learning rate AUTOENC : 1.7422457186352091e-06
Epoch 696, 25% 	 Loss : 1.5556e-02 	 Res : 2.8317e-03 	 Jac : 1.2701e-02 	 Enc : 5.6493e-06 	 AEnc : 1.7179e-05 	 MSE : 8.6730e-03
Epoch 696, 50% 	 Loss : 1.5551e-02 	 Res : 2.8325e-03 	 Jac : 1.2695e-02 	 Enc : 5.5520e-06 	 AEnc : 1.7724e-05 	 MSE : 9.1809e-03
Epoch 696, 75% 	 Loss : 1.5639e-02 	 Res : 2.9288e-03 	 Jac : 1.2687e-02 	 Enc : 5.5069e-06 	 AEnc : 1.8110e-05 	 MSE : 9.6597e-03
Training Epoch 696 : 	 Train : 1.55838e-02 	 Res : 2.86998e-03 	 Jac : 1.26905e-02 	 Enc : 5.56631e-06 	 AE : 1.77545e-05 	 MSE : 9.09537e-03
Validation Epoch 696 : 	 Train : 1.56395e-02 	 Res : 2.90222e-03 	 Jac : 1.27150e-02 	 Enc : 5.53531e-06 	 AE : 1.67753e-05 	 MSE : 8.59229e-03
Training Epoch 696 finished, took current epoch 363.10s, cumulative time 256181.32s
Current Learning rate DEQ : 3.484491437270418e-07
Current Learning rate AUTOENC : 1.7422457186352091e-06
Epoch 697, 25% 	 Loss : 1.5520e-02 	 Res : 2.8172e-03 	 Jac : 1.2680e-02 	 Enc : 5.6332e-06 	 AEnc : 1.7632e-05 	 MSE : 8.7746e-03
Epoch 697, 50% 	 Loss : 1.5612e-02 	 Res : 2.8680e-03 	 Jac : 1.2721e-02 	 Enc : 5.4684e-06 	 AEnc : 1.7839e-05 	 MSE : 9.6084e-03
Epoch 697, 75% 	 Loss : 1.5627e-02 	 Res : 2.9390e-03 	 Jac : 1.2664e-02 	 Enc : 5.5109e-06 	 AEnc : 1.8205e-05 	 MSE : 8.7057e-03
Training Epoch 697 : 	 Train : 1.55833e-02 	 Res : 2.86980e-03 	 Jac : 1.26901e-02 	 Enc : 5.55153e-06 	 AE : 1.78988e-05 	 MSE : 8.97532e-03
Validation Epoch 697 : 	 Train : 1.55786e-02 	 Res : 2.90375e-03 	 Jac : 1.26520e-02 	 Enc : 5.50803e-06 	 AE : 1.72934e-05 	 MSE : 8.48987e-03
Training Epoch 697 finished, took current epoch 362.79s, cumulative time 256544.06s
Current Learning rate DEQ : 3.484491437270418e-07
Current Learning rate AUTOENC : 1.7422457186352091e-06
Epoch 698, 25% 	 Loss : 1.5685e-02 	 Res : 2.9484e-03 	 Jac : 1.2714e-02 	 Enc : 5.6370e-06 	 AEnc : 1.7759e-05 	 MSE : 8.7675e-03
Epoch 698, 50% 	 Loss : 1.5631e-02 	 Res : 2.8523e-03 	 Jac : 1.2756e-02 	 Enc : 5.4331e-06 	 AEnc : 1.7926e-05 	 MSE : 2.2402e-02
Epoch 698, 75% 	 Loss : 1.5574e-02 	 Res : 2.8687e-03 	 Jac : 1.2682e-02 	 Enc : 5.5760e-06 	 AEnc : 1.7952e-05 	 MSE : 8.9861e-03
Training Epoch 698 : 	 Train : 1.56036e-02 	 Res : 2.88502e-03 	 Jac : 1.26951e-02 	 Enc : 5.53569e-06 	 AE : 1.79474e-05 	 MSE : 1.21549e-02
Validation Epoch 698 : 	 Train : 1.57126e-02 	 Res : 2.90244e-03 	 Jac : 1.27865e-02 	 Enc : 5.49926e-06 	 AE : 1.81635e-05 	 MSE : 8.37819e-03
Training Epoch 698 finished, took current epoch 360.76s, cumulative time 256904.78s
Current Learning rate DEQ : 3.484491437270418e-07
Current Learning rate AUTOENC : 1.7422457186352091e-06
Epoch 699, 25% 	 Loss : 1.5605e-02 	 Res : 2.8717e-03 	 Jac : 1.2710e-02 	 Enc : 5.5493e-06 	 AEnc : 1.8111e-05 	 MSE : 9.2955e-03
Epoch 699, 50% 	 Loss : 1.5454e-02 	 Res : 2.8283e-03 	 Jac : 1.2602e-02 	 Enc : 5.3859e-06 	 AEnc : 1.8441e-05 	 MSE : 8.5816e-03
Epoch 699, 75% 	 Loss : 1.5623e-02 	 Res : 2.8567e-03 	 Jac : 1.2743e-02 	 Enc : 5.5384e-06 	 AEnc : 1.7936e-05 	 MSE : 8.9010e-03
Training Epoch 699 : 	 Train : 1.55904e-02 	 Res : 2.86948e-03 	 Jac : 1.26974e-02 	 Enc : 5.52803e-06 	 AE : 1.80412e-05 	 MSE : 8.87385e-03
Validation Epoch 699 : 	 Train : 1.56606e-02 	 Res : 2.90261e-03 	 Jac : 1.27347e-02 	 Enc : 5.49299e-06 	 AE : 1.78000e-05 	 MSE : 8.43703e-03
Training Epoch 699 finished, took current epoch 359.93s, cumulative time 257264.65s
Current Learning rate DEQ : 3.484491437270418e-07
Current Learning rate AUTOENC : 1.7422457186352091e-06