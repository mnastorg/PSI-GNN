Train Metrics
Epoch 0, 25% 	 Loss : 4.8200e+00 	 Res : 3.7218e+00 	 Jac : 9.8467e-02 	 Enc : 6.8557e-01 	 AEnc : 2.6680e-01 	 MSE : 4.7332e+01
Epoch 0, 50% 	 Loss : 2.4474e+00 	 Res : 1.7282e+00 	 Jac : 5.3026e-02 	 Enc : 3.4525e-01 	 AEnc : 2.7823e-01 	 MSE : 4.2728e+01
Epoch 0, 75% 	 Loss : 1.7138e+00 	 Res : 8.4595e-01 	 Jac : 4.0014e-02 	 Enc : 6.2769e-01 	 AEnc : 1.6136e-01 	 MSE : 3.8773e+01
Training Epoch 0 : 	 Train : 2.59310e+00 	 Res : 1.74054e+00 	 Jac : 6.00723e-02 	 Enc : 5.48314e-01 	 AE : 2.02816e-01 	 MSE : 4.13637e+01
Validation Epoch 0 : 	 Train : 1.37492e+00 	 Res : 5.33298e-01 	 Jac : 5.91130e-02 	 Enc : 6.65418e-01 	 AE : 8.13634e-02 	 MSE : 3.57269e+01
Training Epoch 0 finished, took current epoch 371.78s, cumulative time 371.71s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
MODEL SAVED
Epoch 1, 25% 	 Loss : 1.0830e+00 	 Res : 4.5946e-01 	 Jac : 5.7975e-02 	 Enc : 4.6674e-01 	 AEnc : 6.2596e-02 	 MSE : 3.6262e+01
Epoch 1, 50% 	 Loss : 9.6540e-01 	 Res : 4.1106e-01 	 Jac : 6.6737e-02 	 Enc : 4.0486e-01 	 AEnc : 4.7801e-02 	 MSE : 3.4951e+01
Epoch 1, 75% 	 Loss : 8.5199e-01 	 Res : 4.0583e-01 	 Jac : 6.3031e-02 	 Enc : 3.0668e-01 	 AEnc : 4.2624e-02 	 MSE : 3.3821e+01
Training Epoch 1 : 	 Train : 8.93607e-01 	 Res : 3.94026e-01 	 Jac : 6.33377e-02 	 Enc : 3.53991e-01 	 AE : 4.79957e-02 	 MSE : 3.42557e+01
Validation Epoch 1 : 	 Train : 7.96186e-01 	 Res : 4.22905e-01 	 Jac : 6.31941e-02 	 Enc : 1.77734e-01 	 AE : 9.70283e-02 	 MSE : 3.53238e+01
Training Epoch 1 finished, took current epoch 378.05s, cumulative time 749.70s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
MODEL SAVED
Epoch 2, 25% 	 Loss : 6.3303e-01 	 Res : 3.1576e-01 	 Jac : 6.6556e-02 	 Enc : 1.8448e-01 	 AEnc : 3.3182e-02 	 MSE : 3.3058e+01
Epoch 2, 50% 	 Loss : 7.0952e-01 	 Res : 3.6694e-01 	 Jac : 6.3514e-02 	 Enc : 1.9199e-01 	 AEnc : 5.2046e-02 	 MSE : 3.5032e+01
Epoch 2, 75% 	 Loss : 6.1618e-01 	 Res : 3.4921e-01 	 Jac : 4.5986e-02 	 Enc : 1.3678e-01 	 AEnc : 5.0106e-02 	 MSE : 3.4098e+01
Training Epoch 2 : 	 Train : 6.30999e-01 	 Res : 3.29440e-01 	 Jac : 5.70228e-02 	 Enc : 1.63308e-01 	 AE : 4.71833e-02 	 MSE : 3.40449e+01
Validation Epoch 2 : 	 Train : 7.37793e-01 	 Res : 4.76617e-01 	 Jac : 4.75119e-02 	 Enc : 1.37653e-01 	 AE : 3.81114e-02 	 MSE : 3.78998e+01
Training Epoch 2 finished, took current epoch 355.83s, cumulative time 1105.52s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 3, 25% 	 Loss : 5.8186e-01 	 Res : 2.8915e-01 	 Jac : 4.9725e-02 	 Enc : 1.3152e-01 	 AEnc : 7.7359e-02 	 MSE : 3.4115e+01
Epoch 3, 50% 	 Loss : 4.7454e-01 	 Res : 2.0400e-01 	 Jac : 5.1561e-02 	 Enc : 1.2862e-01 	 AEnc : 5.9182e-02 	 MSE : 3.1177e+01
Epoch 3, 75% 	 Loss : 6.1005e-01 	 Res : 3.5133e-01 	 Jac : 4.7229e-02 	 Enc : 1.2774e-01 	 AEnc : 4.7564e-02 	 MSE : 3.6183e+01
Training Epoch 3 : 	 Train : 5.24127e-01 	 Res : 2.52480e-01 	 Jac : 5.02259e-02 	 Enc : 1.26344e-01 	 AE : 6.25604e-02 	 MSE : 3.25175e+01
Validation Epoch 3 : 	 Train : 4.21878e-01 	 Res : 1.20194e-01 	 Jac : 4.85597e-02 	 Enc : 1.04998e-01 	 AE : 1.24395e-01 	 MSE : 2.37315e+01
Training Epoch 3 finished, took current epoch 359.53s, cumulative time 1465.03s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
MODEL SAVED
Epoch 4, 25% 	 Loss : 5.8888e-01 	 Res : 2.9586e-01 	 Jac : 4.6026e-02 	 Enc : 1.1567e-01 	 AEnc : 9.6173e-02 	 MSE : 3.5150e+01
Epoch 4, 50% 	 Loss : 5.2006e-01 	 Res : 2.5838e-01 	 Jac : 4.9054e-02 	 Enc : 1.1215e-01 	 AEnc : 6.7333e-02 	 MSE : 3.3145e+01
Epoch 4, 75% 	 Loss : 4.5081e-01 	 Res : 2.0649e-01 	 Jac : 4.7550e-02 	 Enc : 1.0659e-01 	 AEnc : 6.0704e-02 	 MSE : 2.9468e+01
Training Epoch 4 : 	 Train : 5.31008e-01 	 Res : 2.65950e-01 	 Jac : 4.90881e-02 	 Enc : 1.12345e-01 	 AE : 7.05827e-02 	 MSE : 3.30421e+01
Validation Epoch 4 : 	 Train : 5.95606e-01 	 Res : 2.93241e-01 	 Jac : 4.90347e-02 	 Enc : 1.13750e-01 	 AE : 1.18138e-01 	 MSE : 2.14437e+01
Training Epoch 4 finished, took current epoch 365.21s, cumulative time 1830.22s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 5, 25% 	 Loss : 4.8346e-01 	 Res : 1.8999e-01 	 Jac : 4.1853e-02 	 Enc : 1.0669e-01 	 AEnc : 1.1497e-01 	 MSE : 2.9960e+01
Epoch 5, 50% 	 Loss : 3.8820e-01 	 Res : 1.6150e-01 	 Jac : 4.9929e-02 	 Enc : 1.0004e-01 	 AEnc : 4.9189e-02 	 MSE : 2.7547e+01
Epoch 5, 75% 	 Loss : 4.6712e-01 	 Res : 2.1382e-01 	 Jac : 4.3670e-02 	 Enc : 9.2841e-02 	 AEnc : 8.5639e-02 	 MSE : 3.1154e+01
Training Epoch 5 : 	 Train : 4.81285e-01 	 Res : 2.30987e-01 	 Jac : 4.54631e-02 	 Enc : 1.00147e-01 	 AE : 7.26811e-02 	 MSE : 3.20075e+01
Validation Epoch 5 : 	 Train : 3.90508e-01 	 Res : 1.98744e-01 	 Jac : 4.28136e-02 	 Enc : 9.73049e-02 	 AE : 1.46806e-02 	 MSE : 3.69648e+01
Training Epoch 5 finished, took current epoch 357.80s, cumulative time 2188.00s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 6, 25% 	 Loss : 3.4018e-01 	 Res : 1.4092e-01 	 Jac : 4.5284e-02 	 Enc : 9.5910e-02 	 AEnc : 2.7976e-02 	 MSE : 3.0096e+01
Epoch 6, 50% 	 Loss : 4.1221e-01 	 Res : 2.1953e-01 	 Jac : 4.4610e-02 	 Enc : 9.3817e-02 	 AEnc : 2.2336e-02 	 MSE : 3.1920e+01
Epoch 6, 75% 	 Loss : 5.0448e-01 	 Res : 2.8875e-01 	 Jac : 4.1180e-02 	 Enc : 9.4878e-02 	 AEnc : 4.3302e-02 	 MSE : 3.6370e+01
Training Epoch 6 : 	 Train : 4.39859e-01 	 Res : 2.33903e-01 	 Jac : 4.44004e-02 	 Enc : 9.51030e-02 	 AE : 3.22521e-02 	 MSE : 3.42007e+01
Validation Epoch 6 : 	 Train : 5.43288e-01 	 Res : 3.58174e-01 	 Jac : 4.33469e-02 	 Enc : 8.79972e-02 	 AE : 9.02634e-03 	 MSE : 4.47440e+01
Training Epoch 6 finished, took current epoch 355.03s, cumulative time 2543.01s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 7, 25% 	 Loss : 6.1175e-01 	 Res : 3.3598e-01 	 Jac : 4.5574e-02 	 Enc : 9.3748e-02 	 AEnc : 9.9226e-02 	 MSE : 3.7221e+01
Epoch 7, 50% 	 Loss : 4.6658e-01 	 Res : 2.6348e-01 	 Jac : 5.0440e-02 	 Enc : 9.1695e-02 	 AEnc : 2.5114e-02 	 MSE : 3.5856e+01
Epoch 7, 75% 	 Loss : 5.6798e-01 	 Res : 2.3663e-01 	 Jac : 5.4498e-02 	 Enc : 9.2157e-02 	 AEnc : 1.5392e-01 	 MSE : 3.0777e+01
Training Epoch 7 : 	 Train : 5.23307e-01 	 Res : 2.60758e-01 	 Jac : 5.08926e-02 	 Enc : 9.11098e-02 	 AE : 8.67561e-02 	 MSE : 3.37906e+01
Validation Epoch 7 : 	 Train : 3.69756e-01 	 Res : 1.51360e-01 	 Jac : 5.88718e-02 	 Enc : 8.44728e-02 	 AE : 4.86986e-02 	 MSE : 2.63518e+01
Training Epoch 7 finished, took current epoch 371.13s, cumulative time 2914.10s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 8, 25% 	 Loss : 3.9866e-01 	 Res : 1.9190e-01 	 Jac : 4.6756e-02 	 Enc : 8.3508e-02 	 AEnc : 4.4946e-02 	 MSE : 3.1551e+01
Epoch 8, 50% 	 Loss : 4.2942e-01 	 Res : 2.1292e-01 	 Jac : 5.2037e-02 	 Enc : 8.6482e-02 	 AEnc : 4.2976e-02 	 MSE : 3.5008e+01
Epoch 8, 75% 	 Loss : 4.9716e-01 	 Res : 2.3283e-01 	 Jac : 5.9093e-02 	 Enc : 8.0563e-02 	 AEnc : 9.4515e-02 	 MSE : 3.0160e+01
Training Epoch 8 : 	 Train : 4.53199e-01 	 Res : 2.10662e-01 	 Jac : 5.14998e-02 	 Enc : 8.33112e-02 	 AE : 7.51784e-02 	 MSE : 3.25474e+01
Validation Epoch 8 : 	 Train : 6.47735e-01 	 Res : 3.74538e-01 	 Jac : 5.57843e-02 	 Enc : 9.09402e-02 	 AE : 8.97885e-02 	 MSE : 3.66845e+01
Training Epoch 8 finished, took current epoch 378.19s, cumulative time 3292.26s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 9, 25% 	 Loss : 3.9650e-01 	 Res : 1.8676e-01 	 Jac : 5.2241e-02 	 Enc : 8.0756e-02 	 AEnc : 5.0367e-02 	 MSE : 2.6372e+01
Epoch 9, 50% 	 Loss : 3.4930e-01 	 Res : 1.5012e-01 	 Jac : 4.4397e-02 	 Enc : 7.9358e-02 	 AEnc : 4.7681e-02 	 MSE : 2.7739e+01
Epoch 9, 75% 	 Loss : 5.2116e-01 	 Res : 1.8389e-01 	 Jac : 4.9244e-02 	 Enc : 7.9745e-02 	 AEnc : 1.7983e-01 	 MSE : 2.8460e+01
Training Epoch 9 : 	 Train : 4.46750e-01 	 Res : 1.77974e-01 	 Jac : 4.80023e-02 	 Enc : 7.98340e-02 	 AE : 1.13269e-01 	 MSE : 2.76707e+01
Validation Epoch 9 : 	 Train : 5.33252e-01 	 Res : 1.88772e-01 	 Jac : 4.99779e-02 	 Enc : 7.70490e-02 	 AE : 1.91655e-01 	 MSE : 2.57982e+01
Training Epoch 9 finished, took current epoch 372.65s, cumulative time 3664.89s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 10, 25% 	 Loss : 5.9994e-01 	 Res : 3.0604e-01 	 Jac : 5.2409e-02 	 Enc : 8.1706e-02 	 AEnc : 1.2586e-01 	 MSE : 3.3917e+01
Epoch 10, 50% 	 Loss : 3.7051e-01 	 Res : 1.6553e-01 	 Jac : 5.0920e-02 	 Enc : 7.2996e-02 	 AEnc : 5.5327e-02 	 MSE : 2.5730e+01
Epoch 10, 75% 	 Loss : 3.5081e-01 	 Res : 1.7907e-01 	 Jac : 5.0712e-02 	 Enc : 7.2234e-02 	 AEnc : 1.9153e-02 	 MSE : 2.9637e+01
Training Epoch 10 : 	 Train : 4.17238e-01 	 Res : 2.03495e-01 	 Jac : 5.14308e-02 	 Enc : 7.46661e-02 	 AE : 5.83086e-02 	 MSE : 2.93376e+01
Validation Epoch 10 : 	 Train : 3.18181e-01 	 Res : 1.55179e-01 	 Jac : 4.37923e-02 	 Enc : 6.65830e-02 	 AE : 2.88239e-02 	 MSE : 2.38025e+01
Training Epoch 10 finished, took current epoch 385.13s, cumulative time 4049.99s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 11, 25% 	 Loss : 3.7828e-01 	 Res : 1.7736e-01 	 Jac : 5.5616e-02 	 Enc : 6.8878e-02 	 AEnc : 4.9264e-02 	 MSE : 2.7169e+01
Epoch 11, 50% 	 Loss : 3.5903e-01 	 Res : 1.8164e-01 	 Jac : 4.9324e-02 	 Enc : 6.7034e-02 	 AEnc : 2.9525e-02 	 MSE : 3.1507e+01
Epoch 11, 75% 	 Loss : 4.6079e-01 	 Res : 2.4208e-01 	 Jac : 6.0456e-02 	 Enc : 7.4356e-02 	 AEnc : 5.3118e-02 	 MSE : 3.0777e+01
Training Epoch 11 : 	 Train : 3.98421e-01 	 Res : 1.83169e-01 	 Jac : 5.37877e-02 	 Enc : 7.01002e-02 	 AE : 6.22602e-02 	 MSE : 2.91044e+01
Validation Epoch 11 : 	 Train : 2.84316e-01 	 Res : 8.14216e-02 	 Jac : 4.21902e-02 	 Enc : 6.47732e-02 	 AE : 7.18849e-02 	 MSE : 2.40465e+01
Training Epoch 11 finished, took current epoch 387.29s, cumulative time 4437.22s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
MODEL SAVED
Epoch 12, 25% 	 Loss : 3.6884e-01 	 Res : 2.0025e-01 	 Jac : 5.0336e-02 	 Enc : 6.5703e-02 	 AEnc : 1.9880e-02 	 MSE : 3.2672e+01
Epoch 12, 50% 	 Loss : 3.8069e-01 	 Res : 2.1443e-01 	 Jac : 4.1574e-02 	 Enc : 7.0972e-02 	 AEnc : 2.1130e-02 	 MSE : 3.2584e+01
Epoch 12, 75% 	 Loss : 6.0790e-01 	 Res : 3.4248e-01 	 Jac : 6.6454e-02 	 Enc : 6.7919e-02 	 AEnc : 9.3364e-02 	 MSE : 3.7679e+01
Training Epoch 12 : 	 Train : 4.65202e-01 	 Res : 2.39540e-01 	 Jac : 5.53315e-02 	 Enc : 6.70256e-02 	 AE : 7.10769e-02 	 MSE : 3.22276e+01
Validation Epoch 12 : 	 Train : 4.41578e-01 	 Res : 1.60415e-01 	 Jac : 3.80453e-02 	 Enc : 5.54429e-02 	 AE : 1.53286e-01 	 MSE : 3.43889e+01
Training Epoch 12 finished, took current epoch 379.21s, cumulative time 4816.41s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 13, 25% 	 Loss : 4.6475e-01 	 Res : 2.0392e-01 	 Jac : 5.5522e-02 	 Enc : 6.8259e-02 	 AEnc : 1.0579e-01 	 MSE : 3.1267e+01
Epoch 13, 50% 	 Loss : 3.3985e-01 	 Res : 1.4307e-01 	 Jac : 6.8713e-02 	 Enc : 6.2830e-02 	 AEnc : 3.8462e-02 	 MSE : 2.6770e+01
Epoch 13, 75% 	 Loss : 3.6679e-01 	 Res : 1.9275e-01 	 Jac : 5.6423e-02 	 Enc : 6.0554e-02 	 AEnc : 2.4878e-02 	 MSE : 3.2183e+01
Training Epoch 13 : 	 Train : 3.70829e-01 	 Res : 1.71850e-01 	 Jac : 5.84970e-02 	 Enc : 6.36319e-02 	 AE : 4.64246e-02 	 MSE : 3.04248e+01
Validation Epoch 13 : 	 Train : 5.02235e-01 	 Res : 3.47025e-01 	 Jac : 5.67563e-02 	 Enc : 6.16524e-02 	 AE : 2.64425e-03 	 MSE : 3.41574e+01
Training Epoch 13 finished, took current epoch 400.99s, cumulative time 5217.39s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 14, 25% 	 Loss : 4.2000e-01 	 Res : 2.1510e-01 	 Jac : 5.4776e-02 	 Enc : 5.7220e-02 	 AEnc : 6.3385e-02 	 MSE : 2.9520e+01
Epoch 14, 50% 	 Loss : 3.6915e-01 	 Res : 1.8977e-01 	 Jac : 5.2557e-02 	 Enc : 5.7153e-02 	 AEnc : 4.1213e-02 	 MSE : 2.8457e+01
Epoch 14, 75% 	 Loss : 5.0129e-01 	 Res : 2.7252e-01 	 Jac : 5.2218e-02 	 Enc : 6.5947e-02 	 AEnc : 7.3401e-02 	 MSE : 3.7199e+01
Training Epoch 14 : 	 Train : 4.28996e-01 	 Res : 2.27745e-01 	 Jac : 5.05277e-02 	 Enc : 5.89433e-02 	 AE : 5.95775e-02 	 MSE : 3.22019e+01
Validation Epoch 14 : 	 Train : 3.23847e-01 	 Res : 1.55164e-01 	 Jac : 4.22231e-02 	 Enc : 4.82364e-02 	 AE : 4.85878e-02 	 MSE : 2.96359e+01
Training Epoch 14 finished, took current epoch 389.66s, cumulative time 5607.01s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 15, 25% 	 Loss : 3.9283e-01 	 Res : 2.2348e-01 	 Jac : 6.1850e-02 	 Enc : 5.1935e-02 	 AEnc : 2.7556e-02 	 MSE : 2.8013e+01
Epoch 15, 50% 	 Loss : 3.9884e-01 	 Res : 2.1691e-01 	 Jac : 5.6137e-02 	 Enc : 4.8032e-02 	 AEnc : 4.4183e-02 	 MSE : 3.3572e+01
Epoch 15, 75% 	 Loss : 3.3879e-01 	 Res : 1.6828e-01 	 Jac : 4.8202e-02 	 Enc : 4.4424e-02 	 AEnc : 4.7083e-02 	 MSE : 3.0804e+01
Training Epoch 15 : 	 Train : 3.86350e-01 	 Res : 2.18382e-01 	 Jac : 5.53207e-02 	 Enc : 4.74494e-02 	 AE : 3.33755e-02 	 MSE : 3.18220e+01
Validation Epoch 15 : 	 Train : 2.68222e-01 	 Res : 1.45322e-01 	 Jac : 5.32816e-02 	 Enc : 4.36727e-02 	 AE : 1.56265e-02 	 MSE : 1.03195e+01
Training Epoch 15 finished, took current epoch 427.69s, cumulative time 6034.65s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 16, 25% 	 Loss : 3.2050e-01 	 Res : 1.8100e-01 	 Jac : 5.4443e-02 	 Enc : 4.3563e-02 	 AEnc : 1.4567e-02 	 MSE : 2.6929e+01
Epoch 16, 50% 	 Loss : 3.5659e-01 	 Res : 1.9471e-01 	 Jac : 5.4717e-02 	 Enc : 3.9549e-02 	 AEnc : 3.8617e-02 	 MSE : 2.8996e+01
Epoch 16, 75% 	 Loss : 3.5285e-01 	 Res : 1.7316e-01 	 Jac : 5.9129e-02 	 Enc : 3.9829e-02 	 AEnc : 5.0711e-02 	 MSE : 3.0024e+01
Training Epoch 16 : 	 Train : 3.83251e-01 	 Res : 1.91990e-01 	 Jac : 5.39734e-02 	 Enc : 4.06938e-02 	 AE : 6.70949e-02 	 MSE : 2.94993e+01
Validation Epoch 16 : 	 Train : 3.58312e-01 	 Res : 1.44781e-01 	 Jac : 3.80332e-02 	 Enc : 3.78284e-02 	 AE : 1.00227e-01 	 MSE : 3.74420e+01
Training Epoch 16 finished, took current epoch 400.35s, cumulative time 6434.96s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 17, 25% 	 Loss : 9.7643e-01 	 Res : 5.9644e-01 	 Jac : 1.1244e-01 	 Enc : 4.3176e-02 	 AEnc : 1.7787e-01 	 MSE : 4.6499e+01
Epoch 17, 50% 	 Loss : 3.8038e-01 	 Res : 1.3430e-01 	 Jac : 4.8475e-02 	 Enc : 4.0058e-02 	 AEnc : 1.3374e-01 	 MSE : 2.3809e+01
Epoch 17, 75% 	 Loss : 4.0736e-01 	 Res : 2.1434e-01 	 Jac : 6.4401e-02 	 Enc : 3.8084e-02 	 AEnc : 5.8918e-02 	 MSE : 3.1616e+01
Training Epoch 17 : 	 Train : 5.28955e-01 	 Res : 2.82391e-01 	 Jac : 6.92942e-02 	 Enc : 3.97717e-02 	 AE : 1.04096e-01 	 MSE : 3.34017e+01
Validation Epoch 17 : 	 Train : 3.07506e-01 	 Res : 1.17889e-01 	 Jac : 3.74453e-02 	 Enc : 3.02707e-02 	 AE : 9.05857e-02 	 MSE : 3.13159e+01
Training Epoch 17 finished, took current epoch 389.14s, cumulative time 6824.08s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 18, 25% 	 Loss : 3.0873e-01 	 Res : 1.2230e-01 	 Jac : 5.6999e-02 	 Enc : 3.3297e-02 	 AEnc : 7.0345e-02 	 MSE : 2.5784e+01
Epoch 18, 50% 	 Loss : 2.7082e-01 	 Res : 1.3333e-01 	 Jac : 4.8025e-02 	 Enc : 3.3477e-02 	 AEnc : 2.7900e-02 	 MSE : 2.8084e+01
Epoch 18, 75% 	 Loss : 2.5103e-01 	 Res : 9.5371e-02 	 Jac : 5.8581e-02 	 Enc : 3.1022e-02 	 AEnc : 4.4336e-02 	 MSE : 2.1717e+01
Training Epoch 18 : 	 Train : 2.85211e-01 	 Res : 1.23525e-01 	 Jac : 5.47744e-02 	 Enc : 3.27352e-02 	 AE : 4.90356e-02 	 MSE : 2.51405e+01
Validation Epoch 18 : 	 Train : 2.19734e-01 	 Res : 1.00312e-01 	 Jac : 3.21252e-02 	 Enc : 3.15764e-02 	 AE : 3.12486e-02 	 MSE : 2.44717e+01
Training Epoch 18 finished, took current epoch 398.19s, cumulative time 7222.23s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 19, 25% 	 Loss : 4.5554e-01 	 Res : 1.2964e-01 	 Jac : 4.8608e-02 	 Enc : 3.4548e-02 	 AEnc : 2.2187e-01 	 MSE : 2.0876e+01
Epoch 19, 50% 	 Loss : 2.3373e-01 	 Res : 8.9078e-02 	 Jac : 5.9936e-02 	 Enc : 3.4058e-02 	 AEnc : 2.7509e-02 	 MSE : 2.3151e+01
Epoch 19, 75% 	 Loss : 2.3819e-01 	 Res : 9.7498e-02 	 Jac : 5.0684e-02 	 Enc : 2.9545e-02 	 AEnc : 4.1992e-02 	 MSE : 1.8471e+01
Training Epoch 19 : 	 Train : 3.13083e-01 	 Res : 1.06428e-01 	 Jac : 5.37677e-02 	 Enc : 3.22565e-02 	 AE : 1.00216e-01 	 MSE : 2.04145e+01
Validation Epoch 19 : 	 Train : 2.74193e-01 	 Res : 1.37905e-01 	 Jac : 3.16943e-02 	 Enc : 2.32795e-02 	 AE : 5.54885e-02 	 MSE : 2.58252e+01
Training Epoch 19 finished, took current epoch 414.84s, cumulative time 7637.05s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 20, 25% 	 Loss : 2.8279e-01 	 Res : 1.2069e-01 	 Jac : 4.8811e-02 	 Enc : 2.9449e-02 	 AEnc : 5.8475e-02 	 MSE : 2.5369e+01
Epoch 20, 50% 	 Loss : 5.1972e-01 	 Res : 1.3771e-01 	 Jac : 5.2284e-02 	 Enc : 3.1010e-02 	 AEnc : 2.7256e-01 	 MSE : 2.6157e+01
Epoch 20, 75% 	 Loss : 3.1187e-01 	 Res : 1.5521e-01 	 Jac : 5.8343e-02 	 Enc : 2.9728e-02 	 AEnc : 4.1891e-02 	 MSE : 2.6698e+01
Training Epoch 20 : 	 Train : 3.23047e-01 	 Res : 1.17950e-01 	 Jac : 5.52875e-02 	 Enc : 2.94493e-02 	 AE : 9.71156e-02 	 MSE : 2.32442e+01
Validation Epoch 20 : 	 Train : 3.74693e-01 	 Res : 1.90428e-01 	 Jac : 1.07707e-01 	 Enc : 2.97809e-02 	 AE : 9.82533e-03 	 MSE : 3.69526e+01
Training Epoch 20 finished, took current epoch 463.49s, cumulative time 8100.53s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 21, 25% 	 Loss : 2.8291e-01 	 Res : 1.1373e-01 	 Jac : 5.7007e-02 	 Enc : 2.7804e-02 	 AEnc : 6.1077e-02 	 MSE : 2.3289e+01
Epoch 21, 50% 	 Loss : 3.3042e-01 	 Res : 1.1077e-01 	 Jac : 4.9060e-02 	 Enc : 2.6287e-02 	 AEnc : 1.2820e-01 	 MSE : 1.6103e+01
Epoch 21, 75% 	 Loss : 5.0304e-01 	 Res : 3.2484e-01 	 Jac : 5.7903e-02 	 Enc : 3.5616e-02 	 AEnc : 5.3663e-02 	 MSE : 3.1016e+01
Training Epoch 21 : 	 Train : 3.42365e-01 	 Res : 1.63349e-01 	 Jac : 5.29096e-02 	 Enc : 2.88352e-02 	 AE : 7.43642e-02 	 MSE : 2.29063e+01
Validation Epoch 21 : 	 Train : 2.43241e-01 	 Res : 1.20466e-01 	 Jac : 4.61449e-02 	 Enc : 2.53708e-02 	 AE : 2.33003e-02 	 MSE : 2.79581e+01
Training Epoch 21 finished, took current epoch 439.95s, cumulative time 8540.48s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 22, 25% 	 Loss : 2.2331e-01 	 Res : 1.0141e-01 	 Jac : 4.7855e-02 	 Enc : 2.4519e-02 	 AEnc : 2.5997e-02 	 MSE : 2.3529e+01
Epoch 22, 50% 	 Loss : 2.5683e-01 	 Res : 1.2054e-01 	 Jac : 6.2298e-02 	 Enc : 2.6209e-02 	 AEnc : 2.5057e-02 	 MSE : 2.2735e+01
Epoch 22, 75% 	 Loss : 2.7094e-01 	 Res : 9.8553e-02 	 Jac : 5.0395e-02 	 Enc : 2.4862e-02 	 AEnc : 7.7078e-02 	 MSE : 2.0053e+01
Training Epoch 22 : 	 Train : 2.32889e-01 	 Res : 9.64275e-02 	 Jac : 5.22305e-02 	 Enc : 2.47326e-02 	 AE : 3.87868e-02 	 MSE : 2.07113e+01
Validation Epoch 22 : 	 Train : 1.46334e-01 	 Res : 5.28282e-02 	 Jac : 4.27335e-02 	 Enc : 2.28174e-02 	 AE : 1.50947e-02 	 MSE : 1.28600e+01
Training Epoch 22 finished, took current epoch 436.74s, cumulative time 8977.15s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
MODEL SAVED
Epoch 23, 25% 	 Loss : 2.8414e-01 	 Res : 1.5499e-01 	 Jac : 5.6333e-02 	 Enc : 2.6037e-02 	 AEnc : 2.0328e-02 	 MSE : 2.6453e+01
Epoch 23, 50% 	 Loss : 2.1136e-01 	 Res : 9.8323e-02 	 Jac : 4.8423e-02 	 Enc : 2.6528e-02 	 AEnc : 1.6503e-02 	 MSE : 2.1583e+01
Epoch 23, 75% 	 Loss : 2.3425e-01 	 Res : 1.0416e-01 	 Jac : 5.0883e-02 	 Enc : 2.3126e-02 	 AEnc : 3.4228e-02 	 MSE : 2.1854e+01
Training Epoch 23 : 	 Train : 2.84103e-01 	 Res : 1.50363e-01 	 Jac : 5.16657e-02 	 Enc : 2.55287e-02 	 AE : 3.00471e-02 	 MSE : 2.64989e+01
Validation Epoch 23 : 	 Train : 2.56818e-01 	 Res : 9.22752e-02 	 Jac : 3.17061e-02 	 Enc : 2.48649e-02 	 AE : 8.37615e-02 	 MSE : 2.42108e+01
Training Epoch 23 finished, took current epoch 429.02s, cumulative time 9406.15s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 24, 25% 	 Loss : 2.9290e-01 	 Res : 1.4471e-01 	 Jac : 4.7694e-02 	 Enc : 2.4841e-02 	 AEnc : 4.5193e-02 	 MSE : 3.0464e+01
Epoch 24, 50% 	 Loss : 2.9139e-01 	 Res : 1.4184e-01 	 Jac : 4.9041e-02 	 Enc : 2.2258e-02 	 AEnc : 4.9468e-02 	 MSE : 2.8784e+01
Epoch 24, 75% 	 Loss : 4.9402e-01 	 Res : 2.5338e-01 	 Jac : 5.5476e-02 	 Enc : 2.4113e-02 	 AEnc : 1.2780e-01 	 MSE : 3.3258e+01
Training Epoch 24 : 	 Train : 3.42486e-01 	 Res : 1.65069e-01 	 Jac : 5.19535e-02 	 Enc : 2.45009e-02 	 AE : 7.22577e-02 	 MSE : 2.87047e+01
Validation Epoch 24 : 	 Train : 2.90393e-01 	 Res : 8.03034e-02 	 Jac : 5.04715e-02 	 Enc : 1.81746e-02 	 AE : 1.25017e-01 	 MSE : 1.64260e+01
Training Epoch 24 finished, took current epoch 420.55s, cumulative time 9826.68s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 25, 25% 	 Loss : 2.0261e-01 	 Res : 7.5131e-02 	 Jac : 5.6337e-02 	 Enc : 1.9638e-02 	 AEnc : 3.4138e-02 	 MSE : 1.7366e+01
Epoch 25, 50% 	 Loss : 2.0499e-01 	 Res : 6.8154e-02 	 Jac : 5.7691e-02 	 Enc : 1.9090e-02 	 AEnc : 4.2145e-02 	 MSE : 1.7914e+01
Epoch 25, 75% 	 Loss : 3.2961e-01 	 Res : 1.1702e-01 	 Jac : 4.8616e-02 	 Enc : 2.1017e-02 	 AEnc : 1.2010e-01 	 MSE : 2.2852e+01
Training Epoch 25 : 	 Train : 2.44316e-01 	 Res : 8.45800e-02 	 Jac : 5.33242e-02 	 Enc : 1.99442e-02 	 AE : 6.78672e-02 	 MSE : 1.86008e+01
Validation Epoch 25 : 	 Train : 1.48082e-01 	 Res : 4.03149e-02 	 Jac : 4.49172e-02 	 Enc : 1.87986e-02 	 AE : 2.91750e-02 	 MSE : 1.48761e+01
Training Epoch 25 finished, took current epoch 417.44s, cumulative time 10244.04s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
MODEL SAVED
Epoch 26, 25% 	 Loss : 5.4929e-01 	 Res : 3.6788e-01 	 Jac : 5.4328e-02 	 Enc : 2.8903e-02 	 AEnc : 5.7997e-02 	 MSE : 4.0179e+01
Epoch 26, 50% 	 Loss : 2.7563e-01 	 Res : 1.2223e-01 	 Jac : 5.3596e-02 	 Enc : 2.1938e-02 	 AEnc : 5.6085e-02 	 MSE : 2.1784e+01
Epoch 26, 75% 	 Loss : 2.0709e-01 	 Res : 8.4509e-02 	 Jac : 5.4406e-02 	 Enc : 1.9692e-02 	 AEnc : 3.3339e-02 	 MSE : 1.5145e+01
Training Epoch 26 : 	 Train : 3.23366e-01 	 Res : 1.77940e-01 	 Jac : 5.47502e-02 	 Enc : 2.25319e-02 	 AE : 4.30891e-02 	 MSE : 2.50550e+01
Validation Epoch 26 : 	 Train : 2.20553e-01 	 Res : 1.07426e-01 	 Jac : 3.60724e-02 	 Enc : 1.84318e-02 	 AE : 3.49456e-02 	 MSE : 2.36769e+01
Training Epoch 26 finished, took current epoch 419.00s, cumulative time 10663.02s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 27, 25% 	 Loss : 2.4201e-01 	 Res : 1.1147e-01 	 Jac : 5.0636e-02 	 Enc : 2.1538e-02 	 AEnc : 3.1077e-02 	 MSE : 2.7291e+01
Epoch 27, 50% 	 Loss : 2.7567e-01 	 Res : 9.7287e-02 	 Jac : 4.9340e-02 	 Enc : 1.8458e-02 	 AEnc : 9.0596e-02 	 MSE : 1.9989e+01
Epoch 27, 75% 	 Loss : 2.7206e-01 	 Res : 1.1852e-01 	 Jac : 5.3693e-02 	 Enc : 2.0377e-02 	 AEnc : 5.6250e-02 	 MSE : 2.3220e+01
Training Epoch 27 : 	 Train : 2.59240e-01 	 Res : 1.08696e-01 	 Jac : 4.97673e-02 	 Enc : 2.00914e-02 	 AE : 5.67961e-02 	 MSE : 2.38887e+01
Validation Epoch 27 : 	 Train : 1.34959e-01 	 Res : 4.34934e-02 	 Jac : 5.15453e-02 	 Enc : 1.68157e-02 	 AE : 1.34130e-02 	 MSE : 9.69183e+00
Training Epoch 27 finished, took current epoch 443.89s, cumulative time 11106.90s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 28, 25% 	 Loss : 2.5894e-01 	 Res : 1.3366e-01 	 Jac : 5.1405e-02 	 Enc : 1.8894e-02 	 AEnc : 2.6931e-02 	 MSE : 2.8054e+01
Epoch 28, 50% 	 Loss : 2.1156e-01 	 Res : 7.6238e-02 	 Jac : 5.2619e-02 	 Enc : 1.6223e-02 	 AEnc : 4.7520e-02 	 MSE : 1.8962e+01
Epoch 28, 75% 	 Loss : 1.9489e-01 	 Res : 7.3836e-02 	 Jac : 4.8654e-02 	 Enc : 1.6644e-02 	 AEnc : 3.7026e-02 	 MSE : 1.8731e+01
Training Epoch 28 : 	 Train : 2.46222e-01 	 Res : 1.11484e-01 	 Jac : 5.10293e-02 	 Enc : 1.74980e-02 	 AE : 4.24279e-02 	 MSE : 2.37825e+01
Validation Epoch 28 : 	 Train : 2.66174e-01 	 Res : 1.17864e-01 	 Jac : 2.90068e-02 	 Enc : 1.44399e-02 	 AE : 8.02903e-02 	 MSE : 2.45724e+01
Training Epoch 28 finished, took current epoch 418.42s, cumulative time 11525.31s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 29, 25% 	 Loss : 2.3692e-01 	 Res : 1.1006e-01 	 Jac : 4.2940e-02 	 Enc : 1.6064e-02 	 AEnc : 4.7844e-02 	 MSE : 2.0010e+01
Epoch 29, 50% 	 Loss : 2.6894e-01 	 Res : 1.5767e-01 	 Jac : 4.4078e-02 	 Enc : 1.6399e-02 	 AEnc : 2.6709e-02 	 MSE : 2.4084e+01
Epoch 29, 75% 	 Loss : 2.1699e-01 	 Res : 9.2201e-02 	 Jac : 4.8719e-02 	 Enc : 1.4375e-02 	 AEnc : 4.0981e-02 	 MSE : 2.0719e+01
Training Epoch 29 : 	 Train : 2.39887e-01 	 Res : 1.17989e-01 	 Jac : 4.79330e-02 	 Enc : 1.55975e-02 	 AE : 3.71986e-02 	 MSE : 2.11692e+01
Validation Epoch 29 : 	 Train : 2.04584e-01 	 Res : 7.94190e-02 	 Jac : 7.72970e-02 	 Enc : 2.06496e-02 	 AE : 1.92732e-02 	 MSE : 7.94507e+00
Training Epoch 29 finished, took current epoch 491.40s, cumulative time 12016.69s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 30, 25% 	 Loss : 2.6159e-01 	 Res : 1.2339e-01 	 Jac : 6.3654e-02 	 Enc : 1.4823e-02 	 AEnc : 3.8550e-02 	 MSE : 2.1170e+01
Epoch 30, 50% 	 Loss : 2.2846e-01 	 Res : 1.2429e-01 	 Jac : 4.4404e-02 	 Enc : 1.6546e-02 	 AEnc : 1.5487e-02 	 MSE : 2.7735e+01
Epoch 30, 75% 	 Loss : 5.3746e-01 	 Res : 4.0069e-01 	 Jac : 4.1475e-02 	 Enc : 1.7613e-02 	 AEnc : 3.8150e-02 	 MSE : 3.9528e+01
Training Epoch 30 : 	 Train : 3.22221e-01 	 Res : 1.94913e-01 	 Jac : 5.11884e-02 	 Enc : 1.58518e-02 	 AE : 3.22443e-02 	 MSE : 2.80238e+01
Validation Epoch 30 : 	 Train : 3.59325e-01 	 Res : 2.01752e-01 	 Jac : 6.96693e-02 	 Enc : 1.28631e-02 	 AE : 3.05867e-02 	 MSE : 4.44538e+01
Training Epoch 30 finished, took current epoch 453.09s, cumulative time 12469.75s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 31, 25% 	 Loss : 1.9754e-01 	 Res : 9.7527e-02 	 Jac : 4.5431e-02 	 Enc : 1.1302e-02 	 AEnc : 1.9310e-02 	 MSE : 2.3970e+01
Epoch 31, 50% 	 Loss : 1.8766e-01 	 Res : 9.5449e-02 	 Jac : 4.3203e-02 	 Enc : 1.2161e-02 	 AEnc : 1.1876e-02 	 MSE : 2.4975e+01
Epoch 31, 75% 	 Loss : 3.8921e-01 	 Res : 2.6261e-01 	 Jac : 5.1332e-02 	 Enc : 1.7887e-02 	 AEnc : 2.2193e-02 	 MSE : 3.5185e+01
Training Epoch 31 : 	 Train : 2.47137e-01 	 Res : 1.41051e-01 	 Jac : 4.60610e-02 	 Enc : 1.32449e-02 	 AE : 1.92233e-02 	 MSE : 2.75569e+01
Validation Epoch 31 : 	 Train : 1.40216e-01 	 Res : 5.14213e-02 	 Jac : 4.97431e-02 	 Enc : 9.48257e-03 	 AE : 1.32947e-02 	 MSE : 1.62741e+01
Training Epoch 31 finished, took current epoch 408.66s, cumulative time 12878.39s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 32, 25% 	 Loss : 2.8624e-01 	 Res : 9.4554e-02 	 Jac : 4.4294e-02 	 Enc : 1.1368e-02 	 AEnc : 1.1345e-01 	 MSE : 2.2567e+01
Epoch 32, 50% 	 Loss : 2.5440e-01 	 Res : 9.2731e-02 	 Jac : 5.1521e-02 	 Enc : 1.2099e-02 	 AEnc : 7.7738e-02 	 MSE : 2.0314e+01
Epoch 32, 75% 	 Loss : 3.1217e-01 	 Res : 1.7961e-01 	 Jac : 4.9130e-02 	 Enc : 1.2829e-02 	 AEnc : 4.4589e-02 	 MSE : 2.6016e+01
Training Epoch 32 : 	 Train : 2.94480e-01 	 Res : 1.23918e-01 	 Jac : 4.65297e-02 	 Enc : 1.22149e-02 	 AE : 8.81992e-02 	 MSE : 2.36177e+01
Validation Epoch 32 : 	 Train : 1.61553e-01 	 Res : 6.29880e-02 	 Jac : 4.86697e-02 	 Enc : 1.15030e-02 	 AE : 1.78488e-02 	 MSE : 2.05437e+01
Training Epoch 32 finished, took current epoch 429.54s, cumulative time 13307.91s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 33, 25% 	 Loss : 2.5433e-01 	 Res : 1.2090e-01 	 Jac : 4.4909e-02 	 Enc : 1.3750e-02 	 AEnc : 5.1936e-02 	 MSE : 2.2833e+01
Epoch 33, 50% 	 Loss : 1.6237e-01 	 Res : 7.4792e-02 	 Jac : 4.1640e-02 	 Enc : 9.7789e-03 	 AEnc : 1.6285e-02 	 MSE : 1.9871e+01
Epoch 33, 75% 	 Loss : 2.0618e-01 	 Res : 6.8493e-02 	 Jac : 4.0719e-02 	 Enc : 9.3256e-03 	 AEnc : 7.0396e-02 	 MSE : 1.7250e+01
Training Epoch 33 : 	 Train : 1.91714e-01 	 Res : 7.94338e-02 	 Jac : 4.26387e-02 	 Enc : 1.06072e-02 	 AE : 4.00774e-02 	 MSE : 1.89566e+01
Validation Epoch 33 : 	 Train : 1.16612e-01 	 Res : 5.18404e-02 	 Jac : 3.15305e-02 	 Enc : 8.28271e-03 	 AE : 2.29003e-03 	 MSE : 2.26686e+01
Training Epoch 33 finished, took current epoch 418.43s, cumulative time 13726.33s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 34, 25% 	 Loss : 2.8797e-01 	 Res : 1.8786e-01 	 Jac : 3.8694e-02 	 Enc : 1.1720e-02 	 AEnc : 2.0245e-02 	 MSE : 2.9452e+01
Epoch 34, 50% 	 Loss : 1.5719e-01 	 Res : 7.0444e-02 	 Jac : 3.8738e-02 	 Enc : 9.5822e-03 	 AEnc : 1.8557e-02 	 MSE : 1.9868e+01
Epoch 34, 75% 	 Loss : 2.0902e-01 	 Res : 1.0454e-01 	 Jac : 3.4473e-02 	 Enc : 9.0907e-03 	 AEnc : 3.5693e-02 	 MSE : 2.5224e+01
Training Epoch 34 : 	 Train : 2.08707e-01 	 Res : 1.15007e-01 	 Jac : 3.76305e-02 	 Enc : 9.66881e-03 	 AE : 2.23722e-02 	 MSE : 2.40283e+01
Validation Epoch 34 : 	 Train : 1.65416e-01 	 Res : 8.35930e-02 	 Jac : 3.01609e-02 	 Enc : 8.03555e-03 	 AE : 1.95667e-02 	 MSE : 2.40596e+01
Training Epoch 34 finished, took current epoch 399.19s, cumulative time 14125.51s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 35, 25% 	 Loss : 2.0100e-01 	 Res : 1.1485e-01 	 Jac : 3.5765e-02 	 Enc : 1.1682e-02 	 AEnc : 1.1512e-02 	 MSE : 2.7192e+01
Epoch 35, 50% 	 Loss : 2.3532e-01 	 Res : 1.2143e-01 	 Jac : 3.9950e-02 	 Enc : 1.0005e-02 	 AEnc : 3.7783e-02 	 MSE : 2.6155e+01
Epoch 35, 75% 	 Loss : 1.9705e-01 	 Res : 8.8696e-02 	 Jac : 4.1758e-02 	 Enc : 9.5135e-03 	 AEnc : 3.5207e-02 	 MSE : 2.1879e+01
Training Epoch 35 : 	 Train : 2.13212e-01 	 Res : 1.03277e-01 	 Jac : 3.99279e-02 	 Enc : 1.00596e-02 	 AE : 3.63627e-02 	 MSE : 2.35847e+01
Validation Epoch 35 : 	 Train : 2.33586e-01 	 Res : 8.77179e-02 	 Jac : 2.82620e-02 	 Enc : 7.26309e-03 	 AE : 8.89988e-02 	 MSE : 2.13440e+01
Training Epoch 35 finished, took current epoch 399.86s, cumulative time 14525.34s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 36, 25% 	 Loss : 2.9640e-01 	 Res : 8.5740e-02 	 Jac : 3.7039e-02 	 Enc : 9.3720e-03 	 AEnc : 1.4357e-01 	 MSE : 2.0678e+01
Epoch 36, 50% 	 Loss : 2.4833e-01 	 Res : 7.9439e-02 	 Jac : 4.3875e-02 	 Enc : 8.6128e-03 	 AEnc : 9.8598e-02 	 MSE : 1.7804e+01
Epoch 36, 75% 	 Loss : 3.5005e-01 	 Res : 1.2825e-01 	 Jac : 3.7279e-02 	 Enc : 1.0865e-02 	 AEnc : 1.5009e-01 	 MSE : 2.3564e+01
Training Epoch 36 : 	 Train : 2.63832e-01 	 Res : 8.96118e-02 	 Jac : 4.04077e-02 	 Enc : 9.32495e-03 	 AE : 1.05376e-01 	 MSE : 1.91109e+01
Validation Epoch 36 : 	 Train : 1.26726e-01 	 Res : 5.32599e-02 	 Jac : 3.06873e-02 	 Enc : 7.97708e-03 	 AE : 1.88178e-02 	 MSE : 1.59841e+01
Training Epoch 36 finished, took current epoch 435.37s, cumulative time 14960.66s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 37, 25% 	 Loss : 1.8726e-01 	 Res : 8.4360e-02 	 Jac : 3.9661e-02 	 Enc : 7.8125e-03 	 AEnc : 3.8331e-02 	 MSE : 1.7098e+01
Epoch 37, 50% 	 Loss : 2.2619e-01 	 Res : 9.6381e-02 	 Jac : 3.3491e-02 	 Enc : 8.8626e-03 	 AEnc : 6.5013e-02 	 MSE : 2.2441e+01
Epoch 37, 75% 	 Loss : 2.0672e-01 	 Res : 9.5877e-02 	 Jac : 3.7401e-02 	 Enc : 8.7687e-03 	 AEnc : 4.0708e-02 	 MSE : 2.3968e+01
Training Epoch 37 : 	 Train : 1.95353e-01 	 Res : 9.04800e-02 	 Jac : 3.64455e-02 	 Enc : 8.35424e-03 	 AE : 3.88602e-02 	 MSE : 2.12135e+01
Validation Epoch 37 : 	 Train : 1.10372e-01 	 Res : 5.34888e-02 	 Jac : 2.78038e-02 	 Enc : 6.64658e-03 	 AE : 2.42315e-03 	 MSE : 2.00094e+01
Training Epoch 37 finished, took current epoch 410.78s, cumulative time 15371.43s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 38, 25% 	 Loss : 1.6861e-01 	 Res : 9.6266e-02 	 Jac : 4.0076e-02 	 Enc : 7.5160e-03 	 AEnc : 4.6948e-03 	 MSE : 2.0058e+01
Epoch 38, 50% 	 Loss : 1.5354e-01 	 Res : 8.0219e-02 	 Jac : 3.4592e-02 	 Enc : 8.1090e-03 	 AEnc : 1.0141e-02 	 MSE : 2.0475e+01
Epoch 38, 75% 	 Loss : 1.1106e-01 	 Res : 4.9448e-02 	 Jac : 3.6730e-02 	 Enc : 6.8488e-03 	 AEnc : 3.0272e-03 	 MSE : 1.5004e+01
Training Epoch 38 : 	 Train : 1.53098e-01 	 Res : 7.93842e-02 	 Jac : 3.67694e-02 	 Enc : 7.62101e-03 	 AE : 1.05750e-02 	 MSE : 1.87488e+01
Validation Epoch 38 : 	 Train : 3.07850e-01 	 Res : 1.64579e-01 	 Jac : 4.75298e-02 	 Enc : 8.01636e-03 	 AE : 4.84296e-02 	 MSE : 3.92949e+01
Training Epoch 38 finished, took current epoch 458.19s, cumulative time 15829.61s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 39, 25% 	 Loss : 2.6684e-01 	 Res : 1.4315e-01 	 Jac : 3.5368e-02 	 Enc : 8.4524e-03 	 AEnc : 4.9484e-02 	 MSE : 3.0380e+01
Epoch 39, 50% 	 Loss : 2.6961e-01 	 Res : 1.7608e-01 	 Jac : 3.9239e-02 	 Enc : 1.0826e-02 	 AEnc : 1.3000e-02 	 MSE : 3.0469e+01
Epoch 39, 75% 	 Loss : 1.3436e-01 	 Res : 6.0054e-02 	 Jac : 3.7325e-02 	 Enc : 7.3334e-03 	 AEnc : 1.4400e-02 	 MSE : 1.5248e+01
Training Epoch 39 : 	 Train : 2.25075e-01 	 Res : 1.31504e-01 	 Jac : 3.70198e-02 	 Enc : 8.62166e-03 	 AE : 2.19062e-02 	 MSE : 2.60228e+01
Validation Epoch 39 : 	 Train : 1.24801e-01 	 Res : 6.75509e-02 	 Jac : 2.58742e-02 	 Enc : 7.23671e-03 	 AE : 1.02010e-02 	 MSE : 1.39378e+01
Training Epoch 39 finished, took current epoch 415.29s, cumulative time 16244.87s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 40, 25% 	 Loss : 1.5047e-01 	 Res : 7.9749e-02 	 Jac : 3.3913e-02 	 Enc : 7.2964e-03 	 AEnc : 1.1813e-02 	 MSE : 1.7701e+01
Epoch 40, 50% 	 Loss : 2.8683e-01 	 Res : 1.9563e-01 	 Jac : 3.5843e-02 	 Enc : 7.3278e-03 	 AEnc : 1.6387e-02 	 MSE : 3.1648e+01
Epoch 40, 75% 	 Loss : 2.6810e-01 	 Res : 1.5828e-01 	 Jac : 3.2154e-02 	 Enc : 1.0229e-02 	 AEnc : 3.6792e-02 	 MSE : 3.0642e+01
Training Epoch 40 : 	 Train : 2.14319e-01 	 Res : 1.25592e-01 	 Jac : 3.51274e-02 	 Enc : 8.21656e-03 	 AE : 2.04618e-02 	 MSE : 2.49211e+01
Validation Epoch 40 : 	 Train : 9.23669e-02 	 Res : 2.74235e-02 	 Jac : 3.11992e-02 	 Enc : 6.87194e-03 	 AE : 1.63812e-02 	 MSE : 1.04910e+01
Training Epoch 40 finished, took current epoch 411.71s, cumulative time 16656.55s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
MODEL SAVED
Epoch 41, 25% 	 Loss : 4.0453e-01 	 Res : 1.8689e-01 	 Jac : 3.7126e-02 	 Enc : 1.0645e-02 	 AEnc : 1.4059e-01 	 MSE : 2.9268e+01
Epoch 41, 50% 	 Loss : 2.1599e-01 	 Res : 6.7496e-02 	 Jac : 3.8917e-02 	 Enc : 7.4875e-03 	 AEnc : 8.5796e-02 	 MSE : 1.6297e+01
Epoch 41, 75% 	 Loss : 1.9800e-01 	 Res : 5.1846e-02 	 Jac : 3.8691e-02 	 Enc : 6.0000e-03 	 AEnc : 8.8395e-02 	 MSE : 1.3064e+01
Training Epoch 41 : 	 Train : 2.45980e-01 	 Res : 9.61741e-02 	 Jac : 3.77988e-02 	 Enc : 7.44706e-03 	 AE : 8.45168e-02 	 MSE : 2.00433e+01
Validation Epoch 41 : 	 Train : 5.33931e-01 	 Res : 3.77976e-01 	 Jac : 5.43780e-02 	 Enc : 2.04977e-02 	 AE : 3.91178e-02 	 MSE : 4.19614e+01
Training Epoch 41 finished, took current epoch 485.82s, cumulative time 17142.35s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 42, 25% 	 Loss : 1.5987e-01 	 Res : 8.3274e-02 	 Jac : 3.2054e-02 	 Enc : 6.8666e-03 	 AEnc : 1.9554e-02 	 MSE : 1.8121e+01
Epoch 42, 50% 	 Loss : 1.6874e-01 	 Res : 9.2446e-02 	 Jac : 3.2680e-02 	 Enc : 5.9391e-03 	 AEnc : 1.2122e-02 	 MSE : 2.5554e+01
Epoch 42, 75% 	 Loss : 3.1398e-01 	 Res : 1.3153e-01 	 Jac : 3.5420e-02 	 Enc : 7.7064e-03 	 AEnc : 1.1312e-01 	 MSE : 2.6211e+01
Training Epoch 42 : 	 Train : 1.96674e-01 	 Res : 9.23348e-02 	 Jac : 3.35986e-02 	 Enc : 6.72701e-03 	 AE : 4.24102e-02 	 MSE : 2.16033e+01
Validation Epoch 42 : 	 Train : 1.90748e-01 	 Res : 8.32738e-02 	 Jac : 4.78386e-02 	 Enc : 7.64154e-03 	 AE : 4.42564e-02 	 MSE : 7.73811e+00
Training Epoch 42 finished, took current epoch 491.57s, cumulative time 17633.88s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 43, 25% 	 Loss : 1.3275e-01 	 Res : 5.3557e-02 	 Jac : 3.5445e-02 	 Enc : 7.0498e-03 	 AEnc : 2.2551e-02 	 MSE : 1.4147e+01
Epoch 43, 50% 	 Loss : 1.6677e-01 	 Res : 7.3841e-02 	 Jac : 3.1873e-02 	 Enc : 5.7619e-03 	 AEnc : 3.6570e-02 	 MSE : 1.8728e+01
Epoch 43, 75% 	 Loss : 1.4959e-01 	 Res : 8.1480e-02 	 Jac : 3.2461e-02 	 Enc : 5.4184e-03 	 AEnc : 1.0432e-02 	 MSE : 1.9800e+01
Training Epoch 43 : 	 Train : 1.77807e-01 	 Res : 8.29400e-02 	 Jac : 3.28018e-02 	 Enc : 6.28678e-03 	 AE : 3.58253e-02 	 MSE : 1.99530e+01
Validation Epoch 43 : 	 Train : 2.72450e-01 	 Res : 8.16713e-02 	 Jac : 4.08680e-02 	 Enc : 6.53785e-03 	 AE : 1.27879e-01 	 MSE : 1.54937e+01
Training Epoch 43 finished, took current epoch 426.33s, cumulative time 18060.18s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 44, 25% 	 Loss : 2.0185e-01 	 Res : 9.5826e-02 	 Jac : 3.2427e-02 	 Enc : 6.1195e-03 	 AEnc : 4.5489e-02 	 MSE : 2.1988e+01
Epoch 44, 50% 	 Loss : 1.2411e-01 	 Res : 5.3204e-02 	 Jac : 3.2693e-02 	 Enc : 5.9548e-03 	 AEnc : 1.5134e-02 	 MSE : 1.7125e+01
Epoch 44, 75% 	 Loss : 1.2537e-01 	 Res : 6.4530e-02 	 Jac : 3.2229e-02 	 Enc : 5.8253e-03 	 AEnc : 6.3537e-03 	 MSE : 1.6431e+01
Training Epoch 44 : 	 Train : 1.47747e-01 	 Res : 7.04199e-02 	 Jac : 3.26598e-02 	 Enc : 5.89929e-03 	 AE : 2.07433e-02 	 MSE : 1.80246e+01
Validation Epoch 44 : 	 Train : 3.48909e-01 	 Res : 1.74008e-01 	 Jac : 4.07060e-02 	 Enc : 5.31233e-03 	 AE : 9.81063e-02 	 MSE : 3.07759e+01
Training Epoch 44 finished, took current epoch 452.00s, cumulative time 18512.17s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 45, 25% 	 Loss : 2.1848e-01 	 Res : 1.2885e-01 	 Jac : 2.8961e-02 	 Enc : 5.7739e-03 	 AEnc : 3.0008e-02 	 MSE : 2.4884e+01
Epoch 45, 50% 	 Loss : 1.3183e-01 	 Res : 6.3993e-02 	 Jac : 3.0107e-02 	 Enc : 5.5900e-03 	 AEnc : 1.0359e-02 	 MSE : 2.1781e+01
Epoch 45, 75% 	 Loss : 1.7832e-01 	 Res : 9.7400e-02 	 Jac : 3.3195e-02 	 Enc : 5.6590e-03 	 AEnc : 1.9162e-02 	 MSE : 2.2906e+01
Training Epoch 45 : 	 Train : 2.25363e-01 	 Res : 1.43088e-01 	 Jac : 3.21128e-02 	 Enc : 6.47842e-03 	 AE : 1.80576e-02 	 MSE : 2.56269e+01
Validation Epoch 45 : 	 Train : 1.00427e-01 	 Res : 4.16091e-02 	 Jac : 3.48048e-02 	 Enc : 5.11150e-03 	 AE : 4.09367e-03 	 MSE : 1.48083e+01
Training Epoch 45 finished, took current epoch 414.91s, cumulative time 18927.06s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 46, 25% 	 Loss : 1.9807e-01 	 Res : 1.1707e-01 	 Jac : 3.6727e-02 	 Enc : 6.5560e-03 	 AEnc : 1.1912e-02 	 MSE : 2.5803e+01
Epoch 46, 50% 	 Loss : 1.4049e-01 	 Res : 6.7741e-02 	 Jac : 3.1598e-02 	 Enc : 5.6936e-03 	 AEnc : 1.4072e-02 	 MSE : 2.1381e+01
Epoch 46, 75% 	 Loss : 1.7757e-01 	 Res : 7.6327e-02 	 Jac : 3.2903e-02 	 Enc : 5.7105e-03 	 AEnc : 4.3609e-02 	 MSE : 1.9016e+01
Training Epoch 46 : 	 Train : 3.33821e-01 	 Res : 2.31134e-01 	 Jac : 3.85386e-02 	 Enc : 7.19374e-03 	 AE : 3.09474e-02 	 MSE : 2.60066e+01
Validation Epoch 46 : 	 Train : 2.76973e-01 	 Res : 1.07418e-01 	 Jac : 2.71418e-02 	 Enc : 6.21992e-03 	 AE : 1.18178e-01 	 MSE : 1.80151e+01
Training Epoch 46 finished, took current epoch 413.02s, cumulative time 19340.05s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 47, 25% 	 Loss : 3.2382e-01 	 Res : 1.2829e-01 	 Jac : 3.6260e-02 	 Enc : 7.4644e-03 	 AEnc : 1.2724e-01 	 MSE : 2.4569e+01
Epoch 47, 50% 	 Loss : 3.1548e-01 	 Res : 2.2642e-01 	 Jac : 3.2496e-02 	 Enc : 9.5571e-03 	 AEnc : 1.6444e-02 	 MSE : 3.0558e+01
Epoch 47, 75% 	 Loss : 1.8665e-01 	 Res : 9.1664e-02 	 Jac : 3.3466e-02 	 Enc : 5.3057e-03 	 AEnc : 2.9589e-02 	 MSE : 2.6628e+01
Training Epoch 47 : 	 Train : 2.45214e-01 	 Res : 1.27741e-01 	 Jac : 3.43181e-02 	 Enc : 6.79228e-03 	 AE : 5.09424e-02 	 MSE : 2.54201e+01
Validation Epoch 47 : 	 Train : 1.79946e-01 	 Res : 5.81363e-02 	 Jac : 3.80111e-02 	 Enc : 3.60241e-03 	 AE : 5.59631e-02 	 MSE : 2.42335e+01
Training Epoch 47 finished, took current epoch 402.83s, cumulative time 19742.84s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 48, 25% 	 Loss : 1.3260e-01 	 Res : 6.1689e-02 	 Jac : 3.0464e-02 	 Enc : 4.8429e-03 	 AEnc : 1.6024e-02 	 MSE : 1.9581e+01
Epoch 48, 50% 	 Loss : 2.1361e-01 	 Res : 1.3503e-01 	 Jac : 3.0566e-02 	 Enc : 5.8403e-03 	 AEnc : 1.8239e-02 	 MSE : 2.3936e+01
Epoch 48, 75% 	 Loss : 1.6602e-01 	 Res : 6.8522e-02 	 Jac : 2.9483e-02 	 Enc : 5.1837e-03 	 AEnc : 4.2646e-02 	 MSE : 2.0186e+01
Training Epoch 48 : 	 Train : 1.83988e-01 	 Res : 9.76851e-02 	 Jac : 3.02575e-02 	 Enc : 5.49071e-03 	 AE : 2.93713e-02 	 MSE : 2.11832e+01
Validation Epoch 48 : 	 Train : 2.37195e-01 	 Res : 1.32941e-01 	 Jac : 4.81893e-02 	 Enc : 7.98318e-03 	 AE : 2.69873e-02 	 MSE : 2.10943e+01
Training Epoch 48 finished, took current epoch 468.27s, cumulative time 20211.06s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 49, 25% 	 Loss : 2.5388e-01 	 Res : 1.5390e-01 	 Jac : 3.1443e-02 	 Enc : 6.5254e-03 	 AEnc : 3.9249e-02 	 MSE : 2.2764e+01
Epoch 49, 50% 	 Loss : 1.7151e-01 	 Res : 5.9007e-02 	 Jac : 2.7657e-02 	 Enc : 5.0691e-03 	 AEnc : 6.2746e-02 	 MSE : 1.7029e+01
Epoch 49, 75% 	 Loss : 1.6154e-01 	 Res : 9.7015e-02 	 Jac : 3.1578e-02 	 Enc : 5.6949e-03 	 AEnc : 7.1455e-03 	 MSE : 2.0109e+01
Training Epoch 49 : 	 Train : 1.85561e-01 	 Res : 9.75988e-02 	 Jac : 3.02396e-02 	 Enc : 5.52864e-03 	 AE : 3.15751e-02 	 MSE : 2.06191e+01
Validation Epoch 49 : 	 Train : 9.78316e-02 	 Res : 3.83322e-02 	 Jac : 2.62150e-02 	 Enc : 5.82112e-03 	 AE : 8.13490e-03 	 MSE : 1.93283e+01
Training Epoch 49 finished, took current epoch 417.13s, cumulative time 20628.15s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 50, 25% 	 Loss : 1.1007e-01 	 Res : 5.3500e-02 	 Jac : 3.0755e-02 	 Enc : 5.0798e-03 	 AEnc : 2.5395e-03 	 MSE : 1.8192e+01
Epoch 50, 50% 	 Loss : 1.1388e-01 	 Res : 5.6353e-02 	 Jac : 3.1151e-02 	 Enc : 4.4655e-03 	 AEnc : 3.5995e-03 	 MSE : 1.8307e+01
Epoch 50, 75% 	 Loss : 1.3524e-01 	 Res : 7.3338e-02 	 Jac : 3.0329e-02 	 Enc : 4.8248e-03 	 AEnc : 3.1305e-03 	 MSE : 2.3622e+01
Training Epoch 50 : 	 Train : 1.23781e-01 	 Res : 6.48140e-02 	 Jac : 3.09396e-02 	 Enc : 4.71217e-03 	 AE : 2.78982e-03 	 MSE : 2.05251e+01
Validation Epoch 50 : 	 Train : 9.33369e-02 	 Res : 4.04626e-02 	 Jac : 2.48210e-02 	 Enc : 4.16878e-03 	 AE : 3.14306e-03 	 MSE : 2.07414e+01
Training Epoch 50 finished, took current epoch 408.05s, cumulative time 21036.16s
Current Learning rate DEQ : 0.005
Current Learning rate AUTOENC : 0.01
Epoch 51, 25% 	 Loss : 3.7369e-01 	 Res : 2.0310e-01 	 Jac : 3.1686e-02 	 Enc : 6.5814e-03 	 AEnc : 1.0502e-01 	 MSE : 2.7297e+01
Epoch 51, 50% 	 Loss : 2.5271e-01 	 Res : 7.1690e-02 	 Jac : 3.1125e-02 	 Enc : 5.3452e-03 	 AEnc : 1.2739e-01 	 MSE : 1.7165e+01
Epoch 51, 75% 	 Loss : 2.5930e-01 	 Res : 8.0780e-02 	 Jac : 3.5145e-02 	 Enc : 4.8340e-03 	 AEnc : 1.2190e-01 	 MSE : 1.6644e+01
Training Epoch 51 : 	 Train : 2.98190e-01 	 Res : 1.22160e-01 	 Jac : 3.31370e-02 	 Enc : 5.42465e-03 	 AE : 1.17574e-01 	 MSE : 1.98939e+01
Validation Epoch 51 : 	 Train : 2.24535e-01 	 Res : 7.63889e-02 	 Jac : 2.83545e-02 	 Enc : 3.72016e-03 	 AE : 1.00877e-01 	 MSE : 1.51943e+01
Training Epoch 51 finished, took current epoch 424.07s, cumulative time 21460.21s
Current Learning rate DEQ : 0.0034999999999999996
Current Learning rate AUTOENC : 0.006999999999999999
Epoch 52, 25% 	 Loss : 1.9769e-01 	 Res : 9.2310e-02 	 Jac : 3.1546e-02 	 Enc : 4.0744e-03 	 AEnc : 5.2935e-02 	 MSE : 1.6820e+01
Epoch 52, 50% 	 Loss : 1.7879e-01 	 Res : 9.5106e-02 	 Jac : 3.2426e-02 	 Enc : 4.1777e-03 	 AEnc : 2.8917e-02 	 MSE : 1.8168e+01
Epoch 52, 75% 	 Loss : 2.4949e-01 	 Res : 8.4002e-02 	 Jac : 3.1663e-02 	 Enc : 4.3367e-03 	 AEnc : 1.1137e-01 	 MSE : 1.8121e+01
Training Epoch 52 : 	 Train : 1.98237e-01 	 Res : 8.28041e-02 	 Jac : 3.17004e-02 	 Enc : 4.12119e-03 	 AE : 6.35012e-02 	 MSE : 1.61100e+01
Validation Epoch 52 : 	 Train : 6.06150e-01 	 Res : 4.34444e-01 	 Jac : 5.39585e-02 	 Enc : 3.37914e-03 	 AE : 5.33598e-02 	 MSE : 6.10081e+01
Training Epoch 52 finished, took current epoch 490.20s, cumulative time 21950.40s
Current Learning rate DEQ : 0.0034999999999999996
Current Learning rate AUTOENC : 0.006999999999999999
Epoch 53, 25% 	 Loss : 1.8023e-01 	 Res : 9.7737e-02 	 Jac : 2.8480e-02 	 Enc : 4.2122e-03 	 AEnc : 2.9095e-02 	 MSE : 2.0708e+01
Epoch 53, 50% 	 Loss : 1.2613e-01 	 Res : 6.7188e-02 	 Jac : 2.8721e-02 	 Enc : 4.0744e-03 	 AEnc : 7.6418e-03 	 MSE : 1.8506e+01
Epoch 53, 75% 	 Loss : 8.2054e-01 	 Res : 7.0216e-01 	 Jac : 3.3365e-02 	 Enc : 4.5756e-03 	 AEnc : 4.5369e-02 	 MSE : 3.5070e+01
Training Epoch 53 : 	 Train : 3.13301e-01 	 Res : 2.30658e-01 	 Jac : 3.02402e-02 	 Enc : 4.34468e-03 	 AE : 2.58394e-02 	 MSE : 2.22186e+01
Validation Epoch 53 : 	 Train : 8.51524e-02 	 Res : 3.01735e-02 	 Jac : 2.75013e-02 	 Enc : 4.10223e-03 	 AE : 1.28401e-02 	 MSE : 1.05353e+01
Training Epoch 53 finished, took current epoch 431.47s, cumulative time 22381.83s
Current Learning rate DEQ : 0.0034999999999999996
Current Learning rate AUTOENC : 0.006999999999999999
Epoch 54, 25% 	 Loss : 1.9396e-01 	 Res : 1.2802e-01 	 Jac : 3.1721e-02 	 Enc : 4.4875e-03 	 AEnc : 8.8201e-03 	 MSE : 2.0915e+01
Epoch 54, 50% 	 Loss : 1.3299e-01 	 Res : 6.6332e-02 	 Jac : 2.8592e-02 	 Enc : 4.1216e-03 	 AEnc : 1.7195e-02 	 MSE : 1.6753e+01
Epoch 54, 75% 	 Loss : 1.1790e-01 	 Res : 5.2368e-02 	 Jac : 2.6354e-02 	 Enc : 4.1007e-03 	 AEnc : 1.8009e-02 	 MSE : 1.7069e+01
Training Epoch 54 : 	 Train : 1.33072e-01 	 Res : 7.20804e-02 	 Jac : 2.83188e-02 	 Enc : 4.13206e-03 	 AE : 1.19202e-02 	 MSE : 1.66209e+01
Validation Epoch 54 : 	 Train : 6.35152e-02 	 Res : 2.50816e-02 	 Jac : 2.79596e-02 	 Enc : 4.34333e-03 	 AE : 9.25918e-04 	 MSE : 5.20477e+00
Training Epoch 54 finished, took current epoch 435.09s, cumulative time 22816.89s
Current Learning rate DEQ : 0.0034999999999999996
Current Learning rate AUTOENC : 0.006999999999999999
MODEL SAVED
Epoch 55, 25% 	 Loss : 1.5640e-01 	 Res : 1.0028e-01 	 Jac : 2.7407e-02 	 Enc : 3.6209e-03 	 AEnc : 8.1970e-03 	 MSE : 1.6889e+01
Epoch 55, 50% 	 Loss : 5.2219e-01 	 Res : 4.5322e-01 	 Jac : 3.2005e-02 	 Enc : 5.5276e-03 	 AEnc : 4.0775e-03 	 MSE : 2.7360e+01
Epoch 55, 75% 	 Loss : 1.8015e-01 	 Res : 1.0895e-01 	 Jac : 2.4009e-02 	 Enc : 4.6434e-03 	 AEnc : 1.6327e-02 	 MSE : 2.6219e+01
Training Epoch 55 : 	 Train : 2.55444e-01 	 Res : 1.84507e-01 	 Jac : 2.75675e-02 	 Enc : 4.65934e-03 	 AE : 1.61388e-02 	 MSE : 2.25714e+01
Validation Epoch 55 : 	 Train : 1.55095e-01 	 Res : 7.72136e-02 	 Jac : 2.64418e-02 	 Enc : 4.08600e-03 	 AE : 2.58159e-02 	 MSE : 2.15382e+01
Training Epoch 55 finished, took current epoch 444.95s, cumulative time 23261.81s
Current Learning rate DEQ : 0.0034999999999999996
Current Learning rate AUTOENC : 0.006999999999999999
Epoch 56, 25% 	 Loss : 1.3109e-01 	 Res : 6.5312e-02 	 Jac : 2.7768e-02 	 Enc : 4.2906e-03 	 AEnc : 1.6869e-02 	 MSE : 1.6852e+01
Epoch 56, 50% 	 Loss : 1.1309e-01 	 Res : 6.1561e-02 	 Jac : 2.7496e-02 	 Enc : 3.5183e-03 	 AEnc : 5.2966e-03 	 MSE : 1.5220e+01
Epoch 56, 75% 	 Loss : 2.3673e-01 	 Res : 1.4897e-01 	 Jac : 2.7602e-02 	 Enc : 4.2932e-03 	 AEnc : 3.1110e-02 	 MSE : 2.4757e+01
Training Epoch 56 : 	 Train : 1.62227e-01 	 Res : 8.58603e-02 	 Jac : 2.80442e-02 	 Enc : 3.92390e-03 	 AE : 2.54947e-02 	 MSE : 1.89043e+01
Validation Epoch 56 : 	 Train : 1.16473e-01 	 Res : 4.18123e-02 	 Jac : 2.27760e-02 	 Enc : 3.75002e-03 	 AE : 3.12404e-02 	 MSE : 1.68945e+01
Training Epoch 56 finished, took current epoch 427.66s, cumulative time 23689.43s
Current Learning rate DEQ : 0.0034999999999999996
Current Learning rate AUTOENC : 0.006999999999999999
Epoch 57, 25% 	 Loss : 1.0135e-01 	 Res : 3.9787e-02 	 Jac : 2.6460e-02 	 Enc : 3.8139e-03 	 AEnc : 1.7295e-02 	 MSE : 1.3997e+01
Epoch 57, 50% 	 Loss : 1.4413e-01 	 Res : 8.7455e-02 	 Jac : 2.6466e-02 	 Enc : 3.7659e-03 	 AEnc : 3.9070e-03 	 MSE : 2.2534e+01
Epoch 57, 75% 	 Loss : 2.4069e-01 	 Res : 1.7464e-01 	 Jac : 2.8086e-02 	 Enc : 4.3036e-03 	 AEnc : 4.4439e-03 	 MSE : 2.9219e+01
Training Epoch 57 : 	 Train : 1.60832e-01 	 Res : 9.82762e-02 	 Jac : 2.79993e-02 	 Enc : 3.89484e-03 	 AE : 1.00974e-02 	 MSE : 2.05643e+01
Validation Epoch 57 : 	 Train : 7.07730e-02 	 Res : 2.73950e-02 	 Jac : 2.39426e-02 	 Enc : 3.35279e-03 	 AE : 3.08513e-03 	 MSE : 1.29975e+01
Training Epoch 57 finished, took current epoch 420.57s, cumulative time 24109.96s
Current Learning rate DEQ : 0.0034999999999999996
Current Learning rate AUTOENC : 0.006999999999999999
Epoch 58, 25% 	 Loss : 9.9682e-02 	 Res : 4.9874e-02 	 Jac : 2.6850e-02 	 Enc : 4.0363e-03 	 AEnc : 2.8004e-03 	 MSE : 1.6122e+01
Epoch 58, 50% 	 Loss : 1.3536e-01 	 Res : 8.2901e-02 	 Jac : 2.6869e-02 	 Enc : 3.8038e-03 	 AEnc : 4.8283e-03 	 MSE : 1.6954e+01
Epoch 58, 75% 	 Loss : 1.0117e-01 	 Res : 5.0491e-02 	 Jac : 2.7960e-02 	 Enc : 3.7105e-03 	 AEnc : 6.7850e-03 	 MSE : 1.2227e+01
Training Epoch 58 : 	 Train : 1.11764e-01 	 Res : 5.80652e-02 	 Jac : 2.78297e-02 	 Enc : 3.79023e-03 	 AE : 7.73691e-03 	 MSE : 1.43420e+01
Validation Epoch 58 : 	 Train : 3.43985e-01 	 Res : 2.32047e-01 	 Jac : 4.31008e-02 	 Enc : 3.71608e-03 	 AE : 4.35402e-02 	 MSE : 2.15807e+01
Training Epoch 58 finished, took current epoch 504.73s, cumulative time 24614.67s
Current Learning rate DEQ : 0.0034999999999999996
Current Learning rate AUTOENC : 0.006999999999999999
Epoch 59, 25% 	 Loss : 1.1354e-01 	 Res : 4.5418e-02 	 Jac : 2.5095e-02 	 Enc : 3.5849e-03 	 AEnc : 2.6535e-02 	 MSE : 1.2904e+01
Epoch 59, 50% 	 Loss : 1.0551e-01 	 Res : 4.2368e-02 	 Jac : 2.4704e-02 	 Enc : 3.5099e-03 	 AEnc : 2.0234e-02 	 MSE : 1.4696e+01
Epoch 59, 75% 	 Loss : 1.3176e-01 	 Res : 8.2539e-02 	 Jac : 2.8547e-02 	 Enc : 3.5284e-03 	 AEnc : 1.9720e-03 	 MSE : 1.5169e+01
Training Epoch 59 : 	 Train : 1.44388e-01 	 Res : 8.51117e-02 	 Jac : 2.58542e-02 	 Enc : 3.56264e-03 	 AE : 1.26643e-02 	 MSE : 1.71956e+01
Validation Epoch 59 : 	 Train : 8.21890e-02 	 Res : 3.72907e-02 	 Jac : 2.42120e-02 	 Enc : 4.25727e-03 	 AE : 8.75207e-04 	 MSE : 1.55538e+01
Training Epoch 59 finished, took current epoch 426.23s, cumulative time 25040.88s
Current Learning rate DEQ : 0.0034999999999999996
Current Learning rate AUTOENC : 0.006999999999999999
Epoch 60, 25% 	 Loss : 1.4080e-01 	 Res : 8.9826e-02 	 Jac : 2.6145e-02 	 Enc : 3.6527e-03 	 AEnc : 7.6501e-03 	 MSE : 1.3531e+01
Epoch 60, 50% 	 Loss : 8.8813e-02 	 Res : 3.8237e-02 	 Jac : 2.6080e-02 	 Enc : 3.3349e-03 	 AEnc : 8.9183e-03 	 MSE : 1.2243e+01
Epoch 60, 75% 	 Loss : 7.9038e-02 	 Res : 3.5100e-02 	 Jac : 2.5588e-02 	 Enc : 3.1017e-03 	 AEnc : 3.7543e-03 	 MSE : 1.1494e+01
Training Epoch 60 : 	 Train : 1.18231e-01 	 Res : 6.60841e-02 	 Jac : 2.64661e-02 	 Enc : 3.33168e-03 	 AE : 9.13350e-03 	 MSE : 1.32161e+01
Validation Epoch 60 : 	 Train : 1.33468e-01 	 Res : 5.82463e-02 	 Jac : 2.05267e-02 	 Enc : 3.15421e-03 	 AE : 3.28888e-02 	 MSE : 1.86518e+01
Training Epoch 60 finished, took current epoch 434.93s, cumulative time 25475.80s
Current Learning rate DEQ : 0.0034999999999999996
Current Learning rate AUTOENC : 0.006999999999999999
Epoch 61, 25% 	 Loss : 1.2744e-01 	 Res : 7.2897e-02 	 Jac : 2.3122e-02 	 Enc : 3.7734e-03 	 AEnc : 1.1019e-02 	 MSE : 1.6628e+01
Epoch 61, 50% 	 Loss : 2.4989e-01 	 Res : 1.8300e-01 	 Jac : 2.3385e-02 	 Enc : 4.2839e-03 	 AEnc : 1.1816e-02 	 MSE : 2.7411e+01
Epoch 61, 75% 	 Loss : 1.3219e-01 	 Res : 7.5032e-02 	 Jac : 2.3842e-02 	 Enc : 3.7293e-03 	 AEnc : 8.4117e-03 	 MSE : 2.1171e+01
Training Epoch 61 : 	 Train : 1.47479e-01 	 Res : 9.13710e-02 	 Jac : 2.43825e-02 	 Enc : 3.75302e-03 	 AE : 8.73786e-03 	 MSE : 1.92348e+01
Validation Epoch 61 : 	 Train : 7.95470e-02 	 Res : 3.27964e-02 	 Jac : 3.05733e-02 	 Enc : 2.87462e-03 	 AE : 1.28126e-03 	 MSE : 1.20214e+01
Training Epoch 61 finished, took current epoch 410.17s, cumulative time 25885.95s
Current Learning rate DEQ : 0.0034999999999999996
Current Learning rate AUTOENC : 0.006999999999999999
Epoch 62, 25% 	 Loss : 1.6299e-01 	 Res : 1.0219e-01 	 Jac : 2.6769e-02 	 Enc : 3.3656e-03 	 AEnc : 8.2013e-03 	 MSE : 2.2466e+01
Epoch 62, 50% 	 Loss : 1.4723e-01 	 Res : 8.3541e-02 	 Jac : 2.6462e-02 	 Enc : 3.3786e-03 	 AEnc : 1.1543e-02 	 MSE : 2.2303e+01
Epoch 62, 75% 	 Loss : 9.6187e-02 	 Res : 3.3028e-02 	 Jac : 2.7601e-02 	 Enc : 3.0240e-03 	 AEnc : 2.1723e-02 	 MSE : 1.0811e+01
Training Epoch 62 : 	 Train : 1.35244e-01 	 Res : 7.29828e-02 	 Jac : 2.67075e-02 	 Enc : 3.22738e-03 	 AE : 1.36678e-02 	 MSE : 1.86580e+01
Validation Epoch 62 : 	 Train : 7.94350e-02 	 Res : 3.55416e-02 	 Jac : 2.12583e-02 	 Enc : 2.80155e-03 	 AE : 3.02589e-04 	 MSE : 1.95309e+01
Training Epoch 62 finished, took current epoch 413.60s, cumulative time 26299.48s
Current Learning rate DEQ : 0.0034999999999999996
Current Learning rate AUTOENC : 0.006999999999999999
Epoch 63, 25% 	 Loss : 2.7000e-01 	 Res : 2.0069e-01 	 Jac : 2.5642e-02 	 Enc : 3.8882e-03 	 AEnc : 1.2306e-02 	 MSE : 2.7468e+01
Epoch 63, 50% 	 Loss : 8.3920e-02 	 Res : 3.6311e-02 	 Jac : 2.6324e-02 	 Enc : 3.0283e-03 	 AEnc : 4.1061e-03 	 MSE : 1.4150e+01
Epoch 63, 75% 	 Loss : 1.3329e-01 	 Res : 8.1408e-02 	 Jac : 2.5841e-02 	 Enc : 3.3370e-03 	 AEnc : 7.6256e-03 	 MSE : 1.5081e+01
Training Epoch 63 : 	 Train : 1.71329e-01 	 Res : 1.13448e-01 	 Jac : 2.59609e-02 	 Enc : 3.49879e-03 	 AE : 7.80242e-03 	 MSE : 2.06197e+01
Validation Epoch 63 : 	 Train : 1.42783e-01 	 Res : 9.46587e-02 	 Jac : 2.29081e-02 	 Enc : 3.05601e-03 	 AE : 1.32820e-02 	 MSE : 8.87859e+00
Training Epoch 63 finished, took current epoch 438.57s, cumulative time 26738.04s
Current Learning rate DEQ : 0.0034999999999999996
Current Learning rate AUTOENC : 0.006999999999999999
Epoch 64, 25% 	 Loss : 1.2857e-01 	 Res : 7.5541e-02 	 Jac : 2.4860e-02 	 Enc : 3.1437e-03 	 AEnc : 3.9166e-03 	 MSE : 2.1105e+01
Epoch 64, 50% 	 Loss : 3.7388e-01 	 Res : 3.0811e-01 	 Jac : 2.4700e-02 	 Enc : 4.2377e-03 	 AEnc : 4.7471e-03 	 MSE : 3.2083e+01
Epoch 64, 75% 	 Loss : 1.3114e-01 	 Res : 7.4598e-02 	 Jac : 2.9793e-02 	 Enc : 2.9756e-03 	 AEnc : 5.5354e-03 	 MSE : 1.8238e+01
Training Epoch 64 : 	 Train : 1.83236e-01 	 Res : 1.25204e-01 	 Jac : 2.62858e-02 	 Enc : 3.32427e-03 	 AE : 6.98636e-03 	 MSE : 2.14355e+01
Validation Epoch 64 : 	 Train : 8.17981e-02 	 Res : 3.36472e-02 	 Jac : 2.49308e-02 	 Enc : 2.49037e-03 	 AE : 2.19622e-03 	 MSE : 1.85335e+01
Training Epoch 64 finished, took current epoch 416.26s, cumulative time 27154.29s
Current Learning rate DEQ : 0.0034999999999999996
Current Learning rate AUTOENC : 0.006999999999999999
Epoch 65, 25% 	 Loss : 2.1871e-01 	 Res : 1.4123e-01 	 Jac : 2.4981e-02 	 Enc : 3.5590e-03 	 AEnc : 2.3340e-02 	 MSE : 2.5599e+01
Epoch 65, 50% 	 Loss : 1.0226e-01 	 Res : 3.9334e-02 	 Jac : 2.5642e-02 	 Enc : 3.1295e-03 	 AEnc : 2.2079e-02 	 MSE : 1.2077e+01
Epoch 65, 75% 	 Loss : 1.2095e-01 	 Res : 4.2542e-02 	 Jac : 2.6325e-02 	 Enc : 3.0116e-03 	 AEnc : 3.7040e-02 	 MSE : 1.2030e+01
Training Epoch 65 : 	 Train : 3.65105e-01 	 Res : 2.89767e-01 	 Jac : 2.62195e-02 	 Enc : 3.35681e-03 	 AE : 2.47321e-02 	 MSE : 2.10294e+01
Validation Epoch 65 : 	 Train : 1.39043e-01 	 Res : 7.77501e-02 	 Jac : 1.99108e-02 	 Enc : 3.34760e-03 	 AE : 1.32369e-02 	 MSE : 2.47973e+01
Training Epoch 65 finished, took current epoch 410.11s, cumulative time 27564.35s
Current Learning rate DEQ : 0.0024499999999999995
Current Learning rate AUTOENC : 0.004899999999999999
Epoch 66, 25% 	 Loss : 1.2759e-01 	 Res : 4.8740e-02 	 Jac : 2.5848e-02 	 Enc : 3.7252e-03 	 AEnc : 3.6522e-02 	 MSE : 1.2751e+01
Epoch 66, 50% 	 Loss : 7.4866e-02 	 Res : 2.6429e-02 	 Jac : 2.7683e-02 	 Enc : 3.0975e-03 	 AEnc : 8.6882e-03 	 MSE : 8.9681e+00
Epoch 66, 75% 	 Loss : 8.4610e-02 	 Res : 4.0211e-02 	 Jac : 2.6876e-02 	 Enc : 3.2734e-03 	 AEnc : 2.3322e-03 	 MSE : 1.1918e+01
Training Epoch 66 : 	 Train : 9.02839e-02 	 Res : 3.71840e-02 	 Jac : 2.63219e-02 	 Enc : 3.25045e-03 	 AE : 1.27231e-02 	 MSE : 1.08045e+01
Validation Epoch 66 : 	 Train : 5.02638e-02 	 Res : 1.81756e-02 	 Jac : 2.30154e-02 	 Enc : 2.95013e-03 	 AE : 3.03891e-04 	 MSE : 5.81875e+00
Training Epoch 66 finished, took current epoch 438.26s, cumulative time 28002.58s
Current Learning rate DEQ : 0.0024499999999999995
Current Learning rate AUTOENC : 0.004899999999999999
MODEL SAVED
Epoch 67, 25% 	 Loss : 8.9118e-02 	 Res : 4.7173e-02 	 Jac : 2.2796e-02 	 Enc : 3.2049e-03 	 AEnc : 1.7367e-03 	 MSE : 1.4207e+01
Epoch 67, 50% 	 Loss : 1.3499e-01 	 Res : 8.8786e-02 	 Jac : 2.3903e-02 	 Enc : 3.1506e-03 	 AEnc : 1.4913e-03 	 MSE : 1.7661e+01
Epoch 67, 75% 	 Loss : 8.7261e-02 	 Res : 3.8594e-02 	 Jac : 2.3315e-02 	 Enc : 3.1982e-03 	 AEnc : 1.2528e-02 	 MSE : 9.6265e+00
Training Epoch 67 : 	 Train : 9.37895e-02 	 Res : 4.93720e-02 	 Jac : 2.33410e-02 	 Enc : 3.11694e-03 	 AE : 5.63853e-03 	 MSE : 1.23210e+01
Validation Epoch 67 : 	 Train : 5.62123e-02 	 Res : 1.61033e-02 	 Jac : 2.37003e-02 	 Enc : 2.73533e-03 	 AE : 7.97896e-03 	 MSE : 5.69445e+00
Training Epoch 67 finished, took current epoch 442.11s, cumulative time 28444.67s
Current Learning rate DEQ : 0.0024499999999999995
Current Learning rate AUTOENC : 0.004899999999999999
MODEL SAVED
Epoch 68, 25% 	 Loss : 4.9948e-02 	 Res : 1.4440e-02 	 Jac : 2.4317e-02 	 Enc : 2.8669e-03 	 AEnc : 2.7294e-03 	 MSE : 5.5956e+00
Epoch 68, 50% 	 Loss : 5.7816e-02 	 Res : 2.2692e-02 	 Jac : 2.5318e-02 	 Enc : 2.8225e-03 	 AEnc : 3.6348e-04 	 MSE : 6.6211e+00
Epoch 68, 75% 	 Loss : 7.2929e-02 	 Res : 3.0283e-02 	 Jac : 2.2231e-02 	 Enc : 3.0869e-03 	 AEnc : 8.9182e-03 	 MSE : 8.4087e+00
Training Epoch 68 : 	 Train : 5.96878e-02 	 Res : 2.29277e-02 	 Jac : 2.33082e-02 	 Enc : 2.90825e-03 	 AE : 3.16172e-03 	 MSE : 7.38187e+00
Validation Epoch 68 : 	 Train : 5.25084e-02 	 Res : 2.27969e-02 	 Jac : 2.22723e-02 	 Enc : 2.93367e-03 	 AE : 6.40731e-04 	 MSE : 3.86487e+00
Training Epoch 68 finished, took current epoch 477.52s, cumulative time 28922.17s
Current Learning rate DEQ : 0.0024499999999999995
Current Learning rate AUTOENC : 0.004899999999999999
Epoch 69, 25% 	 Loss : 5.8238e-02 	 Res : 2.4365e-02 	 Jac : 2.1169e-02 	 Enc : 2.8918e-03 	 AEnc : 1.8265e-03 	 MSE : 7.9865e+00
Epoch 69, 50% 	 Loss : 9.8269e-02 	 Res : 4.8281e-02 	 Jac : 2.1980e-02 	 Enc : 3.0652e-03 	 AEnc : 1.1122e-02 	 MSE : 1.3821e+01
Epoch 69, 75% 	 Loss : 1.2341e-01 	 Res : 5.2421e-02 	 Jac : 2.0496e-02 	 Enc : 3.1017e-03 	 AEnc : 3.3612e-02 	 MSE : 1.3778e+01
Training Epoch 69 : 	 Train : 8.89590e-02 	 Res : 3.98016e-02 	 Jac : 2.12328e-02 	 Enc : 3.01678e-03 	 AE : 1.35121e-02 	 MSE : 1.13956e+01
Validation Epoch 69 : 	 Train : 5.27041e-02 	 Res : 1.91631e-02 	 Jac : 2.04408e-02 	 Enc : 2.55672e-03 	 AE : 1.15220e-03 	 MSE : 9.39133e+00
Training Epoch 69 finished, took current epoch 439.76s, cumulative time 29361.91s
Current Learning rate DEQ : 0.0024499999999999995
Current Learning rate AUTOENC : 0.004899999999999999
Epoch 70, 25% 	 Loss : 8.2303e-02 	 Res : 3.8758e-02 	 Jac : 2.0890e-02 	 Enc : 2.8591e-03 	 AEnc : 6.9459e-03 	 MSE : 1.2850e+01
Epoch 70, 50% 	 Loss : 9.8028e-02 	 Res : 4.9033e-02 	 Jac : 2.1206e-02 	 Enc : 2.9271e-03 	 AEnc : 1.5103e-02 	 MSE : 9.7592e+00
Epoch 70, 75% 	 Loss : 5.5758e-02 	 Res : 2.0783e-02 	 Jac : 2.1325e-02 	 Enc : 2.9090e-03 	 AEnc : 3.9234e-03 	 MSE : 6.8183e+00
Training Epoch 70 : 	 Train : 7.48059e-02 	 Res : 3.40842e-02 	 Jac : 2.11768e-02 	 Enc : 2.86186e-03 	 AE : 6.66881e-03 	 MSE : 1.00142e+01
Validation Epoch 70 : 	 Train : 5.02258e-02 	 Res : 1.85950e-02 	 Jac : 2.03630e-02 	 Enc : 2.69817e-03 	 AE : 5.17965e-04 	 MSE : 8.05171e+00
Training Epoch 70 finished, took current epoch 437.40s, cumulative time 29799.28s
Current Learning rate DEQ : 0.0024499999999999995
Current Learning rate AUTOENC : 0.004899999999999999
Epoch 71, 25% 	 Loss : 5.9877e-02 	 Res : 2.4867e-02 	 Jac : 2.1771e-02 	 Enc : 2.9328e-03 	 AEnc : 2.8800e-04 	 MSE : 1.0018e+01
Epoch 71, 50% 	 Loss : 6.0967e-02 	 Res : 2.6927e-02 	 Jac : 2.1411e-02 	 Enc : 2.7765e-03 	 AEnc : 1.2504e-03 	 MSE : 8.6024e+00
Epoch 71, 75% 	 Loss : 8.0246e-02 	 Res : 4.2277e-02 	 Jac : 2.0814e-02 	 Enc : 2.8932e-03 	 AEnc : 1.7923e-03 	 MSE : 1.2470e+01
Training Epoch 71 : 	 Train : 1.22596e-01 	 Res : 7.79051e-02 	 Jac : 2.13813e-02 	 Enc : 2.96130e-03 	 AE : 5.51299e-03 	 MSE : 1.48350e+01
Validation Epoch 71 : 	 Train : 1.78437e-01 	 Res : 1.01089e-01 	 Jac : 2.07212e-02 	 Enc : 3.11270e-03 	 AE : 1.44108e-02 	 MSE : 3.91027e+01
Training Epoch 71 finished, took current epoch 441.75s, cumulative time 30241.01s
Current Learning rate DEQ : 0.0024499999999999995
Current Learning rate AUTOENC : 0.004899999999999999
Epoch 72, 25% 	 Loss : 8.8865e-02 	 Res : 4.4598e-02 	 Jac : 2.0110e-02 	 Enc : 2.9553e-03 	 AEnc : 7.4353e-03 	 MSE : 1.3766e+01
Epoch 72, 50% 	 Loss : 7.8023e-02 	 Res : 3.4527e-02 	 Jac : 2.0955e-02 	 Enc : 2.7277e-03 	 AEnc : 3.8271e-03 	 MSE : 1.5986e+01
Epoch 72, 75% 	 Loss : 2.7019e-01 	 Res : 2.1038e-01 	 Jac : 2.4232e-02 	 Enc : 3.1363e-03 	 AEnc : 9.4923e-03 	 MSE : 2.2952e+01
Training Epoch 72 : 	 Train : 1.45071e-01 	 Res : 9.45367e-02 	 Jac : 2.15949e-02 	 Enc : 3.03244e-03 	 AE : 7.57362e-03 	 MSE : 1.83331e+01
Validation Epoch 72 : 	 Train : 1.06396e-01 	 Res : 3.11194e-02 	 Jac : 2.15819e-02 	 Enc : 2.80144e-03 	 AE : 4.25787e-02 	 MSE : 8.31499e+00
Training Epoch 72 finished, took current epoch 449.75s, cumulative time 30690.72s
Current Learning rate DEQ : 0.0024499999999999995
Current Learning rate AUTOENC : 0.004899999999999999
Epoch 73, 25% 	 Loss : 1.0939e-01 	 Res : 5.3777e-02 	 Jac : 2.2087e-02 	 Enc : 2.6516e-03 	 AEnc : 1.5144e-02 	 MSE : 1.5734e+01
Epoch 73, 50% 	 Loss : 1.0935e-01 	 Res : 6.0297e-02 	 Jac : 2.2054e-02 	 Enc : 2.7700e-03 	 AEnc : 6.8100e-03 	 MSE : 1.7423e+01
Epoch 73, 75% 	 Loss : 7.5273e-02 	 Res : 3.7184e-02 	 Jac : 2.2448e-02 	 Enc : 2.6469e-03 	 AEnc : 7.5241e-04 	 MSE : 1.2241e+01
Training Epoch 73 : 	 Train : 8.83962e-02 	 Res : 4.27146e-02 	 Jac : 2.22327e-02 	 Enc : 2.67404e-03 	 AE : 7.61060e-03 	 MSE : 1.31642e+01
Validation Epoch 73 : 	 Train : 7.39838e-02 	 Res : 1.94302e-02 	 Jac : 2.25003e-02 	 Enc : 2.66534e-03 	 AE : 2.34053e-02 	 MSE : 5.98259e+00
Training Epoch 73 finished, took current epoch 437.11s, cumulative time 31127.78s
Current Learning rate DEQ : 0.0024499999999999995
Current Learning rate AUTOENC : 0.004899999999999999
Epoch 74, 25% 	 Loss : 8.7425e-02 	 Res : 2.3713e-02 	 Jac : 2.2328e-02 	 Enc : 2.5298e-03 	 AEnc : 3.1899e-02 	 MSE : 6.9550e+00
Epoch 74, 50% 	 Loss : 1.0029e-01 	 Res : 5.1996e-02 	 Jac : 2.2301e-02 	 Enc : 2.7668e-03 	 AEnc : 8.1617e-03 	 MSE : 1.5063e+01
Epoch 74, 75% 	 Loss : 7.5107e-02 	 Res : 2.4328e-02 	 Jac : 2.1201e-02 	 Enc : 2.6293e-03 	 AEnc : 1.9443e-02 	 MSE : 7.5055e+00
Training Epoch 74 : 	 Train : 8.69428e-02 	 Res : 3.34994e-02 	 Jac : 2.16410e-02 	 Enc : 2.74406e-03 	 AE : 1.90699e-02 	 MSE : 9.98841e+00
Validation Epoch 74 : 	 Train : 5.99628e-02 	 Res : 2.23568e-02 	 Jac : 1.98041e-02 	 Enc : 2.98182e-03 	 AE : 2.12456e-03 	 MSE : 1.26955e+01
Training Epoch 74 finished, took current epoch 431.05s, cumulative time 31558.79s
Current Learning rate DEQ : 0.0024499999999999995
Current Learning rate AUTOENC : 0.004899999999999999
Epoch 75, 25% 	 Loss : 6.2967e-02 	 Res : 2.3629e-02 	 Jac : 2.0460e-02 	 Enc : 2.7104e-03 	 AEnc : 6.5184e-03 	 MSE : 9.6496e+00
Epoch 75, 50% 	 Loss : 1.5894e-01 	 Res : 9.9630e-02 	 Jac : 2.1332e-02 	 Enc : 3.1174e-03 	 AEnc : 1.8823e-02 	 MSE : 1.6042e+01
Epoch 75, 75% 	 Loss : 2.6410e-01 	 Res : 1.6236e-01 	 Jac : 2.2086e-02 	 Enc : 3.4731e-03 	 AEnc : 5.8014e-02 	 MSE : 1.8170e+01
Training Epoch 75 : 	 Train : 1.55951e-01 	 Res : 9.26438e-02 	 Jac : 2.12557e-02 	 Enc : 3.02218e-03 	 AE : 2.43908e-02 	 MSE : 1.46383e+01
Validation Epoch 75 : 	 Train : 7.89389e-02 	 Res : 2.78573e-02 	 Jac : 1.89523e-02 	 Enc : 2.69431e-03 	 AE : 1.58004e-02 	 MSE : 1.36346e+01
Training Epoch 75 finished, took current epoch 451.59s, cumulative time 32010.34s
Current Learning rate DEQ : 0.0024499999999999995
Current Learning rate AUTOENC : 0.004899999999999999
Epoch 76, 25% 	 Loss : 1.0067e-01 	 Res : 4.3447e-02 	 Jac : 2.1303e-02 	 Enc : 2.9046e-03 	 AEnc : 1.8169e-02 	 MSE : 1.4848e+01
Epoch 76, 50% 	 Loss : 6.8141e-02 	 Res : 2.5102e-02 	 Jac : 2.2711e-02 	 Enc : 2.8253e-03 	 AEnc : 8.1850e-03 	 MSE : 9.3175e+00
Epoch 76, 75% 	 Loss : 6.2027e-02 	 Res : 2.5969e-02 	 Jac : 2.1591e-02 	 Enc : 2.7087e-03 	 AEnc : 2.7308e-03 	 MSE : 9.0270e+00
Training Epoch 76 : 	 Train : 7.38487e-02 	 Res : 3.07937e-02 	 Jac : 2.15987e-02 	 Enc : 2.84764e-03 	 AE : 7.81704e-03 	 MSE : 1.07917e+01
Validation Epoch 76 : 	 Train : 7.88171e-02 	 Res : 4.32950e-02 	 Jac : 2.16797e-02 	 Enc : 3.33589e-03 	 AE : 2.89169e-04 	 MSE : 1.02173e+01
Training Epoch 76 finished, took current epoch 470.68s, cumulative time 32481.01s
Current Learning rate DEQ : 0.0024499999999999995
Current Learning rate AUTOENC : 0.004899999999999999
Epoch 77, 25% 	 Loss : 8.0785e-02 	 Res : 4.5320e-02 	 Jac : 2.0998e-02 	 Enc : 2.9304e-03 	 AEnc : 4.1715e-04 	 MSE : 1.1120e+01
Epoch 77, 50% 	 Loss : 8.4817e-02 	 Res : 4.3912e-02 	 Jac : 2.0232e-02 	 Enc : 2.7670e-03 	 AEnc : 9.0190e-04 	 MSE : 1.7004e+01
Epoch 77, 75% 	 Loss : 8.6924e-02 	 Res : 4.6209e-02 	 Jac : 2.1099e-02 	 Enc : 2.8631e-03 	 AEnc : 9.7413e-04 	 MSE : 1.5779e+01
Training Epoch 77 : 	 Train : 7.99998e-02 	 Res : 4.24267e-02 	 Jac : 2.06324e-02 	 Enc : 2.81188e-03 	 AE : 9.74960e-04 	 MSE : 1.31539e+01
Validation Epoch 77 : 	 Train : 7.38864e-02 	 Res : 3.38094e-02 	 Jac : 1.92568e-02 	 Enc : 2.61602e-03 	 AE : 3.39966e-03 	 MSE : 1.48046e+01
Training Epoch 77 finished, took current epoch 465.54s, cumulative time 32946.50s
Current Learning rate DEQ : 0.0024499999999999995
Current Learning rate AUTOENC : 0.004899999999999999
Epoch 78, 25% 	 Loss : 6.3254e-02 	 Res : 2.7947e-02 	 Jac : 2.0043e-02 	 Enc : 2.8794e-03 	 AEnc : 3.5136e-03 	 MSE : 8.8707e+00
Epoch 78, 50% 	 Loss : 1.0582e-01 	 Res : 6.7060e-02 	 Jac : 2.1112e-02 	 Enc : 3.0396e-03 	 AEnc : 2.6435e-03 	 MSE : 1.1964e+01
Epoch 78, 75% 	 Loss : 6.3389e-02 	 Res : 2.6776e-02 	 Jac : 2.0617e-02 	 Enc : 2.8440e-03 	 AEnc : 1.0183e-03 	 MSE : 1.2133e+01
Training Epoch 78 : 	 Train : 8.55762e-02 	 Res : 4.85672e-02 	 Jac : 2.08568e-02 	 Enc : 2.86488e-03 	 AE : 1.93511e-03 	 MSE : 1.13522e+01
Validation Epoch 78 : 	 Train : 7.21416e-02 	 Res : 3.46461e-02 	 Jac : 2.26196e-02 	 Enc : 3.07517e-03 	 AE : 6.28299e-04 	 MSE : 1.11724e+01
Training Epoch 78 finished, took current epoch 475.79s, cumulative time 33422.27s
Current Learning rate DEQ : 0.0024499999999999995
Current Learning rate AUTOENC : 0.004899999999999999
Epoch 79, 25% 	 Loss : 1.4973e-01 	 Res : 5.8242e-02 	 Jac : 2.0400e-02 	 Enc : 2.8666e-03 	 AEnc : 5.5997e-02 	 MSE : 1.2224e+01
Epoch 79, 50% 	 Loss : 1.0806e-01 	 Res : 3.5713e-02 	 Jac : 2.0431e-02 	 Enc : 2.9071e-03 	 AEnc : 3.5981e-02 	 MSE : 1.3025e+01
Epoch 79, 75% 	 Loss : 8.7087e-02 	 Res : 4.3199e-02 	 Jac : 2.1099e-02 	 Enc : 2.9453e-03 	 AEnc : 7.5330e-03 	 MSE : 1.2311e+01
Training Epoch 79 : 	 Train : 1.05163e-01 	 Res : 4.28394e-02 	 Jac : 2.04643e-02 	 Enc : 2.86786e-03 	 AE : 2.63183e-02 	 MSE : 1.26734e+01
Validation Epoch 79 : 	 Train : 6.49640e-02 	 Res : 2.61225e-02 	 Jac : 2.14157e-02 	 Enc : 3.10093e-03 	 AE : 4.04093e-03 	 MSE : 1.02840e+01
Training Epoch 79 finished, took current epoch 464.65s, cumulative time 33886.91s
Current Learning rate DEQ : 0.0024499999999999995
Current Learning rate AUTOENC : 0.004899999999999999
Epoch 80, 25% 	 Loss : 4.1042e-01 	 Res : 3.6286e-01 	 Jac : 2.3174e-02 	 Enc : 3.0476e-03 	 AEnc : 1.5609e-03 	 MSE : 1.9770e+01
Epoch 80, 50% 	 Loss : 7.9833e-01 	 Res : 7.3593e-01 	 Jac : 2.2267e-02 	 Enc : 3.9143e-03 	 AEnc : 6.6468e-03 	 MSE : 2.9569e+01
Epoch 80, 75% 	 Loss : 1.0933e-01 	 Res : 4.2953e-02 	 Jac : 2.2646e-02 	 Enc : 3.3166e-03 	 AEnc : 2.9858e-02 	 MSE : 1.0555e+01
Training Epoch 80 : 	 Train : 3.52287e-01 	 Res : 2.95792e-01 	 Jac : 2.26759e-02 	 Enc : 3.31405e-03 	 AE : 1.28900e-02 	 MSE : 1.76154e+01
Validation Epoch 80 : 	 Train : 6.31363e-02 	 Res : 2.51470e-02 	 Jac : 2.09913e-02 	 Enc : 2.67439e-03 	 AE : 5.95543e-04 	 MSE : 1.37280e+01
Training Epoch 80 finished, took current epoch 446.41s, cumulative time 34333.26s
Current Learning rate DEQ : 0.0024499999999999995
Current Learning rate AUTOENC : 0.004899999999999999
Epoch 81, 25% 	 Loss : 1.1486e-01 	 Res : 6.9290e-02 	 Jac : 2.1210e-02 	 Enc : 2.7742e-03 	 AEnc : 3.5598e-03 	 MSE : 1.8028e+01
Epoch 81, 50% 	 Loss : 8.9112e-02 	 Res : 4.6959e-02 	 Jac : 1.9988e-02 	 Enc : 3.1883e-03 	 AEnc : 1.7561e-03 	 MSE : 1.7220e+01
Epoch 81, 75% 	 Loss : 8.7626e-02 	 Res : 5.1036e-02 	 Jac : 2.0372e-02 	 Enc : 2.8485e-03 	 AEnc : 6.2104e-04 	 MSE : 1.2748e+01
Training Epoch 81 : 	 Train : 9.81692e-02 	 Res : 5.65531e-02 	 Jac : 2.04082e-02 	 Enc : 2.93361e-03 	 AE : 2.27941e-03 	 MSE : 1.59949e+01
Validation Epoch 81 : 	 Train : 8.47168e-02 	 Res : 4.77115e-02 	 Jac : 2.21899e-02 	 Enc : 2.93772e-03 	 AE : 9.02912e-04 	 MSE : 1.09747e+01
Training Epoch 81 finished, took current epoch 493.34s, cumulative time 34826.57s
Current Learning rate DEQ : 0.0017149999999999995
Current Learning rate AUTOENC : 0.003429999999999999
Epoch 82, 25% 	 Loss : 8.8794e-02 	 Res : 4.6783e-02 	 Jac : 2.1361e-02 	 Enc : 2.8686e-03 	 AEnc : 3.7523e-03 	 MSE : 1.4029e+01
Epoch 82, 50% 	 Loss : 7.4681e-02 	 Res : 3.4968e-02 	 Jac : 2.0255e-02 	 Enc : 2.5998e-03 	 AEnc : 2.9661e-03 	 MSE : 1.3893e+01
Epoch 82, 75% 	 Loss : 6.9175e-02 	 Res : 2.2821e-02 	 Jac : 2.1278e-02 	 Enc : 2.6471e-03 	 AEnc : 1.4524e-02 	 MSE : 7.9040e+00
Training Epoch 82 : 	 Train : 7.30233e-02 	 Res : 3.13107e-02 	 Jac : 2.08905e-02 	 Enc : 2.68993e-03 	 AE : 7.55504e-03 	 MSE : 1.05771e+01
Validation Epoch 82 : 	 Train : 4.21113e-02 	 Res : 1.47402e-02 	 Jac : 2.06130e-02 	 Enc : 2.88890e-03 	 AE : 4.12993e-04 	 MSE : 3.45619e+00
Training Epoch 82 finished, took current epoch 475.93s, cumulative time 35302.45s
Current Learning rate DEQ : 0.0017149999999999995
Current Learning rate AUTOENC : 0.003429999999999999
MODEL SAVED
Epoch 83, 25% 	 Loss : 5.6586e-02 	 Res : 2.2995e-02 	 Jac : 1.9931e-02 	 Enc : 2.6265e-03 	 AEnc : 5.6155e-04 	 MSE : 1.0472e+01
Epoch 83, 50% 	 Loss : 7.4719e-02 	 Res : 3.7623e-02 	 Jac : 2.0679e-02 	 Enc : 2.8152e-03 	 AEnc : 3.2922e-04 	 MSE : 1.3272e+01
Epoch 83, 75% 	 Loss : 4.5535e-02 	 Res : 1.5629e-02 	 Jac : 1.9609e-02 	 Enc : 2.6540e-03 	 AEnc : 1.5552e-03 	 MSE : 6.0881e+00
Training Epoch 83 : 	 Train : 5.73066e-02 	 Res : 2.42467e-02 	 Jac : 2.00723e-02 	 Enc : 2.69183e-03 	 AE : 8.72033e-04 	 MSE : 9.42367e+00
Validation Epoch 83 : 	 Train : 3.85949e-02 	 Res : 1.06546e-02 	 Jac : 1.99402e-02 	 Enc : 2.61429e-03 	 AE : 1.95417e-04 	 MSE : 5.19049e+00
Training Epoch 83 finished, took current epoch 456.03s, cumulative time 35758.44s
Current Learning rate DEQ : 0.0017149999999999995
Current Learning rate AUTOENC : 0.003429999999999999
MODEL SAVED
Epoch 84, 25% 	 Loss : 5.0443e-02 	 Res : 2.0064e-02 	 Jac : 1.9710e-02 	 Enc : 2.7861e-03 	 AEnc : 5.9775e-04 	 MSE : 7.2849e+00
Epoch 84, 50% 	 Loss : 8.9495e-02 	 Res : 3.5995e-02 	 Jac : 1.9784e-02 	 Enc : 2.7366e-03 	 AEnc : 2.2822e-02 	 MSE : 8.1573e+00
Epoch 84, 75% 	 Loss : 7.9804e-02 	 Res : 2.2830e-02 	 Jac : 1.8993e-02 	 Enc : 2.6945e-03 	 AEnc : 2.7776e-02 	 MSE : 7.5100e+00
Training Epoch 84 : 	 Train : 7.44746e-02 	 Res : 2.87921e-02 	 Jac : 1.97391e-02 	 Enc : 2.79688e-03 	 AE : 1.52932e-02 	 MSE : 7.85335e+00
Validation Epoch 84 : 	 Train : 6.40837e-02 	 Res : 2.20548e-02 	 Jac : 1.77472e-02 	 Enc : 2.32930e-03 	 AE : 1.03881e-02 	 MSE : 1.15643e+01
Training Epoch 84 finished, took current epoch 469.18s, cumulative time 36227.60s
Current Learning rate DEQ : 0.0017149999999999995
Current Learning rate AUTOENC : 0.003429999999999999
Epoch 85, 25% 	 Loss : 6.6406e-02 	 Res : 2.7813e-02 	 Jac : 1.8649e-02 	 Enc : 2.8049e-03 	 AEnc : 8.4264e-03 	 MSE : 8.7122e+00
Epoch 85, 50% 	 Loss : 9.4992e-02 	 Res : 3.1131e-02 	 Jac : 1.9009e-02 	 Enc : 2.7480e-03 	 AEnc : 3.4568e-02 	 MSE : 7.5362e+00
Epoch 85, 75% 	 Loss : 7.9511e-02 	 Res : 2.8321e-02 	 Jac : 1.8890e-02 	 Enc : 2.7720e-03 	 AEnc : 1.9141e-02 	 MSE : 1.0387e+01
Training Epoch 85 : 	 Train : 7.51816e-02 	 Res : 2.65127e-02 	 Jac : 1.88838e-02 	 Enc : 2.77043e-03 	 AE : 1.83785e-02 	 MSE : 8.63618e+00
Validation Epoch 85 : 	 Train : 8.33084e-02 	 Res : 3.31422e-02 	 Jac : 1.96172e-02 	 Enc : 2.35180e-03 	 AE : 1.39313e-02 	 MSE : 1.42659e+01
Training Epoch 85 finished, took current epoch 465.02s, cumulative time 36692.61s
Current Learning rate DEQ : 0.0017149999999999995
Current Learning rate AUTOENC : 0.003429999999999999
Epoch 86, 25% 	 Loss : 5.3210e-02 	 Res : 1.9431e-02 	 Jac : 1.9328e-02 	 Enc : 2.6443e-03 	 AEnc : 3.3672e-03 	 MSE : 8.4392e+00
Epoch 86, 50% 	 Loss : 6.2860e-02 	 Res : 2.9472e-02 	 Jac : 1.9545e-02 	 Enc : 2.6892e-03 	 AEnc : 1.0148e-03 	 MSE : 1.0139e+01
Epoch 86, 75% 	 Loss : 8.6446e-02 	 Res : 4.9192e-02 	 Jac : 1.9300e-02 	 Enc : 2.8521e-03 	 AEnc : 5.6419e-04 	 MSE : 1.4537e+01
Training Epoch 86 : 	 Train : 6.32701e-02 	 Res : 2.97817e-02 	 Jac : 1.92863e-02 	 Enc : 2.73617e-03 	 AE : 1.56532e-03 	 MSE : 9.90061e+00
Validation Epoch 86 : 	 Train : 4.02295e-02 	 Res : 1.33773e-02 	 Jac : 1.87001e-02 	 Enc : 2.70944e-03 	 AE : 1.39743e-03 	 MSE : 4.04527e+00
Training Epoch 86 finished, took current epoch 458.18s, cumulative time 37150.77s
Current Learning rate DEQ : 0.0017149999999999995
Current Learning rate AUTOENC : 0.003429999999999999
Epoch 87, 25% 	 Loss : 7.5126e-02 	 Res : 3.7620e-02 	 Jac : 1.8886e-02 	 Enc : 2.7993e-03 	 AEnc : 3.1960e-03 	 MSE : 1.2624e+01
Epoch 87, 50% 	 Loss : 6.5675e-02 	 Res : 3.2512e-02 	 Jac : 1.9189e-02 	 Enc : 2.7945e-03 	 AEnc : 2.4350e-03 	 MSE : 8.7446e+00
Epoch 87, 75% 	 Loss : 6.3848e-02 	 Res : 3.0813e-02 	 Jac : 1.8971e-02 	 Enc : 2.7742e-03 	 AEnc : 1.3408e-03 	 MSE : 9.9485e+00
Training Epoch 87 : 	 Train : 6.33503e-02 	 Res : 2.99596e-02 	 Jac : 1.89014e-02 	 Enc : 2.76194e-03 	 AE : 2.05760e-03 	 MSE : 9.66981e+00
Validation Epoch 87 : 	 Train : 5.54308e-02 	 Res : 2.13139e-02 	 Jac : 1.74591e-02 	 Enc : 2.56453e-03 	 AE : 1.46380e-03 	 MSE : 1.26295e+01
Training Epoch 87 finished, took current epoch 460.14s, cumulative time 37610.88s
Current Learning rate DEQ : 0.0017149999999999995
Current Learning rate AUTOENC : 0.003429999999999999
Epoch 88, 25% 	 Loss : 5.1252e-02 	 Res : 1.9979e-02 	 Jac : 1.8518e-02 	 Enc : 2.6603e-03 	 AEnc : 6.1881e-04 	 MSE : 9.4757e+00
Epoch 88, 50% 	 Loss : 5.0721e-02 	 Res : 2.1107e-02 	 Jac : 1.9184e-02 	 Enc : 2.6719e-03 	 AEnc : 1.8979e-04 	 MSE : 7.5684e+00
Epoch 88, 75% 	 Loss : 1.5971e-01 	 Res : 1.1469e-01 	 Jac : 1.9404e-02 	 Enc : 2.8432e-03 	 AEnc : 2.8137e-04 	 MSE : 2.2492e+01
Training Epoch 88 : 	 Train : 8.20966e-02 	 Res : 4.67187e-02 	 Jac : 1.89115e-02 	 Enc : 2.75568e-03 	 AE : 6.84538e-04 	 MSE : 1.30262e+01
Validation Epoch 88 : 	 Train : 4.44667e-02 	 Res : 1.49855e-02 	 Jac : 1.90320e-02 	 Enc : 2.59459e-03 	 AE : 2.12297e-03 	 MSE : 5.73168e+00
Training Epoch 88 finished, took current epoch 459.43s, cumulative time 38070.26s
Current Learning rate DEQ : 0.0017149999999999995
Current Learning rate AUTOENC : 0.003429999999999999
Epoch 89, 25% 	 Loss : 1.0483e-01 	 Res : 6.9306e-02 	 Jac : 2.0305e-02 	 Enc : 2.6914e-03 	 AEnc : 8.2659e-04 	 MSE : 1.1698e+01
Epoch 89, 50% 	 Loss : 5.5916e-02 	 Res : 2.3385e-02 	 Jac : 1.8957e-02 	 Enc : 2.5937e-03 	 AEnc : 7.8574e-04 	 MSE : 1.0195e+01
Epoch 89, 75% 	 Loss : 4.9782e-02 	 Res : 1.9140e-02 	 Jac : 1.9695e-02 	 Enc : 2.5899e-03 	 AEnc : 5.9503e-04 	 MSE : 7.7620e+00
Training Epoch 89 : 	 Train : 6.48991e-02 	 Res : 3.26237e-02 	 Jac : 1.96103e-02 	 Enc : 2.63532e-03 	 AE : 6.61167e-04 	 MSE : 9.36855e+00
Validation Epoch 89 : 	 Train : 4.35771e-02 	 Res : 1.49579e-02 	 Jac : 2.01285e-02 	 Enc : 2.87690e-03 	 AE : 4.51659e-04 	 MSE : 5.16216e+00
Training Epoch 89 finished, took current epoch 457.30s, cumulative time 38527.52s
Current Learning rate DEQ : 0.0017149999999999995
Current Learning rate AUTOENC : 0.003429999999999999
Epoch 90, 25% 	 Loss : 5.3272e-02 	 Res : 2.1860e-02 	 Jac : 1.9701e-02 	 Enc : 2.6734e-03 	 AEnc : 6.9265e-04 	 MSE : 8.3449e+00
Epoch 90, 50% 	 Loss : 5.7137e-02 	 Res : 2.3985e-02 	 Jac : 1.8882e-02 	 Enc : 2.6827e-03 	 AEnc : 1.3094e-03 	 MSE : 1.0278e+01
Epoch 90, 75% 	 Loss : 5.7781e-02 	 Res : 2.5051e-02 	 Jac : 1.9007e-02 	 Enc : 2.6435e-03 	 AEnc : 1.1731e-03 	 MSE : 9.9074e+00
Training Epoch 90 : 	 Train : 5.41554e-02 	 Res : 2.24517e-02 	 Jac : 1.90440e-02 	 Enc : 2.67007e-03 	 AE : 1.06643e-03 	 MSE : 8.92321e+00
Validation Epoch 90 : 	 Train : 5.46172e-02 	 Res : 2.65894e-02 	 Jac : 1.78422e-02 	 Enc : 2.56006e-03 	 AE : 3.54022e-04 	 MSE : 7.27155e+00
Training Epoch 90 finished, took current epoch 448.70s, cumulative time 38976.20s
Current Learning rate DEQ : 0.0017149999999999995
Current Learning rate AUTOENC : 0.003429999999999999
Epoch 91, 25% 	 Loss : 5.2863e-02 	 Res : 2.5200e-02 	 Jac : 1.8379e-02 	 Enc : 2.5920e-03 	 AEnc : 7.5144e-04 	 MSE : 5.9404e+00
Epoch 91, 50% 	 Loss : 1.1226e-01 	 Res : 7.4452e-02 	 Jac : 1.8934e-02 	 Enc : 2.6959e-03 	 AEnc : 1.8098e-03 	 MSE : 1.4363e+01
Epoch 91, 75% 	 Loss : 1.1732e-01 	 Res : 7.8475e-02 	 Jac : 1.8377e-02 	 Enc : 3.1023e-03 	 AEnc : 1.6186e-03 	 MSE : 1.5749e+01
Training Epoch 91 : 	 Train : 9.39605e-02 	 Res : 5.67622e-02 	 Jac : 1.85195e-02 	 Enc : 2.83555e-03 	 AE : 2.81962e-03 	 MSE : 1.30237e+01
Validation Epoch 91 : 	 Train : 1.70099e-01 	 Res : 1.06983e-01 	 Jac : 2.09924e-02 	 Enc : 3.93299e-03 	 AE : 7.74862e-03 	 MSE : 3.04418e+01
Training Epoch 91 finished, took current epoch 521.10s, cumulative time 39497.27s
Current Learning rate DEQ : 0.0017149999999999995
Current Learning rate AUTOENC : 0.003429999999999999
Epoch 92, 25% 	 Loss : 2.0622e-01 	 Res : 1.0299e-01 	 Jac : 1.8948e-02 	 Enc : 3.1182e-03 	 AEnc : 6.3992e-02 	 MSE : 1.7170e+01
Epoch 92, 50% 	 Loss : 8.7714e-02 	 Res : 2.3226e-02 	 Jac : 1.8827e-02 	 Enc : 2.7631e-03 	 AEnc : 3.4892e-02 	 MSE : 8.0065e+00
Epoch 92, 75% 	 Loss : 1.1177e-01 	 Res : 6.5507e-02 	 Jac : 1.9855e-02 	 Enc : 2.7200e-03 	 AEnc : 1.1017e-02 	 MSE : 1.2667e+01
Training Epoch 92 : 	 Train : 1.19197e-01 	 Res : 5.53509e-02 	 Jac : 1.90582e-02 	 Enc : 2.86339e-03 	 AE : 3.03577e-02 	 MSE : 1.15664e+01
Validation Epoch 92 : 	 Train : 5.53227e-02 	 Res : 1.49540e-02 	 Jac : 1.79693e-02 	 Enc : 2.55348e-03 	 AE : 1.10922e-02 	 MSE : 8.75377e+00
Training Epoch 92 finished, took current epoch 470.90s, cumulative time 39968.16s
Current Learning rate DEQ : 0.0017149999999999995
Current Learning rate AUTOENC : 0.003429999999999999
Epoch 93, 25% 	 Loss : 1.0631e-01 	 Res : 3.6446e-02 	 Jac : 1.9015e-02 	 Enc : 2.8030e-03 	 AEnc : 3.8836e-02 	 MSE : 9.2106e+00
Epoch 93, 50% 	 Loss : 8.2551e-02 	 Res : 3.0848e-02 	 Jac : 1.8843e-02 	 Enc : 2.7676e-03 	 AEnc : 1.8947e-02 	 MSE : 1.1146e+01
Epoch 93, 75% 	 Loss : 6.3922e-02 	 Res : 2.2727e-02 	 Jac : 1.9075e-02 	 Enc : 2.6028e-03 	 AEnc : 1.0448e-02 	 MSE : 9.0693e+00
Training Epoch 93 : 	 Train : 7.71308e-02 	 Res : 2.83215e-02 	 Jac : 1.89930e-02 	 Enc : 2.69124e-03 	 AE : 1.78610e-02 	 MSE : 9.26408e+00
Validation Epoch 93 : 	 Train : 7.11744e-02 	 Res : 3.11493e-02 	 Jac : 1.90149e-02 	 Enc : 2.93135e-03 	 AE : 5.14856e-03 	 MSE : 1.29304e+01
Training Epoch 93 finished, took current epoch 502.69s, cumulative time 40470.81s
Current Learning rate DEQ : 0.0017149999999999995
Current Learning rate AUTOENC : 0.003429999999999999
Epoch 94, 25% 	 Loss : 7.1260e-02 	 Res : 3.4239e-02 	 Jac : 1.8978e-02 	 Enc : 2.6829e-03 	 AEnc : 4.3260e-03 	 MSE : 1.1034e+01
Epoch 94, 50% 	 Loss : 1.5526e-01 	 Res : 1.0661e-01 	 Jac : 1.8754e-02 	 Enc : 3.0485e-03 	 AEnc : 1.7349e-03 	 MSE : 2.5105e+01
Epoch 94, 75% 	 Loss : 9.2711e-02 	 Res : 5.0039e-02 	 Jac : 1.8369e-02 	 Enc : 3.0522e-03 	 AEnc : 1.2728e-03 	 MSE : 1.9977e+01
Training Epoch 94 : 	 Train : 9.68345e-02 	 Res : 5.57643e-02 	 Jac : 1.88971e-02 	 Enc : 2.86977e-03 	 AE : 2.12431e-03 	 MSE : 1.71790e+01
Validation Epoch 94 : 	 Train : 4.18943e-02 	 Res : 1.23044e-02 	 Jac : 1.90048e-02 	 Enc : 2.56630e-03 	 AE : 5.99940e-04 	 MSE : 7.41887e+00
Training Epoch 94 finished, took current epoch 448.26s, cumulative time 40919.03s
Current Learning rate DEQ : 0.0012004999999999995
Current Learning rate AUTOENC : 0.002400999999999999
Epoch 95, 25% 	 Loss : 3.9805e-02 	 Res : 1.2377e-02 	 Jac : 1.9322e-02 	 Enc : 2.6000e-03 	 AEnc : 1.4839e-03 	 MSE : 4.0217e+00
Epoch 95, 50% 	 Loss : 4.5184e-02 	 Res : 1.4937e-02 	 Jac : 1.9036e-02 	 Enc : 2.5842e-03 	 AEnc : 3.1470e-03 	 MSE : 5.4798e+00
Epoch 95, 75% 	 Loss : 6.2299e-02 	 Res : 2.5064e-02 	 Jac : 1.9223e-02 	 Enc : 2.6599e-03 	 AEnc : 6.4214e-03 	 MSE : 8.9297e+00
Training Epoch 95 : 	 Train : 4.80383e-02 	 Res : 1.63447e-02 	 Jac : 1.91120e-02 	 Enc : 2.60951e-03 	 AE : 3.93894e-03 	 MSE : 6.03314e+00
Validation Epoch 95 : 	 Train : 4.14163e-02 	 Res : 1.22240e-02 	 Jac : 1.87791e-02 	 Enc : 2.61418e-03 	 AE : 2.51815e-03 	 MSE : 5.28095e+00
Training Epoch 95 finished, took current epoch 457.61s, cumulative time 41376.61s
Current Learning rate DEQ : 0.0012004999999999995
Current Learning rate AUTOENC : 0.002400999999999999
Epoch 96, 25% 	 Loss : 4.5263e-02 	 Res : 1.3532e-02 	 Jac : 1.9226e-02 	 Enc : 2.6469e-03 	 AEnc : 5.5866e-03 	 MSE : 4.2711e+00
Epoch 96, 50% 	 Loss : 5.6101e-02 	 Res : 1.3765e-02 	 Jac : 1.9116e-02 	 Enc : 2.6488e-03 	 AEnc : 1.5898e-02 	 MSE : 4.6745e+00
Epoch 96, 75% 	 Loss : 4.1622e-02 	 Res : 1.0461e-02 	 Jac : 1.9004e-02 	 Enc : 2.6289e-03 	 AEnc : 5.7148e-03 	 MSE : 3.8128e+00
Training Epoch 96 : 	 Train : 4.87564e-02 	 Res : 1.44081e-02 	 Jac : 1.90271e-02 	 Enc : 2.64981e-03 	 AE : 7.92973e-03 	 MSE : 4.74173e+00
Validation Epoch 96 : 	 Train : 5.49102e-02 	 Res : 2.47684e-02 	 Jac : 1.95672e-02 	 Enc : 2.71310e-03 	 AE : 1.39411e-03 	 MSE : 6.46741e+00
Training Epoch 96 finished, took current epoch 516.38s, cumulative time 41892.95s
Current Learning rate DEQ : 0.0012004999999999995
Current Learning rate AUTOENC : 0.002400999999999999
Epoch 97, 25% 	 Loss : 6.8028e-02 	 Res : 3.2267e-02 	 Jac : 1.9131e-02 	 Enc : 2.8044e-03 	 AEnc : 2.9393e-03 	 MSE : 1.0886e+01
Epoch 97, 50% 	 Loss : 6.0365e-02 	 Res : 2.4931e-02 	 Jac : 1.8573e-02 	 Enc : 2.7972e-03 	 AEnc : 4.4702e-03 	 MSE : 9.5936e+00
Epoch 97, 75% 	 Loss : 4.0351e-02 	 Res : 1.2424e-02 	 Jac : 1.8413e-02 	 Enc : 2.6692e-03 	 AEnc : 2.0523e-03 	 MSE : 4.7924e+00
Training Epoch 97 : 	 Train : 6.02132e-02 	 Res : 2.69750e-02 	 Jac : 1.86608e-02 	 Enc : 2.74544e-03 	 AE : 2.79743e-03 	 MSE : 9.03456e+00
Validation Epoch 97 : 	 Train : 5.45096e-02 	 Res : 2.08089e-02 	 Jac : 1.75666e-02 	 Enc : 2.58515e-03 	 AE : 1.23770e-03 	 MSE : 1.23112e+01
Training Epoch 97 finished, took current epoch 485.09s, cumulative time 42377.99s
Current Learning rate DEQ : 0.0012004999999999995
Current Learning rate AUTOENC : 0.002400999999999999
Epoch 98, 25% 	 Loss : 6.9739e-02 	 Res : 3.3310e-02 	 Jac : 1.8480e-02 	 Enc : 2.8776e-03 	 AEnc : 2.2985e-03 	 MSE : 1.2774e+01
Epoch 98, 50% 	 Loss : 4.5827e-02 	 Res : 1.7107e-02 	 Jac : 1.7928e-02 	 Enc : 2.5831e-03 	 AEnc : 1.3851e-03 	 MSE : 6.8235e+00
Epoch 98, 75% 	 Loss : 4.4277e-02 	 Res : 1.6010e-02 	 Jac : 1.8236e-02 	 Enc : 2.6895e-03 	 AEnc : 3.5375e-04 	 MSE : 6.9871e+00
Training Epoch 98 : 	 Train : 5.12658e-02 	 Res : 2.10577e-02 	 Jac : 1.82054e-02 	 Enc : 2.70325e-03 	 AE : 1.08660e-03 	 MSE : 8.21284e+00
Validation Epoch 98 : 	 Train : 4.98528e-02 	 Res : 2.22993e-02 	 Jac : 1.95193e-02 	 Enc : 3.14644e-03 	 AE : 1.86349e-04 	 MSE : 4.70142e+00
Training Epoch 98 finished, took current epoch 519.56s, cumulative time 42897.54s
Current Learning rate DEQ : 0.0012004999999999995
Current Learning rate AUTOENC : 0.002400999999999999
Epoch 99, 25% 	 Loss : 4.4377e-02 	 Res : 1.6161e-02 	 Jac : 1.8014e-02 	 Enc : 2.6937e-03 	 AEnc : 3.2501e-04 	 MSE : 7.1832e+00
Epoch 99, 50% 	 Loss : 1.2979e-01 	 Res : 9.3742e-02 	 Jac : 1.9225e-02 	 Enc : 2.8571e-03 	 AEnc : 7.3569e-04 	 MSE : 1.3229e+01
Epoch 99, 75% 	 Loss : 5.2887e-02 	 Res : 2.4847e-02 	 Jac : 1.8129e-02 	 Enc : 2.6885e-03 	 AEnc : 1.0487e-03 	 MSE : 6.1746e+00
Training Epoch 99 : 	 Train : 6.72268e-02 	 Res : 3.74367e-02 	 Jac : 1.82836e-02 	 Enc : 2.72851e-03 	 AE : 6.15392e-04 	 MSE : 8.16248e+00
Validation Epoch 99 : 	 Train : 4.21127e-02 	 Res : 1.45018e-02 	 Jac : 1.76967e-02 	 Enc : 2.49096e-03 	 AE : 1.77238e-04 	 MSE : 7.24608e+00
Training Epoch 99 finished, took current epoch 475.09s, cumulative time 43372.59s
Current Learning rate DEQ : 0.0012004999999999995
Current Learning rate AUTOENC : 0.002400999999999999
Epoch 100, 25% 	 Loss : 4.6217e-02 	 Res : 1.7368e-02 	 Jac : 1.7885e-02 	 Enc : 2.6086e-03 	 AEnc : 3.9122e-04 	 MSE : 7.9638e+00
Epoch 100, 50% 	 Loss : 5.5037e-02 	 Res : 2.3807e-02 	 Jac : 1.8344e-02 	 Enc : 2.7095e-03 	 AEnc : 3.3252e-04 	 MSE : 9.8440e+00
Epoch 100, 75% 	 Loss : 4.5786e-02 	 Res : 1.7781e-02 	 Jac : 1.8111e-02 	 Enc : 2.7511e-03 	 AEnc : 3.0316e-04 	 MSE : 6.8397e+00
Training Epoch 100 : 	 Train : 5.06866e-02 	 Res : 2.07175e-02 	 Jac : 1.81566e-02 	 Enc : 2.69063e-03 	 AE : 3.42936e-04 	 MSE : 8.77898e+00
Validation Epoch 100 : 	 Train : 5.07130e-02 	 Res : 1.85478e-02 	 Jac : 1.70415e-02 	 Enc : 2.58978e-03 	 AE : 2.63913e-04 	 MSE : 1.22700e+01
Training Epoch 100 finished, took current epoch 451.85s, cumulative time 43824.41s
Current Learning rate DEQ : 0.0012004999999999995
Current Learning rate AUTOENC : 0.002400999999999999
Epoch 101, 25% 	 Loss : 5.2726e-02 	 Res : 2.3929e-02 	 Jac : 1.8056e-02 	 Enc : 2.6809e-03 	 AEnc : 4.7219e-04 	 MSE : 7.5892e+00
Epoch 101, 50% 	 Loss : 8.1678e-02 	 Res : 4.7421e-02 	 Jac : 1.8287e-02 	 Enc : 2.7820e-03 	 AEnc : 3.6324e-03 	 MSE : 9.5562e+00
Epoch 101, 75% 	 Loss : 5.0479e-02 	 Res : 2.0132e-02 	 Jac : 1.7821e-02 	 Enc : 2.6470e-03 	 AEnc : 1.7753e-03 	 MSE : 8.1041e+00
Training Epoch 101 : 	 Train : 5.78276e-02 	 Res : 2.72886e-02 	 Jac : 1.80564e-02 	 Enc : 2.70328e-03 	 AE : 1.80418e-03 	 MSE : 7.97513e+00
Validation Epoch 101 : 	 Train : 4.01569e-02 	 Res : 1.33367e-02 	 Jac : 1.79187e-02 	 Enc : 2.85950e-03 	 AE : 2.47088e-03 	 MSE : 3.57108e+00
Training Epoch 101 finished, took current epoch 487.59s, cumulative time 44311.97s
Current Learning rate DEQ : 0.0012004999999999995
Current Learning rate AUTOENC : 0.002400999999999999
Epoch 102, 25% 	 Loss : 4.5021e-02 	 Res : 1.5602e-02 	 Jac : 1.8100e-02 	 Enc : 2.6026e-03 	 AEnc : 3.1667e-03 	 MSE : 5.5496e+00
Epoch 102, 50% 	 Loss : 4.6995e-02 	 Res : 1.7274e-02 	 Jac : 1.7834e-02 	 Enc : 2.7472e-03 	 AEnc : 8.3162e-04 	 MSE : 8.3077e+00
Epoch 102, 75% 	 Loss : 3.8410e-02 	 Res : 1.2807e-02 	 Jac : 1.8112e-02 	 Enc : 2.6154e-03 	 AEnc : 6.2279e-04 	 MSE : 4.2527e+00
Training Epoch 102 : 	 Train : 4.81870e-02 	 Res : 1.94822e-02 	 Jac : 1.79633e-02 	 Enc : 2.65285e-03 	 AE : 1.60323e-03 	 MSE : 6.48543e+00
Validation Epoch 102 : 	 Train : 5.24293e-02 	 Res : 2.67259e-02 	 Jac : 1.73926e-02 	 Enc : 2.69964e-03 	 AE : 1.06100e-03 	 MSE : 4.55005e+00
Training Epoch 102 finished, took current epoch 466.44s, cumulative time 44778.39s
Current Learning rate DEQ : 0.0012004999999999995
Current Learning rate AUTOENC : 0.002400999999999999
Epoch 103, 25% 	 Loss : 5.9511e-02 	 Res : 2.6152e-02 	 Jac : 1.7611e-02 	 Enc : 2.7930e-03 	 AEnc : 4.6868e-04 	 MSE : 1.2485e+01
Epoch 103, 50% 	 Loss : 6.1753e-02 	 Res : 2.8174e-02 	 Jac : 1.7838e-02 	 Enc : 2.8067e-03 	 AEnc : 5.2892e-04 	 MSE : 1.2406e+01
Epoch 103, 75% 	 Loss : 4.4703e-02 	 Res : 1.6230e-02 	 Jac : 1.7725e-02 	 Enc : 2.7793e-03 	 AEnc : 5.3028e-04 	 MSE : 7.4381e+00
Training Epoch 103 : 	 Train : 5.50116e-02 	 Res : 2.35225e-02 	 Jac : 1.78897e-02 	 Enc : 2.75423e-03 	 AE : 5.07516e-04 	 MSE : 1.03377e+01
Validation Epoch 103 : 	 Train : 3.59134e-02 	 Res : 9.64260e-03 	 Jac : 1.73596e-02 	 Enc : 2.64346e-03 	 AE : 2.89633e-04 	 MSE : 5.97805e+00
Training Epoch 103 finished, took current epoch 445.61s, cumulative time 45223.96s
Current Learning rate DEQ : 0.0012004999999999995
Current Learning rate AUTOENC : 0.002400999999999999
MODEL SAVED
Epoch 104, 25% 	 Loss : 7.7510e-02 	 Res : 4.4775e-02 	 Jac : 1.7913e-02 	 Enc : 2.7874e-03 	 AEnc : 7.4957e-04 	 MSE : 1.1285e+01
Epoch 104, 50% 	 Loss : 5.3224e-02 	 Res : 2.4337e-02 	 Jac : 1.7573e-02 	 Enc : 2.7416e-03 	 AEnc : 2.8524e-03 	 MSE : 5.7205e+00
Epoch 104, 75% 	 Loss : 4.8463e-02 	 Res : 1.8709e-02 	 Jac : 1.7927e-02 	 Enc : 2.7360e-03 	 AEnc : 3.1342e-03 	 MSE : 5.9578e+00
Training Epoch 104 : 	 Train : 5.76416e-02 	 Res : 2.63343e-02 	 Jac : 1.79437e-02 	 Enc : 2.75485e-03 	 AE : 3.52645e-03 	 MSE : 7.08219e+00
Validation Epoch 104 : 	 Train : 6.01758e-02 	 Res : 2.33763e-02 	 Jac : 1.78759e-02 	 Enc : 2.54327e-03 	 AE : 7.26533e-03 	 MSE : 9.11504e+00
Training Epoch 104 finished, took current epoch 483.85s, cumulative time 45707.79s
Current Learning rate DEQ : 0.0012004999999999995
Current Learning rate AUTOENC : 0.002400999999999999
Epoch 105, 25% 	 Loss : 5.2460e-02 	 Res : 2.0648e-02 	 Jac : 1.7820e-02 	 Enc : 2.7927e-03 	 AEnc : 3.1328e-03 	 MSE : 8.0667e+00
Epoch 105, 50% 	 Loss : 6.9376e-02 	 Res : 3.4314e-02 	 Jac : 1.7966e-02 	 Enc : 2.8630e-03 	 AEnc : 1.9263e-03 	 MSE : 1.2306e+01
Epoch 105, 75% 	 Loss : 4.4744e-02 	 Res : 1.6987e-02 	 Jac : 1.7535e-02 	 Enc : 2.8728e-03 	 AEnc : 6.6498e-04 	 MSE : 6.6844e+00
Training Epoch 105 : 	 Train : 5.05539e-02 	 Res : 2.07068e-02 	 Jac : 1.78073e-02 	 Enc : 2.80914e-03 	 AE : 1.52870e-03 	 MSE : 7.70199e+00
Validation Epoch 105 : 	 Train : 3.08142e-02 	 Res : 7.71972e-03 	 Jac : 1.78754e-02 	 Enc : 2.75786e-03 	 AE : 2.62389e-04 	 MSE : 2.19882e+00
Training Epoch 105 finished, took current epoch 477.57s, cumulative time 46185.32s
Current Learning rate DEQ : 0.0012004999999999995
Current Learning rate AUTOENC : 0.002400999999999999
MODEL SAVED
Epoch 106, 25% 	 Loss : 6.1991e-02 	 Res : 3.0493e-02 	 Jac : 1.7719e-02 	 Enc : 2.7519e-03 	 AEnc : 1.8069e-03 	 MSE : 9.2194e+00
Epoch 106, 50% 	 Loss : 5.6425e-02 	 Res : 2.4693e-02 	 Jac : 1.7657e-02 	 Enc : 2.8061e-03 	 AEnc : 4.6033e-04 	 MSE : 1.0808e+01
Epoch 106, 75% 	 Loss : 4.4696e-02 	 Res : 1.6349e-02 	 Jac : 1.7655e-02 	 Enc : 2.8398e-03 	 AEnc : 5.2538e-04 	 MSE : 7.3262e+00
Training Epoch 106 : 	 Train : 5.15131e-02 	 Res : 2.17275e-02 	 Jac : 1.76327e-02 	 Enc : 2.77046e-03 	 AE : 1.42439e-03 	 MSE : 7.95805e+00
Validation Epoch 106 : 	 Train : 3.63281e-02 	 Res : 1.01136e-02 	 Jac : 1.75559e-02 	 Enc : 2.59345e-03 	 AE : 1.68385e-03 	 MSE : 4.38130e+00
Training Epoch 106 finished, took current epoch 468.94s, cumulative time 46654.23s
Current Learning rate DEQ : 0.0012004999999999995
Current Learning rate AUTOENC : 0.002400999999999999
Epoch 107, 25% 	 Loss : 3.5057e-02 	 Res : 9.8156e-03 	 Jac : 1.7961e-02 	 Enc : 2.6522e-03 	 AEnc : 9.1112e-04 	 MSE : 3.7175e+00
Epoch 107, 50% 	 Loss : 4.2074e-02 	 Res : 1.5036e-02 	 Jac : 1.8082e-02 	 Enc : 2.6854e-03 	 AEnc : 4.5181e-04 	 MSE : 5.8184e+00
Epoch 107, 75% 	 Loss : 5.0836e-02 	 Res : 2.1592e-02 	 Jac : 1.7945e-02 	 Enc : 2.8021e-03 	 AEnc : 1.0514e-03 	 MSE : 7.4450e+00
Training Epoch 107 : 	 Train : 4.55950e-02 	 Res : 1.72609e-02 	 Jac : 1.78853e-02 	 Enc : 2.73487e-03 	 AE : 1.17177e-03 	 MSE : 6.54211e+00
Validation Epoch 107 : 	 Train : 1.03037e-01 	 Res : 5.95678e-02 	 Jac : 1.88269e-02 	 Enc : 3.27488e-03 	 AE : 1.50998e-03 	 MSE : 1.98575e+01
Training Epoch 107 finished, took current epoch 528.08s, cumulative time 47182.29s
Current Learning rate DEQ : 0.0012004999999999995
Current Learning rate AUTOENC : 0.002400999999999999
Epoch 108, 25% 	 Loss : 7.5810e-02 	 Res : 3.7460e-02 	 Jac : 1.7947e-02 	 Enc : 2.8581e-03 	 AEnc : 3.1936e-03 	 MSE : 1.4351e+01
Epoch 108, 50% 	 Loss : 7.7628e-02 	 Res : 2.7808e-02 	 Jac : 1.7162e-02 	 Enc : 2.9055e-03 	 AEnc : 1.7770e-02 	 MSE : 1.1982e+01
Epoch 108, 75% 	 Loss : 5.6651e-02 	 Res : 1.3146e-02 	 Jac : 1.7626e-02 	 Enc : 2.7493e-03 	 AEnc : 1.8937e-02 	 MSE : 4.1930e+00
Training Epoch 108 : 	 Train : 7.23615e-02 	 Res : 2.36763e-02 	 Jac : 1.76444e-02 	 Enc : 2.81666e-03 	 AE : 1.94701e-02 	 MSE : 8.75395e+00
Validation Epoch 108 : 	 Train : 3.45554e-02 	 Res : 9.04303e-03 	 Jac : 1.73023e-02 	 Enc : 2.74084e-03 	 AE : 9.65025e-04 	 MSE : 4.50417e+00
Training Epoch 108 finished, took current epoch 467.73s, cumulative time 47650.01s
Current Learning rate DEQ : 0.0012004999999999995
Current Learning rate AUTOENC : 0.002400999999999999
Epoch 109, 25% 	 Loss : 3.6625e-02 	 Res : 9.7710e-03 	 Jac : 1.7662e-02 	 Enc : 2.6824e-03 	 AEnc : 2.9050e-03 	 MSE : 3.6044e+00
Epoch 109, 50% 	 Loss : 3.4676e-02 	 Res : 9.7290e-03 	 Jac : 1.7969e-02 	 Enc : 2.6861e-03 	 AEnc : 7.6382e-04 	 MSE : 3.5281e+00
Epoch 109, 75% 	 Loss : 4.2949e-02 	 Res : 1.3456e-02 	 Jac : 1.7634e-02 	 Enc : 2.7525e-03 	 AEnc : 3.8680e-03 	 MSE : 5.2375e+00
Training Epoch 109 : 	 Train : 3.97837e-02 	 Res : 1.22104e-02 	 Jac : 1.76461e-02 	 Enc : 2.71742e-03 	 AE : 2.40528e-03 	 MSE : 4.80446e+00
Validation Epoch 109 : 	 Train : 7.84235e-02 	 Res : 4.18338e-02 	 Jac : 1.82469e-02 	 Enc : 2.63684e-03 	 AE : 1.37177e-03 	 MSE : 1.43342e+01
Training Epoch 109 finished, took current epoch 520.01s, cumulative time 48170.00s
Current Learning rate DEQ : 0.0012004999999999995
Current Learning rate AUTOENC : 0.002400999999999999
Epoch 110, 25% 	 Loss : 6.1885e-02 	 Res : 3.1040e-02 	 Jac : 1.7930e-02 	 Enc : 2.9330e-03 	 AEnc : 4.4258e-04 	 MSE : 9.5390e+00
Epoch 110, 50% 	 Loss : 5.9343e-02 	 Res : 2.6446e-02 	 Jac : 1.7079e-02 	 Enc : 2.9513e-03 	 AEnc : 9.4292e-04 	 MSE : 1.1922e+01
Epoch 110, 75% 	 Loss : 4.5645e-02 	 Res : 1.6734e-02 	 Jac : 1.7113e-02 	 Enc : 2.9070e-03 	 AEnc : 1.4227e-03 	 MSE : 7.4680e+00
Training Epoch 110 : 	 Train : 5.33418e-02 	 Res : 2.28502e-02 	 Jac : 1.73999e-02 	 Enc : 2.88022e-03 	 AE : 1.33444e-03 	 MSE : 8.87700e+00
Validation Epoch 110 : 	 Train : 4.38733e-02 	 Res : 1.30451e-02 	 Jac : 1.68793e-02 	 Enc : 2.61280e-03 	 AE : 3.07999e-03 	 MSE : 8.25615e+00
Training Epoch 110 finished, took current epoch 470.55s, cumulative time 48640.54s
Current Learning rate DEQ : 0.0012004999999999995
Current Learning rate AUTOENC : 0.002400999999999999
Epoch 111, 25% 	 Loss : 5.6702e-02 	 Res : 2.5946e-02 	 Jac : 1.7435e-02 	 Enc : 2.8274e-03 	 AEnc : 1.0539e-03 	 MSE : 9.4401e+00
Epoch 111, 50% 	 Loss : 4.5332e-02 	 Res : 1.7247e-02 	 Jac : 1.7455e-02 	 Enc : 2.7744e-03 	 AEnc : 7.6813e-04 	 MSE : 7.0871e+00
Epoch 111, 75% 	 Loss : 6.4039e-02 	 Res : 3.3000e-02 	 Jac : 1.7906e-02 	 Enc : 2.7273e-03 	 AEnc : 4.1315e-04 	 MSE : 9.9930e+00
Training Epoch 111 : 	 Train : 5.66532e-02 	 Res : 2.60152e-02 	 Jac : 1.74851e-02 	 Enc : 2.82537e-03 	 AE : 8.09185e-04 	 MSE : 9.51828e+00
Validation Epoch 111 : 	 Train : 5.76021e-02 	 Res : 2.24389e-02 	 Jac : 1.68882e-02 	 Enc : 3.06651e-03 	 AE : 1.20888e-03 	 MSE : 1.39997e+01
Training Epoch 111 finished, took current epoch 470.10s, cumulative time 49110.63s
Current Learning rate DEQ : 0.0012004999999999995
Current Learning rate AUTOENC : 0.002400999999999999
Epoch 112, 25% 	 Loss : 4.3082e-02 	 Res : 1.5045e-02 	 Jac : 1.7432e-02 	 Enc : 2.7295e-03 	 AEnc : 7.6371e-04 	 MSE : 7.1123e+00
Epoch 112, 50% 	 Loss : 3.9936e-02 	 Res : 1.3761e-02 	 Jac : 1.7598e-02 	 Enc : 2.7514e-03 	 AEnc : 4.9335e-04 	 MSE : 5.3325e+00
Epoch 112, 75% 	 Loss : 6.2439e-02 	 Res : 3.1278e-02 	 Jac : 1.7846e-02 	 Enc : 2.7820e-03 	 AEnc : 3.4469e-04 	 MSE : 1.0189e+01
Training Epoch 112 : 	 Train : 4.56304e-02 	 Res : 1.79456e-02 	 Jac : 1.75387e-02 	 Enc : 2.77748e-03 	 AE : 4.85922e-04 	 MSE : 6.88262e+00
Validation Epoch 112 : 	 Train : 3.09046e-02 	 Res : 7.87278e-03 	 Jac : 1.76034e-02 	 Enc : 2.81653e-03 	 AE : 5.28289e-04 	 MSE : 2.08365e+00
Training Epoch 112 finished, took current epoch 488.61s, cumulative time 49599.23s
Current Learning rate DEQ : 0.0012004999999999995
Current Learning rate AUTOENC : 0.002400999999999999
Epoch 113, 25% 	 Loss : 6.5237e-02 	 Res : 3.1061e-02 	 Jac : 1.7751e-02 	 Enc : 2.8037e-03 	 AEnc : 6.3542e-04 	 MSE : 1.2987e+01
Epoch 113, 50% 	 Loss : 4.8978e-02 	 Res : 1.8892e-02 	 Jac : 1.7438e-02 	 Enc : 2.8604e-03 	 AEnc : 8.6469e-04 	 MSE : 8.9230e+00
Epoch 113, 75% 	 Loss : 6.3239e-02 	 Res : 3.3059e-02 	 Jac : 1.7760e-02 	 Enc : 2.8761e-03 	 AEnc : 9.8793e-04 	 MSE : 8.5562e+00
Training Epoch 113 : 	 Train : 5.50272e-02 	 Res : 2.45979e-02 	 Jac : 1.76343e-02 	 Enc : 2.83662e-03 	 AE : 7.29949e-04 	 MSE : 9.22847e+00
Validation Epoch 113 : 	 Train : 4.95132e-02 	 Res : 1.94758e-02 	 Jac : 1.76653e-02 	 Enc : 2.69392e-03 	 AE : 2.51565e-04 	 MSE : 9.42664e+00
Training Epoch 113 finished, took current epoch 494.41s, cumulative time 50093.60s
Current Learning rate DEQ : 0.0012004999999999995
Current Learning rate AUTOENC : 0.002400999999999999
Epoch 114, 25% 	 Loss : 4.4369e-02 	 Res : 1.5919e-02 	 Jac : 1.7755e-02 	 Enc : 2.7706e-03 	 AEnc : 4.1862e-04 	 MSE : 7.5057e+00
Epoch 114, 50% 	 Loss : 4.1579e-02 	 Res : 1.5498e-02 	 Jac : 1.7758e-02 	 Enc : 2.8264e-03 	 AEnc : 4.7981e-04 	 MSE : 5.0168e+00
Epoch 114, 75% 	 Loss : 5.8533e-02 	 Res : 2.7382e-02 	 Jac : 1.7494e-02 	 Enc : 2.9477e-03 	 AEnc : 5.1780e-04 	 MSE : 1.0191e+01
Training Epoch 114 : 	 Train : 4.67854e-02 	 Res : 1.87939e-02 	 Jac : 1.76651e-02 	 Enc : 2.85427e-03 	 AE : 4.40903e-04 	 MSE : 7.03119e+00
Validation Epoch 114 : 	 Train : 3.49856e-02 	 Res : 9.50768e-03 	 Jac : 1.69248e-02 	 Enc : 2.76196e-03 	 AE : 3.15875e-04 	 MSE : 5.47526e+00
Training Epoch 114 finished, took current epoch 491.72s, cumulative time 50585.28s
Current Learning rate DEQ : 0.0012004999999999995
Current Learning rate AUTOENC : 0.002400999999999999
Epoch 115, 25% 	 Loss : 1.3628e-01 	 Res : 9.5271e-02 	 Jac : 1.7875e-02 	 Enc : 3.0451e-03 	 AEnc : 5.5231e-03 	 MSE : 1.4566e+01
Epoch 115, 50% 	 Loss : 7.0400e-02 	 Res : 3.8211e-02 	 Jac : 1.6851e-02 	 Enc : 3.1066e-03 	 AEnc : 2.4968e-03 	 MSE : 9.7351e+00
Epoch 115, 75% 	 Loss : 5.0676e-02 	 Res : 2.0221e-02 	 Jac : 1.7049e-02 	 Enc : 3.1371e-03 	 AEnc : 1.0093e-03 	 MSE : 9.2602e+00
Training Epoch 115 : 	 Train : 8.09668e-02 	 Res : 4.65063e-02 	 Jac : 1.72829e-02 	 Enc : 3.12165e-03 	 AE : 2.41887e-03 	 MSE : 1.16371e+01
Validation Epoch 115 : 	 Train : 5.64866e-02 	 Res : 2.36636e-02 	 Jac : 1.73789e-02 	 Enc : 3.44107e-03 	 AE : 5.41170e-04 	 MSE : 1.14618e+01
Training Epoch 115 finished, took current epoch 494.07s, cumulative time 51079.33s
Current Learning rate DEQ : 0.0012004999999999995
Current Learning rate AUTOENC : 0.002400999999999999
Epoch 116, 25% 	 Loss : 6.4405e-02 	 Res : 3.0839e-02 	 Jac : 1.7584e-02 	 Enc : 3.2382e-03 	 AEnc : 7.8421e-04 	 MSE : 1.1960e+01
Epoch 116, 50% 	 Loss : 4.7587e-02 	 Res : 1.7846e-02 	 Jac : 1.7141e-02 	 Enc : 3.1502e-03 	 AEnc : 7.0302e-04 	 MSE : 8.7465e+00
Epoch 116, 75% 	 Loss : 7.9076e-02 	 Res : 4.3803e-02 	 Jac : 1.7752e-02 	 Enc : 3.2323e-03 	 AEnc : 1.0226e-03 	 MSE : 1.3266e+01
Training Epoch 116 : 	 Train : 6.00981e-02 	 Res : 2.76673e-02 	 Jac : 1.73946e-02 	 Enc : 3.22504e-03 	 AE : 1.14656e-03 	 MSE : 1.06646e+01
Validation Epoch 116 : 	 Train : 1.15415e-01 	 Res : 6.86160e-02 	 Jac : 1.81427e-02 	 Enc : 2.94127e-03 	 AE : 1.17555e-03 	 MSE : 2.45397e+01
Training Epoch 116 finished, took current epoch 504.79s, cumulative time 51584.10s
Current Learning rate DEQ : 0.0008403499999999996
Current Learning rate AUTOENC : 0.0016806999999999992
Epoch 117, 25% 	 Loss : 7.4599e-02 	 Res : 3.7708e-02 	 Jac : 1.7842e-02 	 Enc : 3.1565e-03 	 AEnc : 6.1641e-04 	 MSE : 1.5276e+01
Epoch 117, 50% 	 Loss : 4.2815e-02 	 Res : 1.5172e-02 	 Jac : 1.7545e-02 	 Enc : 3.1054e-03 	 AEnc : 5.7898e-04 	 MSE : 6.4141e+00
Epoch 117, 75% 	 Loss : 4.7895e-02 	 Res : 1.8875e-02 	 Jac : 1.7354e-02 	 Enc : 2.9744e-03 	 AEnc : 8.6750e-04 	 MSE : 7.8242e+00
Training Epoch 117 : 	 Train : 5.23453e-02 	 Res : 2.19347e-02 	 Jac : 1.75551e-02 	 Enc : 3.07280e-03 	 AE : 8.50377e-04 	 MSE : 8.93235e+00
Validation Epoch 117 : 	 Train : 3.16543e-02 	 Res : 8.03905e-03 	 Jac : 1.76337e-02 	 Enc : 3.03307e-03 	 AE : 4.94367e-04 	 MSE : 2.45408e+00
Training Epoch 117 finished, took current epoch 476.98s, cumulative time 52061.06s
Current Learning rate DEQ : 0.0008403499999999996
Current Learning rate AUTOENC : 0.0016806999999999992
Epoch 118, 25% 	 Loss : 7.8326e-02 	 Res : 4.3760e-02 	 Jac : 1.7652e-02 	 Enc : 2.9735e-03 	 AEnc : 4.6032e-04 	 MSE : 1.3480e+01
Epoch 118, 50% 	 Loss : 5.2324e-02 	 Res : 2.3208e-02 	 Jac : 1.7658e-02 	 Enc : 3.2681e-03 	 AEnc : 1.6228e-03 	 MSE : 6.5678e+00
Epoch 118, 75% 	 Loss : 3.8288e-02 	 Res : 1.2159e-02 	 Jac : 1.7446e-02 	 Enc : 2.9563e-03 	 AEnc : 1.2509e-03 	 MSE : 4.4753e+00
Training Epoch 118 : 	 Train : 5.39986e-02 	 Res : 2.38362e-02 	 Jac : 1.75231e-02 	 Enc : 3.05579e-03 	 AE : 1.79301e-03 	 MSE : 7.79047e+00
Validation Epoch 118 : 	 Train : 3.34387e-02 	 Res : 8.49280e-03 	 Jac : 1.69739e-02 	 Enc : 2.95012e-03 	 AE : 8.34229e-04 	 MSE : 4.18766e+00
Training Epoch 118 finished, took current epoch 472.55s, cumulative time 52533.58s
Current Learning rate DEQ : 0.0008403499999999996
Current Learning rate AUTOENC : 0.0016806999999999992
Epoch 119, 25% 	 Loss : 3.8874e-02 	 Res : 1.2358e-02 	 Jac : 1.7403e-02 	 Enc : 3.0044e-03 	 AEnc : 8.3527e-04 	 MSE : 5.2736e+00
Epoch 119, 50% 	 Loss : 4.1752e-02 	 Res : 1.5127e-02 	 Jac : 1.7295e-02 	 Enc : 2.9741e-03 	 AEnc : 3.6344e-04 	 MSE : 5.9922e+00
Epoch 119, 75% 	 Loss : 6.6441e-02 	 Res : 3.0640e-02 	 Jac : 1.7506e-02 	 Enc : 3.0387e-03 	 AEnc : 2.0290e-03 	 MSE : 1.3227e+01
Training Epoch 119 : 	 Train : 5.58461e-02 	 Res : 2.37450e-02 	 Jac : 1.73490e-02 	 Enc : 3.02930e-03 	 AE : 1.47594e-03 	 MSE : 1.02468e+01
Validation Epoch 119 : 	 Train : 4.65888e-02 	 Res : 1.58688e-02 	 Jac : 1.67794e-02 	 Enc : 3.07268e-03 	 AE : 8.73653e-04 	 MSE : 9.99427e+00
Training Epoch 119 finished, took current epoch 462.40s, cumulative time 52995.97s
Current Learning rate DEQ : 0.0008403499999999996
Current Learning rate AUTOENC : 0.0016806999999999992
Epoch 120, 25% 	 Loss : 5.0053e-02 	 Res : 1.9284e-02 	 Jac : 1.7431e-02 	 Enc : 3.1280e-03 	 AEnc : 5.9227e-04 	 MSE : 9.6172e+00
Epoch 120, 50% 	 Loss : 4.0564e-02 	 Res : 1.3532e-02 	 Jac : 1.7470e-02 	 Enc : 2.9795e-03 	 AEnc : 4.4774e-04 	 MSE : 6.1347e+00
Epoch 120, 75% 	 Loss : 6.5368e-02 	 Res : 3.0045e-02 	 Jac : 1.7397e-02 	 Enc : 3.0709e-03 	 AEnc : 5.6771e-03 	 MSE : 9.1789e+00
Training Epoch 120 : 	 Train : 5.81737e-02 	 Res : 2.51260e-02 	 Jac : 1.73593e-02 	 Enc : 3.08222e-03 	 AE : 3.33910e-03 	 MSE : 9.26703e+00
Validation Epoch 120 : 	 Train : 3.60211e-02 	 Res : 1.05693e-02 	 Jac : 1.70433e-02 	 Enc : 3.03067e-03 	 AE : 9.83740e-04 	 MSE : 4.39401e+00
Training Epoch 120 finished, took current epoch 463.65s, cumulative time 53459.61s
Current Learning rate DEQ : 0.0008403499999999996
Current Learning rate AUTOENC : 0.0016806999999999992
Epoch 121, 25% 	 Loss : 4.7797e-02 	 Res : 1.9139e-02 	 Jac : 1.7398e-02 	 Enc : 3.1017e-03 	 AEnc : 2.6500e-03 	 MSE : 5.5085e+00
Epoch 121, 50% 	 Loss : 5.6151e-02 	 Res : 2.3763e-02 	 Jac : 1.7139e-02 	 Enc : 3.1102e-03 	 AEnc : 2.0802e-03 	 MSE : 1.0059e+01
Epoch 121, 75% 	 Loss : 4.2197e-02 	 Res : 1.1969e-02 	 Jac : 1.7371e-02 	 Enc : 3.0676e-03 	 AEnc : 5.5940e-03 	 MSE : 4.1946e+00
Training Epoch 121 : 	 Train : 5.09057e-02 	 Res : 1.87699e-02 	 Jac : 1.73039e-02 	 Enc : 3.08143e-03 	 AE : 4.81283e-03 	 MSE : 6.93761e+00
Validation Epoch 121 : 	 Train : 4.65942e-02 	 Res : 9.89175e-03 	 Jac : 1.72047e-02 	 Enc : 2.95912e-03 	 AE : 1.38958e-02 	 MSE : 2.64277e+00
Training Epoch 121 finished, took current epoch 486.53s, cumulative time 53946.11s
Current Learning rate DEQ : 0.0008403499999999996
Current Learning rate AUTOENC : 0.0016806999999999992
Epoch 122, 25% 	 Loss : 4.8188e-02 	 Res : 1.2554e-02 	 Jac : 1.7197e-02 	 Enc : 3.0109e-03 	 AEnc : 1.1239e-02 	 MSE : 4.1879e+00
Epoch 122, 50% 	 Loss : 4.7644e-02 	 Res : 1.5353e-02 	 Jac : 1.7025e-02 	 Enc : 3.0484e-03 	 AEnc : 4.8132e-03 	 MSE : 7.4052e+00
Epoch 122, 75% 	 Loss : 5.7739e-02 	 Res : 2.5898e-02 	 Jac : 1.7251e-02 	 Enc : 3.1377e-03 	 AEnc : 2.3980e-03 	 MSE : 9.0547e+00
Training Epoch 122 : 	 Train : 5.20548e-02 	 Res : 1.79937e-02 	 Jac : 1.71773e-02 	 Enc : 3.06864e-03 	 AE : 7.11830e-03 	 MSE : 6.69691e+00
Validation Epoch 122 : 	 Train : 4.40099e-02 	 Res : 1.23371e-02 	 Jac : 1.73727e-02 	 Enc : 3.09205e-03 	 AE : 7.91164e-03 	 MSE : 3.29651e+00
Training Epoch 122 finished, took current epoch 496.27s, cumulative time 54442.37s
Current Learning rate DEQ : 0.0008403499999999996
Current Learning rate AUTOENC : 0.0016806999999999992
Epoch 123, 25% 	 Loss : 6.1807e-02 	 Res : 2.3036e-02 	 Jac : 1.7264e-02 	 Enc : 3.0581e-03 	 AEnc : 9.2365e-03 	 MSE : 9.2122e+00
Epoch 123, 50% 	 Loss : 4.2400e-02 	 Res : 1.4975e-02 	 Jac : 1.7126e-02 	 Enc : 3.1220e-03 	 AEnc : 1.7259e-03 	 MSE : 5.4511e+00
Epoch 123, 75% 	 Loss : 4.3718e-02 	 Res : 1.5921e-02 	 Jac : 1.6930e-02 	 Enc : 3.0814e-03 	 AEnc : 1.6120e-03 	 MSE : 6.1741e+00
Training Epoch 123 : 	 Train : 4.88389e-02 	 Res : 1.66804e-02 	 Jac : 1.70956e-02 	 Enc : 3.08512e-03 	 AE : 5.52701e-03 	 MSE : 6.45075e+00
Validation Epoch 123 : 	 Train : 4.15765e-02 	 Res : 9.77106e-03 	 Jac : 1.76305e-02 	 Enc : 3.06231e-03 	 AE : 9.39207e-03 	 MSE : 1.72053e+00
Training Epoch 123 finished, took current epoch 498.46s, cumulative time 54940.82s
Current Learning rate DEQ : 0.0008403499999999996
Current Learning rate AUTOENC : 0.0016806999999999992
Epoch 124, 25% 	 Loss : 4.0698e-02 	 Res : 1.0520e-02 	 Jac : 1.7118e-02 	 Enc : 3.0284e-03 	 AEnc : 6.1102e-03 	 MSE : 3.9206e+00
Epoch 124, 50% 	 Loss : 3.8941e-02 	 Res : 1.2543e-02 	 Jac : 1.7391e-02 	 Enc : 3.0996e-03 	 AEnc : 1.1677e-03 	 MSE : 4.7397e+00
Epoch 124, 75% 	 Loss : 3.9304e-02 	 Res : 1.1782e-02 	 Jac : 1.7122e-02 	 Enc : 3.0896e-03 	 AEnc : 2.3135e-03 	 MSE : 4.9965e+00
Training Epoch 124 : 	 Train : 3.98921e-02 	 Res : 1.20504e-02 	 Jac : 1.72183e-02 	 Enc : 3.06323e-03 	 AE : 2.73664e-03 	 MSE : 4.82348e+00
Validation Epoch 124 : 	 Train : 3.98252e-02 	 Res : 1.28549e-02 	 Jac : 1.71151e-02 	 Enc : 2.97470e-03 	 AE : 4.18660e-04 	 MSE : 6.46186e+00
Training Epoch 124 finished, took current epoch 494.14s, cumulative time 55434.92s
Current Learning rate DEQ : 0.0008403499999999996
Current Learning rate AUTOENC : 0.0016806999999999992
Epoch 125, 25% 	 Loss : 4.5434e-02 	 Res : 1.8081e-02 	 Jac : 1.7074e-02 	 Enc : 3.1614e-03 	 AEnc : 3.3716e-04 	 MSE : 6.7812e+00
Epoch 125, 50% 	 Loss : 5.2753e-02 	 Res : 2.3182e-02 	 Jac : 1.7203e-02 	 Enc : 3.1083e-03 	 AEnc : 2.9337e-04 	 MSE : 8.9674e+00
Epoch 125, 75% 	 Loss : 7.3557e-02 	 Res : 3.6729e-02 	 Jac : 1.7143e-02 	 Enc : 3.1163e-03 	 AEnc : 3.6816e-04 	 MSE : 1.6200e+01
Training Epoch 125 : 	 Train : 5.79112e-02 	 Res : 2.63155e-02 	 Jac : 1.71806e-02 	 Enc : 3.16386e-03 	 AE : 3.51491e-04 	 MSE : 1.08998e+01
Validation Epoch 125 : 	 Train : 3.15405e-02 	 Res : 8.34530e-03 	 Jac : 1.71644e-02 	 Enc : 3.15671e-03 	 AE : 2.21653e-04 	 MSE : 2.65250e+00
Training Epoch 125 finished, took current epoch 490.21s, cumulative time 55925.11s
Current Learning rate DEQ : 0.0008403499999999996
Current Learning rate AUTOENC : 0.0016806999999999992
Epoch 126, 25% 	 Loss : 3.8171e-02 	 Res : 1.1867e-02 	 Jac : 1.7366e-02 	 Enc : 3.0381e-03 	 AEnc : 2.4422e-03 	 MSE : 3.4575e+00
Epoch 126, 50% 	 Loss : 5.6150e-02 	 Res : 2.5041e-02 	 Jac : 1.6783e-02 	 Enc : 3.0953e-03 	 AEnc : 4.0939e-03 	 MSE : 7.1368e+00
Epoch 126, 75% 	 Loss : 4.0640e-02 	 Res : 1.4720e-02 	 Jac : 1.6941e-02 	 Enc : 3.0576e-03 	 AEnc : 6.4330e-04 	 MSE : 5.2775e+00
Training Epoch 126 : 	 Train : 4.29044e-02 	 Res : 1.57267e-02 	 Jac : 1.70052e-02 	 Enc : 3.07628e-03 	 AE : 1.90348e-03 	 MSE : 5.19278e+00
Validation Epoch 126 : 	 Train : 3.78336e-02 	 Res : 1.13556e-02 	 Jac : 1.70645e-02 	 Enc : 2.98853e-03 	 AE : 2.83549e-04 	 MSE : 6.14147e+00
Training Epoch 126 finished, took current epoch 472.51s, cumulative time 56397.57s
Current Learning rate DEQ : 0.0008403499999999996
Current Learning rate AUTOENC : 0.0016806999999999992
Epoch 127, 25% 	 Loss : 3.6843e-02 	 Res : 1.1659e-02 	 Jac : 1.7328e-02 	 Enc : 3.0752e-03 	 AEnc : 2.5385e-04 	 MSE : 4.5268e+00
Epoch 127, 50% 	 Loss : 5.2070e-02 	 Res : 2.2815e-02 	 Jac : 1.7018e-02 	 Enc : 3.1747e-03 	 AEnc : 9.0467e-04 	 MSE : 8.1568e+00
Epoch 127, 75% 	 Loss : 4.6037e-02 	 Res : 1.7534e-02 	 Jac : 1.7140e-02 	 Enc : 3.1846e-03 	 AEnc : 3.0466e-04 	 MSE : 7.8742e+00
Training Epoch 127 : 	 Train : 4.75614e-02 	 Res : 1.93163e-02 	 Jac : 1.71094e-02 	 Enc : 3.13886e-03 	 AE : 4.41426e-04 	 MSE : 7.55541e+00
Validation Epoch 127 : 	 Train : 4.60020e-02 	 Res : 1.74023e-02 	 Jac : 1.72253e-02 	 Enc : 3.00424e-03 	 AE : 3.69700e-04 	 MSE : 8.00053e+00
Training Epoch 127 finished, took current epoch 508.13s, cumulative time 56905.65s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
Epoch 128, 25% 	 Loss : 4.3222e-02 	 Res : 1.5240e-02 	 Jac : 1.6929e-02 	 Enc : 3.1125e-03 	 AEnc : 5.5149e-04 	 MSE : 7.3896e+00
Epoch 128, 50% 	 Loss : 4.0453e-02 	 Res : 1.3669e-02 	 Jac : 1.7047e-02 	 Enc : 3.0840e-03 	 AEnc : 3.2094e-04 	 MSE : 6.3315e+00
Epoch 128, 75% 	 Loss : 4.0489e-02 	 Res : 1.3427e-02 	 Jac : 1.7199e-02 	 Enc : 3.1091e-03 	 AEnc : 2.4293e-04 	 MSE : 6.5112e+00
Training Epoch 128 : 	 Train : 4.07774e-02 	 Res : 1.36257e-02 	 Jac : 1.70611e-02 	 Enc : 3.09733e-03 	 AE : 3.35226e-04 	 MSE : 6.65803e+00
Validation Epoch 128 : 	 Train : 3.60167e-02 	 Res : 1.05658e-02 	 Jac : 1.70746e-02 	 Enc : 3.01869e-03 	 AE : 1.73701e-04 	 MSE : 5.18384e+00
Training Epoch 128 finished, took current epoch 471.27s, cumulative time 57376.91s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
Epoch 129, 25% 	 Loss : 3.9377e-02 	 Res : 1.3174e-02 	 Jac : 1.7330e-02 	 Enc : 3.0708e-03 	 AEnc : 2.1175e-04 	 MSE : 5.5907e+00
Epoch 129, 50% 	 Loss : 4.1865e-02 	 Res : 1.5568e-02 	 Jac : 1.7197e-02 	 Enc : 3.1040e-03 	 AEnc : 8.8808e-04 	 MSE : 5.1081e+00
Epoch 129, 75% 	 Loss : 3.4541e-02 	 Res : 9.9427e-03 	 Jac : 1.7081e-02 	 Enc : 3.1098e-03 	 AEnc : 1.0504e-03 	 MSE : 3.3579e+00
Training Epoch 129 : 	 Train : 3.90672e-02 	 Res : 1.30020e-02 	 Jac : 1.71433e-02 	 Enc : 3.09626e-03 	 AE : 6.08151e-04 	 MSE : 5.21749e+00
Validation Epoch 129 : 	 Train : 3.35455e-02 	 Res : 1.05962e-02 	 Jac : 1.74939e-02 	 Enc : 3.11648e-03 	 AE : 2.16753e-04 	 MSE : 2.12217e+00
Training Epoch 129 finished, took current epoch 507.40s, cumulative time 57884.27s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
Epoch 130, 25% 	 Loss : 4.9074e-02 	 Res : 2.0146e-02 	 Jac : 1.6873e-02 	 Enc : 3.1303e-03 	 AEnc : 8.4571e-04 	 MSE : 8.0783e+00
Epoch 130, 50% 	 Loss : 3.4879e-02 	 Res : 9.8178e-03 	 Jac : 1.7144e-02 	 Enc : 3.1539e-03 	 AEnc : 6.8849e-04 	 MSE : 4.0747e+00
Epoch 130, 75% 	 Loss : 3.3210e-02 	 Res : 9.2055e-03 	 Jac : 1.7114e-02 	 Enc : 3.0631e-03 	 AEnc : 2.2733e-04 	 MSE : 3.5992e+00
Training Epoch 130 : 	 Train : 4.34689e-02 	 Res : 1.59639e-02 	 Jac : 1.71269e-02 	 Enc : 3.12329e-03 	 AE : 4.97126e-04 	 MSE : 6.75759e+00
Validation Epoch 130 : 	 Train : 3.96577e-02 	 Res : 1.19241e-02 	 Jac : 1.65218e-02 	 Enc : 3.11401e-03 	 AE : 2.50014e-04 	 MSE : 7.84768e+00
Training Epoch 130 finished, took current epoch 480.93s, cumulative time 58365.17s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
Epoch 131, 25% 	 Loss : 3.8777e-02 	 Res : 1.3096e-02 	 Jac : 1.6957e-02 	 Enc : 3.1624e-03 	 AEnc : 2.0016e-04 	 MSE : 5.3617e+00
Epoch 131, 50% 	 Loss : 3.0162e-02 	 Res : 7.3331e-03 	 Jac : 1.6972e-02 	 Enc : 3.1171e-03 	 AEnc : 2.0155e-04 	 MSE : 2.5387e+00
Epoch 131, 75% 	 Loss : 3.1054e-02 	 Res : 8.1348e-03 	 Jac : 1.6954e-02 	 Enc : 3.0796e-03 	 AEnc : 1.9438e-04 	 MSE : 2.6909e+00
Training Epoch 131 : 	 Train : 3.76328e-02 	 Res : 1.23215e-02 	 Jac : 1.70503e-02 	 Enc : 3.11528e-03 	 AE : 2.09739e-04 	 MSE : 4.93602e+00
Validation Epoch 131 : 	 Train : 5.28970e-02 	 Res : 2.08497e-02 	 Jac : 1.62823e-02 	 Enc : 3.19368e-03 	 AE : 2.88030e-04 	 MSE : 1.22833e+01
Training Epoch 131 finished, took current epoch 475.05s, cumulative time 58840.19s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
Epoch 132, 25% 	 Loss : 4.5216e-02 	 Res : 1.6804e-02 	 Jac : 1.6759e-02 	 Enc : 3.2391e-03 	 AEnc : 3.7386e-04 	 MSE : 8.0404e+00
Epoch 132, 50% 	 Loss : 4.3123e-02 	 Res : 1.6607e-02 	 Jac : 1.7177e-02 	 Enc : 3.2143e-03 	 AEnc : 2.6377e-04 	 MSE : 5.8606e+00
Epoch 132, 75% 	 Loss : 4.6540e-02 	 Res : 1.9320e-02 	 Jac : 1.7035e-02 	 Enc : 3.0955e-03 	 AEnc : 3.2399e-04 	 MSE : 6.7657e+00
Training Epoch 132 : 	 Train : 4.34405e-02 	 Res : 1.64482e-02 	 Jac : 1.69247e-02 	 Enc : 3.17546e-03 	 AE : 2.94393e-04 	 MSE : 6.59782e+00
Validation Epoch 132 : 	 Train : 3.05353e-02 	 Res : 7.46433e-03 	 Jac : 1.65450e-02 	 Enc : 3.15265e-03 	 AE : 3.80058e-04 	 MSE : 2.99327e+00
Training Epoch 132 finished, took current epoch 482.00s, cumulative time 59322.09s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
MODEL SAVED
Epoch 133, 25% 	 Loss : 3.3954e-02 	 Res : 9.3598e-03 	 Jac : 1.6871e-02 	 Enc : 3.1419e-03 	 AEnc : 9.8056e-04 	 MSE : 3.6008e+00
Epoch 133, 50% 	 Loss : 3.0306e-02 	 Res : 7.2616e-03 	 Jac : 1.7099e-02 	 Enc : 3.0855e-03 	 AEnc : 6.1151e-04 	 MSE : 2.2481e+00
Epoch 133, 75% 	 Loss : 4.2807e-02 	 Res : 1.4748e-02 	 Jac : 1.7038e-02 	 Enc : 3.1004e-03 	 AEnc : 1.1752e-03 	 MSE : 6.7447e+00
Training Epoch 133 : 	 Train : 3.64888e-02 	 Res : 1.07066e-02 	 Jac : 1.69922e-02 	 Enc : 3.12704e-03 	 AE : 1.38915e-03 	 MSE : 4.27385e+00
Validation Epoch 133 : 	 Train : 3.43239e-02 	 Res : 8.45390e-03 	 Jac : 1.65737e-02 	 Enc : 3.15781e-03 	 AE : 1.93405e-03 	 MSE : 4.20442e+00
Training Epoch 133 finished, took current epoch 486.18s, cumulative time 59808.23s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
Epoch 134, 25% 	 Loss : 4.7662e-02 	 Res : 1.9033e-02 	 Jac : 1.7009e-02 	 Enc : 3.1757e-03 	 AEnc : 1.0354e-03 	 MSE : 7.4093e+00
Epoch 134, 50% 	 Loss : 4.6175e-02 	 Res : 1.7444e-02 	 Jac : 1.6872e-02 	 Enc : 3.2321e-03 	 AEnc : 1.0640e-03 	 MSE : 7.5638e+00
Epoch 134, 75% 	 Loss : 4.0141e-02 	 Res : 1.3451e-02 	 Jac : 1.6736e-02 	 Enc : 3.1935e-03 	 AEnc : 3.3796e-04 	 MSE : 6.4220e+00
Training Epoch 134 : 	 Train : 4.38851e-02 	 Res : 1.60080e-02 	 Jac : 1.68792e-02 	 Enc : 3.19437e-03 	 AE : 6.80252e-04 	 MSE : 7.12326e+00
Validation Epoch 134 : 	 Train : 3.48061e-02 	 Res : 9.52731e-03 	 Jac : 1.64414e-02 	 Enc : 3.21614e-03 	 AE : 2.63558e-04 	 MSE : 5.35770e+00
Training Epoch 134 finished, took current epoch 489.21s, cumulative time 60297.41s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
Epoch 135, 25% 	 Loss : 3.2269e-02 	 Res : 8.6131e-03 	 Jac : 1.6727e-02 	 Enc : 3.1856e-03 	 AEnc : 1.8545e-04 	 MSE : 3.5582e+00
Epoch 135, 50% 	 Loss : 5.6973e-02 	 Res : 2.7899e-02 	 Jac : 1.6929e-02 	 Enc : 3.1841e-03 	 AEnc : 1.2210e-03 	 MSE : 7.7401e+00
Epoch 135, 75% 	 Loss : 8.3865e-02 	 Res : 4.5122e-02 	 Jac : 1.6930e-02 	 Enc : 3.3149e-03 	 AEnc : 8.9793e-04 	 MSE : 1.7601e+01
Training Epoch 135 : 	 Train : 5.27382e-02 	 Res : 2.33549e-02 	 Jac : 1.67860e-02 	 Enc : 3.24023e-03 	 AE : 1.00539e-03 	 MSE : 8.35175e+00
Validation Epoch 135 : 	 Train : 4.09866e-02 	 Res : 1.31626e-02 	 Jac : 1.69629e-02 	 Enc : 3.27100e-03 	 AE : 5.60439e-03 	 MSE : 1.98578e+00
Training Epoch 135 finished, took current epoch 523.08s, cumulative time 60820.43s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
Epoch 136, 25% 	 Loss : 4.0356e-02 	 Res : 1.1890e-02 	 Jac : 1.6958e-02 	 Enc : 3.1679e-03 	 AEnc : 4.8987e-03 	 MSE : 3.4415e+00
Epoch 136, 50% 	 Loss : 3.4460e-02 	 Res : 9.6091e-03 	 Jac : 1.6924e-02 	 Enc : 3.1517e-03 	 AEnc : 8.8820e-04 	 MSE : 3.8871e+00
Epoch 136, 75% 	 Loss : 3.3251e-02 	 Res : 8.9450e-03 	 Jac : 1.6997e-02 	 Enc : 3.1607e-03 	 AEnc : 2.5234e-04 	 MSE : 3.8958e+00
Training Epoch 136 : 	 Train : 3.59728e-02 	 Res : 1.01606e-02 	 Jac : 1.69876e-02 	 Enc : 3.16248e-03 	 AE : 1.90969e-03 	 MSE : 3.75245e+00
Validation Epoch 136 : 	 Train : 6.01212e-02 	 Res : 2.48069e-02 	 Jac : 1.70579e-02 	 Enc : 3.00921e-03 	 AE : 2.50945e-04 	 MSE : 1.49963e+01
Training Epoch 136 finished, took current epoch 490.23s, cumulative time 61310.61s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
Epoch 137, 25% 	 Loss : 3.7110e-02 	 Res : 1.1348e-02 	 Jac : 1.6818e-02 	 Enc : 3.1623e-03 	 AEnc : 7.3686e-04 	 MSE : 5.0449e+00
Epoch 137, 50% 	 Loss : 5.0084e-02 	 Res : 2.0492e-02 	 Jac : 1.6702e-02 	 Enc : 3.2309e-03 	 AEnc : 8.2817e-04 	 MSE : 8.8311e+00
Epoch 137, 75% 	 Loss : 3.5065e-02 	 Res : 9.9674e-03 	 Jac : 1.6770e-02 	 Enc : 3.2415e-03 	 AEnc : 9.6438e-04 	 MSE : 4.1214e+00
Training Epoch 137 : 	 Train : 3.91876e-02 	 Res : 1.28620e-02 	 Jac : 1.68011e-02 	 Enc : 3.20399e-03 	 AE : 8.36127e-04 	 MSE : 5.48445e+00
Validation Epoch 137 : 	 Train : 3.17820e-02 	 Res : 8.59550e-03 	 Jac : 1.71015e-02 	 Enc : 3.25918e-03 	 AE : 5.67171e-04 	 MSE : 2.25869e+00
Training Epoch 137 finished, took current epoch 505.96s, cumulative time 61816.56s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
Epoch 138, 25% 	 Loss : 3.4284e-02 	 Res : 9.7229e-03 	 Jac : 1.7071e-02 	 Enc : 3.1797e-03 	 AEnc : 2.3984e-04 	 MSE : 4.0704e+00
Epoch 138, 50% 	 Loss : 3.4624e-02 	 Res : 1.0430e-02 	 Jac : 1.6941e-02 	 Enc : 3.1540e-03 	 AEnc : 4.4052e-04 	 MSE : 3.6590e+00
Epoch 138, 75% 	 Loss : 4.7478e-02 	 Res : 1.4436e-02 	 Jac : 1.6795e-02 	 Enc : 3.1788e-03 	 AEnc : 7.0905e-03 	 MSE : 5.9785e+00
Training Epoch 138 : 	 Train : 4.12531e-02 	 Res : 1.24496e-02 	 Jac : 1.68938e-02 	 Enc : 3.19272e-03 	 AE : 3.61051e-03 	 MSE : 5.10648e+00
Validation Epoch 138 : 	 Train : 6.03641e-02 	 Res : 2.95058e-02 	 Jac : 1.79318e-02 	 Enc : 3.21742e-03 	 AE : 9.91446e-04 	 MSE : 8.71766e+00
Training Epoch 138 finished, took current epoch 530.40s, cumulative time 62346.93s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
Epoch 139, 25% 	 Loss : 6.1437e-02 	 Res : 2.8461e-02 	 Jac : 1.6768e-02 	 Enc : 3.3375e-03 	 AEnc : 7.3979e-04 	 MSE : 1.2131e+01
Epoch 139, 50% 	 Loss : 4.4170e-02 	 Res : 1.5853e-02 	 Jac : 1.6784e-02 	 Enc : 3.3384e-03 	 AEnc : 4.2577e-04 	 MSE : 7.7682e+00
Epoch 139, 75% 	 Loss : 3.9259e-02 	 Res : 1.2550e-02 	 Jac : 1.6943e-02 	 Enc : 3.2340e-03 	 AEnc : 5.3111e-04 	 MSE : 6.0005e+00
Training Epoch 139 : 	 Train : 4.64975e-02 	 Res : 1.76228e-02 	 Jac : 1.67949e-02 	 Enc : 3.27615e-03 	 AE : 5.18736e-04 	 MSE : 8.28489e+00
Validation Epoch 139 : 	 Train : 3.11788e-02 	 Res : 7.52082e-03 	 Jac : 1.69436e-02 	 Enc : 3.27932e-03 	 AE : 4.44099e-04 	 MSE : 2.99093e+00
Training Epoch 139 finished, took current epoch 500.47s, cumulative time 62847.39s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
Epoch 140, 25% 	 Loss : 3.4091e-02 	 Res : 9.9136e-03 	 Jac : 1.7013e-02 	 Enc : 3.2173e-03 	 AEnc : 2.1796e-04 	 MSE : 3.7291e+00
Epoch 140, 50% 	 Loss : 8.5616e-02 	 Res : 4.9064e-02 	 Jac : 1.7114e-02 	 Enc : 3.4069e-03 	 AEnc : 3.7275e-04 	 MSE : 1.5658e+01
Epoch 140, 75% 	 Loss : 4.5012e-02 	 Res : 1.7019e-02 	 Jac : 1.6565e-02 	 Enc : 3.4388e-03 	 AEnc : 3.3118e-04 	 MSE : 7.6582e+00
Training Epoch 140 : 	 Train : 5.52288e-02 	 Res : 2.55718e-02 	 Jac : 1.68606e-02 	 Enc : 3.35016e-03 	 AE : 6.53458e-04 	 MSE : 8.79286e+00
Validation Epoch 140 : 	 Train : 3.61213e-01 	 Res : 2.58628e-01 	 Jac : 1.92284e-02 	 Enc : 4.36135e-03 	 AE : 9.25458e-03 	 MSE : 6.97410e+01
Training Epoch 140 finished, took current epoch 556.19s, cumulative time 63403.57s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
Epoch 141, 25% 	 Loss : 7.1765e-02 	 Res : 3.6361e-02 	 Jac : 1.6652e-02 	 Enc : 3.4068e-03 	 AEnc : 2.8603e-03 	 MSE : 1.2485e+01
Epoch 141, 50% 	 Loss : 3.8329e-02 	 Res : 1.2407e-02 	 Jac : 1.6695e-02 	 Enc : 3.3766e-03 	 AEnc : 5.3589e-04 	 MSE : 5.3146e+00
Epoch 141, 75% 	 Loss : 3.4519e-02 	 Res : 9.8572e-03 	 Jac : 1.6806e-02 	 Enc : 3.2532e-03 	 AEnc : 7.1256e-04 	 MSE : 3.8901e+00
Training Epoch 141 : 	 Train : 4.47167e-02 	 Res : 1.71435e-02 	 Jac : 1.67263e-02 	 Enc : 3.31279e-03 	 AE : 1.10939e-03 	 MSE : 6.42472e+00
Validation Epoch 141 : 	 Train : 3.02502e-02 	 Res : 6.88066e-03 	 Jac : 1.64365e-02 	 Enc : 3.21514e-03 	 AE : 1.62520e-04 	 MSE : 3.55535e+00
Training Epoch 141 finished, took current epoch 481.56s, cumulative time 63885.04s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
MODEL SAVED
Epoch 142, 25% 	 Loss : 4.2207e-02 	 Res : 1.4438e-02 	 Jac : 1.6874e-02 	 Enc : 3.2775e-03 	 AEnc : 2.0308e-04 	 MSE : 7.4148e+00
Epoch 142, 50% 	 Loss : 3.4133e-02 	 Res : 9.7052e-03 	 Jac : 1.6739e-02 	 Enc : 3.2645e-03 	 AEnc : 3.9232e-04 	 MSE : 4.0313e+00
Epoch 142, 75% 	 Loss : 3.6571e-02 	 Res : 8.8751e-03 	 Jac : 1.6854e-02 	 Enc : 3.2220e-03 	 AEnc : 4.8927e-03 	 MSE : 2.7275e+00
Training Epoch 142 : 	 Train : 4.06888e-02 	 Res : 1.23019e-02 	 Jac : 1.67875e-02 	 Enc : 3.24197e-03 	 AE : 3.19976e-03 	 MSE : 5.15763e+00
Validation Epoch 142 : 	 Train : 1.15847e-01 	 Res : 6.30138e-02 	 Jac : 1.76725e-02 	 Enc : 3.11062e-03 	 AE : 7.54387e-03 	 MSE : 2.45058e+01
Training Epoch 142 finished, took current epoch 534.57s, cumulative time 64419.57s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
Epoch 143, 25% 	 Loss : 4.6086e-02 	 Res : 1.5731e-02 	 Jac : 1.6423e-02 	 Enc : 3.3199e-03 	 AEnc : 2.2892e-03 	 MSE : 8.3232e+00
Epoch 143, 50% 	 Loss : 4.0306e-02 	 Res : 1.3066e-02 	 Jac : 1.6863e-02 	 Enc : 3.3424e-03 	 AEnc : 1.4483e-03 	 MSE : 5.5862e+00
Epoch 143, 75% 	 Loss : 3.7188e-02 	 Res : 1.0065e-02 	 Jac : 1.6763e-02 	 Enc : 3.1993e-03 	 AEnc : 3.2128e-03 	 MSE : 3.9478e+00
Training Epoch 143 : 	 Train : 4.44481e-02 	 Res : 1.28891e-02 	 Jac : 1.66699e-02 	 Enc : 3.27939e-03 	 AE : 6.08892e-03 	 MSE : 5.52074e+00
Validation Epoch 143 : 	 Train : 3.22947e-02 	 Res : 6.40803e-03 	 Jac : 1.64822e-02 	 Enc : 3.23948e-03 	 AE : 3.80173e-03 	 MSE : 2.36326e+00
Training Epoch 143 finished, took current epoch 482.87s, cumulative time 64902.37s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
MODEL SAVED
Epoch 144, 25% 	 Loss : 3.9119e-02 	 Res : 1.1191e-02 	 Jac : 1.6598e-02 	 Enc : 3.2530e-03 	 AEnc : 2.7706e-03 	 MSE : 5.3062e+00
Epoch 144, 50% 	 Loss : 3.9997e-02 	 Res : 1.3862e-02 	 Jac : 1.6490e-02 	 Enc : 3.2118e-03 	 AEnc : 2.6543e-04 	 MSE : 6.1680e+00
Epoch 144, 75% 	 Loss : 4.3692e-02 	 Res : 1.5078e-02 	 Jac : 1.6585e-02 	 Enc : 3.2854e-03 	 AEnc : 2.4196e-04 	 MSE : 8.5018e+00
Training Epoch 144 : 	 Train : 3.95660e-02 	 Res : 1.27164e-02 	 Jac : 1.66057e-02 	 Enc : 3.26472e-03 	 AE : 8.88679e-04 	 MSE : 6.09055e+00
Validation Epoch 144 : 	 Train : 3.89406e-02 	 Res : 1.21097e-02 	 Jac : 1.65858e-02 	 Enc : 3.19986e-03 	 AE : 1.18362e-04 	 MSE : 6.92690e+00
Training Epoch 144 finished, took current epoch 477.83s, cumulative time 65380.16s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
Epoch 145, 25% 	 Loss : 3.4122e-02 	 Res : 9.4687e-03 	 Jac : 1.6644e-02 	 Enc : 3.2539e-03 	 AEnc : 1.7607e-04 	 MSE : 4.5791e+00
Epoch 145, 50% 	 Loss : 4.5841e-02 	 Res : 1.7740e-02 	 Jac : 1.6668e-02 	 Enc : 3.2723e-03 	 AEnc : 1.5447e-04 	 MSE : 8.0056e+00
Epoch 145, 75% 	 Loss : 4.2172e-02 	 Res : 1.4043e-02 	 Jac : 1.6578e-02 	 Enc : 3.3039e-03 	 AEnc : 1.5195e-04 	 MSE : 8.0948e+00
Training Epoch 145 : 	 Train : 4.13111e-02 	 Res : 1.40501e-02 	 Jac : 1.66788e-02 	 Enc : 3.27867e-03 	 AE : 1.53658e-04 	 MSE : 7.14984e+00
Validation Epoch 145 : 	 Train : 3.77387e-02 	 Res : 1.06295e-02 	 Jac : 1.62184e-02 	 Enc : 3.28240e-03 	 AE : 1.37992e-04 	 MSE : 7.47041e+00
Training Epoch 145 finished, took current epoch 459.21s, cumulative time 65839.33s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
Epoch 146, 25% 	 Loss : 3.5980e-02 	 Res : 1.1136e-02 	 Jac : 1.6660e-02 	 Enc : 3.3156e-03 	 AEnc : 1.9161e-04 	 MSE : 4.6769e+00
Epoch 146, 50% 	 Loss : 3.5151e-02 	 Res : 1.0492e-02 	 Jac : 1.6688e-02 	 Enc : 3.3018e-03 	 AEnc : 2.7437e-04 	 MSE : 4.3943e+00
Epoch 146, 75% 	 Loss : 3.7211e-02 	 Res : 1.2369e-02 	 Jac : 1.6534e-02 	 Enc : 3.2494e-03 	 AEnc : 8.2516e-04 	 MSE : 4.2333e+00
Training Epoch 146 : 	 Train : 3.77119e-02 	 Res : 1.24678e-02 	 Jac : 1.66397e-02 	 Enc : 3.28932e-03 	 AE : 4.02512e-04 	 MSE : 4.91267e+00
Validation Epoch 146 : 	 Train : 3.15528e-02 	 Res : 8.88990e-03 	 Jac : 1.67818e-02 	 Enc : 3.35336e-03 	 AE : 1.71336e-04 	 MSE : 2.35646e+00
Training Epoch 146 finished, took current epoch 509.92s, cumulative time 66349.23s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
Epoch 147, 25% 	 Loss : 3.8680e-02 	 Res : 1.3267e-02 	 Jac : 1.6489e-02 	 Enc : 3.2943e-03 	 AEnc : 1.3767e-03 	 MSE : 4.2523e+00
Epoch 147, 50% 	 Loss : 3.7537e-02 	 Res : 1.2452e-02 	 Jac : 1.6442e-02 	 Enc : 3.3095e-03 	 AEnc : 7.0319e-04 	 MSE : 4.6304e+00
Epoch 147, 75% 	 Loss : 3.0337e-02 	 Res : 7.6249e-03 	 Jac : 1.6582e-02 	 Enc : 3.3097e-03 	 AEnc : 2.5282e-04 	 MSE : 2.5675e+00
Training Epoch 147 : 	 Train : 3.40268e-02 	 Res : 1.01321e-02 	 Jac : 1.64943e-02 	 Enc : 3.28954e-03 	 AE : 6.34242e-04 	 MSE : 3.47664e+00
Validation Epoch 147 : 	 Train : 3.35857e-02 	 Res : 9.49594e-03 	 Jac : 1.66784e-02 	 Enc : 3.20231e-03 	 AE : 1.05199e-04 	 MSE : 4.10384e+00
Training Epoch 147 finished, took current epoch 502.95s, cumulative time 66852.17s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
Epoch 148, 25% 	 Loss : 3.7903e-02 	 Res : 1.2098e-02 	 Jac : 1.6350e-02 	 Enc : 3.2919e-03 	 AEnc : 1.2747e-04 	 MSE : 6.0358e+00
Epoch 148, 50% 	 Loss : 3.2586e-02 	 Res : 8.9172e-03 	 Jac : 1.6559e-02 	 Enc : 3.2862e-03 	 AEnc : 1.8072e-04 	 MSE : 3.6426e+00
Epoch 148, 75% 	 Loss : 3.4791e-02 	 Res : 1.0446e-02 	 Jac : 1.6608e-02 	 Enc : 3.2687e-03 	 AEnc : 8.6278e-04 	 MSE : 3.6046e+00
Training Epoch 148 : 	 Train : 3.59541e-02 	 Res : 1.09271e-02 	 Jac : 1.64763e-02 	 Enc : 3.29381e-03 	 AE : 3.71538e-04 	 MSE : 4.88540e+00
Validation Epoch 148 : 	 Train : 4.89704e-02 	 Res : 1.82505e-02 	 Jac : 1.68468e-02 	 Enc : 3.24525e-03 	 AE : 6.27748e-04 	 MSE : 1.00001e+01
Training Epoch 148 finished, took current epoch 500.06s, cumulative time 67352.21s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
Epoch 149, 25% 	 Loss : 3.8653e-02 	 Res : 1.2386e-02 	 Jac : 1.6533e-02 	 Enc : 3.3474e-03 	 AEnc : 2.7593e-04 	 MSE : 6.1112e+00
Epoch 149, 50% 	 Loss : 3.6005e-02 	 Res : 1.1099e-02 	 Jac : 1.6566e-02 	 Enc : 3.3187e-03 	 AEnc : 2.7036e-04 	 MSE : 4.7498e+00
Epoch 149, 75% 	 Loss : 3.1446e-02 	 Res : 8.0961e-03 	 Jac : 1.6434e-02 	 Enc : 3.2821e-03 	 AEnc : 4.3591e-04 	 MSE : 3.1977e+00
Training Epoch 149 : 	 Train : 4.06541e-02 	 Res : 1.40139e-02 	 Jac : 1.64649e-02 	 Enc : 3.31450e-03 	 AE : 3.24881e-04 	 MSE : 6.53584e+00
Validation Epoch 149 : 	 Train : 4.33622e-02 	 Res : 1.34835e-02 	 Jac : 1.58344e-02 	 Enc : 3.41564e-03 	 AE : 2.84986e-04 	 MSE : 1.03437e+01
Training Epoch 149 finished, took current epoch 469.80s, cumulative time 67822.00s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
Epoch 150, 25% 	 Loss : 4.1422e-02 	 Res : 1.4897e-02 	 Jac : 1.6474e-02 	 Enc : 3.4312e-03 	 AEnc : 2.4773e-04 	 MSE : 6.3721e+00
Epoch 150, 50% 	 Loss : 3.4142e-02 	 Res : 9.5801e-03 	 Jac : 1.6542e-02 	 Enc : 3.3665e-03 	 AEnc : 1.7612e-04 	 MSE : 4.4766e+00
Epoch 150, 75% 	 Loss : 3.8535e-02 	 Res : 1.2372e-02 	 Jac : 1.6464e-02 	 Enc : 3.3099e-03 	 AEnc : 1.8506e-04 	 MSE : 6.2037e+00
Training Epoch 150 : 	 Train : 3.79682e-02 	 Res : 1.22605e-02 	 Jac : 1.65005e-02 	 Enc : 3.36067e-03 	 AE : 2.15970e-04 	 MSE : 5.63061e+00
Validation Epoch 150 : 	 Train : 3.57646e-02 	 Res : 1.12503e-02 	 Jac : 1.66415e-02 	 Enc : 3.42632e-03 	 AE : 1.46064e-04 	 MSE : 4.30042e+00
Training Epoch 150 finished, took current epoch 506.76s, cumulative time 68328.73s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
Epoch 151, 25% 	 Loss : 3.5379e-02 	 Res : 1.0780e-02 	 Jac : 1.6544e-02 	 Enc : 3.3391e-03 	 AEnc : 2.1841e-04 	 MSE : 4.4971e+00
Epoch 151, 50% 	 Loss : 4.1565e-02 	 Res : 1.3784e-02 	 Jac : 1.6417e-02 	 Enc : 3.2921e-03 	 AEnc : 5.3439e-04 	 MSE : 7.5373e+00
Epoch 151, 75% 	 Loss : 3.6362e-02 	 Res : 1.1186e-02 	 Jac : 1.6623e-02 	 Enc : 3.3636e-03 	 AEnc : 9.0376e-04 	 MSE : 4.2858e+00
Training Epoch 151 : 	 Train : 3.74287e-02 	 Res : 1.18784e-02 	 Jac : 1.65528e-02 	 Enc : 3.32979e-03 	 AE : 5.00035e-04 	 MSE : 5.16762e+00
Validation Epoch 151 : 	 Train : 3.04743e-02 	 Res : 7.37579e-03 	 Jac : 1.61704e-02 	 Enc : 3.35997e-03 	 AE : 1.67190e-04 	 MSE : 3.40101e+00
Training Epoch 151 finished, took current epoch 477.34s, cumulative time 68806.05s
Current Learning rate DEQ : 0.0005882449999999997
Current Learning rate AUTOENC : 0.0011764899999999994
Epoch 152, 25% 	 Loss : 4.2223e-02 	 Res : 1.5665e-02 	 Jac : 1.6456e-02 	 Enc : 3.3679e-03 	 AEnc : 2.1997e-04 	 MSE : 6.5134e+00
Epoch 152, 50% 	 Loss : 3.3177e-02 	 Res : 9.0945e-03 	 Jac : 1.6544e-02 	 Enc : 3.3422e-03 	 AEnc : 1.3563e-04 	 MSE : 4.0607e+00
Epoch 152, 75% 	 Loss : 3.7608e-02 	 Res : 1.2272e-02 	 Jac : 1.6547e-02 	 Enc : 3.3521e-03 	 AEnc : 1.9958e-04 	 MSE : 5.2381e+00
Training Epoch 152 : 	 Train : 3.74174e-02 	 Res : 1.21625e-02 	 Jac : 1.64679e-02 	 Enc : 3.35161e-03 	 AE : 2.38483e-04 	 MSE : 5.19693e+00
Validation Epoch 152 : 	 Train : 3.38862e-02 	 Res : 9.08481e-03 	 Jac : 1.60759e-02 	 Enc : 3.28913e-03 	 AE : 5.23036e-04 	 MSE : 4.91333e+00
Training Epoch 152 finished, took current epoch 508.75s, cumulative time 69314.77s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 153, 25% 	 Loss : 3.5325e-02 	 Res : 1.0178e-02 	 Jac : 1.6361e-02 	 Enc : 3.3581e-03 	 AEnc : 4.0118e-04 	 MSE : 5.0275e+00
Epoch 153, 50% 	 Loss : 3.3223e-02 	 Res : 9.1627e-03 	 Jac : 1.6469e-02 	 Enc : 3.3413e-03 	 AEnc : 1.6252e-04 	 MSE : 4.0875e+00
Epoch 153, 75% 	 Loss : 2.9249e-02 	 Res : 6.9780e-03 	 Jac : 1.6485e-02 	 Enc : 3.2815e-03 	 AEnc : 1.6922e-04 	 MSE : 2.3352e+00
Training Epoch 153 : 	 Train : 3.19829e-02 	 Res : 8.43612e-03 	 Jac : 1.64630e-02 	 Enc : 3.31798e-03 	 AE : 2.78176e-04 	 MSE : 3.48765e+00
Validation Epoch 153 : 	 Train : 3.84342e-02 	 Res : 1.11488e-02 	 Jac : 1.68207e-02 	 Enc : 3.21552e-03 	 AE : 2.86048e-03 	 MSE : 4.38870e+00
Training Epoch 153 finished, took current epoch 530.48s, cumulative time 69845.21s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 154, 25% 	 Loss : 3.2662e-02 	 Res : 8.4269e-03 	 Jac : 1.6467e-02 	 Enc : 3.2828e-03 	 AEnc : 1.0969e-03 	 MSE : 3.3891e+00
Epoch 154, 50% 	 Loss : 4.1044e-02 	 Res : 8.7968e-03 	 Jac : 1.6474e-02 	 Enc : 3.2812e-03 	 AEnc : 9.7855e-03 	 MSE : 2.7061e+00
Epoch 154, 75% 	 Loss : 3.6308e-02 	 Res : 9.2210e-03 	 Jac : 1.6432e-02 	 Enc : 3.2842e-03 	 AEnc : 3.7284e-03 	 MSE : 3.6420e+00
Training Epoch 154 : 	 Train : 3.64114e-02 	 Res : 8.92075e-03 	 Jac : 1.64525e-02 	 Enc : 3.29355e-03 	 AE : 4.29248e-03 	 MSE : 3.45217e+00
Validation Epoch 154 : 	 Train : 3.25203e-02 	 Res : 8.20195e-03 	 Jac : 1.64246e-02 	 Enc : 3.38745e-03 	 AE : 8.81198e-04 	 MSE : 3.62507e+00
Training Epoch 154 finished, took current epoch 497.43s, cumulative time 70342.62s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 155, 25% 	 Loss : 3.4020e-02 	 Res : 8.5813e-03 	 Jac : 1.6479e-02 	 Enc : 3.3362e-03 	 AEnc : 2.5058e-03 	 MSE : 3.1184e+00
Epoch 155, 50% 	 Loss : 3.1079e-02 	 Res : 7.8754e-03 	 Jac : 1.6372e-02 	 Enc : 3.2843e-03 	 AEnc : 8.2139e-04 	 MSE : 2.7256e+00
Epoch 155, 75% 	 Loss : 3.0625e-02 	 Res : 7.5677e-03 	 Jac : 1.6404e-02 	 Enc : 3.3161e-03 	 AEnc : 1.7454e-04 	 MSE : 3.1622e+00
Training Epoch 155 : 	 Train : 3.27845e-02 	 Res : 8.56209e-03 	 Jac : 1.63853e-02 	 Enc : 3.31301e-03 	 AE : 9.38914e-04 	 MSE : 3.58511e+00
Validation Epoch 155 : 	 Train : 4.07591e-02 	 Res : 1.33871e-02 	 Jac : 1.62228e-02 	 Enc : 3.44040e-03 	 AE : 1.56417e-04 	 MSE : 7.55232e+00
Training Epoch 155 finished, took current epoch 507.54s, cumulative time 70850.13s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 156, 25% 	 Loss : 3.2042e-02 	 Res : 8.2755e-03 	 Jac : 1.6352e-02 	 Enc : 3.3459e-03 	 AEnc : 2.1883e-04 	 MSE : 3.8495e+00
Epoch 156, 50% 	 Loss : 3.4702e-02 	 Res : 1.0644e-02 	 Jac : 1.6524e-02 	 Enc : 3.3066e-03 	 AEnc : 5.3567e-04 	 MSE : 3.6925e+00
Epoch 156, 75% 	 Loss : 3.3307e-02 	 Res : 9.0462e-03 	 Jac : 1.6397e-02 	 Enc : 3.3434e-03 	 AEnc : 8.5189e-04 	 MSE : 3.6686e+00
Training Epoch 156 : 	 Train : 3.33131e-02 	 Res : 9.25826e-03 	 Jac : 1.63893e-02 	 Enc : 3.33791e-03 	 AE : 5.95754e-04 	 MSE : 3.73187e+00
Validation Epoch 156 : 	 Train : 2.84485e-02 	 Res : 6.43590e-03 	 Jac : 1.63800e-02 	 Enc : 3.31004e-03 	 AE : 1.53350e-04 	 MSE : 2.16920e+00
Training Epoch 156 finished, took current epoch 500.76s, cumulative time 71350.87s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 157, 25% 	 Loss : 4.0145e-02 	 Res : 1.4079e-02 	 Jac : 1.6498e-02 	 Enc : 3.3519e-03 	 AEnc : 1.9072e-04 	 MSE : 6.0259e+00
Epoch 157, 50% 	 Loss : 3.3639e-02 	 Res : 9.3818e-03 	 Jac : 1.6355e-02 	 Enc : 3.4092e-03 	 AEnc : 1.7251e-04 	 MSE : 4.3208e+00
Epoch 157, 75% 	 Loss : 3.0333e-02 	 Res : 7.6816e-03 	 Jac : 1.6380e-02 	 Enc : 3.3273e-03 	 AEnc : 1.7630e-04 	 MSE : 2.7676e+00
Training Epoch 157 : 	 Train : 3.70444e-02 	 Res : 1.21242e-02 	 Jac : 1.64394e-02 	 Enc : 3.36632e-03 	 AE : 1.86921e-04 	 MSE : 4.92756e+00
Validation Epoch 157 : 	 Train : 3.01084e-02 	 Res : 6.92551e-03 	 Jac : 1.61200e-02 	 Enc : 3.43233e-03 	 AE : 4.47909e-04 	 MSE : 3.18265e+00
Training Epoch 157 finished, took current epoch 526.20s, cumulative time 71877.02s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 158, 25% 	 Loss : 2.8305e-02 	 Res : 6.1686e-03 	 Jac : 1.6410e-02 	 Enc : 3.3499e-03 	 AEnc : 4.7740e-04 	 MSE : 1.8995e+00
Epoch 158, 50% 	 Loss : 2.9321e-02 	 Res : 6.6622e-03 	 Jac : 1.6397e-02 	 Enc : 3.3139e-03 	 AEnc : 4.8519e-04 	 MSE : 2.4630e+00
Epoch 158, 75% 	 Loss : 3.0573e-02 	 Res : 7.4422e-03 	 Jac : 1.6340e-02 	 Enc : 3.3506e-03 	 AEnc : 4.6913e-04 	 MSE : 2.9711e+00
Training Epoch 158 : 	 Train : 3.07878e-02 	 Res : 7.64396e-03 	 Jac : 1.63851e-02 	 Enc : 3.33565e-03 	 AE : 4.01525e-04 	 MSE : 3.02157e+00
Validation Epoch 158 : 	 Train : 2.99224e-02 	 Res : 6.81934e-03 	 Jac : 1.59660e-02 	 Enc : 3.31892e-03 	 AE : 1.48813e-04 	 MSE : 3.66930e+00
Training Epoch 158 finished, took current epoch 675.04s, cumulative time 72552.05s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 159, 25% 	 Loss : 5.0642e-02 	 Res : 1.9550e-02 	 Jac : 1.6427e-02 	 Enc : 3.3858e-03 	 AEnc : 1.6640e-04 	 MSE : 1.1113e+01
Epoch 159, 50% 	 Loss : 3.2808e-02 	 Res : 8.8629e-03 	 Jac : 1.6299e-02 	 Enc : 3.4189e-03 	 AEnc : 1.8243e-04 	 MSE : 4.0452e+00
Epoch 159, 75% 	 Loss : 2.7760e-02 	 Res : 6.1258e-03 	 Jac : 1.6379e-02 	 Enc : 3.3578e-03 	 AEnc : 1.6502e-04 	 MSE : 1.7323e+00
Training Epoch 159 : 	 Train : 3.56989e-02 	 Res : 1.07601e-02 	 Jac : 1.63710e-02 	 Enc : 3.37789e-03 	 AE : 2.31578e-04 	 MSE : 4.95836e+00
Validation Epoch 159 : 	 Train : 4.30397e-02 	 Res : 1.49793e-02 	 Jac : 1.65208e-02 	 Enc : 3.31096e-03 	 AE : 3.44425e-03 	 MSE : 4.78439e+00
Training Epoch 159 finished, took current epoch 627.96s, cumulative time 73179.99s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 160, 25% 	 Loss : 3.9002e-02 	 Res : 1.2950e-02 	 Jac : 1.6184e-02 	 Enc : 3.3678e-03 	 AEnc : 9.6589e-04 	 MSE : 5.5341e+00
Epoch 160, 50% 	 Loss : 3.0939e-02 	 Res : 8.1311e-03 	 Jac : 1.6258e-02 	 Enc : 3.4156e-03 	 AEnc : 2.2873e-04 	 MSE : 2.9056e+00
Epoch 160, 75% 	 Loss : 3.6148e-02 	 Res : 1.1224e-02 	 Jac : 1.6398e-02 	 Enc : 3.3294e-03 	 AEnc : 6.3517e-04 	 MSE : 4.5606e+00
Training Epoch 160 : 	 Train : 3.64488e-02 	 Res : 1.14515e-02 	 Jac : 1.62737e-02 	 Enc : 3.37370e-03 	 AE : 6.45417e-04 	 MSE : 4.70458e+00
Validation Epoch 160 : 	 Train : 5.54147e-02 	 Res : 2.15309e-02 	 Jac : 1.68302e-02 	 Enc : 3.27080e-03 	 AE : 4.76371e-04 	 MSE : 1.33065e+01
Training Epoch 160 finished, took current epoch 507.74s, cumulative time 73687.68s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 161, 25% 	 Loss : 3.6883e-02 	 Res : 1.1572e-02 	 Jac : 1.6458e-02 	 Enc : 3.4065e-03 	 AEnc : 2.5012e-04 	 MSE : 5.1962e+00
Epoch 161, 50% 	 Loss : 3.8969e-02 	 Res : 1.2220e-02 	 Jac : 1.6344e-02 	 Enc : 3.3712e-03 	 AEnc : 1.7315e-03 	 MSE : 5.3029e+00
Epoch 161, 75% 	 Loss : 4.5425e-02 	 Res : 1.5271e-02 	 Jac : 1.6502e-02 	 Enc : 3.3941e-03 	 AEnc : 2.2148e-03 	 MSE : 8.0429e+00
Training Epoch 161 : 	 Train : 3.87349e-02 	 Res : 1.21222e-02 	 Jac : 1.64138e-02 	 Enc : 3.39905e-03 	 AE : 1.11751e-03 	 MSE : 5.68235e+00
Validation Epoch 161 : 	 Train : 2.88506e-02 	 Res : 6.54409e-03 	 Jac : 1.62371e-02 	 Enc : 3.44264e-03 	 AE : 1.55290e-04 	 MSE : 2.47147e+00
Training Epoch 161 finished, took current epoch 507.02s, cumulative time 74194.69s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 162, 25% 	 Loss : 3.0393e-02 	 Res : 7.3861e-03 	 Jac : 1.6269e-02 	 Enc : 3.4032e-03 	 AEnc : 1.1276e-04 	 MSE : 3.2219e+00
Epoch 162, 50% 	 Loss : 2.9971e-02 	 Res : 7.1535e-03 	 Jac : 1.6485e-02 	 Enc : 3.3766e-03 	 AEnc : 1.2603e-04 	 MSE : 2.8292e+00
Epoch 162, 75% 	 Loss : 4.8533e-02 	 Res : 1.8489e-02 	 Jac : 1.6397e-02 	 Enc : 3.3854e-03 	 AEnc : 1.9454e-04 	 MSE : 1.0067e+01
Training Epoch 162 : 	 Train : 3.43930e-02 	 Res : 9.92550e-03 	 Jac : 1.63861e-02 	 Enc : 3.38587e-03 	 AE : 1.94230e-04 	 MSE : 4.50133e+00
Validation Epoch 162 : 	 Train : 2.99288e-02 	 Res : 8.37344e-03 	 Jac : 1.62357e-02 	 Enc : 3.35863e-03 	 AE : 7.53915e-04 	 MSE : 1.20712e+00
Training Epoch 162 finished, took current epoch 490.39s, cumulative time 74685.06s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 163, 25% 	 Loss : 3.7690e-02 	 Res : 1.3605e-02 	 Jac : 1.6186e-02 	 Enc : 3.3742e-03 	 AEnc : 9.6409e-04 	 MSE : 3.5614e+00
Epoch 163, 50% 	 Loss : 3.3660e-02 	 Res : 1.1026e-02 	 Jac : 1.6390e-02 	 Enc : 3.3998e-03 	 AEnc : 3.5238e-04 	 MSE : 2.4917e+00
Epoch 163, 75% 	 Loss : 4.0816e-02 	 Res : 1.4553e-02 	 Jac : 1.6106e-02 	 Enc : 3.4259e-03 	 AEnc : 4.0589e-04 	 MSE : 6.3250e+00
Training Epoch 163 : 	 Train : 3.58043e-02 	 Res : 1.18082e-02 	 Jac : 1.62273e-02 	 Enc : 3.40259e-03 	 AE : 4.76930e-04 	 MSE : 3.88922e+00
Validation Epoch 163 : 	 Train : 4.90827e-02 	 Res : 1.97395e-02 	 Jac : 1.67851e-02 	 Enc : 3.32646e-03 	 AE : 1.16558e-04 	 MSE : 9.11508e+00
Training Epoch 163 finished, took current epoch 524.62s, cumulative time 75209.63s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 164, 25% 	 Loss : 2.9666e-02 	 Res : 7.2221e-03 	 Jac : 1.6335e-02 	 Enc : 3.3727e-03 	 AEnc : 2.2141e-04 	 MSE : 2.5146e+00
Epoch 164, 50% 	 Loss : 3.1794e-02 	 Res : 7.9894e-03 	 Jac : 1.6251e-02 	 Enc : 3.3780e-03 	 AEnc : 7.4528e-04 	 MSE : 3.4303e+00
Epoch 164, 75% 	 Loss : 3.2463e-02 	 Res : 8.2647e-03 	 Jac : 1.6202e-02 	 Enc : 3.3780e-03 	 AEnc : 9.4030e-04 	 MSE : 3.6781e+00
Training Epoch 164 : 	 Train : 3.11807e-02 	 Res : 7.84825e-03 	 Jac : 1.62570e-02 	 Enc : 3.38066e-03 	 AE : 5.62688e-04 	 MSE : 3.13205e+00
Validation Epoch 164 : 	 Train : 2.66820e-02 	 Res : 5.31778e-03 	 Jac : 1.64011e-02 	 Enc : 3.36413e-03 	 AE : 2.52261e-04 	 MSE : 1.34681e+00
Training Epoch 164 finished, took current epoch 517.88s, cumulative time 75727.47s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
MODEL SAVED
Epoch 165, 25% 	 Loss : 2.7557e-02 	 Res : 5.7994e-03 	 Jac : 1.6274e-02 	 Enc : 3.3686e-03 	 AEnc : 2.8841e-04 	 MSE : 1.8261e+00
Epoch 165, 50% 	 Loss : 4.2618e-02 	 Res : 1.5209e-02 	 Jac : 1.6378e-02 	 Enc : 3.3675e-03 	 AEnc : 4.7151e-04 	 MSE : 7.1928e+00
Epoch 165, 75% 	 Loss : 3.4753e-02 	 Res : 9.1105e-03 	 Jac : 1.6222e-02 	 Enc : 3.4069e-03 	 AEnc : 2.3554e-03 	 MSE : 3.6583e+00
Training Epoch 165 : 	 Train : 3.54899e-02 	 Res : 9.20683e-03 	 Jac : 1.62842e-02 	 Enc : 3.38567e-03 	 AE : 3.01070e-03 	 MSE : 3.60248e+00
Validation Epoch 165 : 	 Train : 4.05552e-02 	 Res : 8.28882e-03 	 Jac : 1.62017e-02 	 Enc : 3.42578e-03 	 AE : 1.01662e-02 	 MSE : 2.47266e+00
Training Epoch 165 finished, took current epoch 520.66s, cumulative time 76248.10s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 166, 25% 	 Loss : 4.3532e-02 	 Res : 8.8461e-03 	 Jac : 1.6207e-02 	 Enc : 3.3578e-03 	 AEnc : 1.1568e-02 	 MSE : 3.5528e+00
Epoch 166, 50% 	 Loss : 6.3987e-02 	 Res : 1.5189e-02 	 Jac : 1.6350e-02 	 Enc : 3.4113e-03 	 AEnc : 2.3986e-02 	 MSE : 5.0507e+00
Epoch 166, 75% 	 Loss : 3.4748e-02 	 Res : 9.1079e-03 	 Jac : 1.6258e-02 	 Enc : 3.4090e-03 	 AEnc : 1.7672e-03 	 MSE : 4.2058e+00
Training Epoch 166 : 	 Train : 4.49946e-02 	 Res : 1.11056e-02 	 Jac : 1.62725e-02 	 Enc : 3.40048e-03 	 AE : 9.60231e-03 	 MSE : 4.61374e+00
Validation Epoch 166 : 	 Train : 5.60411e-02 	 Res : 2.21441e-02 	 Jac : 1.66338e-02 	 Enc : 3.29057e-03 	 AE : 2.61301e-04 	 MSE : 1.37113e+01
Training Epoch 166 finished, took current epoch 501.73s, cumulative time 76749.81s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 167, 25% 	 Loss : 3.9808e-02 	 Res : 1.3347e-02 	 Jac : 1.6321e-02 	 Enc : 3.4225e-03 	 AEnc : 1.7649e-04 	 MSE : 6.5416e+00
Epoch 167, 50% 	 Loss : 2.9645e-02 	 Res : 7.0700e-03 	 Jac : 1.6187e-02 	 Enc : 3.4131e-03 	 AEnc : 2.5400e-04 	 MSE : 2.7206e+00
Epoch 167, 75% 	 Loss : 3.6809e-02 	 Res : 1.1851e-02 	 Jac : 1.6199e-02 	 Enc : 3.4077e-03 	 AEnc : 8.6542e-04 	 MSE : 4.4861e+00
Training Epoch 167 : 	 Train : 3.38777e-02 	 Res : 9.86000e-03 	 Jac : 1.62338e-02 	 Enc : 3.41917e-03 	 AE : 3.97261e-04 	 MSE : 3.96749e+00
Validation Epoch 167 : 	 Train : 2.62756e-02 	 Res : 5.46331e-03 	 Jac : 1.63116e-02 	 Enc : 3.40791e-03 	 AE : 1.92587e-04 	 MSE : 9.00251e-01
Training Epoch 167 finished, took current epoch 507.88s, cumulative time 77257.68s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 168, 25% 	 Loss : 3.3028e-02 	 Res : 9.5554e-03 	 Jac : 1.6219e-02 	 Enc : 3.4245e-03 	 AEnc : 1.9733e-04 	 MSE : 3.6314e+00
Epoch 168, 50% 	 Loss : 2.9380e-02 	 Res : 6.9667e-03 	 Jac : 1.6204e-02 	 Enc : 3.3920e-03 	 AEnc : 1.4301e-04 	 MSE : 2.6740e+00
Epoch 168, 75% 	 Loss : 4.5255e-02 	 Res : 1.6148e-02 	 Jac : 1.6195e-02 	 Enc : 3.4208e-03 	 AEnc : 1.3061e-04 	 MSE : 9.3611e+00
Training Epoch 168 : 	 Train : 3.58982e-02 	 Res : 1.08667e-02 	 Jac : 1.62480e-02 	 Enc : 3.42179e-03 	 AE : 2.12677e-04 	 MSE : 5.14903e+00
Validation Epoch 168 : 	 Train : 2.71526e-02 	 Res : 5.34682e-03 	 Jac : 1.61123e-02 	 Enc : 3.40385e-03 	 AE : 9.93877e-05 	 MSE : 2.19025e+00
Training Epoch 168 finished, took current epoch 503.40s, cumulative time 77761.06s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 169, 25% 	 Loss : 2.9613e-02 	 Res : 7.3661e-03 	 Jac : 1.6284e-02 	 Enc : 3.3981e-03 	 AEnc : 6.5725e-04 	 MSE : 1.9078e+00
Epoch 169, 50% 	 Loss : 3.2061e-02 	 Res : 8.7594e-03 	 Jac : 1.6121e-02 	 Enc : 3.3988e-03 	 AEnc : 6.8943e-04 	 MSE : 3.0931e+00
Epoch 169, 75% 	 Loss : 3.5073e-02 	 Res : 1.0226e-02 	 Jac : 1.6226e-02 	 Enc : 3.4133e-03 	 AEnc : 1.0244e-03 	 MSE : 4.1836e+00
Training Epoch 169 : 	 Train : 3.27100e-02 	 Res : 9.16598e-03 	 Jac : 1.61793e-02 	 Enc : 3.40662e-03 	 AE : 9.28082e-04 	 MSE : 3.02997e+00
Validation Epoch 169 : 	 Train : 3.99648e-02 	 Res : 1.31343e-02 	 Jac : 1.59598e-02 	 Enc : 3.51862e-03 	 AE : 4.35154e-04 	 MSE : 6.91696e+00
Training Epoch 169 finished, took current epoch 512.13s, cumulative time 78273.17s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 170, 25% 	 Loss : 3.2342e-02 	 Res : 9.0242e-03 	 Jac : 1.6127e-02 	 Enc : 3.4132e-03 	 AEnc : 2.1436e-04 	 MSE : 3.5632e+00
Epoch 170, 50% 	 Loss : 3.0151e-02 	 Res : 7.2108e-03 	 Jac : 1.6176e-02 	 Enc : 3.4114e-03 	 AEnc : 1.2393e-04 	 MSE : 3.2286e+00
Epoch 170, 75% 	 Loss : 2.9940e-02 	 Res : 7.0972e-03 	 Jac : 1.6209e-02 	 Enc : 3.4304e-03 	 AEnc : 1.2167e-04 	 MSE : 3.0812e+00
Training Epoch 170 : 	 Train : 3.06921e-02 	 Res : 7.66151e-03 	 Jac : 1.61756e-02 	 Enc : 3.41759e-03 	 AE : 1.42154e-04 	 MSE : 3.29527e+00
Validation Epoch 170 : 	 Train : 2.97817e-02 	 Res : 7.06094e-03 	 Jac : 1.61976e-02 	 Enc : 3.47923e-03 	 AE : 1.12970e-04 	 MSE : 2.93099e+00
Training Epoch 170 finished, took current epoch 500.91s, cumulative time 78774.06s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 171, 25% 	 Loss : 2.9861e-02 	 Res : 7.2349e-03 	 Jac : 1.6257e-02 	 Enc : 3.4129e-03 	 AEnc : 1.4382e-04 	 MSE : 2.8122e+00
Epoch 171, 50% 	 Loss : 3.3531e-02 	 Res : 9.8401e-03 	 Jac : 1.6180e-02 	 Enc : 3.4088e-03 	 AEnc : 2.8667e-04 	 MSE : 3.8153e+00
Epoch 171, 75% 	 Loss : 8.8747e-02 	 Res : 1.8281e-02 	 Jac : 1.6124e-02 	 Enc : 3.4796e-03 	 AEnc : 4.4569e-02 	 MSE : 6.2929e+00
Training Epoch 171 : 	 Train : 4.61904e-02 	 Res : 1.08692e-02 	 Jac : 1.61835e-02 	 Enc : 3.43570e-03 	 AE : 1.16592e-02 	 MSE : 4.04274e+00
Validation Epoch 171 : 	 Train : 2.93697e-02 	 Res : 7.40012e-03 	 Jac : 1.63739e-02 	 Enc : 3.47827e-03 	 AE : 6.73021e-04 	 MSE : 1.44442e+00
Training Epoch 171 finished, took current epoch 533.39s, cumulative time 79307.44s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 172, 25% 	 Loss : 3.0424e-02 	 Res : 7.5877e-03 	 Jac : 1.6100e-02 	 Enc : 3.4161e-03 	 AEnc : 3.4291e-04 	 MSE : 2.9772e+00
Epoch 172, 50% 	 Loss : 3.1547e-02 	 Res : 8.1143e-03 	 Jac : 1.6247e-02 	 Enc : 3.4215e-03 	 AEnc : 1.6347e-04 	 MSE : 3.6005e+00
Epoch 172, 75% 	 Loss : 3.1470e-02 	 Res : 7.9420e-03 	 Jac : 1.6194e-02 	 Enc : 3.4529e-03 	 AEnc : 2.0974e-04 	 MSE : 3.6717e+00
Training Epoch 172 : 	 Train : 3.14701e-02 	 Res : 8.06587e-03 	 Jac : 1.62057e-02 	 Enc : 3.43297e-03 	 AE : 2.25059e-04 	 MSE : 3.54045e+00
Validation Epoch 172 : 	 Train : 2.78927e-02 	 Res : 5.91979e-03 	 Jac : 1.62544e-02 	 Enc : 3.45370e-03 	 AE : 1.15903e-03 	 MSE : 1.10577e+00
Training Epoch 172 finished, took current epoch 498.98s, cumulative time 79806.40s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 173, 25% 	 Loss : 3.1156e-02 	 Res : 7.8885e-03 	 Jac : 1.6221e-02 	 Enc : 3.4168e-03 	 AEnc : 2.3455e-04 	 MSE : 3.3949e+00
Epoch 173, 50% 	 Loss : 2.8654e-02 	 Res : 6.5063e-03 	 Jac : 1.6205e-02 	 Enc : 3.4004e-03 	 AEnc : 8.7599e-05 	 MSE : 2.4548e+00
Epoch 173, 75% 	 Loss : 4.0133e-02 	 Res : 1.3685e-02 	 Jac : 1.6145e-02 	 Enc : 3.4133e-03 	 AEnc : 1.3547e-04 	 MSE : 6.7541e+00
Training Epoch 173 : 	 Train : 3.23980e-02 	 Res : 8.76901e-03 	 Jac : 1.61990e-02 	 Enc : 3.41870e-03 	 AE : 1.73217e-04 	 MSE : 3.83803e+00
Validation Epoch 173 : 	 Train : 2.96724e-02 	 Res : 6.61317e-03 	 Jac : 1.61728e-02 	 Enc : 3.36087e-03 	 AE : 3.94441e-04 	 MSE : 3.13111e+00
Training Epoch 173 finished, took current epoch 496.94s, cumulative time 80303.32s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 174, 25% 	 Loss : 3.1742e-02 	 Res : 8.1974e-03 	 Jac : 1.6155e-02 	 Enc : 3.4183e-03 	 AEnc : 3.5512e-04 	 MSE : 3.6159e+00
Epoch 174, 50% 	 Loss : 3.2151e-02 	 Res : 8.1755e-03 	 Jac : 1.6151e-02 	 Enc : 3.4267e-03 	 AEnc : 1.2817e-03 	 MSE : 3.1161e+00
Epoch 174, 75% 	 Loss : 3.3139e-02 	 Res : 8.4870e-03 	 Jac : 1.6007e-02 	 Enc : 3.4213e-03 	 AEnc : 1.9077e-03 	 MSE : 3.3157e+00
Training Epoch 174 : 	 Train : 3.41880e-02 	 Res : 9.28711e-03 	 Jac : 1.61182e-02 	 Enc : 3.42614e-03 	 AE : 1.35472e-03 	 MSE : 4.00188e+00
Validation Epoch 174 : 	 Train : 2.87331e-02 	 Res : 7.06501e-03 	 Jac : 1.62426e-02 	 Enc : 3.47337e-03 	 AE : 6.06917e-04 	 MSE : 1.34521e+00
Training Epoch 174 finished, took current epoch 499.44s, cumulative time 80802.73s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 175, 25% 	 Loss : 3.6568e-02 	 Res : 1.0926e-02 	 Jac : 1.6144e-02 	 Enc : 3.4456e-03 	 AEnc : 3.1948e-03 	 MSE : 2.8566e+00
Epoch 175, 50% 	 Loss : 4.0816e-02 	 Res : 1.3617e-02 	 Jac : 1.6038e-02 	 Enc : 3.4678e-03 	 AEnc : 2.0855e-03 	 MSE : 5.6080e+00
Epoch 175, 75% 	 Loss : 3.0765e-02 	 Res : 7.3024e-03 	 Jac : 1.6245e-02 	 Enc : 3.4565e-03 	 AEnc : 4.0871e-04 	 MSE : 3.3525e+00
Training Epoch 175 : 	 Train : 3.82348e-02 	 Res : 1.20458e-02 	 Jac : 1.61623e-02 	 Enc : 3.46129e-03 	 AE : 1.53972e-03 	 MSE : 5.02579e+00
Validation Epoch 175 : 	 Train : 2.76485e-02 	 Res : 5.80136e-03 	 Jac : 1.60543e-02 	 Enc : 3.50633e-03 	 AE : 2.06559e-04 	 MSE : 2.08003e+00
Training Epoch 175 finished, took current epoch 489.24s, cumulative time 81291.95s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 176, 25% 	 Loss : 2.7798e-02 	 Res : 6.0439e-03 	 Jac : 1.6176e-02 	 Enc : 3.4630e-03 	 AEnc : 1.6703e-04 	 MSE : 1.9482e+00
Epoch 176, 50% 	 Loss : 3.9160e-02 	 Res : 1.2537e-02 	 Jac : 1.6139e-02 	 Enc : 3.4126e-03 	 AEnc : 2.0129e-04 	 MSE : 6.8700e+00
Epoch 176, 75% 	 Loss : 2.9682e-02 	 Res : 7.2270e-03 	 Jac : 1.6130e-02 	 Enc : 3.4689e-03 	 AEnc : 1.9089e-04 	 MSE : 2.6652e+00
Training Epoch 176 : 	 Train : 3.10069e-02 	 Res : 7.89708e-03 	 Jac : 1.61381e-02 	 Enc : 3.44633e-03 	 AE : 2.03049e-04 	 MSE : 3.32238e+00
Validation Epoch 176 : 	 Train : 5.30043e-02 	 Res : 2.23232e-02 	 Jac : 1.70369e-02 	 Enc : 3.42856e-03 	 AE : 8.90444e-04 	 MSE : 9.32516e+00
Training Epoch 176 finished, took current epoch 538.92s, cumulative time 81830.86s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 177, 25% 	 Loss : 3.2169e-02 	 Res : 9.0375e-03 	 Jac : 1.6244e-02 	 Enc : 3.4838e-03 	 AEnc : 2.2568e-04 	 MSE : 3.1778e+00
Epoch 177, 50% 	 Loss : 8.6123e-02 	 Res : 4.4356e-02 	 Jac : 1.6282e-02 	 Enc : 3.5311e-03 	 AEnc : 1.3027e-03 	 MSE : 2.0651e+01
Epoch 177, 75% 	 Loss : 4.5660e-02 	 Res : 1.2499e-02 	 Jac : 1.6168e-02 	 Enc : 3.5369e-03 	 AEnc : 8.9316e-03 	 MSE : 4.5240e+00
Training Epoch 177 : 	 Train : 5.02261e-02 	 Res : 1.87959e-02 	 Jac : 1.62115e-02 	 Enc : 3.51015e-03 	 AE : 3.73432e-03 	 MSE : 7.97422e+00
Validation Epoch 177 : 	 Train : 3.69335e-02 	 Res : 9.08110e-03 	 Jac : 1.62626e-02 	 Enc : 3.45906e-03 	 AE : 6.92478e-03 	 MSE : 1.20596e+00
Training Epoch 177 finished, took current epoch 511.96s, cumulative time 82342.80s
Current Learning rate DEQ : 0.0004117714999999998
Current Learning rate AUTOENC : 0.0008235429999999996
Epoch 178, 25% 	 Loss : 3.1844e-02 	 Res : 7.2256e-03 	 Jac : 1.6164e-02 	 Enc : 3.4420e-03 	 AEnc : 2.4550e-03 	 MSE : 2.5581e+00
Epoch 178, 50% 	 Loss : 3.2163e-02 	 Res : 7.9442e-03 	 Jac : 1.6106e-02 	 Enc : 3.4549e-03 	 AEnc : 1.1604e-03 	 MSE : 3.4982e+00
Epoch 178, 75% 	 Loss : 2.7305e-02 	 Res : 5.6494e-03 	 Jac : 1.6215e-02 	 Enc : 3.4433e-03 	 AEnc : 2.1055e-04 	 MSE : 1.7861e+00
Training Epoch 178 : 	 Train : 3.17075e-02 	 Res : 7.86326e-03 	 Jac : 1.61912e-02 	 Enc : 3.44554e-03 	 AE : 1.01322e-03 	 MSE : 3.19431e+00
Validation Epoch 178 : 	 Train : 2.72427e-02 	 Res : 5.85424e-03 	 Jac : 1.61306e-02 	 Enc : 3.48215e-03 	 AE : 1.99511e-04 	 MSE : 1.57624e+00
Training Epoch 178 finished, took current epoch 515.78s, cumulative time 82858.56s
Current Learning rate DEQ : 0.00028824004999999985
Current Learning rate AUTOENC : 0.0005764800999999997
Epoch 179, 25% 	 Loss : 2.7841e-02 	 Res : 5.9538e-03 	 Jac : 1.6193e-02 	 Enc : 3.4442e-03 	 AEnc : 1.5222e-04 	 MSE : 2.0977e+00
Epoch 179, 50% 	 Loss : 2.8137e-02 	 Res : 6.1458e-03 	 Jac : 1.6254e-02 	 Enc : 3.4395e-03 	 AEnc : 1.5082e-04 	 MSE : 2.1461e+00
Epoch 179, 75% 	 Loss : 2.7908e-02 	 Res : 6.0488e-03 	 Jac : 1.6244e-02 	 Enc : 3.4215e-03 	 AEnc : 1.9207e-04 	 MSE : 2.0024e+00
Training Epoch 179 : 	 Train : 2.94633e-02 	 Res : 6.91254e-03 	 Jac : 1.62077e-02 	 Enc : 3.43278e-03 	 AE : 1.63473e-04 	 MSE : 2.74678e+00
Validation Epoch 179 : 	 Train : 3.55563e-02 	 Res : 1.03114e-02 	 Jac : 1.63780e-02 	 Enc : 3.38094e-03 	 AE : 1.43568e-04 	 MSE : 5.34247e+00
Training Epoch 179 finished, took current epoch 499.38s, cumulative time 83357.93s
Current Learning rate DEQ : 0.00028824004999999985
Current Learning rate AUTOENC : 0.0005764800999999997
Epoch 180, 25% 	 Loss : 3.1318e-02 	 Res : 7.9572e-03 	 Jac : 1.6263e-02 	 Enc : 3.4586e-03 	 AEnc : 3.5073e-04 	 MSE : 3.2893e+00
Epoch 180, 50% 	 Loss : 2.8629e-02 	 Res : 5.5916e-03 	 Jac : 1.6155e-02 	 Enc : 3.4238e-03 	 AEnc : 1.8421e-03 	 MSE : 1.6160e+00
Epoch 180, 75% 	 Loss : 2.6243e-02 	 Res : 5.0022e-03 	 Jac : 1.6111e-02 	 Enc : 3.4212e-03 	 AEnc : 5.3184e-04 	 MSE : 1.1765e+00
Training Epoch 180 : 	 Train : 2.91908e-02 	 Res : 6.56173e-03 	 Jac : 1.62083e-02 	 Enc : 3.43139e-03 	 AE : 7.42027e-04 	 MSE : 2.24741e+00
Validation Epoch 180 : 	 Train : 2.72055e-02 	 Res : 5.48855e-03 	 Jac : 1.61784e-02 	 Enc : 3.39373e-03 	 AE : 2.14786e-04 	 MSE : 1.93003e+00
Training Epoch 180 finished, took current epoch 508.05s, cumulative time 83865.97s
Current Learning rate DEQ : 0.00028824004999999985
Current Learning rate AUTOENC : 0.0005764800999999997
Epoch 181, 25% 	 Loss : 2.8106e-02 	 Res : 6.0219e-03 	 Jac : 1.6245e-02 	 Enc : 3.4344e-03 	 AEnc : 1.4837e-04 	 MSE : 2.2564e+00
Epoch 181, 50% 	 Loss : 2.7879e-02 	 Res : 6.1062e-03 	 Jac : 1.6196e-02 	 Enc : 3.4319e-03 	 AEnc : 1.2406e-04 	 MSE : 2.0212e+00
Epoch 181, 75% 	 Loss : 4.3594e-02 	 Res : 1.1217e-02 	 Jac : 1.6128e-02 	 Enc : 3.5103e-03 	 AEnc : 8.5883e-03 	 MSE : 4.1510e+00
Training Epoch 181 : 	 Train : 3.25292e-02 	 Res : 7.40055e-03 	 Jac : 1.61866e-02 	 Enc : 3.45395e-03 	 AE : 2.90453e-03 	 MSE : 2.58354e+00
Validation Epoch 181 : 	 Train : 2.79928e-02 	 Res : 6.61419e-03 	 Jac : 1.64036e-02 	 Enc : 3.47875e-03 	 AE : 1.99602e-04 	 MSE : 1.29660e+00
Training Epoch 181 finished, took current epoch 529.15s, cumulative time 84395.10s
Current Learning rate DEQ : 0.00028824004999999985
Current Learning rate AUTOENC : 0.0005764800999999997
Epoch 182, 25% 	 Loss : 3.3346e-02 	 Res : 9.3352e-03 	 Jac : 1.6264e-02 	 Enc : 3.4246e-03 	 AEnc : 3.0488e-04 	 MSE : 4.0181e+00
Epoch 182, 50% 	 Loss : 2.9403e-02 	 Res : 6.8519e-03 	 Jac : 1.6071e-02 	 Enc : 3.4514e-03 	 AEnc : 1.8039e-04 	 MSE : 2.8484e+00
Epoch 182, 75% 	 Loss : 2.7903e-02 	 Res : 5.9433e-03 	 Jac : 1.6211e-02 	 Enc : 3.4709e-03 	 AEnc : 1.0606e-04 	 MSE : 2.1718e+00
Training Epoch 182 : 	 Train : 3.09253e-02 	 Res : 7.72326e-03 	 Jac : 1.61841e-02 	 Enc : 3.44786e-03 	 AE : 1.73580e-04 	 MSE : 3.39647e+00
Validation Epoch 182 : 	 Train : 3.11323e-02 	 Res : 8.07983e-03 	 Jac : 1.64297e-02 	 Enc : 3.41312e-03 	 AE : 9.11921e-05 	 MSE : 3.11845e+00
Training Epoch 182 finished, took current epoch 500.17s, cumulative time 84895.26s
Current Learning rate DEQ : 0.00028824004999999985
Current Learning rate AUTOENC : 0.0005764800999999997
Epoch 183, 25% 	 Loss : 3.4332e-02 	 Res : 9.7139e-03 	 Jac : 1.6312e-02 	 Enc : 3.4901e-03 	 AEnc : 1.1195e-04 	 MSE : 4.7033e+00
Epoch 183, 50% 	 Loss : 2.7862e-02 	 Res : 5.9519e-03 	 Jac : 1.6199e-02 	 Enc : 3.4626e-03 	 AEnc : 1.0275e-04 	 MSE : 2.1453e+00
Epoch 183, 75% 	 Loss : 2.8911e-02 	 Res : 6.5295e-03 	 Jac : 1.6160e-02 	 Enc : 3.4167e-03 	 AEnc : 9.6784e-05 	 MSE : 2.7073e+00
Training Epoch 183 : 	 Train : 2.98300e-02 	 Res : 7.23654e-03 	 Jac : 1.62016e-02 	 Enc : 3.44912e-03 	 AE : 1.24849e-04 	 MSE : 2.81796e+00
Validation Epoch 183 : 	 Train : 3.21935e-02 	 Res : 8.34461e-03 	 Jac : 1.56920e-02 	 Enc : 3.44019e-03 	 AE : 1.83283e-04 	 MSE : 4.53334e+00
Training Epoch 183 finished, took current epoch 494.91s, cumulative time 85390.14s
Current Learning rate DEQ : 0.00028824004999999985
Current Learning rate AUTOENC : 0.0005764800999999997
Epoch 184, 25% 	 Loss : 3.0506e-02 	 Res : 7.5972e-03 	 Jac : 1.6049e-02 	 Enc : 3.4339e-03 	 AEnc : 1.6682e-04 	 MSE : 3.2587e+00
Epoch 184, 50% 	 Loss : 2.5886e-02 	 Res : 4.9309e-03 	 Jac : 1.6120e-02 	 Enc : 3.4321e-03 	 AEnc : 1.3716e-04 	 MSE : 1.2653e+00
Epoch 184, 75% 	 Loss : 3.8525e-02 	 Res : 1.3538e-02 	 Jac : 1.6217e-02 	 Enc : 3.4735e-03 	 AEnc : 8.2254e-04 	 MSE : 4.4747e+00
Training Epoch 184 : 	 Train : 3.59401e-02 	 Res : 1.20557e-02 	 Jac : 1.60872e-02 	 Enc : 3.45581e-03 	 AE : 5.16901e-04 	 MSE : 3.82450e+00
Validation Epoch 184 : 	 Train : 3.34808e-02 	 Res : 1.19830e-02 	 Jac : 1.60426e-02 	 Enc : 3.47587e-03 	 AE : 7.39935e-04 	 MSE : 1.23937e+00
Training Epoch 184 finished, took current epoch 514.46s, cumulative time 85904.58s
Current Learning rate DEQ : 0.00028824004999999985
Current Learning rate AUTOENC : 0.0005764800999999997
Epoch 185, 25% 	 Loss : 3.1169e-02 	 Res : 9.3400e-03 	 Jac : 1.6131e-02 	 Enc : 3.4800e-03 	 AEnc : 2.7498e-04 	 MSE : 1.9434e+00
Epoch 185, 50% 	 Loss : 2.6388e-02 	 Res : 5.4153e-03 	 Jac : 1.6162e-02 	 Enc : 3.4655e-03 	 AEnc : 1.1103e-04 	 MSE : 1.2332e+00
Epoch 185, 75% 	 Loss : 3.0128e-02 	 Res : 7.5003e-03 	 Jac : 1.6193e-02 	 Enc : 3.4635e-03 	 AEnc : 1.0939e-04 	 MSE : 2.8620e+00
Training Epoch 185 : 	 Train : 3.22842e-02 	 Res : 9.14732e-03 	 Jac : 1.61790e-02 	 Enc : 3.47973e-03 	 AE : 1.62163e-04 	 MSE : 3.31602e+00
Validation Epoch 185 : 	 Train : 3.28185e-02 	 Res : 8.54093e-03 	 Jac : 1.60128e-02 	 Enc : 3.42129e-03 	 AE : 8.36647e-05 	 MSE : 4.75979e+00
Training Epoch 185 finished, took current epoch 514.66s, cumulative time 86419.22s
Current Learning rate DEQ : 0.00028824004999999985
Current Learning rate AUTOENC : 0.0005764800999999997
Epoch 186, 25% 	 Loss : 2.8537e-02 	 Res : 6.2200e-03 	 Jac : 1.6113e-02 	 Enc : 3.4844e-03 	 AEnc : 1.6058e-04 	 MSE : 2.5587e+00
Epoch 186, 50% 	 Loss : 3.1880e-02 	 Res : 8.1865e-03 	 Jac : 1.6072e-02 	 Enc : 3.4688e-03 	 AEnc : 1.5814e-04 	 MSE : 3.9944e+00
Epoch 186, 75% 	 Loss : 3.2747e-02 	 Res : 8.5962e-03 	 Jac : 1.6155e-02 	 Enc : 3.4673e-03 	 AEnc : 3.8611e-04 	 MSE : 4.1427e+00
Training Epoch 186 : 	 Train : 3.16497e-02 	 Res : 7.97583e-03 	 Jac : 1.61216e-02 	 Enc : 3.47380e-03 	 AE : 2.28150e-04 	 MSE : 3.85029e+00
Validation Epoch 186 : 	 Train : 4.48787e-02 	 Res : 1.59038e-02 	 Jac : 1.62308e-02 	 Enc : 3.58748e-03 	 AE : 1.24535e-04 	 MSE : 9.03205e+00
Training Epoch 186 finished, took current epoch 528.95s, cumulative time 86948.15s
Current Learning rate DEQ : 0.00028824004999999985
Current Learning rate AUTOENC : 0.0005764800999999997
Epoch 187, 25% 	 Loss : 2.9414e-02 	 Res : 6.7391e-03 	 Jac : 1.6281e-02 	 Enc : 3.4705e-03 	 AEnc : 1.3794e-04 	 MSE : 2.7861e+00
Epoch 187, 50% 	 Loss : 2.8193e-02 	 Res : 6.1004e-03 	 Jac : 1.6273e-02 	 Enc : 3.4578e-03 	 AEnc : 1.5508e-04 	 MSE : 2.2069e+00
Epoch 187, 75% 	 Loss : 2.8731e-02 	 Res : 6.4867e-03 	 Jac : 1.6119e-02 	 Enc : 3.4560e-03 	 AEnc : 9.7767e-05 	 MSE : 2.5724e+00
Training Epoch 187 : 	 Train : 2.89144e-02 	 Res : 6.64442e-03 	 Jac : 1.62079e-02 	 Enc : 3.45651e-03 	 AE : 1.38402e-04 	 MSE : 2.46712e+00
Validation Epoch 187 : 	 Train : 2.68840e-02 	 Res : 5.49959e-03 	 Jac : 1.60505e-02 	 Enc : 3.48368e-03 	 AE : 1.15496e-04 	 MSE : 1.73475e+00
Training Epoch 187 finished, took current epoch 509.02s, cumulative time 87457.16s
Current Learning rate DEQ : 0.00028824004999999985
Current Learning rate AUTOENC : 0.0005764800999999997
Epoch 188, 25% 	 Loss : 2.7587e-02 	 Res : 5.8565e-03 	 Jac : 1.6074e-02 	 Enc : 3.4421e-03 	 AEnc : 1.4694e-04 	 MSE : 2.0673e+00
Epoch 188, 50% 	 Loss : 3.0577e-02 	 Res : 7.5047e-03 	 Jac : 1.6013e-02 	 Enc : 3.4475e-03 	 AEnc : 1.5759e-04 	 MSE : 3.4538e+00
Epoch 188, 75% 	 Loss : 3.0773e-02 	 Res : 7.8637e-03 	 Jac : 1.6036e-02 	 Enc : 3.4793e-03 	 AEnc : 1.4689e-04 	 MSE : 3.2476e+00
Training Epoch 188 : 	 Train : 3.06410e-02 	 Res : 7.64165e-03 	 Jac : 1.60846e-02 	 Enc : 3.45439e-03 	 AE : 1.58964e-04 	 MSE : 3.30142e+00
Validation Epoch 188 : 	 Train : 5.31615e-02 	 Res : 2.09383e-02 	 Jac : 1.63659e-02 	 Enc : 3.35711e-03 	 AE : 1.24643e-04 	 MSE : 1.23756e+01
Training Epoch 188 finished, took current epoch 510.54s, cumulative time 87967.68s
Current Learning rate DEQ : 0.00028824004999999985
Current Learning rate AUTOENC : 0.0005764800999999997
Epoch 189, 25% 	 Loss : 3.2370e-02 	 Res : 8.4090e-03 	 Jac : 1.6115e-02 	 Enc : 3.4661e-03 	 AEnc : 1.4632e-04 	 MSE : 4.2328e+00
Epoch 189, 50% 	 Loss : 3.2463e-02 	 Res : 8.8379e-03 	 Jac : 1.6108e-02 	 Enc : 3.4821e-03 	 AEnc : 1.3079e-04 	 MSE : 3.9039e+00
Epoch 189, 75% 	 Loss : 3.2079e-02 	 Res : 8.1479e-03 	 Jac : 1.6122e-02 	 Enc : 3.4564e-03 	 AEnc : 1.3597e-04 	 MSE : 4.2169e+00
Training Epoch 189 : 	 Train : 3.28725e-02 	 Res : 8.77792e-03 	 Jac : 1.61431e-02 	 Enc : 3.47185e-03 	 AE : 1.36943e-04 	 MSE : 4.34269e+00
Validation Epoch 189 : 	 Train : 2.97748e-02 	 Res : 6.77223e-03 	 Jac : 1.60994e-02 	 Enc : 3.53854e-03 	 AE : 1.11338e-04 	 MSE : 3.25327e+00
Training Epoch 189 finished, took current epoch 508.09s, cumulative time 88475.76s
Current Learning rate DEQ : 0.00020176803499999987
Current Learning rate AUTOENC : 0.00040353606999999974
Epoch 190, 25% 	 Loss : 2.7765e-02 	 Res : 5.9291e-03 	 Jac : 1.6123e-02 	 Enc : 3.4847e-03 	 AEnc : 1.6228e-04 	 MSE : 2.0658e+00
Epoch 190, 50% 	 Loss : 2.6643e-02 	 Res : 5.3378e-03 	 Jac : 1.6156e-02 	 Enc : 3.4560e-03 	 AEnc : 1.2851e-04 	 MSE : 1.5646e+00
Epoch 190, 75% 	 Loss : 2.7260e-02 	 Res : 5.7872e-03 	 Jac : 1.6190e-02 	 Enc : 3.4483e-03 	 AEnc : 1.0536e-04 	 MSE : 1.7292e+00
Training Epoch 190 : 	 Train : 2.71773e-02 	 Res : 5.67752e-03 	 Jac : 1.61559e-02 	 Enc : 3.46281e-03 	 AE : 1.19942e-04 	 MSE : 1.76111e+00
Validation Epoch 190 : 	 Train : 2.69535e-02 	 Res : 5.50813e-03 	 Jac : 1.60664e-02 	 Enc : 3.42520e-03 	 AE : 7.77538e-05 	 MSE : 1.87603e+00
Training Epoch 190 finished, took current epoch 507.70s, cumulative time 88983.45s
Current Learning rate DEQ : 0.00020176803499999987
Current Learning rate AUTOENC : 0.00040353606999999974
Epoch 191, 25% 	 Loss : 3.1342e-02 	 Res : 8.0677e-03 	 Jac : 1.6173e-02 	 Enc : 3.4584e-03 	 AEnc : 1.1650e-04 	 MSE : 3.5262e+00
Epoch 191, 50% 	 Loss : 2.8514e-02 	 Res : 6.3990e-03 	 Jac : 1.6073e-02 	 Enc : 3.4407e-03 	 AEnc : 1.3886e-04 	 MSE : 2.4629e+00
Epoch 191, 75% 	 Loss : 6.2634e-02 	 Res : 3.7913e-02 	 Jac : 1.6932e-02 	 Enc : 3.4514e-03 	 AEnc : 4.3506e-04 	 MSE : 3.9025e+00
Training Epoch 191 : 	 Train : 3.70278e-02 	 Res : 1.42864e-02 	 Jac : 1.63291e-02 	 Enc : 3.45325e-03 	 AE : 2.31101e-04 	 MSE : 2.72795e+00
Validation Epoch 191 : 	 Train : 2.54181e-02 	 Res : 4.50419e-03 	 Jac : 1.61358e-02 	 Enc : 3.46640e-03 	 AE : 4.06758e-04 	 MSE : 9.04907e-01
Training Epoch 191 finished, took current epoch 508.20s, cumulative time 89491.59s
Current Learning rate DEQ : 0.00020176803499999987
Current Learning rate AUTOENC : 0.00040353606999999974
MODEL SAVED
Epoch 192, 25% 	 Loss : 2.6124e-02 	 Res : 4.9255e-03 	 Jac : 1.6149e-02 	 Enc : 3.4498e-03 	 AEnc : 3.2338e-04 	 MSE : 1.2762e+00
Epoch 192, 50% 	 Loss : 2.8979e-02 	 Res : 6.6296e-03 	 Jac : 1.6244e-02 	 Enc : 3.4720e-03 	 AEnc : 2.6811e-04 	 MSE : 2.3648e+00
Epoch 192, 75% 	 Loss : 2.6213e-02 	 Res : 5.0986e-03 	 Jac : 1.6217e-02 	 Enc : 3.4618e-03 	 AEnc : 2.4021e-04 	 MSE : 1.1959e+00
Training Epoch 192 : 	 Train : 2.76375e-02 	 Res : 5.85640e-03 	 Jac : 1.61978e-02 	 Enc : 3.45551e-03 	 AE : 2.63790e-04 	 MSE : 1.86398e+00
Validation Epoch 192 : 	 Train : 2.69866e-02 	 Res : 5.27217e-03 	 Jac : 1.59611e-02 	 Enc : 3.48847e-03 	 AE : 1.89608e-04 	 MSE : 2.07521e+00
Training Epoch 192 finished, took current epoch 499.54s, cumulative time 89991.11s
Current Learning rate DEQ : 0.00020176803499999987
Current Learning rate AUTOENC : 0.00040353606999999974
Epoch 193, 25% 	 Loss : 2.9832e-02 	 Res : 6.8906e-03 	 Jac : 1.6230e-02 	 Enc : 3.4531e-03 	 AEnc : 1.1957e-04 	 MSE : 3.1392e+00
Epoch 193, 50% 	 Loss : 2.6092e-02 	 Res : 4.9282e-03 	 Jac : 1.6153e-02 	 Enc : 3.4673e-03 	 AEnc : 1.3474e-04 	 MSE : 1.4091e+00
Epoch 193, 75% 	 Loss : 2.6585e-02 	 Res : 5.2698e-03 	 Jac : 1.6197e-02 	 Enc : 3.4451e-03 	 AEnc : 1.1126e-04 	 MSE : 1.5623e+00
Training Epoch 193 : 	 Train : 2.76996e-02 	 Res : 5.84792e-03 	 Jac : 1.62054e-02 	 Enc : 3.46140e-03 	 AE : 1.19377e-04 	 MSE : 2.06548e+00
Validation Epoch 193 : 	 Train : 2.51063e-02 	 Res : 4.37882e-03 	 Jac : 1.60367e-02 	 Enc : 3.46953e-03 	 AE : 1.49274e-04 	 MSE : 1.07191e+00
Training Epoch 193 finished, took current epoch 496.79s, cumulative time 90487.86s
Current Learning rate DEQ : 0.00020176803499999987
Current Learning rate AUTOENC : 0.00040353606999999974
MODEL SAVED
Epoch 194, 25% 	 Loss : 2.8312e-02 	 Res : 6.3178e-03 	 Jac : 1.6109e-02 	 Enc : 3.4589e-03 	 AEnc : 8.8912e-05 	 MSE : 2.3371e+00
Epoch 194, 50% 	 Loss : 2.7534e-02 	 Res : 5.7331e-03 	 Jac : 1.6057e-02 	 Enc : 3.4573e-03 	 AEnc : 1.2084e-04 	 MSE : 2.1651e+00
Epoch 194, 75% 	 Loss : 2.6027e-02 	 Res : 4.9552e-03 	 Jac : 1.6183e-02 	 Enc : 3.4513e-03 	 AEnc : 1.3532e-04 	 MSE : 1.3026e+00
Training Epoch 194 : 	 Train : 2.78766e-02 	 Res : 5.97794e-03 	 Jac : 1.61422e-02 	 Enc : 3.45549e-03 	 AE : 1.32014e-04 	 MSE : 2.16894e+00
Validation Epoch 194 : 	 Train : 2.85163e-02 	 Res : 7.23823e-03 	 Jac : 1.62281e-02 	 Enc : 3.49231e-03 	 AE : 5.09006e-04 	 MSE : 1.04869e+00
Training Epoch 194 finished, took current epoch 504.08s, cumulative time 90991.92s
Current Learning rate DEQ : 0.00020176803499999987
Current Learning rate AUTOENC : 0.00040353606999999974
Epoch 195, 25% 	 Loss : 2.6629e-02 	 Res : 5.4116e-03 	 Jac : 1.6130e-02 	 Enc : 3.4764e-03 	 AEnc : 2.7567e-04 	 MSE : 1.3355e+00
Epoch 195, 50% 	 Loss : 3.1787e-02 	 Res : 7.0880e-03 	 Jac : 1.6206e-02 	 Enc : 3.4433e-03 	 AEnc : 1.9032e-03 	 MSE : 3.1464e+00
Epoch 195, 75% 	 Loss : 3.2335e-02 	 Res : 5.3050e-03 	 Jac : 1.6109e-02 	 Enc : 3.4699e-03 	 AEnc : 6.3662e-03 	 MSE : 1.0853e+00
Training Epoch 195 : 	 Train : 3.02506e-02 	 Res : 5.76878e-03 	 Jac : 1.61740e-02 	 Enc : 3.45971e-03 	 AE : 3.19622e-03 	 MSE : 1.65186e+00
Validation Epoch 195 : 	 Train : 4.34823e-02 	 Res : 8.08753e-03 	 Jac : 1.63614e-02 	 Enc : 3.45178e-03 	 AE : 1.43695e-02 	 MSE : 1.21219e+00
Training Epoch 195 finished, took current epoch 508.76s, cumulative time 91500.66s
Current Learning rate DEQ : 0.00020176803499999987
Current Learning rate AUTOENC : 0.00040353606999999974
Epoch 196, 25% 	 Loss : 3.0032e-02 	 Res : 6.1457e-03 	 Jac : 1.6197e-02 	 Enc : 3.4410e-03 	 AEnc : 2.7037e-03 	 MSE : 1.5447e+00
Epoch 196, 50% 	 Loss : 2.6526e-02 	 Res : 5.1266e-03 	 Jac : 1.6411e-02 	 Enc : 3.4618e-03 	 AEnc : 5.9077e-04 	 MSE : 9.3566e-01
Epoch 196, 75% 	 Loss : 3.2191e-02 	 Res : 8.0314e-03 	 Jac : 1.6163e-02 	 Enc : 3.4740e-03 	 AEnc : 1.8021e-03 	 MSE : 2.7206e+00
Training Epoch 196 : 	 Train : 2.91514e-02 	 Res : 6.27840e-03 	 Jac : 1.62356e-02 	 Enc : 3.45788e-03 	 AE : 1.38141e-03 	 MSE : 1.79813e+00
Validation Epoch 196 : 	 Train : 2.60853e-02 	 Res : 4.94527e-03 	 Jac : 1.61191e-02 	 Enc : 3.49567e-03 	 AE : 2.84917e-04 	 MSE : 1.24037e+00
Training Epoch 196 finished, took current epoch 518.89s, cumulative time 92019.54s
Current Learning rate DEQ : 0.00020176803499999987
Current Learning rate AUTOENC : 0.00040353606999999974
Epoch 197, 25% 	 Loss : 2.6623e-02 	 Res : 5.1912e-03 	 Jac : 1.6232e-02 	 Enc : 3.4715e-03 	 AEnc : 2.0020e-04 	 MSE : 1.5277e+00
Epoch 197, 50% 	 Loss : 2.5755e-02 	 Res : 4.7712e-03 	 Jac : 1.6150e-02 	 Enc : 3.4456e-03 	 AEnc : 1.6412e-04 	 MSE : 1.2245e+00
Epoch 197, 75% 	 Loss : 2.6146e-02 	 Res : 4.9984e-03 	 Jac : 1.6359e-02 	 Enc : 3.4504e-03 	 AEnc : 1.2450e-04 	 MSE : 1.2143e+00
Training Epoch 197 : 	 Train : 2.61499e-02 	 Res : 4.96757e-03 	 Jac : 1.62628e-02 	 Enc : 3.45987e-03 	 AE : 1.55285e-04 	 MSE : 1.30443e+00
Validation Epoch 197 : 	 Train : 2.67585e-02 	 Res : 5.24722e-03 	 Jac : 1.61954e-02 	 Enc : 3.50211e-03 	 AE : 1.09470e-04 	 MSE : 1.70432e+00
Training Epoch 197 finished, took current epoch 509.93s, cumulative time 92529.45s
Current Learning rate DEQ : 0.00020176803499999987
Current Learning rate AUTOENC : 0.00040353606999999974
Epoch 198, 25% 	 Loss : 2.6831e-02 	 Res : 5.3046e-03 	 Jac : 1.6222e-02 	 Enc : 3.4513e-03 	 AEnc : 1.0524e-04 	 MSE : 1.7480e+00
Epoch 198, 50% 	 Loss : 3.0384e-02 	 Res : 7.1960e-03 	 Jac : 1.6355e-02 	 Enc : 3.4921e-03 	 AEnc : 1.2571e-04 	 MSE : 3.2149e+00
Epoch 198, 75% 	 Loss : 2.8199e-02 	 Res : 6.1382e-03 	 Jac : 1.6341e-02 	 Enc : 3.4763e-03 	 AEnc : 1.2906e-04 	 MSE : 2.1146e+00
Training Epoch 198 : 	 Train : 2.81793e-02 	 Res : 6.06771e-03 	 Jac : 1.62955e-02 	 Enc : 3.46995e-03 	 AE : 1.21702e-04 	 MSE : 2.22452e+00
Validation Epoch 198 : 	 Train : 2.74933e-02 	 Res : 5.51074e-03 	 Jac : 1.62932e-02 	 Enc : 3.42940e-03 	 AE : 9.44804e-05 	 MSE : 2.16555e+00
Training Epoch 198 finished, took current epoch 508.11s, cumulative time 93037.54s
Current Learning rate DEQ : 0.00020176803499999987
Current Learning rate AUTOENC : 0.00040353606999999974
Epoch 199, 25% 	 Loss : 2.6737e-02 	 Res : 5.1781e-03 	 Jac : 1.6254e-02 	 Enc : 3.4858e-03 	 AEnc : 1.0823e-04 	 MSE : 1.7109e+00
Epoch 199, 50% 	 Loss : 2.8729e-02 	 Res : 6.3813e-03 	 Jac : 1.6399e-02 	 Enc : 3.4591e-03 	 AEnc : 1.1651e-04 	 MSE : 2.3728e+00
Epoch 199, 75% 	 Loss : 2.8098e-02 	 Res : 6.1632e-03 	 Jac : 1.6112e-02 	 Enc : 3.4440e-03 	 AEnc : 9.9588e-05 	 MSE : 2.2801e+00
Training Epoch 199 : 	 Train : 2.83326e-02 	 Res : 6.14007e-03 	 Jac : 1.62318e-02 	 Enc : 3.46462e-03 	 AE : 1.11664e-04 	 MSE : 2.38447e+00
Validation Epoch 199 : 	 Train : 2.68216e-02 	 Res : 5.18201e-03 	 Jac : 1.59823e-02 	 Enc : 3.43338e-03 	 AE : 1.03916e-04 	 MSE : 2.12001e+00
Training Epoch 199 finished, took current epoch 491.43s, cumulative time 93528.96s
Current Learning rate DEQ : 0.00020176803499999987
Current Learning rate AUTOENC : 0.00040353606999999974
Epoch 200, 25% 	 Loss : 2.8912e-02 	 Res : 6.4088e-03 	 Jac : 1.6184e-02 	 Enc : 3.4801e-03 	 AEnc : 1.1207e-04 	 MSE : 2.7274e+00
Epoch 200, 50% 	 Loss : 3.1574e-02 	 Res : 8.0367e-03 	 Jac : 1.6145e-02 	 Enc : 3.4594e-03 	 AEnc : 1.2418e-04 	 MSE : 3.8089e+00
Epoch 200, 75% 	 Loss : 3.5921e-02 	 Res : 1.0172e-02 	 Jac : 1.6157e-02 	 Enc : 3.4834e-03 	 AEnc : 2.2895e-04 	 MSE : 5.8792e+00
Training Epoch 200 : 	 Train : 3.10463e-02 	 Res : 7.56748e-03 	 Jac : 1.61719e-02 	 Enc : 3.47818e-03 	 AE : 1.49837e-04 	 MSE : 3.67888e+00
Validation Epoch 200 : 	 Train : 3.60558e-02 	 Res : 1.02080e-02 	 Jac : 1.63032e-02 	 Enc : 3.56642e-03 	 AE : 1.33068e-04 	 MSE : 5.84513e+00
Training Epoch 200 finished, took current epoch 516.80s, cumulative time 94045.75s
Current Learning rate DEQ : 0.00020176803499999987
Current Learning rate AUTOENC : 0.00040353606999999974
Epoch 201, 25% 	 Loss : 2.9865e-02 	 Res : 6.8635e-03 	 Jac : 1.6176e-02 	 Enc : 3.4702e-03 	 AEnc : 9.6590e-05 	 MSE : 3.2587e+00
Epoch 201, 50% 	 Loss : 4.0997e-02 	 Res : 1.3539e-02 	 Jac : 1.6121e-02 	 Enc : 3.5160e-03 	 AEnc : 1.3355e-04 	 MSE : 7.6876e+00
Epoch 201, 75% 	 Loss : 2.6583e-02 	 Res : 5.3171e-03 	 Jac : 1.6127e-02 	 Enc : 3.4910e-03 	 AEnc : 2.3102e-04 	 MSE : 1.4169e+00
Training Epoch 201 : 	 Train : 3.21821e-02 	 Res : 8.33588e-03 	 Jac : 1.61691e-02 	 Enc : 3.48528e-03 	 AE : 2.88917e-04 	 MSE : 3.90294e+00
Validation Epoch 201 : 	 Train : 2.50988e-02 	 Res : 4.39021e-03 	 Jac : 1.61117e-02 	 Enc : 3.48618e-03 	 AE : 2.12488e-04 	 MSE : 8.98304e-01
Training Epoch 201 finished, took current epoch 505.90s, cumulative time 94551.58s
Current Learning rate DEQ : 0.00020176803499999987
Current Learning rate AUTOENC : 0.00040353606999999974
Epoch 202, 25% 	 Loss : 2.7508e-02 	 Res : 5.6803e-03 	 Jac : 1.6091e-02 	 Enc : 3.4653e-03 	 AEnc : 1.5199e-04 	 MSE : 2.1191e+00
Epoch 202, 50% 	 Loss : 2.6147e-02 	 Res : 5.0044e-03 	 Jac : 1.6061e-02 	 Enc : 3.4696e-03 	 AEnc : 1.1758e-04 	 MSE : 1.4946e+00
Epoch 202, 75% 	 Loss : 2.6264e-02 	 Res : 5.0013e-03 	 Jac : 1.6143e-02 	 Enc : 3.4786e-03 	 AEnc : 1.0028e-04 	 MSE : 1.5409e+00
Training Epoch 202 : 	 Train : 2.65790e-02 	 Res : 5.21135e-03 	 Jac : 1.60847e-02 	 Enc : 3.47076e-03 	 AE : 1.17000e-04 	 MSE : 1.69527e+00
Validation Epoch 202 : 	 Train : 2.82979e-02 	 Res : 6.04127e-03 	 Jac : 1.60686e-02 	 Enc : 3.51335e-03 	 AE : 1.09412e-04 	 MSE : 2.56528e+00
Training Epoch 202 finished, took current epoch 502.71s, cumulative time 95054.23s
Current Learning rate DEQ : 0.00020176803499999987
Current Learning rate AUTOENC : 0.00040353606999999974
Epoch 203, 25% 	 Loss : 3.2055e-02 	 Res : 8.2090e-03 	 Jac : 1.6185e-02 	 Enc : 3.4863e-03 	 AEnc : 1.0934e-04 	 MSE : 4.0657e+00
Epoch 203, 50% 	 Loss : 2.5798e-02 	 Res : 4.8180e-03 	 Jac : 1.6197e-02 	 Enc : 3.4723e-03 	 AEnc : 1.1157e-04 	 MSE : 1.1995e+00
Epoch 203, 75% 	 Loss : 2.7981e-02 	 Res : 5.9102e-03 	 Jac : 1.6185e-02 	 Enc : 3.4782e-03 	 AEnc : 1.3668e-04 	 MSE : 2.2708e+00
Training Epoch 203 : 	 Train : 2.97325e-02 	 Res : 6.94097e-03 	 Jac : 1.62054e-02 	 Enc : 3.46929e-03 	 AE : 1.56128e-04 	 MSE : 2.96066e+00
Validation Epoch 203 : 	 Train : 2.51646e-02 	 Res : 4.31596e-03 	 Jac : 1.60986e-02 	 Enc : 3.49785e-03 	 AE : 3.56467e-04 	 MSE : 8.95700e-01
Training Epoch 203 finished, took current epoch 500.60s, cumulative time 95554.74s
Current Learning rate DEQ : 0.00020176803499999987
Current Learning rate AUTOENC : 0.00040353606999999974
MODEL SAVED
Epoch 204, 25% 	 Loss : 4.6490e-02 	 Res : 1.6243e-02 	 Jac : 1.6234e-02 	 Enc : 3.5009e-03 	 AEnc : 2.6666e-03 	 MSE : 7.8458e+00
Epoch 204, 50% 	 Loss : 2.7713e-02 	 Res : 5.5804e-03 	 Jac : 1.6149e-02 	 Enc : 3.5003e-03 	 AEnc : 5.6420e-04 	 MSE : 1.9195e+00
Epoch 204, 75% 	 Loss : 2.8749e-02 	 Res : 6.4327e-03 	 Jac : 1.6083e-02 	 Enc : 3.4734e-03 	 AEnc : 1.7988e-04 	 MSE : 2.5796e+00
Training Epoch 204 : 	 Train : 3.30183e-02 	 Res : 8.73061e-03 	 Jac : 1.61528e-02 	 Enc : 3.48894e-03 	 AE : 9.05369e-04 	 MSE : 3.74063e+00
Validation Epoch 204 : 	 Train : 2.72006e-02 	 Res : 5.69125e-03 	 Jac : 1.63134e-02 	 Enc : 3.47481e-03 	 AE : 1.45918e-04 	 MSE : 1.57521e+00
Training Epoch 204 finished, took current epoch 519.87s, cumulative time 96074.59s
Current Learning rate DEQ : 0.00020176803499999987
Current Learning rate AUTOENC : 0.00040353606999999974
Epoch 205, 25% 	 Loss : 2.6584e-02 	 Res : 5.2611e-03 	 Jac : 1.6034e-02 	 Enc : 3.4598e-03 	 AEnc : 3.7120e-04 	 MSE : 1.4582e+00
Epoch 205, 50% 	 Loss : 2.9922e-02 	 Res : 6.9442e-03 	 Jac : 1.6334e-02 	 Enc : 3.4785e-03 	 AEnc : 2.9063e-04 	 MSE : 2.8750e+00
Epoch 205, 75% 	 Loss : 2.8192e-02 	 Res : 6.2255e-03 	 Jac : 1.6198e-02 	 Enc : 3.4984e-03 	 AEnc : 1.7867e-04 	 MSE : 2.0921e+00
Training Epoch 205 : 	 Train : 2.93886e-02 	 Res : 6.89602e-03 	 Jac : 1.61820e-02 	 Enc : 3.48436e-03 	 AE : 3.18202e-04 	 MSE : 2.50800e+00
Validation Epoch 205 : 	 Train : 3.19338e-02 	 Res : 8.14707e-03 	 Jac : 1.59094e-02 	 Enc : 3.52601e-03 	 AE : 3.81067e-04 	 MSE : 3.97031e+00
Training Epoch 205 finished, took current epoch 507.16s, cumulative time 96581.74s
Current Learning rate DEQ : 0.00020176803499999987
Current Learning rate AUTOENC : 0.00040353606999999974
Epoch 206, 25% 	 Loss : 3.3588e-02 	 Res : 9.0790e-03 	 Jac : 1.6047e-02 	 Enc : 3.5124e-03 	 AEnc : 2.1246e-03 	 MSE : 2.8254e+00
Epoch 206, 50% 	 Loss : 2.8720e-02 	 Res : 6.4739e-03 	 Jac : 1.6120e-02 	 Enc : 3.5166e-03 	 AEnc : 2.1990e-04 	 MSE : 2.3894e+00
Epoch 206, 75% 	 Loss : 3.2602e-02 	 Res : 8.9015e-03 	 Jac : 1.6244e-02 	 Enc : 3.4880e-03 	 AEnc : 2.7618e-04 	 MSE : 3.6924e+00
Training Epoch 206 : 	 Train : 3.09847e-02 	 Res : 7.71880e-03 	 Jac : 1.61521e-02 	 Enc : 3.49544e-03 	 AE : 7.15896e-04 	 MSE : 2.90242e+00
Validation Epoch 206 : 	 Train : 2.55154e-02 	 Res : 4.78589e-03 	 Jac : 1.61531e-02 	 Enc : 3.46215e-03 	 AE : 2.76788e-04 	 MSE : 8.37426e-01
Training Epoch 206 finished, took current epoch 505.44s, cumulative time 97087.13s
Current Learning rate DEQ : 0.00020176803499999987
Current Learning rate AUTOENC : 0.00040353606999999974
Epoch 207, 25% 	 Loss : 2.7400e-02 	 Res : 5.7288e-03 	 Jac : 1.6142e-02 	 Enc : 3.4570e-03 	 AEnc : 2.5002e-04 	 MSE : 1.8220e+00
Epoch 207, 50% 	 Loss : 2.8478e-02 	 Res : 6.2557e-03 	 Jac : 1.6148e-02 	 Enc : 3.4659e-03 	 AEnc : 1.0565e-04 	 MSE : 2.5027e+00
Epoch 207, 75% 	 Loss : 2.6336e-02 	 Res : 5.0457e-03 	 Jac : 1.6123e-02 	 Enc : 3.4989e-03 	 AEnc : 1.1261e-04 	 MSE : 1.5558e+00
Training Epoch 207 : 	 Train : 2.70769e-02 	 Res : 5.49048e-03 	 Jac : 1.61074e-02 	 Enc : 3.47368e-03 	 AE : 1.42368e-04 	 MSE : 1.86303e+00
Validation Epoch 207 : 	 Train : 2.84983e-02 	 Res : 6.15339e-03 	 Jac : 1.62907e-02 	 Enc : 3.43940e-03 	 AE : 8.16852e-05 	 MSE : 2.53307e+00
Training Epoch 207 finished, took current epoch 496.41s, cumulative time 97583.50s
Current Learning rate DEQ : 0.00020176803499999987
Current Learning rate AUTOENC : 0.00040353606999999974
Epoch 208, 25% 	 Loss : 2.6356e-02 	 Res : 4.9432e-03 	 Jac : 1.6257e-02 	 Enc : 3.4905e-03 	 AEnc : 9.6322e-05 	 MSE : 1.5696e+00
Epoch 208, 50% 	 Loss : 2.9478e-02 	 Res : 6.7606e-03 	 Jac : 1.6074e-02 	 Enc : 3.4614e-03 	 AEnc : 9.8149e-05 	 MSE : 3.0834e+00
Epoch 208, 75% 	 Loss : 2.8973e-02 	 Res : 6.4192e-03 	 Jac : 1.6105e-02 	 Enc : 3.4796e-03 	 AEnc : 1.1614e-04 	 MSE : 2.8535e+00
Training Epoch 208 : 	 Train : 2.81528e-02 	 Res : 5.98264e-03 	 Jac : 1.61290e-02 	 Enc : 3.47751e-03 	 AE : 1.08252e-04 	 MSE : 2.45541e+00
Validation Epoch 208 : 	 Train : 3.66360e-02 	 Res : 1.03791e-02 	 Jac : 1.61419e-02 	 Enc : 3.55917e-03 	 AE : 1.12048e-04 	 MSE : 6.44381e+00
Training Epoch 208 finished, took current epoch 502.35s, cumulative time 98085.82s
Current Learning rate DEQ : 0.00020176803499999987
Current Learning rate AUTOENC : 0.00040353606999999974
Epoch 209, 25% 	 Loss : 2.9096e-02 	 Res : 6.4576e-03 	 Jac : 1.6151e-02 	 Enc : 3.4684e-03 	 AEnc : 9.7812e-05 	 MSE : 2.9212e+00
Epoch 209, 50% 	 Loss : 2.5598e-02 	 Res : 4.7134e-03 	 Jac : 1.6128e-02 	 Enc : 3.4793e-03 	 AEnc : 1.3383e-04 	 MSE : 1.1437e+00
Epoch 209, 75% 	 Loss : 2.9650e-02 	 Res : 6.7729e-03 	 Jac : 1.6149e-02 	 Enc : 3.4826e-03 	 AEnc : 4.0933e-04 	 MSE : 2.8367e+00
Training Epoch 209 : 	 Train : 2.86599e-02 	 Res : 6.15193e-03 	 Jac : 1.61565e-02 	 Enc : 3.47733e-03 	 AE : 7.20118e-04 	 MSE : 2.15402e+00
Validation Epoch 209 : 	 Train : 3.81186e-02 	 Res : 1.05971e-02 	 Jac : 1.61675e-02 	 Enc : 3.55389e-03 	 AE : 2.67892e-03 	 MSE : 5.12123e+00
Training Epoch 209 finished, took current epoch 506.36s, cumulative time 98592.17s
Current Learning rate DEQ : 0.00020176803499999987
Current Learning rate AUTOENC : 0.00040353606999999974
Epoch 210, 25% 	 Loss : 3.4093e-02 	 Res : 8.3687e-03 	 Jac : 1.6147e-02 	 Enc : 3.4594e-03 	 AEnc : 2.8678e-03 	 MSE : 3.2493e+00
Epoch 210, 50% 	 Loss : 2.7042e-02 	 Res : 4.9471e-03 	 Jac : 1.6138e-02 	 Enc : 3.5071e-03 	 AEnc : 1.2500e-03 	 MSE : 1.2001e+00
Epoch 210, 75% 	 Loss : 3.0285e-02 	 Res : 5.9329e-03 	 Jac : 1.6114e-02 	 Enc : 3.4799e-03 	 AEnc : 2.8235e-03 	 MSE : 1.9348e+00
Training Epoch 210 : 	 Train : 2.97614e-02 	 Res : 6.20487e-03 	 Jac : 1.61330e-02 	 Enc : 3.48168e-03 	 AE : 1.94086e-03 	 MSE : 2.00098e+00
Validation Epoch 210 : 	 Train : 2.60267e-02 	 Res : 4.70017e-03 	 Jac : 1.60474e-02 	 Enc : 3.49226e-03 	 AE : 9.73030e-05 	 MSE : 1.68954e+00
Training Epoch 210 finished, took current epoch 494.70s, cumulative time 99086.84s
Current Learning rate DEQ : 0.00020176803499999987
Current Learning rate AUTOENC : 0.00040353606999999974
Epoch 211, 25% 	 Loss : 2.7045e-02 	 Res : 5.4440e-03 	 Jac : 1.6140e-02 	 Enc : 3.4803e-03 	 AEnc : 1.1919e-04 	 MSE : 1.8621e+00
Epoch 211, 50% 	 Loss : 2.5598e-02 	 Res : 4.7131e-03 	 Jac : 1.6108e-02 	 Enc : 3.4649e-03 	 AEnc : 1.2287e-04 	 MSE : 1.1889e+00
Epoch 211, 75% 	 Loss : 2.6550e-02 	 Res : 5.1855e-03 	 Jac : 1.6046e-02 	 Enc : 3.4901e-03 	 AEnc : 1.0988e-04 	 MSE : 1.7187e+00
Training Epoch 211 : 	 Train : 2.65343e-02 	 Res : 5.17132e-03 	 Jac : 1.60935e-02 	 Enc : 3.47790e-03 	 AE : 1.46996e-04 	 MSE : 1.64458e+00
Validation Epoch 211 : 	 Train : 3.49318e-02 	 Res : 9.61574e-03 	 Jac : 1.64524e-02 	 Enc : 3.44161e-03 	 AE : 2.47408e-04 	 MSE : 5.17464e+00
Training Epoch 211 finished, took current epoch 507.32s, cumulative time 99594.13s
Current Learning rate DEQ : 0.00020176803499999987
Current Learning rate AUTOENC : 0.00040353606999999974
Epoch 212, 25% 	 Loss : 2.6943e-02 	 Res : 5.3599e-03 	 Jac : 1.6084e-02 	 Enc : 3.4766e-03 	 AEnc : 1.9896e-04 	 MSE : 1.8234e+00
Epoch 212, 50% 	 Loss : 2.5783e-02 	 Res : 4.7192e-03 	 Jac : 1.6232e-02 	 Enc : 3.4881e-03 	 AEnc : 1.1429e-04 	 MSE : 1.2298e+00
Epoch 212, 75% 	 Loss : 2.4791e-02 	 Res : 4.2475e-03 	 Jac : 1.6177e-02 	 Enc : 3.4507e-03 	 AEnc : 1.0148e-04 	 MSE : 8.1353e-01
Training Epoch 212 : 	 Train : 2.60395e-02 	 Res : 4.87479e-03 	 Jac : 1.61466e-02 	 Enc : 3.47466e-03 	 AE : 1.29825e-04 	 MSE : 1.41358e+00
Validation Epoch 212 : 	 Train : 2.92590e-02 	 Res : 6.48325e-03 	 Jac : 1.62807e-02 	 Enc : 3.44341e-03 	 AE : 8.04707e-05 	 MSE : 2.97124e+00
Training Epoch 212 finished, took current epoch 512.46s, cumulative time 100106.58s
Current Learning rate DEQ : 0.0001412376244999999
Current Learning rate AUTOENC : 0.0002824752489999998
Epoch 213, 25% 	 Loss : 2.5503e-02 	 Res : 4.4757e-03 	 Jac : 1.6277e-02 	 Enc : 3.4655e-03 	 AEnc : 1.0501e-04 	 MSE : 1.1796e+00
Epoch 213, 50% 	 Loss : 2.5337e-02 	 Res : 4.5303e-03 	 Jac : 1.6149e-02 	 Enc : 3.4863e-03 	 AEnc : 9.0123e-05 	 MSE : 1.0818e+00
Epoch 213, 75% 	 Loss : 2.8572e-02 	 Res : 6.5022e-03 	 Jac : 1.6193e-02 	 Enc : 3.4891e-03 	 AEnc : 1.1400e-04 	 MSE : 2.2733e+00
Training Epoch 213 : 	 Train : 2.63888e-02 	 Res : 5.13197e-03 	 Jac : 1.61582e-02 	 Enc : 3.47685e-03 	 AE : 1.05705e-04 	 MSE : 1.51601e+00
Validation Epoch 213 : 	 Train : 2.41184e-02 	 Res : 3.90795e-03 	 Jac : 1.61509e-02 	 Enc : 3.47388e-03 	 AE : 1.07231e-04 	 MSE : 4.78451e-01
Training Epoch 213 finished, took current epoch 503.74s, cumulative time 100610.25s
Current Learning rate DEQ : 0.0001412376244999999
Current Learning rate AUTOENC : 0.0002824752489999998
MODEL SAVED
Epoch 214, 25% 	 Loss : 2.8770e-02 	 Res : 6.3317e-03 	 Jac : 1.6141e-02 	 Enc : 3.4746e-03 	 AEnc : 1.1999e-04 	 MSE : 2.7030e+00
Epoch 214, 50% 	 Loss : 2.6537e-02 	 Res : 5.1911e-03 	 Jac : 1.6058e-02 	 Enc : 3.4832e-03 	 AEnc : 1.0619e-04 	 MSE : 1.6989e+00
Epoch 214, 75% 	 Loss : 2.6284e-02 	 Res : 4.9236e-03 	 Jac : 1.6136e-02 	 Enc : 3.4738e-03 	 AEnc : 1.1181e-04 	 MSE : 1.6389e+00
Training Epoch 214 : 	 Train : 2.72311e-02 	 Res : 5.54847e-03 	 Jac : 1.61090e-02 	 Enc : 3.47806e-03 	 AE : 1.14024e-04 	 MSE : 1.98161e+00
Validation Epoch 214 : 	 Train : 2.55557e-02 	 Res : 4.55544e-03 	 Jac : 1.58931e-02 	 Enc : 3.48516e-03 	 AE : 7.93398e-05 	 MSE : 1.54265e+00
Training Epoch 214 finished, took current epoch 492.65s, cumulative time 101102.89s
Current Learning rate DEQ : 0.0001412376244999999
Current Learning rate AUTOENC : 0.0002824752489999998
Epoch 215, 25% 	 Loss : 2.5083e-02 	 Res : 4.5096e-03 	 Jac : 1.6139e-02 	 Enc : 3.4653e-03 	 AEnc : 1.1019e-04 	 MSE : 8.5945e-01
Epoch 215, 50% 	 Loss : 2.4529e-02 	 Res : 4.1479e-03 	 Jac : 1.6218e-02 	 Enc : 3.4772e-03 	 AEnc : 9.6288e-05 	 MSE : 5.8962e-01
Epoch 215, 75% 	 Loss : 2.4268e-02 	 Res : 3.9062e-03 	 Jac : 1.6276e-02 	 Enc : 3.4461e-03 	 AEnc : 9.0125e-05 	 MSE : 5.4951e-01
Training Epoch 215 : 	 Train : 2.52969e-02 	 Res : 4.49756e-03 	 Jac : 1.62293e-02 	 Enc : 3.47375e-03 	 AE : 9.93284e-05 	 MSE : 9.96918e-01
Validation Epoch 215 : 	 Train : 2.52695e-02 	 Res : 4.48988e-03 	 Jac : 1.61427e-02 	 Enc : 3.44934e-03 	 AE : 7.54205e-05 	 MSE : 1.11209e+00
Training Epoch 215 finished, took current epoch 501.24s, cumulative time 101604.11s
Current Learning rate DEQ : 0.0001412376244999999
Current Learning rate AUTOENC : 0.0002824752489999998
Epoch 216, 25% 	 Loss : 2.6979e-02 	 Res : 5.5063e-03 	 Jac : 1.6202e-02 	 Enc : 3.4730e-03 	 AEnc : 1.2319e-04 	 MSE : 1.6747e+00
Epoch 216, 50% 	 Loss : 2.6345e-02 	 Res : 4.9742e-03 	 Jac : 1.6222e-02 	 Enc : 3.4809e-03 	 AEnc : 1.1822e-04 	 MSE : 1.5498e+00
Epoch 216, 75% 	 Loss : 2.7592e-02 	 Res : 5.5886e-03 	 Jac : 1.6175e-02 	 Enc : 3.4856e-03 	 AEnc : 1.0754e-04 	 MSE : 2.2351e+00
Training Epoch 216 : 	 Train : 2.70179e-02 	 Res : 5.37160e-03 	 Jac : 1.61824e-02 	 Enc : 3.47773e-03 	 AE : 1.10241e-04 	 MSE : 1.87595e+00
Validation Epoch 216 : 	 Train : 2.44152e-02 	 Res : 4.02790e-03 	 Jac : 1.59476e-02 	 Enc : 3.47259e-03 	 AE : 8.38823e-05 	 MSE : 8.83218e-01
Training Epoch 216 finished, took current epoch 486.57s, cumulative time 102090.67s
Current Learning rate DEQ : 0.0001412376244999999
Current Learning rate AUTOENC : 0.0002824752489999998
Epoch 217, 25% 	 Loss : 2.5378e-02 	 Res : 4.4957e-03 	 Jac : 1.6154e-02 	 Enc : 3.4939e-03 	 AEnc : 1.2088e-04 	 MSE : 1.1127e+00
Epoch 217, 50% 	 Loss : 2.4983e-02 	 Res : 4.3674e-03 	 Jac : 1.6188e-02 	 Enc : 3.4648e-03 	 AEnc : 9.9709e-05 	 MSE : 8.6354e-01
Epoch 217, 75% 	 Loss : 2.4580e-02 	 Res : 4.0923e-03 	 Jac : 1.6168e-02 	 Enc : 3.4675e-03 	 AEnc : 2.3737e-04 	 MSE : 6.1490e-01
Training Epoch 217 : 	 Train : 2.50305e-02 	 Res : 4.36828e-03 	 Jac : 1.61640e-02 	 Enc : 3.47757e-03 	 AE : 1.45666e-04 	 MSE : 8.74983e-01
Validation Epoch 217 : 	 Train : 2.44178e-02 	 Res : 4.06124e-03 	 Jac : 1.60819e-02 	 Enc : 3.46097e-03 	 AE : 8.79635e-05 	 MSE : 7.25686e-01
Training Epoch 217 finished, took current epoch 509.34s, cumulative time 102600.00s
Current Learning rate DEQ : 0.0001412376244999999
Current Learning rate AUTOENC : 0.0002824752489999998
Epoch 218, 25% 	 Loss : 2.4895e-02 	 Res : 4.2919e-03 	 Jac : 1.6241e-02 	 Enc : 3.4581e-03 	 AEnc : 1.4971e-04 	 MSE : 7.5383e-01
Epoch 218, 50% 	 Loss : 2.6923e-02 	 Res : 5.4398e-03 	 Jac : 1.6178e-02 	 Enc : 3.4840e-03 	 AEnc : 2.3498e-04 	 MSE : 1.5860e+00
Epoch 218, 75% 	 Loss : 2.6679e-02 	 Res : 5.1206e-03 	 Jac : 1.6151e-02 	 Enc : 3.4704e-03 	 AEnc : 3.3556e-04 	 MSE : 1.6016e+00
Training Epoch 218 : 	 Train : 2.61070e-02 	 Res : 4.88918e-03 	 Jac : 1.61934e-02 	 Enc : 3.47584e-03 	 AE : 2.74817e-04 	 MSE : 1.27384e+00
Validation Epoch 218 : 	 Train : 2.60771e-02 	 Res : 4.75614e-03 	 Jac : 1.61358e-02 	 Enc : 3.51297e-03 	 AE : 2.43623e-04 	 MSE : 1.42858e+00
Training Epoch 218 finished, took current epoch 497.64s, cumulative time 103097.62s
Current Learning rate DEQ : 0.0001412376244999999
Current Learning rate AUTOENC : 0.0002824752489999998
Epoch 219, 25% 	 Loss : 2.5372e-02 	 Res : 4.2957e-03 	 Jac : 1.6216e-02 	 Enc : 3.4699e-03 	 AEnc : 3.4656e-04 	 MSE : 1.0432e+00
Epoch 219, 50% 	 Loss : 2.8215e-02 	 Res : 5.3212e-03 	 Jac : 1.6164e-02 	 Enc : 3.4785e-03 	 AEnc : 1.5011e-03 	 MSE : 1.7500e+00
Epoch 219, 75% 	 Loss : 3.2191e-02 	 Res : 5.7519e-03 	 Jac : 1.6283e-02 	 Enc : 3.4915e-03 	 AEnc : 5.2740e-03 	 MSE : 1.3913e+00
Training Epoch 219 : 	 Train : 2.84313e-02 	 Res : 5.10939e-03 	 Jac : 1.62280e-02 	 Enc : 3.48194e-03 	 AE : 2.25848e-03 	 MSE : 1.35356e+00
Validation Epoch 219 : 	 Train : 2.78208e-02 	 Res : 4.40154e-03 	 Jac : 1.60446e-02 	 Enc : 3.50264e-03 	 AE : 3.02529e-03 	 MSE : 8.46782e-01
Training Epoch 219 finished, took current epoch 507.07s, cumulative time 103604.65s
Current Learning rate DEQ : 0.0001412376244999999
Current Learning rate AUTOENC : 0.0002824752489999998
Epoch 220, 25% 	 Loss : 3.0326e-02 	 Res : 5.6578e-03 	 Jac : 1.6325e-02 	 Enc : 3.4709e-03 	 AEnc : 2.9842e-03 	 MSE : 1.8882e+00
Epoch 220, 50% 	 Loss : 2.6365e-02 	 Res : 4.8870e-03 	 Jac : 1.6164e-02 	 Enc : 3.4926e-03 	 AEnc : 4.4172e-04 	 MSE : 1.3793e+00
Epoch 220, 75% 	 Loss : 2.5279e-02 	 Res : 4.4627e-03 	 Jac : 1.6132e-02 	 Enc : 3.4784e-03 	 AEnc : 2.1992e-04 	 MSE : 9.8619e-01
Training Epoch 220 : 	 Train : 2.68136e-02 	 Res : 4.86585e-03 	 Jac : 1.61848e-02 	 Enc : 3.48387e-03 	 AE : 9.60503e-04 	 MSE : 1.31851e+00
Validation Epoch 220 : 	 Train : 2.43611e-02 	 Res : 3.99098e-03 	 Jac : 1.62207e-02 	 Enc : 3.46917e-03 	 AE : 8.47724e-05 	 MSE : 5.95483e-01
Training Epoch 220 finished, took current epoch 493.74s, cumulative time 104098.37s
Current Learning rate DEQ : 0.0001412376244999999
Current Learning rate AUTOENC : 0.0002824752489999998
Epoch 221, 25% 	 Loss : 2.4987e-02 	 Res : 4.2969e-03 	 Jac : 1.6139e-02 	 Enc : 3.4776e-03 	 AEnc : 9.5834e-05 	 MSE : 9.7790e-01
Epoch 221, 50% 	 Loss : 2.5078e-02 	 Res : 4.3826e-03 	 Jac : 1.6165e-02 	 Enc : 3.4756e-03 	 AEnc : 1.0328e-04 	 MSE : 9.5136e-01
Epoch 221, 75% 	 Loss : 2.6416e-02 	 Res : 4.6783e-03 	 Jac : 1.6206e-02 	 Enc : 3.4714e-03 	 AEnc : 1.1371e-03 	 MSE : 9.2295e-01
Training Epoch 221 : 	 Train : 2.55639e-02 	 Res : 4.54733e-03 	 Jac : 1.61694e-02 	 Enc : 3.47317e-03 	 AE : 3.94335e-04 	 MSE : 9.79697e-01
Validation Epoch 221 : 	 Train : 2.57974e-02 	 Res : 4.69717e-03 	 Jac : 1.62042e-02 	 Enc : 3.50403e-03 	 AE : 1.51082e-04 	 MSE : 1.24094e+00
Training Epoch 221 finished, took current epoch 515.06s, cumulative time 104613.41s
Current Learning rate DEQ : 0.0001412376244999999
Current Learning rate AUTOENC : 0.0002824752489999998
Epoch 222, 25% 	 Loss : 2.7961e-02 	 Res : 5.8030e-03 	 Jac : 1.6103e-02 	 Enc : 3.4989e-03 	 AEnc : 1.0451e-04 	 MSE : 2.4523e+00
Epoch 222, 50% 	 Loss : 2.5421e-02 	 Res : 4.5324e-03 	 Jac : 1.6153e-02 	 Enc : 3.4673e-03 	 AEnc : 9.9657e-05 	 MSE : 1.1686e+00
Epoch 222, 75% 	 Loss : 2.5398e-02 	 Res : 4.6481e-03 	 Jac : 1.6274e-02 	 Enc : 3.4735e-03 	 AEnc : 1.6886e-04 	 MSE : 8.3323e-01
Training Epoch 222 : 	 Train : 2.61613e-02 	 Res : 4.94274e-03 	 Jac : 1.61943e-02 	 Enc : 3.47720e-03 	 AE : 1.24829e-04 	 MSE : 1.42223e+00
Validation Epoch 222 : 	 Train : 2.54750e-02 	 Res : 4.57019e-03 	 Jac : 1.61261e-02 	 Enc : 3.50317e-03 	 AE : 1.32588e-04 	 MSE : 1.14289e+00
Training Epoch 222 finished, took current epoch 496.45s, cumulative time 105109.81s
Current Learning rate DEQ : 0.0001412376244999999
Current Learning rate AUTOENC : 0.0002824752489999998
Epoch 223, 25% 	 Loss : 2.5097e-02 	 Res : 4.4162e-03 	 Jac : 1.6066e-02 	 Enc : 3.4805e-03 	 AEnc : 1.0950e-04 	 MSE : 1.0246e+00
Epoch 223, 50% 	 Loss : 2.5186e-02 	 Res : 4.4155e-03 	 Jac : 1.6202e-02 	 Enc : 3.4577e-03 	 AEnc : 9.0245e-05 	 MSE : 1.0206e+00
Epoch 223, 75% 	 Loss : 2.5053e-02 	 Res : 4.3219e-03 	 Jac : 1.6088e-02 	 Enc : 3.4766e-03 	 AEnc : 9.9680e-05 	 MSE : 1.0666e+00
Training Epoch 223 : 	 Train : 2.61410e-02 	 Res : 4.90410e-03 	 Jac : 1.61299e-02 	 Enc : 3.47316e-03 	 AE : 1.00105e-04 	 MSE : 1.53369e+00
Validation Epoch 223 : 	 Train : 2.45375e-02 	 Res : 4.15415e-03 	 Jac : 1.61014e-02 	 Enc : 3.46506e-03 	 AE : 9.05056e-05 	 MSE : 7.26433e-01
Training Epoch 223 finished, took current epoch 489.52s, cumulative time 105599.30s
Current Learning rate DEQ : 0.0001412376244999999
Current Learning rate AUTOENC : 0.0002824752489999998
Epoch 224, 25% 	 Loss : 3.1552e-02 	 Res : 7.6192e-03 	 Jac : 1.6145e-02 	 Enc : 3.4728e-03 	 AEnc : 1.0256e-04 	 MSE : 4.2125e+00
Epoch 224, 50% 	 Loss : 2.8958e-02 	 Res : 6.2326e-03 	 Jac : 1.6045e-02 	 Enc : 3.5000e-03 	 AEnc : 1.1944e-04 	 MSE : 3.0606e+00
Epoch 224, 75% 	 Loss : 2.7039e-02 	 Res : 5.2897e-03 	 Jac : 1.6157e-02 	 Enc : 3.4956e-03 	 AEnc : 1.0239e-04 	 MSE : 1.9945e+00
Training Epoch 224 : 	 Train : 2.87236e-02 	 Res : 6.16185e-03 	 Jac : 1.61036e-02 	 Enc : 3.48810e-03 	 AE : 1.05720e-04 	 MSE : 2.86431e+00
Validation Epoch 224 : 	 Train : 2.89454e-02 	 Res : 6.29676e-03 	 Jac : 1.61813e-02 	 Enc : 3.44720e-03 	 AE : 7.67746e-05 	 MSE : 2.94331e+00
Training Epoch 224 finished, took current epoch 491.18s, cumulative time 106090.47s
Current Learning rate DEQ : 9.886633714999992e-05
Current Learning rate AUTOENC : 0.00019773267429999984
Epoch 225, 25% 	 Loss : 2.5751e-02 	 Res : 4.6774e-03 	 Jac : 1.6125e-02 	 Enc : 3.4766e-03 	 AEnc : 8.9834e-05 	 MSE : 1.3824e+00
Epoch 225, 50% 	 Loss : 2.5568e-02 	 Res : 4.5444e-03 	 Jac : 1.6203e-02 	 Enc : 3.4746e-03 	 AEnc : 9.5374e-05 	 MSE : 1.2506e+00
Epoch 225, 75% 	 Loss : 2.5691e-02 	 Res : 4.6513e-03 	 Jac : 1.6084e-02 	 Enc : 3.4768e-03 	 AEnc : 9.5109e-05 	 MSE : 1.3841e+00
Training Epoch 225 : 	 Train : 2.56032e-02 	 Res : 4.60374e-03 	 Jac : 1.61204e-02 	 Enc : 3.47958e-03 	 AE : 9.76810e-05 	 MSE : 1.30180e+00
Validation Epoch 225 : 	 Train : 2.42115e-02 	 Res : 4.05812e-03 	 Jac : 1.61228e-02 	 Enc : 3.48250e-03 	 AE : 9.88852e-05 	 MSE : 4.49197e-01
Training Epoch 225 finished, took current epoch 499.37s, cumulative time 106589.80s
Current Learning rate DEQ : 9.886633714999992e-05
Current Learning rate AUTOENC : 0.00019773267429999984
Epoch 226, 25% 	 Loss : 2.5720e-02 	 Res : 4.8390e-03 	 Jac : 1.6210e-02 	 Enc : 3.4776e-03 	 AEnc : 1.4805e-04 	 MSE : 1.0448e+00
Epoch 226, 50% 	 Loss : 2.4583e-02 	 Res : 4.0563e-03 	 Jac : 1.6186e-02 	 Enc : 3.4890e-03 	 AEnc : 1.2834e-04 	 MSE : 7.2397e-01
Epoch 226, 75% 	 Loss : 2.4491e-02 	 Res : 4.0509e-03 	 Jac : 1.6071e-02 	 Enc : 3.4648e-03 	 AEnc : 1.0315e-04 	 MSE : 8.0110e-01
Training Epoch 226 : 	 Train : 2.51511e-02 	 Res : 4.42634e-03 	 Jac : 1.61779e-02 	 Enc : 3.47988e-03 	 AE : 1.20976e-04 	 MSE : 9.45948e-01
Validation Epoch 226 : 	 Train : 2.43501e-02 	 Res : 3.93943e-03 	 Jac : 1.63124e-02 	 Enc : 3.47548e-03 	 AE : 9.30476e-05 	 MSE : 5.29827e-01
Training Epoch 226 finished, took current epoch 505.05s, cumulative time 107094.83s
Current Learning rate DEQ : 9.886633714999992e-05
Current Learning rate AUTOENC : 0.00019773267429999984
Epoch 227, 25% 	 Loss : 2.5050e-02 	 Res : 4.3251e-03 	 Jac : 1.6112e-02 	 Enc : 3.4683e-03 	 AEnc : 1.0690e-04 	 MSE : 1.0376e+00
Epoch 227, 50% 	 Loss : 2.4311e-02 	 Res : 4.0221e-03 	 Jac : 1.6167e-02 	 Enc : 3.4854e-03 	 AEnc : 1.1506e-04 	 MSE : 5.2103e-01
Epoch 227, 75% 	 Loss : 2.6066e-02 	 Res : 4.8982e-03 	 Jac : 1.6171e-02 	 Enc : 3.4808e-03 	 AEnc : 1.2241e-04 	 MSE : 1.3936e+00
Training Epoch 227 : 	 Train : 2.52930e-02 	 Res : 4.45870e-03 	 Jac : 1.61482e-02 	 Enc : 3.47580e-03 	 AE : 1.82267e-04 	 MSE : 1.02798e+00
Validation Epoch 227 : 	 Train : 2.87476e-02 	 Res : 5.57333e-03 	 Jac : 1.60373e-02 	 Enc : 3.48908e-03 	 AE : 2.16896e-03 	 MSE : 1.47891e+00
Training Epoch 227 finished, took current epoch 487.95s, cumulative time 107582.76s
Current Learning rate DEQ : 9.886633714999992e-05
Current Learning rate AUTOENC : 0.00019773267429999984
Epoch 228, 25% 	 Loss : 2.5310e-02 	 Res : 4.2266e-03 	 Jac : 1.6195e-02 	 Enc : 3.4827e-03 	 AEnc : 6.0553e-04 	 MSE : 7.9984e-01
Epoch 228, 50% 	 Loss : 2.7849e-02 	 Res : 5.6796e-03 	 Jac : 1.6276e-02 	 Enc : 3.5000e-03 	 AEnc : 1.2369e-04 	 MSE : 2.2700e+00
Epoch 228, 75% 	 Loss : 2.4797e-02 	 Res : 4.2476e-03 	 Jac : 1.6180e-02 	 Enc : 3.4603e-03 	 AEnc : 1.0914e-04 	 MSE : 8.0000e-01
Training Epoch 228 : 	 Train : 2.58821e-02 	 Res : 4.76791e-03 	 Jac : 1.62188e-02 	 Enc : 3.47985e-03 	 AE : 2.41335e-04 	 MSE : 1.17419e+00
Validation Epoch 228 : 	 Train : 2.46804e-02 	 Res : 4.32276e-03 	 Jac : 1.61110e-02 	 Enc : 3.46302e-03 	 AE : 9.84014e-05 	 MSE : 6.85166e-01
Training Epoch 228 finished, took current epoch 503.78s, cumulative time 108086.53s
Current Learning rate DEQ : 9.886633714999992e-05
Current Learning rate AUTOENC : 0.00019773267429999984
Epoch 229, 25% 	 Loss : 2.4824e-02 	 Res : 4.2995e-03 	 Jac : 1.6179e-02 	 Enc : 3.4898e-03 	 AEnc : 1.3597e-04 	 MSE : 7.1994e-01
Epoch 229, 50% 	 Loss : 2.5148e-02 	 Res : 4.4129e-03 	 Jac : 1.6139e-02 	 Enc : 3.4719e-03 	 AEnc : 3.0010e-04 	 MSE : 8.2493e-01
Epoch 229, 75% 	 Loss : 2.4755e-02 	 Res : 4.1248e-03 	 Jac : 1.6291e-02 	 Enc : 3.4798e-03 	 AEnc : 1.4124e-04 	 MSE : 7.1762e-01
Training Epoch 229 : 	 Train : 2.49252e-02 	 Res : 4.28605e-03 	 Jac : 1.61792e-02 	 Enc : 3.47753e-03 	 AE : 1.93203e-04 	 MSE : 7.89165e-01
Validation Epoch 229 : 	 Train : 2.51212e-02 	 Res : 4.27530e-03 	 Jac : 1.61288e-02 	 Enc : 3.49658e-03 	 AE : 1.99835e-04 	 MSE : 1.02073e+00
Training Epoch 229 finished, took current epoch 511.75s, cumulative time 108598.27s
Current Learning rate DEQ : 9.886633714999992e-05
Current Learning rate AUTOENC : 0.00019773267429999984
Epoch 230, 25% 	 Loss : 2.5514e-02 	 Res : 4.4155e-03 	 Jac : 1.6165e-02 	 Enc : 3.4882e-03 	 AEnc : 4.4437e-04 	 MSE : 1.0010e+00
Epoch 230, 50% 	 Loss : 2.6507e-02 	 Res : 4.2853e-03 	 Jac : 1.6202e-02 	 Enc : 3.4712e-03 	 AEnc : 1.8850e-03 	 MSE : 6.6365e-01
Epoch 230, 75% 	 Loss : 2.7106e-02 	 Res : 4.3961e-03 	 Jac : 1.6235e-02 	 Enc : 3.4763e-03 	 AEnc : 2.3626e-03 	 MSE : 6.3606e-01
Training Epoch 230 : 	 Train : 2.65275e-02 	 Res : 4.39272e-03 	 Jac : 1.62169e-02 	 Enc : 3.47545e-03 	 AE : 1.67745e-03 	 MSE : 7.65004e-01
Validation Epoch 230 : 	 Train : 2.75933e-02 	 Res : 4.25254e-03 	 Jac : 1.60796e-02 	 Enc : 3.48558e-03 	 AE : 2.91304e-03 	 MSE : 8.62589e-01
Training Epoch 230 finished, took current epoch 505.76s, cumulative time 109104.01s
Current Learning rate DEQ : 9.886633714999992e-05
Current Learning rate AUTOENC : 0.00019773267429999984
Epoch 231, 25% 	 Loss : 2.7387e-02 	 Res : 4.7004e-03 	 Jac : 1.6198e-02 	 Enc : 3.4737e-03 	 AEnc : 1.7466e-03 	 MSE : 1.2684e+00
Epoch 231, 50% 	 Loss : 2.4879e-02 	 Res : 4.1449e-03 	 Jac : 1.6242e-02 	 Enc : 3.4754e-03 	 AEnc : 1.6864e-04 	 MSE : 8.4776e-01
Epoch 231, 75% 	 Loss : 2.4507e-02 	 Res : 4.0736e-03 	 Jac : 1.6164e-02 	 Enc : 3.4889e-03 	 AEnc : 1.0824e-04 	 MSE : 6.7261e-01
Training Epoch 231 : 	 Train : 2.61100e-02 	 Res : 4.63264e-03 	 Jac : 1.61795e-02 	 Enc : 3.47975e-03 	 AE : 5.45745e-04 	 MSE : 1.27236e+00
Validation Epoch 231 : 	 Train : 2.43625e-02 	 Res : 3.96191e-03 	 Jac : 1.61108e-02 	 Enc : 3.46155e-03 	 AE : 9.92742e-05 	 MSE : 7.28982e-01
Training Epoch 231 finished, took current epoch 490.61s, cumulative time 109594.60s
Current Learning rate DEQ : 9.886633714999992e-05
Current Learning rate AUTOENC : 0.00019773267429999984
Epoch 232, 25% 	 Loss : 2.5384e-02 	 Res : 4.5578e-03 	 Jac : 1.6061e-02 	 Enc : 3.4718e-03 	 AEnc : 1.1018e-04 	 MSE : 1.1839e+00
Epoch 232, 50% 	 Loss : 2.4317e-02 	 Res : 3.9906e-03 	 Jac : 1.6075e-02 	 Enc : 3.4795e-03 	 AEnc : 1.1094e-04 	 MSE : 6.6132e-01
Epoch 232, 75% 	 Loss : 2.4421e-02 	 Res : 4.0271e-03 	 Jac : 1.6182e-02 	 Enc : 3.4901e-03 	 AEnc : 1.2284e-04 	 MSE : 5.9881e-01
Training Epoch 232 : 	 Train : 2.46245e-02 	 Res : 4.13622e-03 	 Jac : 1.61199e-02 	 Enc : 3.47644e-03 	 AE : 1.16672e-04 	 MSE : 7.75244e-01
Validation Epoch 232 : 	 Train : 2.39820e-02 	 Res : 3.76562e-03 	 Jac : 1.62444e-02 	 Enc : 3.47160e-03 	 AE : 1.06031e-04 	 MSE : 3.94357e-01
Training Epoch 232 finished, took current epoch 498.91s, cumulative time 110093.47s
Current Learning rate DEQ : 9.886633714999992e-05
Current Learning rate AUTOENC : 0.00019773267429999984
MODEL SAVED
Epoch 233, 25% 	 Loss : 2.4666e-02 	 Res : 4.1204e-03 	 Jac : 1.6163e-02 	 Enc : 3.4884e-03 	 AEnc : 1.1058e-04 	 MSE : 7.8364e-01
Epoch 233, 50% 	 Loss : 2.4656e-02 	 Res : 4.2101e-03 	 Jac : 1.6117e-02 	 Enc : 3.4811e-03 	 AEnc : 1.2548e-04 	 MSE : 7.2308e-01
Epoch 233, 75% 	 Loss : 2.4519e-02 	 Res : 3.9971e-03 	 Jac : 1.6249e-02 	 Enc : 3.4618e-03 	 AEnc : 1.0098e-04 	 MSE : 7.1022e-01
Training Epoch 233 : 	 Train : 2.46290e-02 	 Res : 4.11726e-03 	 Jac : 1.61864e-02 	 Enc : 3.47539e-03 	 AE : 1.10237e-04 	 MSE : 7.39700e-01
Validation Epoch 233 : 	 Train : 2.56005e-02 	 Res : 4.55037e-03 	 Jac : 1.63528e-02 	 Enc : 3.45953e-03 	 AE : 1.01820e-04 	 MSE : 1.13592e+00
Training Epoch 233 finished, took current epoch 505.79s, cumulative time 110599.25s
Current Learning rate DEQ : 9.886633714999992e-05
Current Learning rate AUTOENC : 0.00019773267429999984
Epoch 234, 25% 	 Loss : 2.6580e-02 	 Res : 5.0487e-03 	 Jac : 1.6274e-02 	 Enc : 3.4744e-03 	 AEnc : 1.1043e-04 	 MSE : 1.6724e+00
Epoch 234, 50% 	 Loss : 2.5075e-02 	 Res : 4.3423e-03 	 Jac : 1.6351e-02 	 Enc : 3.4780e-03 	 AEnc : 1.2961e-04 	 MSE : 7.7436e-01
Epoch 234, 75% 	 Loss : 2.5114e-02 	 Res : 4.4835e-03 	 Jac : 1.6185e-02 	 Enc : 3.4851e-03 	 AEnc : 1.2721e-04 	 MSE : 8.3364e-01
Training Epoch 234 : 	 Train : 2.53773e-02 	 Res : 4.52396e-03 	 Jac : 1.62296e-02 	 Enc : 3.47604e-03 	 AE : 1.28527e-04 	 MSE : 1.01919e+00
Validation Epoch 234 : 	 Train : 2.38792e-02 	 Res : 3.74763e-03 	 Jac : 1.61684e-02 	 Enc : 3.48417e-03 	 AE : 1.44961e-04 	 MSE : 3.34036e-01
Training Epoch 234 finished, took current epoch 495.97s, cumulative time 111095.20s
Current Learning rate DEQ : 9.886633714999992e-05
Current Learning rate AUTOENC : 0.00019773267429999984
MODEL SAVED
Epoch 235, 25% 	 Loss : 2.5073e-02 	 Res : 4.4298e-03 	 Jac : 1.6256e-02 	 Enc : 3.4776e-03 	 AEnc : 1.1872e-04 	 MSE : 7.9040e-01
Epoch 235, 50% 	 Loss : 2.5028e-02 	 Res : 4.4907e-03 	 Jac : 1.6145e-02 	 Enc : 3.4743e-03 	 AEnc : 1.2378e-04 	 MSE : 7.9423e-01
Epoch 235, 75% 	 Loss : 2.5398e-02 	 Res : 4.5687e-03 	 Jac : 1.6160e-02 	 Enc : 3.4818e-03 	 AEnc : 4.1088e-04 	 MSE : 7.7682e-01
Training Epoch 235 : 	 Train : 2.54421e-02 	 Res : 4.57697e-03 	 Jac : 1.61830e-02 	 Enc : 3.48008e-03 	 AE : 2.73983e-04 	 MSE : 9.28063e-01
Validation Epoch 235 : 	 Train : 2.79725e-02 	 Res : 5.89881e-03 	 Jac : 1.62528e-02 	 Enc : 3.44855e-03 	 AE : 1.15936e-04 	 MSE : 2.25646e+00
Training Epoch 235 finished, took current epoch 506.42s, cumulative time 111601.59s
Current Learning rate DEQ : 9.886633714999992e-05
Current Learning rate AUTOENC : 0.00019773267429999984
Epoch 236, 25% 	 Loss : 2.4899e-02 	 Res : 4.3409e-03 	 Jac : 1.6115e-02 	 Enc : 3.4588e-03 	 AEnc : 1.3542e-04 	 MSE : 8.4919e-01
Epoch 236, 50% 	 Loss : 2.4804e-02 	 Res : 4.1273e-03 	 Jac : 1.6169e-02 	 Enc : 3.4784e-03 	 AEnc : 1.5475e-04 	 MSE : 8.7433e-01
Epoch 236, 75% 	 Loss : 2.5187e-02 	 Res : 4.3854e-03 	 Jac : 1.6071e-02 	 Enc : 3.4763e-03 	 AEnc : 1.8901e-04 	 MSE : 1.0652e+00
Training Epoch 236 : 	 Train : 2.48873e-02 	 Res : 4.25885e-03 	 Jac : 1.61240e-02 	 Enc : 3.47464e-03 	 AE : 1.54459e-04 	 MSE : 8.75351e-01
Validation Epoch 236 : 	 Train : 2.40664e-02 	 Res : 3.78268e-03 	 Jac : 1.60860e-02 	 Enc : 3.48611e-03 	 AE : 1.38026e-04 	 MSE : 5.73594e-01
Training Epoch 236 finished, took current epoch 491.77s, cumulative time 112093.36s
Current Learning rate DEQ : 9.886633714999992e-05
Current Learning rate AUTOENC : 0.00019773267429999984
Epoch 237, 25% 	 Loss : 2.4653e-02 	 Res : 4.0580e-03 	 Jac : 1.6310e-02 	 Enc : 3.4702e-03 	 AEnc : 1.3913e-04 	 MSE : 6.7527e-01
Epoch 237, 50% 	 Loss : 2.5548e-02 	 Res : 4.4995e-03 	 Jac : 1.6255e-02 	 Enc : 3.4779e-03 	 AEnc : 2.0770e-04 	 MSE : 1.1084e+00
Epoch 237, 75% 	 Loss : 2.5410e-02 	 Res : 4.4123e-03 	 Jac : 1.6279e-02 	 Enc : 3.4713e-03 	 AEnc : 1.7377e-04 	 MSE : 1.0738e+00
Training Epoch 237 : 	 Train : 2.67137e-02 	 Res : 5.08774e-03 	 Jac : 1.62466e-02 	 Enc : 3.48208e-03 	 AE : 1.64057e-04 	 MSE : 1.73322e+00
Validation Epoch 237 : 	 Train : 3.02792e-02 	 Res : 6.72477e-03 	 Jac : 1.59162e-02 	 Enc : 3.52974e-03 	 AE : 1.44831e-04 	 MSE : 3.96367e+00
Training Epoch 237 finished, took current epoch 489.26s, cumulative time 112582.60s
Current Learning rate DEQ : 9.886633714999992e-05
Current Learning rate AUTOENC : 0.00019773267429999984
Epoch 238, 25% 	 Loss : 2.7991e-02 	 Res : 5.6958e-03 	 Jac : 1.6189e-02 	 Enc : 3.4789e-03 	 AEnc : 1.2640e-04 	 MSE : 2.5007e+00
Epoch 238, 50% 	 Loss : 2.8439e-02 	 Res : 5.9587e-03 	 Jac : 1.6089e-02 	 Enc : 3.5030e-03 	 AEnc : 1.2159e-04 	 MSE : 2.7670e+00
Epoch 238, 75% 	 Loss : 2.8637e-02 	 Res : 6.1604e-03 	 Jac : 1.6064e-02 	 Enc : 3.4975e-03 	 AEnc : 1.2549e-04 	 MSE : 2.7893e+00
Training Epoch 238 : 	 Train : 2.74526e-02 	 Res : 5.50486e-03 	 Jac : 1.60980e-02 	 Enc : 3.48815e-03 	 AE : 1.23587e-04 	 MSE : 2.23803e+00
Validation Epoch 238 : 	 Train : 2.42474e-02 	 Res : 3.87131e-03 	 Jac : 1.60519e-02 	 Enc : 3.49089e-03 	 AE : 1.18442e-04 	 MSE : 7.14917e-01
Training Epoch 238 finished, took current epoch 478.83s, cumulative time 113061.41s
Current Learning rate DEQ : 9.886633714999992e-05
Current Learning rate AUTOENC : 0.00019773267429999984
Epoch 239, 25% 	 Loss : 2.4503e-02 	 Res : 4.0524e-03 	 Jac : 1.6163e-02 	 Enc : 3.4887e-03 	 AEnc : 1.1412e-04 	 MSE : 6.8493e-01
Epoch 239, 50% 	 Loss : 2.4429e-02 	 Res : 3.9808e-03 	 Jac : 1.6112e-02 	 Enc : 3.4766e-03 	 AEnc : 1.0232e-04 	 MSE : 7.5719e-01
Epoch 239, 75% 	 Loss : 2.4455e-02 	 Res : 4.0070e-03 	 Jac : 1.6168e-02 	 Enc : 3.4895e-03 	 AEnc : 1.0588e-04 	 MSE : 6.8421e-01
Training Epoch 239 : 	 Train : 2.44410e-02 	 Res : 4.00620e-03 	 Jac : 1.61354e-02 	 Enc : 3.47801e-03 	 AE : 1.06861e-04 	 MSE : 7.14522e-01
Validation Epoch 239 : 	 Train : 2.44305e-02 	 Res : 4.01222e-03 	 Jac : 1.62637e-02 	 Enc : 3.46925e-03 	 AE : 9.21887e-05 	 MSE : 5.93175e-01
Training Epoch 239 finished, took current epoch 497.43s, cumulative time 113558.83s
Current Learning rate DEQ : 9.886633714999992e-05
Current Learning rate AUTOENC : 0.00019773267429999984
Epoch 240, 25% 	 Loss : 2.6081e-02 	 Res : 4.8983e-03 	 Jac : 1.6054e-02 	 Enc : 3.5003e-03 	 AEnc : 1.3002e-04 	 MSE : 1.4990e+00
Epoch 240, 50% 	 Loss : 2.4097e-02 	 Res : 3.8652e-03 	 Jac : 1.6077e-02 	 Enc : 3.4690e-03 	 AEnc : 1.3665e-04 	 MSE : 5.4845e-01
Epoch 240, 75% 	 Loss : 2.3936e-02 	 Res : 3.8116e-03 	 Jac : 1.6108e-02 	 Enc : 3.4710e-03 	 AEnc : 1.1415e-04 	 MSE : 4.3102e-01
Training Epoch 240 : 	 Train : 2.46035e-02 	 Res : 4.15176e-03 	 Jac : 1.60487e-02 	 Enc : 3.47584e-03 	 AE : 1.21574e-04 	 MSE : 8.05726e-01
Validation Epoch 240 : 	 Train : 2.46418e-02 	 Res : 4.14709e-03 	 Jac : 1.61704e-02 	 Enc : 3.46143e-03 	 AE : 1.02847e-04 	 MSE : 7.59986e-01
Training Epoch 240 finished, took current epoch 502.52s, cumulative time 114061.34s
Current Learning rate DEQ : 9.886633714999992e-05
Current Learning rate AUTOENC : 0.00019773267429999984
Epoch 241, 25% 	 Loss : 2.4371e-02 	 Res : 3.9520e-03 	 Jac : 1.6125e-02 	 Enc : 3.4795e-03 	 AEnc : 1.1510e-04 	 MSE : 6.9889e-01
Epoch 241, 50% 	 Loss : 2.6102e-02 	 Res : 4.9068e-03 	 Jac : 1.6067e-02 	 Enc : 3.4841e-03 	 AEnc : 1.1456e-04 	 MSE : 1.5299e+00
Epoch 241, 75% 	 Loss : 2.4724e-02 	 Res : 4.1807e-03 	 Jac : 1.6094e-02 	 Enc : 3.4704e-03 	 AEnc : 1.1381e-04 	 MSE : 8.6492e-01
Training Epoch 241 : 	 Train : 2.52889e-02 	 Res : 4.48098e-03 	 Jac : 1.61069e-02 	 Enc : 3.47677e-03 	 AE : 1.25756e-04 	 MSE : 1.09846e+00
Validation Epoch 241 : 	 Train : 2.45678e-02 	 Res : 4.01120e-03 	 Jac : 1.62238e-02 	 Enc : 3.46261e-03 	 AE : 7.34057e-05 	 MSE : 7.96728e-01
Training Epoch 241 finished, took current epoch 493.29s, cumulative time 114554.61s
Current Learning rate DEQ : 9.886633714999992e-05
Current Learning rate AUTOENC : 0.00019773267429999984
Epoch 242, 25% 	 Loss : 2.5293e-02 	 Res : 4.5128e-03 	 Jac : 1.6178e-02 	 Enc : 3.4809e-03 	 AEnc : 1.3062e-04 	 MSE : 9.9022e-01
Epoch 242, 50% 	 Loss : 2.6437e-02 	 Res : 5.0754e-03 	 Jac : 1.6099e-02 	 Enc : 3.4750e-03 	 AEnc : 1.5254e-04 	 MSE : 1.6352e+00
Epoch 242, 75% 	 Loss : 2.4460e-02 	 Res : 4.0201e-03 	 Jac : 1.6102e-02 	 Enc : 3.4740e-03 	 AEnc : 1.2668e-04 	 MSE : 7.3687e-01
Training Epoch 242 : 	 Train : 2.58836e-02 	 Res : 4.77759e-03 	 Jac : 1.61017e-02 	 Enc : 3.47479e-03 	 AE : 1.69347e-04 	 MSE : 1.36019e+00
Validation Epoch 242 : 	 Train : 2.48753e-02 	 Res : 4.23214e-03 	 Jac : 1.61010e-02 	 Enc : 3.45361e-03 	 AE : 7.75983e-05 	 MSE : 1.01095e+00
Training Epoch 242 finished, took current epoch 496.24s, cumulative time 115050.83s
Current Learning rate DEQ : 9.886633714999992e-05
Current Learning rate AUTOENC : 0.00019773267429999984
Epoch 243, 25% 	 Loss : 3.3276e-02 	 Res : 5.9929e-03 	 Jac : 1.6196e-02 	 Enc : 3.4688e-03 	 AEnc : 5.6489e-03 	 MSE : 1.9700e+00
Epoch 243, 50% 	 Loss : 2.6511e-02 	 Res : 4.1567e-03 	 Jac : 1.6089e-02 	 Enc : 3.4709e-03 	 AEnc : 2.2339e-03 	 MSE : 5.6108e-01
Epoch 243, 75% 	 Loss : 2.4307e-02 	 Res : 3.7478e-03 	 Jac : 1.6080e-02 	 Enc : 3.4884e-03 	 AEnc : 5.5531e-04 	 MSE : 4.3577e-01
Training Epoch 243 : 	 Train : 2.72023e-02 	 Res : 4.48693e-03 	 Jac : 1.61370e-02 	 Enc : 3.47638e-03 	 AE : 2.18798e-03 	 MSE : 9.14044e-01
Validation Epoch 243 : 	 Train : 2.51864e-02 	 Res : 4.44198e-03 	 Jac : 1.60949e-02 	 Enc : 3.49924e-03 	 AE : 1.26054e-04 	 MSE : 1.02421e+00
Training Epoch 243 finished, took current epoch 497.20s, cumulative time 115548.02s
Current Learning rate DEQ : 9.886633714999992e-05
Current Learning rate AUTOENC : 0.00019773267429999984
Epoch 244, 25% 	 Loss : 2.5949e-02 	 Res : 4.8329e-03 	 Jac : 1.6056e-02 	 Enc : 3.4866e-03 	 AEnc : 1.1732e-04 	 MSE : 1.4561e+00
Epoch 244, 50% 	 Loss : 2.5600e-02 	 Res : 4.6214e-03 	 Jac : 1.6170e-02 	 Enc : 3.4661e-03 	 AEnc : 1.1467e-04 	 MSE : 1.2281e+00
Epoch 244, 75% 	 Loss : 2.4946e-02 	 Res : 4.2868e-03 	 Jac : 1.6150e-02 	 Enc : 3.4686e-03 	 AEnc : 1.1103e-04 	 MSE : 9.3019e-01
Training Epoch 244 : 	 Train : 2.55352e-02 	 Res : 4.58832e-03 	 Jac : 1.61478e-02 	 Enc : 3.47842e-03 	 AE : 1.15842e-04 	 MSE : 1.20478e+00
Validation Epoch 244 : 	 Train : 2.61968e-02 	 Res : 4.85307e-03 	 Jac : 1.61768e-02 	 Enc : 3.45719e-03 	 AE : 9.76426e-05 	 MSE : 1.61210e+00
Training Epoch 244 finished, took current epoch 501.98s, cumulative time 116049.99s
Current Learning rate DEQ : 9.886633714999992e-05
Current Learning rate AUTOENC : 0.00019773267429999984
Epoch 245, 25% 	 Loss : 2.5098e-02 	 Res : 4.3216e-03 	 Jac : 1.6187e-02 	 Enc : 3.4739e-03 	 AEnc : 1.0620e-04 	 MSE : 1.0098e+00
Epoch 245, 50% 	 Loss : 2.7072e-02 	 Res : 5.6087e-03 	 Jac : 1.6141e-02 	 Enc : 3.4755e-03 	 AEnc : 1.3830e-04 	 MSE : 1.7085e+00
Epoch 245, 75% 	 Loss : 2.5729e-02 	 Res : 4.6918e-03 	 Jac : 1.6085e-02 	 Enc : 3.4670e-03 	 AEnc : 9.9114e-05 	 MSE : 1.3860e+00
Training Epoch 245 : 	 Train : 2.60140e-02 	 Res : 4.87940e-03 	 Jac : 1.61189e-02 	 Enc : 3.47332e-03 	 AE : 1.13672e-04 	 MSE : 1.42876e+00
Validation Epoch 245 : 	 Train : 2.48627e-02 	 Res : 4.23564e-03 	 Jac : 1.59830e-02 	 Enc : 3.44983e-03 	 AE : 1.06794e-04 	 MSE : 1.08747e+00
Training Epoch 245 finished, took current epoch 477.24s, cumulative time 116527.18s
Current Learning rate DEQ : 6.920643600499994e-05
Current Learning rate AUTOENC : 0.00013841287200999988
Epoch 246, 25% 	 Loss : 2.4617e-02 	 Res : 4.0579e-03 	 Jac : 1.6227e-02 	 Enc : 3.4778e-03 	 AEnc : 1.0770e-04 	 MSE : 7.4629e-01
Epoch 246, 50% 	 Loss : 2.4543e-02 	 Res : 4.0217e-03 	 Jac : 1.6092e-02 	 Enc : 3.4776e-03 	 AEnc : 1.0513e-04 	 MSE : 8.4643e-01
Epoch 246, 75% 	 Loss : 2.4959e-02 	 Res : 4.2703e-03 	 Jac : 1.6159e-02 	 Enc : 3.4699e-03 	 AEnc : 1.0587e-04 	 MSE : 9.5410e-01
Training Epoch 246 : 	 Train : 2.47415e-02 	 Res : 4.16124e-03 	 Jac : 1.61690e-02 	 Enc : 3.47102e-03 	 AE : 1.43333e-04 	 MSE : 7.96951e-01
Validation Epoch 246 : 	 Train : 2.46023e-02 	 Res : 4.08055e-03 	 Jac : 1.61624e-02 	 Enc : 3.45362e-03 	 AE : 3.63486e-04 	 MSE : 5.42277e-01
Training Epoch 246 finished, took current epoch 495.93s, cumulative time 117023.10s
Current Learning rate DEQ : 6.920643600499994e-05
Current Learning rate AUTOENC : 0.00013841287200999988
Epoch 247, 25% 	 Loss : 2.3850e-02 	 Res : 3.7580e-03 	 Jac : 1.6107e-02 	 Enc : 3.4527e-03 	 AEnc : 1.9133e-04 	 MSE : 3.4047e-01
Epoch 247, 50% 	 Loss : 2.3855e-02 	 Res : 3.6650e-03 	 Jac : 1.6248e-02 	 Enc : 3.4658e-03 	 AEnc : 1.1109e-04 	 MSE : 3.6539e-01
Epoch 247, 75% 	 Loss : 2.4391e-02 	 Res : 3.9838e-03 	 Jac : 1.6129e-02 	 Enc : 3.4844e-03 	 AEnc : 1.1752e-04 	 MSE : 6.7627e-01
Training Epoch 247 : 	 Train : 2.42593e-02 	 Res : 3.91143e-03 	 Jac : 1.61464e-02 	 Enc : 3.46805e-03 	 AE : 1.32009e-04 	 MSE : 6.01454e-01
Validation Epoch 247 : 	 Train : 2.39202e-02 	 Res : 3.74330e-03 	 Jac : 1.61139e-02 	 Enc : 3.45603e-03 	 AE : 7.86580e-05 	 MSE : 5.28309e-01
Training Epoch 247 finished, took current epoch 489.87s, cumulative time 117512.94s
Current Learning rate DEQ : 6.920643600499994e-05
Current Learning rate AUTOENC : 0.00013841287200999988
MODEL SAVED
Epoch 248, 25% 	 Loss : 2.6045e-02 	 Res : 4.7523e-03 	 Jac : 1.6167e-02 	 Enc : 3.4656e-03 	 AEnc : 8.8858e-05 	 MSE : 1.5705e+00
Epoch 248, 50% 	 Loss : 2.6117e-02 	 Res : 4.9188e-03 	 Jac : 1.6091e-02 	 Enc : 3.4580e-03 	 AEnc : 1.0506e-04 	 MSE : 1.5444e+00
Epoch 248, 75% 	 Loss : 2.5504e-02 	 Res : 4.5530e-03 	 Jac : 1.6124e-02 	 Enc : 3.4810e-03 	 AEnc : 1.0159e-04 	 MSE : 1.2447e+00
Training Epoch 248 : 	 Train : 2.54422e-02 	 Res : 4.51307e-03 	 Jac : 1.61278e-02 	 Enc : 3.46908e-03 	 AE : 9.94096e-05 	 MSE : 1.23280e+00
Validation Epoch 248 : 	 Train : 2.36508e-02 	 Res : 3.61742e-03 	 Jac : 1.60651e-02 	 Enc : 3.46262e-03 	 AE : 8.65381e-05 	 MSE : 4.19060e-01
Training Epoch 248 finished, took current epoch 492.18s, cumulative time 118005.10s
Current Learning rate DEQ : 6.920643600499994e-05
Current Learning rate AUTOENC : 0.00013841287200999988
MODEL SAVED
Epoch 249, 25% 	 Loss : 2.3784e-02 	 Res : 3.7374e-03 	 Jac : 1.6121e-02 	 Enc : 3.4682e-03 	 AEnc : 1.0571e-04 	 MSE : 3.5199e-01
Epoch 249, 50% 	 Loss : 2.4816e-02 	 Res : 4.1211e-03 	 Jac : 1.6246e-02 	 Enc : 3.4544e-03 	 AEnc : 1.0496e-04 	 MSE : 8.8975e-01
Epoch 249, 75% 	 Loss : 2.3890e-02 	 Res : 3.7564e-03 	 Jac : 1.6118e-02 	 Enc : 3.4820e-03 	 AEnc : 1.2493e-04 	 MSE : 4.0839e-01
Training Epoch 249 : 	 Train : 2.41621e-02 	 Res : 3.87539e-03 	 Jac : 1.61468e-02 	 Enc : 3.46683e-03 	 AE : 1.20609e-04 	 MSE : 5.52450e-01
Validation Epoch 249 : 	 Train : 2.42564e-02 	 Res : 3.99940e-03 	 Jac : 1.61352e-02 	 Enc : 3.48595e-03 	 AE : 1.14735e-04 	 MSE : 5.21179e-01
Training Epoch 249 finished, took current epoch 504.44s, cumulative time 118509.51s
Current Learning rate DEQ : 6.920643600499994e-05
Current Learning rate AUTOENC : 0.00013841287200999988
Epoch 250, 25% 	 Loss : 2.4133e-02 	 Res : 3.8788e-03 	 Jac : 1.6119e-02 	 Enc : 3.4581e-03 	 AEnc : 1.0737e-04 	 MSE : 5.7033e-01
Epoch 250, 50% 	 Loss : 2.4694e-02 	 Res : 4.1704e-03 	 Jac : 1.6196e-02 	 Enc : 3.4542e-03 	 AEnc : 2.9433e-04 	 MSE : 5.7956e-01
Epoch 250, 75% 	 Loss : 2.5046e-02 	 Res : 4.2596e-03 	 Jac : 1.6245e-02 	 Enc : 3.4751e-03 	 AEnc : 2.5484e-04 	 MSE : 8.1129e-01
Training Epoch 250 : 	 Train : 2.61070e-02 	 Res : 4.84864e-03 	 Jac : 1.62058e-02 	 Enc : 3.46191e-03 	 AE : 2.00685e-04 	 MSE : 1.38991e+00
Validation Epoch 250 : 	 Train : 2.61513e-02 	 Res : 4.84755e-03 	 Jac : 1.59667e-02 	 Enc : 3.49478e-03 	 AE : 1.31950e-04 	 MSE : 1.71036e+00
Training Epoch 250 finished, took current epoch 509.68s, cumulative time 119019.18s
Current Learning rate DEQ : 6.920643600499994e-05
Current Learning rate AUTOENC : 0.00013841287200999988
Epoch 251, 25% 	 Loss : 2.4924e-02 	 Res : 4.1925e-03 	 Jac : 1.6069e-02 	 Enc : 3.4658e-03 	 AEnc : 3.5996e-04 	 MSE : 8.3612e-01
Epoch 251, 50% 	 Loss : 2.3796e-02 	 Res : 3.7040e-03 	 Jac : 1.6161e-02 	 Enc : 3.4642e-03 	 AEnc : 1.3627e-04 	 MSE : 3.3086e-01
Epoch 251, 75% 	 Loss : 2.4641e-02 	 Res : 4.1023e-03 	 Jac : 1.6163e-02 	 Enc : 3.4427e-03 	 AEnc : 1.2409e-04 	 MSE : 8.0820e-01
Training Epoch 251 : 	 Train : 2.43548e-02 	 Res : 3.95107e-03 	 Jac : 1.61483e-02 	 Enc : 3.46050e-03 	 AE : 1.86629e-04 	 MSE : 6.08228e-01
Validation Epoch 251 : 	 Train : 2.37666e-02 	 Res : 3.66661e-03 	 Jac : 1.61763e-02 	 Enc : 3.46236e-03 	 AE : 1.59074e-04 	 MSE : 3.02244e-01
Training Epoch 251 finished, took current epoch 495.90s, cumulative time 119515.07s
Current Learning rate DEQ : 6.920643600499994e-05
Current Learning rate AUTOENC : 0.00013841287200999988
Epoch 252, 25% 	 Loss : 2.4992e-02 	 Res : 3.9649e-03 	 Jac : 1.6159e-02 	 Enc : 3.4614e-03 	 AEnc : 8.9797e-04 	 MSE : 5.0881e-01
Epoch 252, 50% 	 Loss : 2.3897e-02 	 Res : 3.7573e-03 	 Jac : 1.6043e-02 	 Enc : 3.4560e-03 	 AEnc : 1.8129e-04 	 MSE : 4.5990e-01
Epoch 252, 75% 	 Loss : 2.3936e-02 	 Res : 3.7846e-03 	 Jac : 1.6016e-02 	 Enc : 3.4539e-03 	 AEnc : 1.0714e-04 	 MSE : 5.7465e-01
Training Epoch 252 : 	 Train : 2.41935e-02 	 Res : 3.82203e-03 	 Jac : 1.60921e-02 	 Enc : 3.45916e-03 	 AE : 3.31373e-04 	 MSE : 4.88858e-01
Validation Epoch 252 : 	 Train : 2.42531e-02 	 Res : 3.91229e-03 	 Jac : 1.60809e-02 	 Enc : 3.47807e-03 	 AE : 1.16840e-04 	 MSE : 6.65048e-01
Training Epoch 252 finished, took current epoch 501.62s, cumulative time 120016.66s
Current Learning rate DEQ : 6.920643600499994e-05
Current Learning rate AUTOENC : 0.00013841287200999988
Epoch 253, 25% 	 Loss : 2.4232e-02 	 Res : 3.8746e-03 	 Jac : 1.6165e-02 	 Enc : 3.4585e-03 	 AEnc : 1.8096e-04 	 MSE : 5.5355e-01
Epoch 253, 50% 	 Loss : 2.4098e-02 	 Res : 3.7941e-03 	 Jac : 1.6261e-02 	 Enc : 3.4654e-03 	 AEnc : 1.2104e-04 	 MSE : 4.5613e-01
Epoch 253, 75% 	 Loss : 2.4289e-02 	 Res : 3.9079e-03 	 Jac : 1.6196e-02 	 Enc : 3.4368e-03 	 AEnc : 1.3773e-04 	 MSE : 6.1071e-01
Training Epoch 253 : 	 Train : 2.41605e-02 	 Res : 3.84453e-03 	 Jac : 1.61870e-02 	 Enc : 3.45448e-03 	 AE : 1.41370e-04 	 MSE : 5.33077e-01
Validation Epoch 253 : 	 Train : 2.39636e-02 	 Res : 3.78357e-03 	 Jac : 1.61732e-02 	 Enc : 3.44909e-03 	 AE : 9.38655e-05 	 MSE : 4.63881e-01
Training Epoch 253 finished, took current epoch 498.31s, cumulative time 120514.92s
Current Learning rate DEQ : 6.920643600499994e-05
Current Learning rate AUTOENC : 0.00013841287200999988
Epoch 254, 25% 	 Loss : 2.4035e-02 	 Res : 3.7852e-03 	 Jac : 1.6149e-02 	 Enc : 3.4647e-03 	 AEnc : 1.2111e-04 	 MSE : 5.1492e-01
Epoch 254, 50% 	 Loss : 2.3942e-02 	 Res : 3.7412e-03 	 Jac : 1.6183e-02 	 Enc : 3.4564e-03 	 AEnc : 1.0273e-04 	 MSE : 4.5883e-01
Epoch 254, 75% 	 Loss : 2.4635e-02 	 Res : 4.1311e-03 	 Jac : 1.6131e-02 	 Enc : 3.4476e-03 	 AEnc : 1.0463e-04 	 MSE : 8.2109e-01
Training Epoch 254 : 	 Train : 2.41298e-02 	 Res : 3.83913e-03 	 Jac : 1.61575e-02 	 Enc : 3.45306e-03 	 AE : 1.09373e-04 	 MSE : 5.70700e-01
Validation Epoch 254 : 	 Train : 2.39779e-02 	 Res : 3.81330e-03 	 Jac : 1.62255e-02 	 Enc : 3.46322e-03 	 AE : 1.19190e-04 	 MSE : 3.56618e-01
Training Epoch 254 finished, took current epoch 495.09s, cumulative time 121009.98s
Current Learning rate DEQ : 6.920643600499994e-05
Current Learning rate AUTOENC : 0.00013841287200999988
Epoch 255, 25% 	 Loss : 2.4062e-02 	 Res : 3.8131e-03 	 Jac : 1.6192e-02 	 Enc : 3.4536e-03 	 AEnc : 1.2554e-04 	 MSE : 4.7802e-01
Epoch 255, 50% 	 Loss : 2.3529e-02 	 Res : 3.5468e-03 	 Jac : 1.6110e-02 	 Enc : 3.4642e-03 	 AEnc : 1.1073e-04 	 MSE : 2.9714e-01
Epoch 255, 75% 	 Loss : 2.3752e-02 	 Res : 3.6523e-03 	 Jac : 1.6220e-02 	 Enc : 3.4474e-03 	 AEnc : 1.0694e-04 	 MSE : 3.2496e-01
Training Epoch 255 : 	 Train : 2.37782e-02 	 Res : 3.66727e-03 	 Jac : 1.61787e-02 	 Enc : 3.45048e-03 	 AE : 1.15764e-04 	 MSE : 3.65885e-01
Validation Epoch 255 : 	 Train : 2.38212e-02 	 Res : 3.61617e-03 	 Jac : 1.61725e-02 	 Enc : 3.44234e-03 	 AE : 9.48795e-05 	 MSE : 4.95331e-01
Training Epoch 255 finished, took current epoch 490.33s, cumulative time 121500.29s
Current Learning rate DEQ : 6.920643600499994e-05
Current Learning rate AUTOENC : 0.00013841287200999988
MODEL SAVED
Epoch 256, 25% 	 Loss : 2.5003e-02 	 Res : 4.1265e-03 	 Jac : 1.6232e-02 	 Enc : 3.4778e-03 	 AEnc : 3.2900e-04 	 MSE : 8.3795e-01
Epoch 256, 50% 	 Loss : 2.4033e-02 	 Res : 3.7562e-03 	 Jac : 1.6195e-02 	 Enc : 3.4496e-03 	 AEnc : 1.5746e-04 	 MSE : 4.7435e-01
Epoch 256, 75% 	 Loss : 2.3980e-02 	 Res : 3.7965e-03 	 Jac : 1.6131e-02 	 Enc : 3.4406e-03 	 AEnc : 1.0518e-04 	 MSE : 5.0626e-01
Training Epoch 256 : 	 Train : 2.43547e-02 	 Res : 3.92983e-03 	 Jac : 1.61653e-02 	 Enc : 3.45186e-03 	 AE : 1.77930e-04 	 MSE : 6.29799e-01
Validation Epoch 256 : 	 Train : 2.37055e-02 	 Res : 3.61138e-03 	 Jac : 1.61846e-02 	 Enc : 3.46184e-03 	 AE : 1.43562e-04 	 MSE : 3.04104e-01
Training Epoch 256 finished, took current epoch 494.38s, cumulative time 121994.64s
Current Learning rate DEQ : 6.920643600499994e-05
Current Learning rate AUTOENC : 0.00013841287200999988
MODEL SAVED
Epoch 257, 25% 	 Loss : 2.4047e-02 	 Res : 3.7826e-03 	 Jac : 1.6140e-02 	 Enc : 3.4599e-03 	 AEnc : 2.3271e-04 	 MSE : 4.3163e-01
Epoch 257, 50% 	 Loss : 2.4380e-02 	 Res : 3.9921e-03 	 Jac : 1.6120e-02 	 Enc : 3.4467e-03 	 AEnc : 2.8680e-04 	 MSE : 5.3440e-01
Epoch 257, 75% 	 Loss : 2.3767e-02 	 Res : 3.6816e-03 	 Jac : 1.6127e-02 	 Enc : 3.4508e-03 	 AEnc : 1.3442e-04 	 MSE : 3.7285e-01
Training Epoch 257 : 	 Train : 2.41630e-02 	 Res : 3.86023e-03 	 Jac : 1.61457e-02 	 Enc : 3.44913e-03 	 AE : 2.09726e-04 	 MSE : 4.98134e-01
Validation Epoch 257 : 	 Train : 2.38023e-02 	 Res : 3.53203e-03 	 Jac : 1.62530e-02 	 Enc : 3.44778e-03 	 AE : 2.79077e-04 	 MSE : 2.90444e-01
Training Epoch 257 finished, took current epoch 501.54s, cumulative time 122496.16s
Current Learning rate DEQ : 6.920643600499994e-05
Current Learning rate AUTOENC : 0.00013841287200999988
MODEL SAVED
Epoch 258, 25% 	 Loss : 2.5080e-02 	 Res : 4.2041e-03 	 Jac : 1.6241e-02 	 Enc : 3.4304e-03 	 AEnc : 2.1169e-04 	 MSE : 9.9265e-01
Epoch 258, 50% 	 Loss : 2.4589e-02 	 Res : 3.9692e-03 	 Jac : 1.6181e-02 	 Enc : 3.4440e-03 	 AEnc : 2.2474e-04 	 MSE : 7.7009e-01
Epoch 258, 75% 	 Loss : 2.4128e-02 	 Res : 3.8346e-03 	 Jac : 1.6204e-02 	 Enc : 3.4555e-03 	 AEnc : 1.4421e-04 	 MSE : 4.8950e-01
Training Epoch 258 : 	 Train : 2.44775e-02 	 Res : 3.93932e-03 	 Jac : 1.62320e-02 	 Enc : 3.44643e-03 	 AE : 1.74632e-04 	 MSE : 6.85098e-01
Validation Epoch 258 : 	 Train : 2.45510e-02 	 Res : 4.02561e-03 	 Jac : 1.61681e-02 	 Enc : 3.42940e-03 	 AE : 9.84506e-05 	 MSE : 8.29451e-01
Training Epoch 258 finished, took current epoch 492.89s, cumulative time 122989.04s
Current Learning rate DEQ : 6.920643600499994e-05
Current Learning rate AUTOENC : 0.00013841287200999988
Epoch 259, 25% 	 Loss : 2.4611e-02 	 Res : 4.0999e-03 	 Jac : 1.6144e-02 	 Enc : 3.4377e-03 	 AEnc : 1.1525e-04 	 MSE : 8.1426e-01
Epoch 259, 50% 	 Loss : 2.3789e-02 	 Res : 3.7197e-03 	 Jac : 1.6061e-02 	 Enc : 3.4480e-03 	 AEnc : 1.2388e-04 	 MSE : 4.3712e-01
Epoch 259, 75% 	 Loss : 2.4077e-02 	 Res : 3.8185e-03 	 Jac : 1.6109e-02 	 Enc : 3.4688e-03 	 AEnc : 1.3967e-04 	 MSE : 5.4010e-01
Training Epoch 259 : 	 Train : 2.41137e-02 	 Res : 3.84284e-03 	 Jac : 1.61504e-02 	 Enc : 3.44898e-03 	 AE : 1.26327e-04 	 MSE : 5.45185e-01
Validation Epoch 259 : 	 Train : 2.37467e-02 	 Res : 3.67239e-03 	 Jac : 1.62327e-02 	 Enc : 3.44944e-03 	 AE : 1.03213e-04 	 MSE : 2.88957e-01
Training Epoch 259 finished, took current epoch 507.80s, cumulative time 123496.81s
Current Learning rate DEQ : 4.844450520349996e-05
Current Learning rate AUTOENC : 9.688901040699991e-05
Epoch 260, 25% 	 Loss : 2.3843e-02 	 Res : 3.7096e-03 	 Jac : 1.6086e-02 	 Enc : 3.4508e-03 	 AEnc : 1.9664e-04 	 MSE : 3.9924e-01
Epoch 260, 50% 	 Loss : 2.4263e-02 	 Res : 3.7696e-03 	 Jac : 1.6172e-02 	 Enc : 3.4293e-03 	 AEnc : 4.6389e-04 	 MSE : 4.2858e-01
Epoch 260, 75% 	 Loss : 2.4188e-02 	 Res : 3.9390e-03 	 Jac : 1.6210e-02 	 Enc : 3.4491e-03 	 AEnc : 2.3318e-04 	 MSE : 3.5679e-01
Training Epoch 260 : 	 Train : 2.43808e-02 	 Res : 4.00538e-03 	 Jac : 1.61431e-02 	 Enc : 3.44827e-03 	 AE : 3.51959e-04 	 MSE : 4.32113e-01
Validation Epoch 260 : 	 Train : 2.59667e-02 	 Res : 4.70902e-03 	 Jac : 1.61898e-02 	 Enc : 3.44797e-03 	 AE : 1.34500e-03 	 MSE : 2.74943e-01
Training Epoch 260 finished, took current epoch 489.67s, cumulative time 123986.47s
Current Learning rate DEQ : 4.844450520349996e-05
Current Learning rate AUTOENC : 9.688901040699991e-05
Epoch 261, 25% 	 Loss : 2.4963e-02 	 Res : 4.1822e-03 	 Jac : 1.6249e-02 	 Enc : 3.4461e-03 	 AEnc : 2.9854e-04 	 MSE : 7.8718e-01
Epoch 261, 50% 	 Loss : 2.3951e-02 	 Res : 3.7139e-03 	 Jac : 1.6202e-02 	 Enc : 3.4457e-03 	 AEnc : 1.1801e-04 	 MSE : 4.7057e-01
Epoch 261, 75% 	 Loss : 2.4504e-02 	 Res : 3.9931e-03 	 Jac : 1.6236e-02 	 Enc : 3.4583e-03 	 AEnc : 1.0566e-04 	 MSE : 7.1032e-01
Training Epoch 261 : 	 Train : 2.43874e-02 	 Res : 3.90844e-03 	 Jac : 1.62313e-02 	 Enc : 3.44637e-03 	 AE : 1.57616e-04 	 MSE : 6.43658e-01
Validation Epoch 261 : 	 Train : 2.34461e-02 	 Res : 3.52966e-03 	 Jac : 1.60851e-02 	 Enc : 3.45448e-03 	 AE : 1.03521e-04 	 MSE : 2.73292e-01
Training Epoch 261 finished, took current epoch 493.12s, cumulative time 124479.52s
Current Learning rate DEQ : 4.844450520349996e-05
Current Learning rate AUTOENC : 9.688901040699991e-05
MODEL SAVED
Epoch 262, 25% 	 Loss : 2.4015e-02 	 Res : 3.7182e-03 	 Jac : 1.6248e-02 	 Enc : 3.4405e-03 	 AEnc : 1.1016e-04 	 MSE : 4.9835e-01
Epoch 262, 50% 	 Loss : 2.4244e-02 	 Res : 3.9898e-03 	 Jac : 1.6054e-02 	 Enc : 3.4416e-03 	 AEnc : 1.0173e-04 	 MSE : 6.5684e-01
Epoch 262, 75% 	 Loss : 2.4038e-02 	 Res : 3.7433e-03 	 Jac : 1.6096e-02 	 Enc : 3.4575e-03 	 AEnc : 2.6489e-04 	 MSE : 4.7584e-01
Training Epoch 262 : 	 Train : 2.39815e-02 	 Res : 3.77336e-03 	 Jac : 1.61214e-02 	 Enc : 3.44771e-03 	 AE : 1.55016e-04 	 MSE : 4.83983e-01
Validation Epoch 262 : 	 Train : 2.35114e-02 	 Res : 3.56955e-03 	 Jac : 1.61530e-02 	 Enc : 3.45000e-03 	 AE : 9.57257e-05 	 MSE : 2.43172e-01
Training Epoch 262 finished, took current epoch 502.54s, cumulative time 124982.04s
Current Learning rate DEQ : 4.844450520349996e-05
Current Learning rate AUTOENC : 9.688901040699991e-05
Epoch 263, 25% 	 Loss : 2.3841e-02 	 Res : 3.6983e-03 	 Jac : 1.6116e-02 	 Enc : 3.4433e-03 	 AEnc : 1.2329e-04 	 MSE : 4.5982e-01
Epoch 263, 50% 	 Loss : 2.4086e-02 	 Res : 3.7511e-03 	 Jac : 1.6237e-02 	 Enc : 3.4355e-03 	 AEnc : 1.1460e-04 	 MSE : 5.4733e-01
Epoch 263, 75% 	 Loss : 2.3977e-02 	 Res : 3.7363e-03 	 Jac : 1.6251e-02 	 Enc : 3.4352e-03 	 AEnc : 1.3076e-04 	 MSE : 4.2329e-01
Training Epoch 263 : 	 Train : 2.38957e-02 	 Res : 3.71176e-03 	 Jac : 1.61686e-02 	 Enc : 3.44331e-03 	 AE : 1.22235e-04 	 MSE : 4.49865e-01
Validation Epoch 263 : 	 Train : 2.37328e-02 	 Res : 3.65852e-03 	 Jac : 1.60516e-02 	 Enc : 3.45745e-03 	 AE : 1.07443e-04 	 MSE : 4.57764e-01
Training Epoch 263 finished, took current epoch 504.60s, cumulative time 125486.59s
Current Learning rate DEQ : 4.844450520349996e-05
Current Learning rate AUTOENC : 9.688901040699991e-05
Epoch 264, 25% 	 Loss : 2.3632e-02 	 Res : 3.5448e-03 	 Jac : 1.6157e-02 	 Enc : 3.4498e-03 	 AEnc : 1.1195e-04 	 MSE : 3.6847e-01
Epoch 264, 50% 	 Loss : 2.3681e-02 	 Res : 3.6170e-03 	 Jac : 1.6170e-02 	 Enc : 3.4215e-03 	 AEnc : 1.0748e-04 	 MSE : 3.6509e-01
Epoch 264, 75% 	 Loss : 2.4083e-02 	 Res : 3.8965e-03 	 Jac : 1.6174e-02 	 Enc : 3.4405e-03 	 AEnc : 1.0485e-04 	 MSE : 4.6731e-01
Training Epoch 264 : 	 Train : 2.38145e-02 	 Res : 3.69360e-03 	 Jac : 1.61765e-02 	 Enc : 3.44240e-03 	 AE : 1.08735e-04 	 MSE : 3.93282e-01
Validation Epoch 264 : 	 Train : 2.41417e-02 	 Res : 3.77582e-03 	 Jac : 1.60925e-02 	 Enc : 3.44707e-03 	 AE : 1.16425e-04 	 MSE : 7.09842e-01
Training Epoch 264 finished, took current epoch 497.16s, cumulative time 125983.74s
Current Learning rate DEQ : 4.844450520349996e-05
Current Learning rate AUTOENC : 9.688901040699991e-05
Epoch 265, 25% 	 Loss : 2.3740e-02 	 Res : 3.6218e-03 	 Jac : 1.6134e-02 	 Enc : 3.4474e-03 	 AEnc : 1.1537e-04 	 MSE : 4.2100e-01
Epoch 265, 50% 	 Loss : 2.3898e-02 	 Res : 3.6897e-03 	 Jac : 1.6196e-02 	 Enc : 3.4487e-03 	 AEnc : 1.2491e-04 	 MSE : 4.3873e-01
Epoch 265, 75% 	 Loss : 2.3874e-02 	 Res : 3.7984e-03 	 Jac : 1.6088e-02 	 Enc : 3.4308e-03 	 AEnc : 1.1664e-04 	 MSE : 4.4001e-01
Training Epoch 265 : 	 Train : 2.38078e-02 	 Res : 3.70143e-03 	 Jac : 1.61169e-02 	 Enc : 3.44409e-03 	 AE : 1.17015e-04 	 MSE : 4.28347e-01
Validation Epoch 265 : 	 Train : 2.37304e-02 	 Res : 3.62081e-03 	 Jac : 1.60754e-02 	 Enc : 3.43064e-03 	 AE : 1.13297e-04 	 MSE : 4.90298e-01
Training Epoch 265 finished, took current epoch 479.64s, cumulative time 126463.36s
Current Learning rate DEQ : 4.844450520349996e-05
Current Learning rate AUTOENC : 9.688901040699991e-05
Epoch 266, 25% 	 Loss : 2.3633e-02 	 Res : 3.5699e-03 	 Jac : 1.6155e-02 	 Enc : 3.4313e-03 	 AEnc : 1.0720e-04 	 MSE : 3.6973e-01
Epoch 266, 50% 	 Loss : 2.3624e-02 	 Res : 3.5731e-03 	 Jac : 1.6119e-02 	 Enc : 3.4433e-03 	 AEnc : 1.1632e-04 	 MSE : 3.7245e-01
Epoch 266, 75% 	 Loss : 2.3982e-02 	 Res : 3.8063e-03 	 Jac : 1.6118e-02 	 Enc : 3.4463e-03 	 AEnc : 1.1166e-04 	 MSE : 4.9950e-01
Training Epoch 266 : 	 Train : 2.39540e-02 	 Res : 3.73846e-03 	 Jac : 1.61513e-02 	 Enc : 3.44133e-03 	 AE : 1.11923e-04 	 MSE : 5.10995e-01
Validation Epoch 266 : 	 Train : 2.54330e-02 	 Res : 4.44493e-03 	 Jac : 1.59356e-02 	 Enc : 3.46569e-03 	 AE : 1.15876e-04 	 MSE : 1.47090e+00
Training Epoch 266 finished, took current epoch 484.77s, cumulative time 126948.13s
Current Learning rate DEQ : 4.844450520349996e-05
Current Learning rate AUTOENC : 9.688901040699991e-05
Epoch 267, 25% 	 Loss : 2.5068e-02 	 Res : 4.2737e-03 	 Jac : 1.6115e-02 	 Enc : 3.4404e-03 	 AEnc : 9.5280e-05 	 MSE : 1.1431e+00
Epoch 267, 50% 	 Loss : 2.4142e-02 	 Res : 3.8764e-03 	 Jac : 1.6168e-02 	 Enc : 3.4609e-03 	 AEnc : 1.2797e-04 	 MSE : 5.0817e-01
Epoch 267, 75% 	 Loss : 2.3555e-02 	 Res : 3.6086e-03 	 Jac : 1.6093e-02 	 Enc : 3.4451e-03 	 AEnc : 1.0198e-04 	 MSE : 3.0669e-01
Training Epoch 267 : 	 Train : 2.40598e-02 	 Res : 3.82825e-03 	 Jac : 1.61196e-02 	 Enc : 3.44326e-03 	 AE : 1.10723e-04 	 MSE : 5.58001e-01
Validation Epoch 267 : 	 Train : 2.35013e-02 	 Res : 3.56083e-03 	 Jac : 1.59869e-02 	 Enc : 3.45224e-03 	 AE : 1.20438e-04 	 MSE : 3.80801e-01
Training Epoch 267 finished, took current epoch 495.56s, cumulative time 127443.67s
Current Learning rate DEQ : 4.844450520349996e-05
Current Learning rate AUTOENC : 9.688901040699991e-05
Epoch 268, 25% 	 Loss : 2.4254e-02 	 Res : 3.8684e-03 	 Jac : 1.6159e-02 	 Enc : 3.4393e-03 	 AEnc : 1.1231e-04 	 MSE : 6.7448e-01
Epoch 268, 50% 	 Loss : 2.3654e-02 	 Res : 3.6406e-03 	 Jac : 1.6110e-02 	 Enc : 3.4469e-03 	 AEnc : 1.0637e-04 	 MSE : 3.5004e-01
Epoch 268, 75% 	 Loss : 2.3789e-02 	 Res : 3.6536e-03 	 Jac : 1.6169e-02 	 Enc : 3.4374e-03 	 AEnc : 1.0422e-04 	 MSE : 4.2383e-01
Training Epoch 268 : 	 Train : 2.38351e-02 	 Res : 3.69208e-03 	 Jac : 1.61385e-02 	 Enc : 3.44279e-03 	 AE : 1.07673e-04 	 MSE : 4.54050e-01
Validation Epoch 268 : 	 Train : 2.35555e-02 	 Res : 3.50796e-03 	 Jac : 1.61859e-02 	 Enc : 3.43344e-03 	 AE : 1.05711e-04 	 MSE : 3.22498e-01
Training Epoch 268 finished, took current epoch 490.98s, cumulative time 127934.63s
Current Learning rate DEQ : 4.844450520349996e-05
Current Learning rate AUTOENC : 9.688901040699991e-05
MODEL SAVED
Epoch 269, 25% 	 Loss : 2.3541e-02 	 Res : 3.5099e-03 	 Jac : 1.6151e-02 	 Enc : 3.4322e-03 	 AEnc : 1.0082e-04 	 MSE : 3.4712e-01
Epoch 269, 50% 	 Loss : 2.3642e-02 	 Res : 3.5631e-03 	 Jac : 1.6164e-02 	 Enc : 3.4371e-03 	 AEnc : 1.0582e-04 	 MSE : 3.7218e-01
Epoch 269, 75% 	 Loss : 2.3883e-02 	 Res : 3.7867e-03 	 Jac : 1.6099e-02 	 Enc : 3.4633e-03 	 AEnc : 1.2274e-04 	 MSE : 4.1146e-01
Training Epoch 269 : 	 Train : 2.36704e-02 	 Res : 3.61760e-03 	 Jac : 1.61260e-02 	 Enc : 3.44212e-03 	 AE : 1.12508e-04 	 MSE : 3.72151e-01
Validation Epoch 269 : 	 Train : 2.35594e-02 	 Res : 3.59424e-03 	 Jac : 1.60631e-02 	 Enc : 3.45037e-03 	 AE : 1.08054e-04 	 MSE : 3.43732e-01
Training Epoch 269 finished, took current epoch 497.46s, cumulative time 128432.06s
Current Learning rate DEQ : 4.844450520349996e-05
Current Learning rate AUTOENC : 9.688901040699991e-05
Epoch 270, 25% 	 Loss : 2.3595e-02 	 Res : 3.5482e-03 	 Jac : 1.6149e-02 	 Enc : 3.4370e-03 	 AEnc : 1.1024e-04 	 MSE : 3.5150e-01
Epoch 270, 50% 	 Loss : 2.3832e-02 	 Res : 3.6921e-03 	 Jac : 1.6211e-02 	 Enc : 3.4348e-03 	 AEnc : 1.0142e-04 	 MSE : 3.9231e-01
Epoch 270, 75% 	 Loss : 2.3841e-02 	 Res : 3.6616e-03 	 Jac : 1.6167e-02 	 Enc : 3.4474e-03 	 AEnc : 1.3991e-04 	 MSE : 4.2492e-01
Training Epoch 270 : 	 Train : 2.37323e-02 	 Res : 3.64634e-03 	 Jac : 1.61511e-02 	 Enc : 3.43982e-03 	 AE : 1.18542e-04 	 MSE : 3.76456e-01
Validation Epoch 270 : 	 Train : 2.33488e-02 	 Res : 3.48142e-03 	 Jac : 1.60616e-02 	 Enc : 3.43858e-03 	 AE : 9.41249e-05 	 MSE : 2.73071e-01
Training Epoch 270 finished, took current epoch 496.43s, cumulative time 128928.47s
Current Learning rate DEQ : 4.844450520349996e-05
Current Learning rate AUTOENC : 9.688901040699991e-05
MODEL SAVED
Epoch 271, 25% 	 Loss : 2.3696e-02 	 Res : 3.6548e-03 	 Jac : 1.6094e-02 	 Enc : 3.4411e-03 	 AEnc : 1.1216e-04 	 MSE : 3.9423e-01
Epoch 271, 50% 	 Loss : 2.3839e-02 	 Res : 3.6654e-03 	 Jac : 1.6123e-02 	 Enc : 3.4457e-03 	 AEnc : 1.8113e-04 	 MSE : 4.2331e-01
Epoch 271, 75% 	 Loss : 2.3748e-02 	 Res : 3.6057e-03 	 Jac : 1.6241e-02 	 Enc : 3.4219e-03 	 AEnc : 1.4604e-04 	 MSE : 3.3401e-01
Training Epoch 271 : 	 Train : 2.38978e-02 	 Res : 3.67151e-03 	 Jac : 1.61778e-02 	 Enc : 3.44049e-03 	 AE : 1.81228e-04 	 MSE : 4.26749e-01
Validation Epoch 271 : 	 Train : 2.39774e-02 	 Res : 3.63795e-03 	 Jac : 1.61026e-02 	 Enc : 3.45170e-03 	 AE : 5.21252e-04 	 MSE : 2.63894e-01
Training Epoch 271 finished, took current epoch 493.15s, cumulative time 129421.61s
Current Learning rate DEQ : 4.844450520349996e-05
Current Learning rate AUTOENC : 9.688901040699991e-05
Epoch 272, 25% 	 Loss : 2.4483e-02 	 Res : 3.8330e-03 	 Jac : 1.6132e-02 	 Enc : 3.4309e-03 	 AEnc : 6.5711e-04 	 MSE : 4.3069e-01
Epoch 272, 50% 	 Loss : 2.5160e-02 	 Res : 3.9704e-03 	 Jac : 1.6054e-02 	 Enc : 3.4514e-03 	 AEnc : 1.1125e-03 	 MSE : 5.7216e-01
Epoch 272, 75% 	 Loss : 2.4259e-02 	 Res : 3.9074e-03 	 Jac : 1.6086e-02 	 Enc : 3.4374e-03 	 AEnc : 1.8534e-04 	 MSE : 6.4241e-01
Training Epoch 272 : 	 Train : 2.44319e-02 	 Res : 3.84728e-03 	 Jac : 1.60958e-02 	 Enc : 3.43957e-03 	 AE : 5.22759e-04 	 MSE : 5.26469e-01
Validation Epoch 272 : 	 Train : 2.43795e-02 	 Res : 4.08435e-03 	 Jac : 1.62211e-02 	 Enc : 3.44878e-03 	 AE : 9.35068e-05 	 MSE : 5.31796e-01
Training Epoch 272 finished, took current epoch 512.32s, cumulative time 129933.92s
Current Learning rate DEQ : 4.844450520349996e-05
Current Learning rate AUTOENC : 9.688901040699991e-05
Epoch 273, 25% 	 Loss : 2.4093e-02 	 Res : 3.8265e-03 	 Jac : 1.6109e-02 	 Enc : 3.4440e-03 	 AEnc : 1.0145e-04 	 MSE : 6.1236e-01
Epoch 273, 50% 	 Loss : 2.4001e-02 	 Res : 3.6612e-03 	 Jac : 1.6262e-02 	 Enc : 3.4142e-03 	 AEnc : 9.3520e-05 	 MSE : 5.7001e-01
Epoch 273, 75% 	 Loss : 2.3792e-02 	 Res : 3.7183e-03 	 Jac : 1.6085e-02 	 Enc : 3.4473e-03 	 AEnc : 1.6259e-04 	 MSE : 3.7836e-01
Training Epoch 273 : 	 Train : 2.39744e-02 	 Res : 3.76834e-03 	 Jac : 1.61464e-02 	 Enc : 3.43731e-03 	 AE : 1.41114e-04 	 MSE : 4.81228e-01
Validation Epoch 273 : 	 Train : 2.51979e-02 	 Res : 4.60124e-03 	 Jac : 1.61510e-02 	 Enc : 3.41775e-03 	 AE : 7.67885e-05 	 MSE : 9.51097e-01
Training Epoch 273 finished, took current epoch 493.30s, cumulative time 130427.22s
Current Learning rate DEQ : 4.844450520349996e-05
Current Learning rate AUTOENC : 9.688901040699991e-05
Epoch 274, 25% 	 Loss : 2.3860e-02 	 Res : 3.6831e-03 	 Jac : 1.6193e-02 	 Enc : 3.4625e-03 	 AEnc : 1.3958e-04 	 MSE : 3.8215e-01
Epoch 274, 50% 	 Loss : 2.3628e-02 	 Res : 3.6242e-03 	 Jac : 1.6063e-02 	 Enc : 3.4522e-03 	 AEnc : 1.3756e-04 	 MSE : 3.5133e-01
Epoch 274, 75% 	 Loss : 2.3565e-02 	 Res : 3.5115e-03 	 Jac : 1.6150e-02 	 Enc : 3.4221e-03 	 AEnc : 1.0970e-04 	 MSE : 3.7151e-01
Training Epoch 274 : 	 Train : 2.36780e-02 	 Res : 3.62291e-03 	 Jac : 1.61252e-02 	 Enc : 3.43792e-03 	 AE : 1.22561e-04 	 MSE : 3.69412e-01
Validation Epoch 274 : 	 Train : 2.36583e-02 	 Res : 3.58193e-03 	 Jac : 1.61459e-02 	 Enc : 3.44656e-03 	 AE : 1.07936e-04 	 MSE : 3.75987e-01
Training Epoch 274 finished, took current epoch 486.09s, cumulative time 130913.30s
Current Learning rate DEQ : 4.844450520349996e-05
Current Learning rate AUTOENC : 9.688901040699991e-05
Epoch 275, 25% 	 Loss : 2.3601e-02 	 Res : 3.5870e-03 	 Jac : 1.6115e-02 	 Enc : 3.4326e-03 	 AEnc : 1.1494e-04 	 MSE : 3.5238e-01
Epoch 275, 50% 	 Loss : 2.3798e-02 	 Res : 3.6901e-03 	 Jac : 1.6147e-02 	 Enc : 3.4311e-03 	 AEnc : 1.1560e-04 	 MSE : 4.1437e-01
Epoch 275, 75% 	 Loss : 2.4763e-02 	 Res : 4.2371e-03 	 Jac : 1.6183e-02 	 Enc : 3.4360e-03 	 AEnc : 1.0676e-04 	 MSE : 8.0066e-01
Training Epoch 275 : 	 Train : 2.39268e-02 	 Res : 3.77410e-03 	 Jac : 1.61299e-02 	 Enc : 3.43902e-03 	 AE : 1.14749e-04 	 MSE : 4.69058e-01
Validation Epoch 275 : 	 Train : 2.37641e-02 	 Res : 3.63707e-03 	 Jac : 1.62078e-02 	 Enc : 3.45431e-03 	 AE : 1.25786e-04 	 MSE : 3.39111e-01
Training Epoch 275 finished, took current epoch 504.68s, cumulative time 131417.96s
Current Learning rate DEQ : 4.844450520349996e-05
Current Learning rate AUTOENC : 9.688901040699991e-05
Epoch 276, 25% 	 Loss : 2.3592e-02 	 Res : 3.5400e-03 	 Jac : 1.6173e-02 	 Enc : 3.4326e-03 	 AEnc : 1.3672e-04 	 MSE : 3.0932e-01
Epoch 276, 50% 	 Loss : 2.3577e-02 	 Res : 3.5709e-03 	 Jac : 1.6095e-02 	 Enc : 3.4404e-03 	 AEnc : 1.3322e-04 	 MSE : 3.3734e-01
Epoch 276, 75% 	 Loss : 2.3634e-02 	 Res : 3.5580e-03 	 Jac : 1.6209e-02 	 Enc : 3.4325e-03 	 AEnc : 1.0514e-04 	 MSE : 3.2910e-01
Training Epoch 276 : 	 Train : 2.36095e-02 	 Res : 3.58784e-03 	 Jac : 1.61206e-02 	 Enc : 3.43709e-03 	 AE : 1.22933e-04 	 MSE : 3.41100e-01
Validation Epoch 276 : 	 Train : 2.33764e-02 	 Res : 3.52996e-03 	 Jac : 1.60953e-02 	 Enc : 3.43851e-03 	 AE : 8.87263e-05 	 MSE : 2.23866e-01
Training Epoch 276 finished, took current epoch 500.79s, cumulative time 131918.74s
Current Learning rate DEQ : 4.844450520349996e-05
Current Learning rate AUTOENC : 9.688901040699991e-05
Epoch 277, 25% 	 Loss : 2.3900e-02 	 Res : 3.6697e-03 	 Jac : 1.6177e-02 	 Enc : 3.4297e-03 	 AEnc : 1.5094e-04 	 MSE : 4.7220e-01
Epoch 277, 50% 	 Loss : 2.3974e-02 	 Res : 3.6917e-03 	 Jac : 1.6232e-02 	 Enc : 3.4454e-03 	 AEnc : 1.4215e-04 	 MSE : 4.6287e-01
Epoch 277, 75% 	 Loss : 2.3911e-02 	 Res : 3.6989e-03 	 Jac : 1.6143e-02 	 Enc : 3.4194e-03 	 AEnc : 1.0930e-04 	 MSE : 5.4002e-01
Training Epoch 277 : 	 Train : 2.40860e-02 	 Res : 3.79646e-03 	 Jac : 1.61538e-02 	 Enc : 3.43530e-03 	 AE : 1.29515e-04 	 MSE : 5.70908e-01
Validation Epoch 277 : 	 Train : 2.39499e-02 	 Res : 3.73314e-03 	 Jac : 1.61399e-02 	 Enc : 3.45320e-03 	 AE : 9.81404e-05 	 MSE : 5.25506e-01
Training Epoch 277 finished, took current epoch 501.73s, cumulative time 132420.46s
Current Learning rate DEQ : 4.844450520349996e-05
Current Learning rate AUTOENC : 9.688901040699991e-05
Epoch 278, 25% 	 Loss : 2.4911e-02 	 Res : 4.1613e-03 	 Jac : 1.6186e-02 	 Enc : 3.4490e-03 	 AEnc : 1.1246e-04 	 MSE : 1.0021e+00
Epoch 278, 50% 	 Loss : 2.4695e-02 	 Res : 4.1586e-03 	 Jac : 1.6120e-02 	 Enc : 3.4438e-03 	 AEnc : 1.0331e-04 	 MSE : 8.6926e-01
Epoch 278, 75% 	 Loss : 2.3648e-02 	 Res : 3.5878e-03 	 Jac : 1.6114e-02 	 Enc : 3.4309e-03 	 AEnc : 1.0035e-04 	 MSE : 4.1524e-01
Training Epoch 278 : 	 Train : 2.43299e-02 	 Res : 3.92706e-03 	 Jac : 1.61351e-02 	 Enc : 3.43695e-03 	 AE : 1.02001e-04 	 MSE : 7.28727e-01
Validation Epoch 278 : 	 Train : 2.40591e-02 	 Res : 3.77184e-03 	 Jac : 1.62227e-02 	 Enc : 3.42687e-03 	 AE : 8.43292e-05 	 MSE : 5.53309e-01
Training Epoch 278 finished, took current epoch 501.85s, cumulative time 132922.30s
Current Learning rate DEQ : 4.844450520349996e-05
Current Learning rate AUTOENC : 9.688901040699991e-05
Epoch 279, 25% 	 Loss : 2.3802e-02 	 Res : 3.6842e-03 	 Jac : 1.6136e-02 	 Enc : 3.4286e-03 	 AEnc : 1.0495e-04 	 MSE : 4.4813e-01
Epoch 279, 50% 	 Loss : 2.3618e-02 	 Res : 3.5418e-03 	 Jac : 1.6152e-02 	 Enc : 3.4221e-03 	 AEnc : 9.9961e-05 	 MSE : 4.0258e-01
Epoch 279, 75% 	 Loss : 2.3526e-02 	 Res : 3.5416e-03 	 Jac : 1.6088e-02 	 Enc : 3.4576e-03 	 AEnc : 9.6409e-05 	 MSE : 3.4278e-01
Training Epoch 279 : 	 Train : 2.36224e-02 	 Res : 3.59591e-03 	 Jac : 1.61002e-02 	 Enc : 3.43459e-03 	 AE : 9.92309e-05 	 MSE : 3.92419e-01
Validation Epoch 279 : 	 Train : 2.35360e-02 	 Res : 3.55047e-03 	 Jac : 1.61171e-02 	 Enc : 3.44912e-03 	 AE : 9.28666e-05 	 MSE : 3.26408e-01
Training Epoch 279 finished, took current epoch 490.26s, cumulative time 133412.54s
Current Learning rate DEQ : 4.844450520349996e-05
Current Learning rate AUTOENC : 9.688901040699991e-05
Epoch 280, 25% 	 Loss : 2.3558e-02 	 Res : 3.5809e-03 	 Jac : 1.6082e-02 	 Enc : 3.4368e-03 	 AEnc : 1.0222e-04 	 MSE : 3.5612e-01
Epoch 280, 50% 	 Loss : 2.4716e-02 	 Res : 4.1288e-03 	 Jac : 1.6033e-02 	 Enc : 3.4305e-03 	 AEnc : 9.7355e-05 	 MSE : 1.0264e+00
Epoch 280, 75% 	 Loss : 2.3670e-02 	 Res : 3.6283e-03 	 Jac : 1.6100e-02 	 Enc : 3.4589e-03 	 AEnc : 1.1558e-04 	 MSE : 3.6719e-01
Training Epoch 280 : 	 Train : 2.38836e-02 	 Res : 3.72124e-03 	 Jac : 1.60955e-02 	 Enc : 3.43754e-03 	 AE : 1.03458e-04 	 MSE : 5.25863e-01
Validation Epoch 280 : 	 Train : 2.35618e-02 	 Res : 3.56532e-03 	 Jac : 1.60128e-02 	 Enc : 3.43844e-03 	 AE : 1.04257e-04 	 MSE : 4.41000e-01
Training Epoch 280 finished, took current epoch 497.27s, cumulative time 133909.79s
Current Learning rate DEQ : 4.844450520349996e-05
Current Learning rate AUTOENC : 9.688901040699991e-05
Epoch 281, 25% 	 Loss : 2.3393e-02 	 Res : 3.5350e-03 	 Jac : 1.6023e-02 	 Enc : 3.4404e-03 	 AEnc : 1.0501e-04 	 MSE : 2.8967e-01
Epoch 281, 50% 	 Loss : 2.3630e-02 	 Res : 3.6316e-03 	 Jac : 1.6036e-02 	 Enc : 3.4400e-03 	 AEnc : 1.2674e-04 	 MSE : 3.9551e-01
Epoch 281, 75% 	 Loss : 2.3480e-02 	 Res : 3.5158e-03 	 Jac : 1.6138e-02 	 Enc : 3.4283e-03 	 AEnc : 1.0318e-04 	 MSE : 2.9426e-01
Training Epoch 281 : 	 Train : 2.35310e-02 	 Res : 3.57097e-03 	 Jac : 1.60826e-02 	 Enc : 3.43458e-03 	 AE : 1.12203e-04 	 MSE : 3.30600e-01
Validation Epoch 281 : 	 Train : 2.34173e-02 	 Res : 3.49577e-03 	 Jac : 1.61213e-02 	 Enc : 3.42529e-03 	 AE : 8.55884e-05 	 MSE : 2.89355e-01
Training Epoch 281 finished, took current epoch 489.29s, cumulative time 134399.07s
Current Learning rate DEQ : 3.391115364244997e-05
Current Learning rate AUTOENC : 6.782230728489993e-05
Epoch 282, 25% 	 Loss : 2.3336e-02 	 Res : 3.4571e-03 	 Jac : 1.6079e-02 	 Enc : 3.4374e-03 	 AEnc : 9.5290e-05 	 MSE : 2.6751e-01
Epoch 282, 50% 	 Loss : 2.3579e-02 	 Res : 3.5097e-03 	 Jac : 1.6151e-02 	 Enc : 3.4317e-03 	 AEnc : 1.0744e-04 	 MSE : 3.7888e-01
Epoch 282, 75% 	 Loss : 2.3789e-02 	 Res : 3.6616e-03 	 Jac : 1.6174e-02 	 Enc : 3.4261e-03 	 AEnc : 1.1904e-04 	 MSE : 4.0762e-01
Training Epoch 282 : 	 Train : 2.35900e-02 	 Res : 3.56654e-03 	 Jac : 1.61178e-02 	 Enc : 3.43439e-03 	 AE : 1.06770e-04 	 MSE : 3.64583e-01
Validation Epoch 282 : 	 Train : 2.37715e-02 	 Res : 3.63170e-03 	 Jac : 1.60974e-02 	 Enc : 3.44989e-03 	 AE : 9.91043e-05 	 MSE : 4.93408e-01
Training Epoch 282 finished, took current epoch 499.07s, cumulative time 134898.13s
Current Learning rate DEQ : 3.391115364244997e-05
Current Learning rate AUTOENC : 6.782230728489993e-05
Epoch 283, 25% 	 Loss : 2.3633e-02 	 Res : 3.6188e-03 	 Jac : 1.6075e-02 	 Enc : 3.4403e-03 	 AEnc : 9.9203e-05 	 MSE : 3.9915e-01
Epoch 283, 50% 	 Loss : 2.3687e-02 	 Res : 3.6520e-03 	 Jac : 1.6102e-02 	 Enc : 3.4227e-03 	 AEnc : 9.8433e-05 	 MSE : 4.1126e-01
Epoch 283, 75% 	 Loss : 2.4026e-02 	 Res : 3.8175e-03 	 Jac : 1.6085e-02 	 Enc : 3.4358e-03 	 AEnc : 1.1048e-04 	 MSE : 5.7673e-01
Training Epoch 283 : 	 Train : 2.37401e-02 	 Res : 3.67750e-03 	 Jac : 1.60789e-02 	 Enc : 3.43577e-03 	 AE : 1.05370e-04 	 MSE : 4.42596e-01
Validation Epoch 283 : 	 Train : 2.48661e-02 	 Res : 4.48712e-03 	 Jac : 1.61329e-02 	 Enc : 3.42527e-03 	 AE : 1.78051e-04 	 MSE : 6.42722e-01
Training Epoch 283 finished, took current epoch 492.85s, cumulative time 135390.96s
Current Learning rate DEQ : 3.391115364244997e-05
Current Learning rate AUTOENC : 6.782230728489993e-05
Epoch 284, 25% 	 Loss : 2.3780e-02 	 Res : 3.6941e-03 	 Jac : 1.6083e-02 	 Enc : 3.4317e-03 	 AEnc : 1.7950e-04 	 MSE : 3.9214e-01
Epoch 284, 50% 	 Loss : 2.3856e-02 	 Res : 3.6752e-03 	 Jac : 1.6082e-02 	 Enc : 3.4391e-03 	 AEnc : 1.3175e-04 	 MSE : 5.2708e-01
Epoch 284, 75% 	 Loss : 2.3917e-02 	 Res : 3.7013e-03 	 Jac : 1.6183e-02 	 Enc : 3.4302e-03 	 AEnc : 1.0989e-04 	 MSE : 4.9279e-01
Training Epoch 284 : 	 Train : 2.37658e-02 	 Res : 3.65480e-03 	 Jac : 1.61115e-02 	 Enc : 3.43357e-03 	 AE : 1.34668e-04 	 MSE : 4.31234e-01
Validation Epoch 284 : 	 Train : 2.41247e-02 	 Res : 3.93014e-03 	 Jac : 1.60701e-02 	 Enc : 3.44734e-03 	 AE : 1.03537e-04 	 MSE : 5.73622e-01
Training Epoch 284 finished, took current epoch 490.34s, cumulative time 135881.29s
Current Learning rate DEQ : 3.391115364244997e-05
Current Learning rate AUTOENC : 6.782230728489993e-05
Epoch 285, 25% 	 Loss : 2.3543e-02 	 Res : 3.6011e-03 	 Jac : 1.6082e-02 	 Enc : 3.4415e-03 	 AEnc : 1.3178e-04 	 MSE : 2.8625e-01
Epoch 285, 50% 	 Loss : 2.3564e-02 	 Res : 3.5431e-03 	 Jac : 1.6105e-02 	 Enc : 3.4444e-03 	 AEnc : 1.1917e-04 	 MSE : 3.5221e-01
Epoch 285, 75% 	 Loss : 2.3916e-02 	 Res : 3.7659e-03 	 Jac : 1.6145e-02 	 Enc : 3.4156e-03 	 AEnc : 1.0024e-04 	 MSE : 4.8947e-01
Training Epoch 285 : 	 Train : 2.36229e-02 	 Res : 3.60981e-03 	 Jac : 1.61113e-02 	 Enc : 3.43664e-03 	 AE : 1.12913e-04 	 MSE : 3.52275e-01
Validation Epoch 285 : 	 Train : 2.32067e-02 	 Res : 3.42446e-03 	 Jac : 1.60208e-02 	 Enc : 3.43483e-03 	 AE : 1.04534e-04 	 MSE : 2.22030e-01
Training Epoch 285 finished, took current epoch 494.80s, cumulative time 136376.04s
Current Learning rate DEQ : 3.391115364244997e-05
Current Learning rate AUTOENC : 6.782230728489993e-05
MODEL SAVED
Epoch 286, 25% 	 Loss : 2.3646e-02 	 Res : 3.5799e-03 	 Jac : 1.6071e-02 	 Enc : 3.4157e-03 	 AEnc : 1.1380e-04 	 MSE : 4.6536e-01
Epoch 286, 50% 	 Loss : 2.3570e-02 	 Res : 3.5952e-03 	 Jac : 1.6148e-02 	 Enc : 3.4255e-03 	 AEnc : 1.5910e-04 	 MSE : 2.4273e-01
Epoch 286, 75% 	 Loss : 2.4083e-02 	 Res : 3.9176e-03 	 Jac : 1.6119e-02 	 Enc : 3.4459e-03 	 AEnc : 2.6355e-04 	 MSE : 3.3647e-01
Training Epoch 286 : 	 Train : 2.38082e-02 	 Res : 3.74492e-03 	 Jac : 1.60939e-02 	 Enc : 3.43306e-03 	 AE : 1.71749e-04 	 MSE : 3.64556e-01
Validation Epoch 286 : 	 Train : 2.33820e-02 	 Res : 3.47186e-03 	 Jac : 1.60608e-02 	 Enc : 3.42669e-03 	 AE : 1.14947e-04 	 MSE : 3.07754e-01
Training Epoch 286 finished, took current epoch 488.23s, cumulative time 136864.26s
Current Learning rate DEQ : 3.391115364244997e-05
Current Learning rate AUTOENC : 6.782230728489993e-05
Epoch 287, 25% 	 Loss : 2.3294e-02 	 Res : 3.4754e-03 	 Jac : 1.5997e-02 	 Enc : 3.4455e-03 	 AEnc : 1.0642e-04 	 MSE : 2.6916e-01
Epoch 287, 50% 	 Loss : 2.3743e-02 	 Res : 3.6947e-03 	 Jac : 1.5999e-02 	 Enc : 3.4169e-03 	 AEnc : 9.6648e-05 	 MSE : 5.3638e-01
Epoch 287, 75% 	 Loss : 2.3340e-02 	 Res : 3.4650e-03 	 Jac : 1.6123e-02 	 Enc : 3.4182e-03 	 AEnc : 9.6268e-05 	 MSE : 2.3736e-01
Training Epoch 287 : 	 Train : 2.34671e-02 	 Res : 3.53920e-03 	 Jac : 1.60596e-02 	 Enc : 3.43327e-03 	 AE : 1.00542e-04 	 MSE : 3.34459e-01
Validation Epoch 287 : 	 Train : 2.33182e-02 	 Res : 3.40851e-03 	 Jac : 1.61405e-02 	 Enc : 3.42778e-03 	 AE : 9.22129e-05 	 MSE : 2.49166e-01
Training Epoch 287 finished, took current epoch 486.90s, cumulative time 137351.14s
Current Learning rate DEQ : 3.391115364244997e-05
Current Learning rate AUTOENC : 6.782230728489993e-05
MODEL SAVED
Epoch 288, 25% 	 Loss : 2.3629e-02 	 Res : 3.5560e-03 	 Jac : 1.6176e-02 	 Enc : 3.4242e-03 	 AEnc : 1.0694e-04 	 MSE : 3.6530e-01
Epoch 288, 50% 	 Loss : 2.3378e-02 	 Res : 3.4878e-03 	 Jac : 1.6088e-02 	 Enc : 3.4420e-03 	 AEnc : 1.0143e-04 	 MSE : 2.5853e-01
Epoch 288, 75% 	 Loss : 2.3412e-02 	 Res : 3.5270e-03 	 Jac : 1.6033e-02 	 Enc : 3.4252e-03 	 AEnc : 9.3676e-05 	 MSE : 3.3372e-01
Training Epoch 288 : 	 Train : 2.35485e-02 	 Res : 3.56751e-03 	 Jac : 1.61039e-02 	 Enc : 3.43256e-03 	 AE : 1.02534e-04 	 MSE : 3.41951e-01
Validation Epoch 288 : 	 Train : 2.38583e-02 	 Res : 3.73096e-03 	 Jac : 1.61159e-02 	 Enc : 3.45263e-03 	 AE : 1.20117e-04 	 MSE : 4.38629e-01
Training Epoch 288 finished, took current epoch 486.16s, cumulative time 137837.29s
Current Learning rate DEQ : 3.391115364244997e-05
Current Learning rate AUTOENC : 6.782230728489993e-05
Epoch 289, 25% 	 Loss : 2.3649e-02 	 Res : 3.6578e-03 	 Jac : 1.6017e-02 	 Enc : 3.4441e-03 	 AEnc : 1.0351e-04 	 MSE : 4.2647e-01
Epoch 289, 50% 	 Loss : 2.4115e-02 	 Res : 3.7965e-03 	 Jac : 1.6142e-02 	 Enc : 3.4296e-03 	 AEnc : 1.0118e-04 	 MSE : 6.4561e-01
Epoch 289, 75% 	 Loss : 2.4133e-02 	 Res : 3.7570e-03 	 Jac : 1.6157e-02 	 Enc : 3.4502e-03 	 AEnc : 1.3801e-04 	 MSE : 6.3104e-01
Training Epoch 289 : 	 Train : 2.38861e-02 	 Res : 3.68558e-03 	 Jac : 1.61182e-02 	 Enc : 3.43229e-03 	 AE : 1.26501e-04 	 MSE : 5.23542e-01
Validation Epoch 289 : 	 Train : 2.34142e-02 	 Res : 3.44706e-03 	 Jac : 1.61457e-02 	 Enc : 3.42422e-03 	 AE : 9.41840e-05 	 MSE : 3.03017e-01
Training Epoch 289 finished, took current epoch 487.42s, cumulative time 138324.67s
Current Learning rate DEQ : 3.391115364244997e-05
Current Learning rate AUTOENC : 6.782230728489993e-05
Epoch 290, 25% 	 Loss : 2.3660e-02 	 Res : 3.6145e-03 	 Jac : 1.6044e-02 	 Enc : 3.4164e-03 	 AEnc : 1.5898e-04 	 MSE : 4.2652e-01
Epoch 290, 50% 	 Loss : 2.4360e-02 	 Res : 3.6868e-03 	 Jac : 1.6117e-02 	 Enc : 3.4525e-03 	 AEnc : 6.8826e-04 	 MSE : 4.1505e-01
Epoch 290, 75% 	 Loss : 2.3416e-02 	 Res : 3.4719e-03 	 Jac : 1.6040e-02 	 Enc : 3.4504e-03 	 AEnc : 1.7860e-04 	 MSE : 2.7477e-01
Training Epoch 290 : 	 Train : 2.37167e-02 	 Res : 3.56263e-03 	 Jac : 1.60884e-02 	 Enc : 3.43166e-03 	 AE : 2.86668e-04 	 MSE : 3.47256e-01
Validation Epoch 290 : 	 Train : 2.32490e-02 	 Res : 3.41433e-03 	 Jac : 1.60260e-02 	 Enc : 3.43132e-03 	 AE : 1.09002e-04 	 MSE : 2.68355e-01
Training Epoch 290 finished, took current epoch 492.10s, cumulative time 138816.76s
Current Learning rate DEQ : 3.391115364244997e-05
Current Learning rate AUTOENC : 6.782230728489993e-05
Epoch 291, 25% 	 Loss : 2.3415e-02 	 Res : 3.4827e-03 	 Jac : 1.6072e-02 	 Enc : 3.4420e-03 	 AEnc : 1.0702e-04 	 MSE : 3.1152e-01
Epoch 291, 50% 	 Loss : 2.3984e-02 	 Res : 3.7810e-03 	 Jac : 1.6148e-02 	 Enc : 3.4182e-03 	 AEnc : 8.8453e-05 	 MSE : 5.4837e-01
Epoch 291, 75% 	 Loss : 2.3159e-02 	 Res : 3.4019e-03 	 Jac : 1.5991e-02 	 Enc : 3.4210e-03 	 AEnc : 9.5783e-05 	 MSE : 2.4958e-01
Training Epoch 291 : 	 Train : 2.34962e-02 	 Res : 3.52969e-03 	 Jac : 1.61022e-02 	 Enc : 3.42923e-03 	 AE : 9.98701e-05 	 MSE : 3.35204e-01
Validation Epoch 291 : 	 Train : 2.33120e-02 	 Res : 3.45591e-03 	 Jac : 1.61192e-02 	 Enc : 3.43658e-03 	 AE : 1.03018e-04 	 MSE : 1.97248e-01
Training Epoch 291 finished, took current epoch 484.90s, cumulative time 139301.63s
Current Learning rate DEQ : 3.391115364244997e-05
Current Learning rate AUTOENC : 6.782230728489993e-05
Epoch 292, 25% 	 Loss : 2.3352e-02 	 Res : 3.4908e-03 	 Jac : 1.6050e-02 	 Enc : 3.4381e-03 	 AEnc : 9.5147e-05 	 MSE : 2.7785e-01
Epoch 292, 50% 	 Loss : 2.3396e-02 	 Res : 3.4443e-03 	 Jac : 1.6098e-02 	 Enc : 3.4329e-03 	 AEnc : 1.0859e-04 	 MSE : 3.1212e-01
Epoch 292, 75% 	 Loss : 2.3919e-02 	 Res : 3.8163e-03 	 Jac : 1.6099e-02 	 Enc : 3.4180e-03 	 AEnc : 1.0630e-04 	 MSE : 4.7948e-01
Training Epoch 292 : 	 Train : 2.36750e-02 	 Res : 3.71936e-03 	 Jac : 1.60673e-02 	 Enc : 3.42962e-03 	 AE : 1.20485e-04 	 MSE : 3.38233e-01
Validation Epoch 292 : 	 Train : 2.34096e-02 	 Res : 3.59807e-03 	 Jac : 1.60224e-02 	 Enc : 3.43009e-03 	 AE : 1.45426e-04 	 MSE : 2.13521e-01
Training Epoch 292 finished, took current epoch 492.40s, cumulative time 139794.01s
Current Learning rate DEQ : 3.391115364244997e-05
Current Learning rate AUTOENC : 6.782230728489993e-05
Epoch 293, 25% 	 Loss : 2.3540e-02 	 Res : 3.5785e-03 	 Jac : 1.6117e-02 	 Enc : 3.4212e-03 	 AEnc : 1.0341e-04 	 MSE : 3.2015e-01
Epoch 293, 50% 	 Loss : 2.3501e-02 	 Res : 3.5184e-03 	 Jac : 1.6161e-02 	 Enc : 3.4234e-03 	 AEnc : 9.6267e-05 	 MSE : 3.0230e-01
Epoch 293, 75% 	 Loss : 2.3604e-02 	 Res : 3.6043e-03 	 Jac : 1.6071e-02 	 Enc : 3.4394e-03 	 AEnc : 8.8668e-05 	 MSE : 4.0054e-01
Training Epoch 293 : 	 Train : 2.35693e-02 	 Res : 3.56184e-03 	 Jac : 1.61291e-02 	 Enc : 3.42658e-03 	 AE : 9.73224e-05 	 MSE : 3.54373e-01
Validation Epoch 293 : 	 Train : 2.36692e-02 	 Res : 3.63229e-03 	 Jac : 1.61224e-02 	 Enc : 3.42055e-03 	 AE : 7.85194e-05 	 MSE : 4.15484e-01
Training Epoch 293 finished, took current epoch 487.62s, cumulative time 140281.61s
Current Learning rate DEQ : 3.391115364244997e-05
Current Learning rate AUTOENC : 6.782230728489993e-05
Epoch 294, 25% 	 Loss : 2.3599e-02 	 Res : 3.6010e-03 	 Jac : 1.6040e-02 	 Enc : 3.4398e-03 	 AEnc : 9.5938e-05 	 MSE : 4.2305e-01
Epoch 294, 50% 	 Loss : 2.3533e-02 	 Res : 3.5514e-03 	 Jac : 1.6074e-02 	 Enc : 3.4153e-03 	 AEnc : 8.9904e-05 	 MSE : 4.0240e-01
Epoch 294, 75% 	 Loss : 2.3588e-02 	 Res : 3.6536e-03 	 Jac : 1.5998e-02 	 Enc : 3.4285e-03 	 AEnc : 9.5868e-05 	 MSE : 4.1220e-01
Training Epoch 294 : 	 Train : 2.35544e-02 	 Res : 3.58275e-03 	 Jac : 1.60526e-02 	 Enc : 3.42615e-03 	 AE : 9.42963e-05 	 MSE : 3.98638e-01
Validation Epoch 294 : 	 Train : 2.36897e-02 	 Res : 3.61279e-03 	 Jac : 1.61196e-02 	 Enc : 3.43695e-03 	 AE : 1.25776e-04 	 MSE : 3.94507e-01
Training Epoch 294 finished, took current epoch 491.64s, cumulative time 140773.24s
Current Learning rate DEQ : 3.391115364244997e-05
Current Learning rate AUTOENC : 6.782230728489993e-05
Epoch 295, 25% 	 Loss : 2.3614e-02 	 Res : 3.5532e-03 	 Jac : 1.6156e-02 	 Enc : 3.4232e-03 	 AEnc : 1.1845e-04 	 MSE : 3.6358e-01
Epoch 295, 50% 	 Loss : 2.3766e-02 	 Res : 3.6624e-03 	 Jac : 1.6126e-02 	 Enc : 3.4214e-03 	 AEnc : 9.4865e-05 	 MSE : 4.6144e-01
Epoch 295, 75% 	 Loss : 2.3382e-02 	 Res : 3.4893e-03 	 Jac : 1.6062e-02 	 Enc : 3.4328e-03 	 AEnc : 1.3342e-04 	 MSE : 2.6485e-01
Training Epoch 295 : 	 Train : 2.35866e-02 	 Res : 3.57456e-03 	 Jac : 1.61230e-02 	 Enc : 3.42573e-03 	 AE : 1.16006e-04 	 MSE : 3.47355e-01
Validation Epoch 295 : 	 Train : 2.32995e-02 	 Res : 3.45693e-03 	 Jac : 1.60959e-02 	 Enc : 3.43340e-03 	 AE : 9.57366e-05 	 MSE : 2.17467e-01
Training Epoch 295 finished, took current epoch 506.78s, cumulative time 141280.00s
Current Learning rate DEQ : 3.391115364244997e-05
Current Learning rate AUTOENC : 6.782230728489993e-05
Epoch 296, 25% 	 Loss : 2.3573e-02 	 Res : 3.5316e-03 	 Jac : 1.6181e-02 	 Enc : 3.4128e-03 	 AEnc : 1.1561e-04 	 MSE : 3.3174e-01
Epoch 296, 50% 	 Loss : 2.3226e-02 	 Res : 3.3684e-03 	 Jac : 1.6093e-02 	 Enc : 3.4311e-03 	 AEnc : 9.4481e-05 	 MSE : 2.3909e-01
Epoch 296, 75% 	 Loss : 2.3564e-02 	 Res : 3.5364e-03 	 Jac : 1.6107e-02 	 Enc : 3.4320e-03 	 AEnc : 1.4606e-04 	 MSE : 3.4226e-01
Training Epoch 296 : 	 Train : 2.35262e-02 	 Res : 3.48813e-03 	 Jac : 1.61337e-02 	 Enc : 3.42557e-03 	 AE : 1.80505e-04 	 MSE : 2.98348e-01
Validation Epoch 296 : 	 Train : 2.38317e-02 	 Res : 3.58557e-03 	 Jac : 1.60471e-02 	 Enc : 3.42256e-03 	 AE : 4.30876e-04 	 MSE : 3.45604e-01
Training Epoch 296 finished, took current epoch 494.19s, cumulative time 141774.17s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 297, 25% 	 Loss : 2.3367e-02 	 Res : 3.4518e-03 	 Jac : 1.5984e-02 	 Enc : 3.4305e-03 	 AEnc : 2.4404e-04 	 MSE : 2.5713e-01
Epoch 297, 50% 	 Loss : 2.3854e-02 	 Res : 3.7474e-03 	 Jac : 1.6040e-02 	 Enc : 3.4251e-03 	 AEnc : 1.0780e-04 	 MSE : 5.3346e-01
Epoch 297, 75% 	 Loss : 2.3994e-02 	 Res : 3.7895e-03 	 Jac : 1.6019e-02 	 Enc : 3.4111e-03 	 AEnc : 2.1449e-04 	 MSE : 5.5937e-01
Training Epoch 297 : 	 Train : 2.36299e-02 	 Res : 3.61297e-03 	 Jac : 1.60248e-02 	 Enc : 3.42270e-03 	 AE : 1.69594e-04 	 MSE : 3.99885e-01
Validation Epoch 297 : 	 Train : 2.33444e-02 	 Res : 3.44914e-03 	 Jac : 1.61275e-02 	 Enc : 3.41768e-03 	 AE : 9.83640e-05 	 MSE : 2.51665e-01
Training Epoch 297 finished, took current epoch 481.01s, cumulative time 142255.17s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 298, 25% 	 Loss : 2.3192e-02 	 Res : 3.4184e-03 	 Jac : 1.6031e-02 	 Enc : 3.4311e-03 	 AEnc : 1.0599e-04 	 MSE : 2.0523e-01
Epoch 298, 50% 	 Loss : 2.3251e-02 	 Res : 3.4567e-03 	 Jac : 1.6018e-02 	 Enc : 3.4178e-03 	 AEnc : 1.0106e-04 	 MSE : 2.5750e-01
Epoch 298, 75% 	 Loss : 2.3509e-02 	 Res : 3.5217e-03 	 Jac : 1.6141e-02 	 Enc : 3.4229e-03 	 AEnc : 1.0957e-04 	 MSE : 3.1370e-01
Training Epoch 298 : 	 Train : 2.32974e-02 	 Res : 3.45789e-03 	 Jac : 1.60458e-02 	 Enc : 3.42277e-03 	 AE : 1.04996e-04 	 MSE : 2.65929e-01
Validation Epoch 298 : 	 Train : 2.33271e-02 	 Res : 3.41949e-03 	 Jac : 1.60940e-02 	 Enc : 3.41383e-03 	 AE : 1.07496e-04 	 MSE : 2.92297e-01
Training Epoch 298 finished, took current epoch 485.03s, cumulative time 142740.19s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 299, 25% 	 Loss : 2.3142e-02 	 Res : 3.3773e-03 	 Jac : 1.6008e-02 	 Enc : 3.4267e-03 	 AEnc : 1.1380e-04 	 MSE : 2.1636e-01
Epoch 299, 50% 	 Loss : 2.3317e-02 	 Res : 3.4550e-03 	 Jac : 1.6061e-02 	 Enc : 3.4075e-03 	 AEnc : 1.0936e-04 	 MSE : 2.8379e-01
Epoch 299, 75% 	 Loss : 2.3868e-02 	 Res : 3.6763e-03 	 Jac : 1.6174e-02 	 Enc : 3.4476e-03 	 AEnc : 1.6340e-04 	 MSE : 4.0692e-01
Training Epoch 299 : 	 Train : 2.33836e-02 	 Res : 3.47384e-03 	 Jac : 1.60795e-02 	 Enc : 3.42358e-03 	 AE : 1.24427e-04 	 MSE : 2.82295e-01
Validation Epoch 299 : 	 Train : 2.33216e-02 	 Res : 3.37841e-03 	 Jac : 1.61585e-02 	 Enc : 3.42132e-03 	 AE : 1.18844e-04 	 MSE : 2.44567e-01
Training Epoch 299 finished, took current epoch 499.79s, cumulative time 143239.96s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
MODEL SAVED
Epoch 300, 25% 	 Loss : 2.3396e-02 	 Res : 3.5064e-03 	 Jac : 1.6020e-02 	 Enc : 3.4017e-03 	 AEnc : 9.8998e-05 	 MSE : 3.6852e-01
Epoch 300, 50% 	 Loss : 2.3278e-02 	 Res : 3.3813e-03 	 Jac : 1.6135e-02 	 Enc : 3.4165e-03 	 AEnc : 1.0206e-04 	 MSE : 2.4279e-01
Epoch 300, 75% 	 Loss : 2.3531e-02 	 Res : 3.4807e-03 	 Jac : 1.6211e-02 	 Enc : 3.4432e-03 	 AEnc : 1.1136e-04 	 MSE : 2.8450e-01
Training Epoch 300 : 	 Train : 2.33911e-02 	 Res : 3.46621e-03 	 Jac : 1.61146e-02 	 Enc : 3.42293e-03 	 AE : 1.04676e-04 	 MSE : 2.82669e-01
Validation Epoch 300 : 	 Train : 2.32341e-02 	 Res : 3.39282e-03 	 Jac : 1.60820e-02 	 Enc : 3.42945e-03 	 AE : 1.10239e-04 	 MSE : 2.19607e-01
Training Epoch 300 finished, took current epoch 492.67s, cumulative time 143732.61s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 301, 25% 	 Loss : 2.3258e-02 	 Res : 3.3777e-03 	 Jac : 1.6132e-02 	 Enc : 3.4208e-03 	 AEnc : 1.0721e-04 	 MSE : 2.2073e-01
Epoch 301, 50% 	 Loss : 2.3250e-02 	 Res : 3.4378e-03 	 Jac : 1.6095e-02 	 Enc : 3.4180e-03 	 AEnc : 8.9721e-05 	 MSE : 2.0914e-01
Epoch 301, 75% 	 Loss : 2.3451e-02 	 Res : 3.4614e-03 	 Jac : 1.6155e-02 	 Enc : 3.4365e-03 	 AEnc : 1.0487e-04 	 MSE : 2.9342e-01
Training Epoch 301 : 	 Train : 2.33417e-02 	 Res : 3.43634e-03 	 Jac : 1.61254e-02 	 Enc : 3.42373e-03 	 AE : 1.00733e-04 	 MSE : 2.55417e-01
Validation Epoch 301 : 	 Train : 2.35645e-02 	 Res : 3.54646e-03 	 Jac : 1.61071e-02 	 Enc : 3.43584e-03 	 AE : 9.33816e-05 	 MSE : 3.81787e-01
Training Epoch 301 finished, took current epoch 494.92s, cumulative time 144227.52s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 302, 25% 	 Loss : 2.3570e-02 	 Res : 3.5859e-03 	 Jac : 1.6085e-02 	 Enc : 3.4365e-03 	 AEnc : 1.0390e-04 	 MSE : 3.5904e-01
Epoch 302, 50% 	 Loss : 2.3911e-02 	 Res : 3.7283e-03 	 Jac : 1.6070e-02 	 Enc : 3.4100e-03 	 AEnc : 8.3981e-05 	 MSE : 6.1864e-01
Epoch 302, 75% 	 Loss : 2.3663e-02 	 Res : 3.6253e-03 	 Jac : 1.6065e-02 	 Enc : 3.4204e-03 	 AEnc : 9.0883e-05 	 MSE : 4.6136e-01
Training Epoch 302 : 	 Train : 2.36850e-02 	 Res : 3.61636e-03 	 Jac : 1.60799e-02 	 Enc : 3.42321e-03 	 AE : 9.46266e-05 	 MSE : 4.70890e-01
Validation Epoch 302 : 	 Train : 2.36488e-02 	 Res : 3.62533e-03 	 Jac : 1.60788e-02 	 Enc : 3.41034e-03 	 AE : 7.83801e-05 	 MSE : 4.55949e-01
Training Epoch 302 finished, took current epoch 492.52s, cumulative time 144720.03s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 303, 25% 	 Loss : 2.3444e-02 	 Res : 3.4836e-03 	 Jac : 1.6137e-02 	 Enc : 3.4230e-03 	 AEnc : 9.8214e-05 	 MSE : 3.0260e-01
Epoch 303, 50% 	 Loss : 2.3174e-02 	 Res : 3.3873e-03 	 Jac : 1.6025e-02 	 Enc : 3.4152e-03 	 AEnc : 9.6163e-05 	 MSE : 2.5072e-01
Epoch 303, 75% 	 Loss : 2.3257e-02 	 Res : 3.4763e-03 	 Jac : 1.5997e-02 	 Enc : 3.4250e-03 	 AEnc : 9.2689e-05 	 MSE : 2.6578e-01
Training Epoch 303 : 	 Train : 2.32914e-02 	 Res : 3.45790e-03 	 Jac : 1.60438e-02 	 Enc : 3.41995e-03 	 AE : 9.47610e-05 	 MSE : 2.75048e-01
Validation Epoch 303 : 	 Train : 2.32589e-02 	 Res : 3.40080e-03 	 Jac : 1.61213e-02 	 Enc : 3.42590e-03 	 AE : 9.19327e-05 	 MSE : 2.19028e-01
Training Epoch 303 finished, took current epoch 489.00s, cumulative time 145209.02s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 304, 25% 	 Loss : 2.3716e-02 	 Res : 3.6837e-03 	 Jac : 1.6145e-02 	 Enc : 3.4160e-03 	 AEnc : 9.1920e-05 	 MSE : 3.7977e-01
Epoch 304, 50% 	 Loss : 2.3306e-02 	 Res : 3.3811e-03 	 Jac : 1.6079e-02 	 Enc : 3.4136e-03 	 AEnc : 1.0752e-04 	 MSE : 3.2420e-01
Epoch 304, 75% 	 Loss : 2.3420e-02 	 Res : 3.4979e-03 	 Jac : 1.6100e-02 	 Enc : 3.4222e-03 	 AEnc : 1.0082e-04 	 MSE : 2.9924e-01
Training Epoch 304 : 	 Train : 2.34549e-02 	 Res : 3.50648e-03 	 Jac : 1.61168e-02 	 Enc : 3.41948e-03 	 AE : 9.97902e-05 	 MSE : 3.12422e-01
Validation Epoch 304 : 	 Train : 2.32094e-02 	 Res : 3.38793e-03 	 Jac : 1.61204e-02 	 Enc : 3.41909e-03 	 AE : 7.51979e-05 	 MSE : 2.06782e-01
Training Epoch 304 finished, took current epoch 493.51s, cumulative time 145702.52s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 305, 25% 	 Loss : 2.3276e-02 	 Res : 3.4342e-03 	 Jac : 1.6102e-02 	 Enc : 3.4015e-03 	 AEnc : 9.2161e-05 	 MSE : 2.4702e-01
Epoch 305, 50% 	 Loss : 2.3749e-02 	 Res : 3.7066e-03 	 Jac : 1.5999e-02 	 Enc : 3.4345e-03 	 AEnc : 9.8114e-05 	 MSE : 5.1113e-01
Epoch 305, 75% 	 Loss : 2.3277e-02 	 Res : 3.3830e-03 	 Jac : 1.6135e-02 	 Enc : 3.4220e-03 	 AEnc : 9.0505e-05 	 MSE : 2.4681e-01
Training Epoch 305 : 	 Train : 2.34200e-02 	 Res : 3.50310e-03 	 Jac : 1.60876e-02 	 Enc : 3.41886e-03 	 AE : 9.42500e-05 	 MSE : 3.16122e-01
Validation Epoch 305 : 	 Train : 2.33525e-02 	 Res : 3.42618e-03 	 Jac : 1.61950e-02 	 Enc : 3.41804e-03 	 AE : 7.83812e-05 	 MSE : 2.34937e-01
Training Epoch 305 finished, took current epoch 503.52s, cumulative time 146206.02s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 306, 25% 	 Loss : 2.3288e-02 	 Res : 3.4375e-03 	 Jac : 1.6069e-02 	 Enc : 3.4284e-03 	 AEnc : 1.0240e-04 	 MSE : 2.5044e-01
Epoch 306, 50% 	 Loss : 2.3339e-02 	 Res : 3.4330e-03 	 Jac : 1.6083e-02 	 Enc : 3.4139e-03 	 AEnc : 8.7007e-05 	 MSE : 3.2295e-01
Epoch 306, 75% 	 Loss : 2.3347e-02 	 Res : 3.4456e-03 	 Jac : 1.6094e-02 	 Enc : 3.4288e-03 	 AEnc : 8.6349e-05 	 MSE : 2.9237e-01
Training Epoch 306 : 	 Train : 2.33369e-02 	 Res : 3.43988e-03 	 Jac : 1.61036e-02 	 Enc : 3.41909e-03 	 AE : 9.13403e-05 	 MSE : 2.82960e-01
Validation Epoch 306 : 	 Train : 2.38707e-02 	 Res : 3.72066e-03 	 Jac : 1.61556e-02 	 Enc : 3.40497e-03 	 AE : 7.70264e-05 	 MSE : 5.12409e-01
Training Epoch 306 finished, took current epoch 490.50s, cumulative time 146696.51s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 307, 25% 	 Loss : 2.3232e-02 	 Res : 3.4134e-03 	 Jac : 1.6064e-02 	 Enc : 3.4169e-03 	 AEnc : 1.0734e-04 	 MSE : 2.3050e-01
Epoch 307, 50% 	 Loss : 2.3201e-02 	 Res : 3.3772e-03 	 Jac : 1.6066e-02 	 Enc : 3.4036e-03 	 AEnc : 9.3185e-05 	 MSE : 2.6123e-01
Epoch 307, 75% 	 Loss : 2.3347e-02 	 Res : 3.3983e-03 	 Jac : 1.6195e-02 	 Enc : 3.4268e-03 	 AEnc : 1.0282e-04 	 MSE : 2.2423e-01
Training Epoch 307 : 	 Train : 2.32743e-02 	 Res : 3.41345e-03 	 Jac : 1.61107e-02 	 Enc : 3.41844e-03 	 AE : 9.81783e-05 	 MSE : 2.33602e-01
Validation Epoch 307 : 	 Train : 2.31232e-02 	 Res : 3.36385e-03 	 Jac : 1.60376e-02 	 Enc : 3.41434e-03 	 AE : 7.86212e-05 	 MSE : 2.28851e-01
Training Epoch 307 finished, took current epoch 500.06s, cumulative time 147196.54s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
MODEL SAVED
Epoch 308, 25% 	 Loss : 2.3232e-02 	 Res : 3.4278e-03 	 Jac : 1.6039e-02 	 Enc : 3.4238e-03 	 AEnc : 8.8050e-05 	 MSE : 2.5274e-01
Epoch 308, 50% 	 Loss : 2.3215e-02 	 Res : 3.4575e-03 	 Jac : 1.6050e-02 	 Enc : 3.4021e-03 	 AEnc : 9.3928e-05 	 MSE : 2.1198e-01
Epoch 308, 75% 	 Loss : 2.3109e-02 	 Res : 3.3095e-03 	 Jac : 1.6060e-02 	 Enc : 3.4171e-03 	 AEnc : 8.1687e-05 	 MSE : 2.4031e-01
Training Epoch 308 : 	 Train : 2.33129e-02 	 Res : 3.43891e-03 	 Jac : 1.60756e-02 	 Enc : 3.41762e-03 	 AE : 9.41245e-05 	 MSE : 2.86655e-01
Validation Epoch 308 : 	 Train : 2.40103e-02 	 Res : 3.77066e-03 	 Jac : 1.59873e-02 	 Enc : 3.43577e-03 	 AE : 9.71835e-05 	 MSE : 7.19402e-01
Training Epoch 308 finished, took current epoch 500.97s, cumulative time 147697.51s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 309, 25% 	 Loss : 2.3656e-02 	 Res : 3.5543e-03 	 Jac : 1.6130e-02 	 Enc : 3.4178e-03 	 AEnc : 8.2734e-05 	 MSE : 4.7116e-01
Epoch 309, 50% 	 Loss : 2.3469e-02 	 Res : 3.4562e-03 	 Jac : 1.6108e-02 	 Enc : 3.3993e-03 	 AEnc : 8.0353e-05 	 MSE : 4.2435e-01
Epoch 309, 75% 	 Loss : 2.3556e-02 	 Res : 3.6022e-03 	 Jac : 1.6030e-02 	 Enc : 3.4152e-03 	 AEnc : 9.9163e-05 	 MSE : 4.0910e-01
Training Epoch 309 : 	 Train : 2.34957e-02 	 Res : 3.51807e-03 	 Jac : 1.60876e-02 	 Enc : 3.41834e-03 	 AE : 8.85148e-05 	 MSE : 3.83125e-01
Validation Epoch 309 : 	 Train : 2.31940e-02 	 Res : 3.38831e-03 	 Jac : 1.60897e-02 	 Enc : 3.42282e-03 	 AE : 9.32336e-05 	 MSE : 1.99923e-01
Training Epoch 309 finished, took current epoch 501.50s, cumulative time 148198.99s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 310, 25% 	 Loss : 2.3384e-02 	 Res : 3.4403e-03 	 Jac : 1.6124e-02 	 Enc : 3.4164e-03 	 AEnc : 9.0326e-05 	 MSE : 3.1265e-01
Epoch 310, 50% 	 Loss : 2.3354e-02 	 Res : 3.4677e-03 	 Jac : 1.6029e-02 	 Enc : 3.4043e-03 	 AEnc : 1.0294e-04 	 MSE : 3.5058e-01
Epoch 310, 75% 	 Loss : 2.4090e-02 	 Res : 3.7929e-03 	 Jac : 1.6127e-02 	 Enc : 3.4212e-03 	 AEnc : 1.0422e-04 	 MSE : 6.4472e-01
Training Epoch 310 : 	 Train : 2.35647e-02 	 Res : 3.53043e-03 	 Jac : 1.61171e-02 	 Enc : 3.41821e-03 	 AE : 9.45557e-05 	 MSE : 4.04347e-01
Validation Epoch 310 : 	 Train : 2.36835e-02 	 Res : 3.59937e-03 	 Jac : 1.60518e-02 	 Enc : 3.42836e-03 	 AE : 9.00967e-05 	 MSE : 5.13864e-01
Training Epoch 310 finished, took current epoch 492.72s, cumulative time 148691.70s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 311, 25% 	 Loss : 2.3281e-02 	 Res : 3.4080e-03 	 Jac : 1.6103e-02 	 Enc : 3.4075e-03 	 AEnc : 9.2573e-05 	 MSE : 2.6979e-01
Epoch 311, 50% 	 Loss : 2.3182e-02 	 Res : 3.3490e-03 	 Jac : 1.6092e-02 	 Enc : 3.4183e-03 	 AEnc : 9.2541e-05 	 MSE : 2.3054e-01
Epoch 311, 75% 	 Loss : 2.3244e-02 	 Res : 3.4653e-03 	 Jac : 1.6055e-02 	 Enc : 3.4155e-03 	 AEnc : 1.0532e-04 	 MSE : 2.0189e-01
Training Epoch 311 : 	 Train : 2.32808e-02 	 Res : 3.42878e-03 	 Jac : 1.60955e-02 	 Enc : 3.41585e-03 	 AE : 1.06136e-04 	 MSE : 2.34508e-01
Validation Epoch 311 : 	 Train : 2.33099e-02 	 Res : 3.43075e-03 	 Jac : 1.61335e-02 	 Enc : 3.41087e-03 	 AE : 9.96015e-05 	 MSE : 2.35145e-01
Training Epoch 311 finished, took current epoch 495.76s, cumulative time 149187.43s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 312, 25% 	 Loss : 2.3609e-02 	 Res : 3.4861e-03 	 Jac : 1.5996e-02 	 Enc : 3.4014e-03 	 AEnc : 3.9663e-04 	 MSE : 3.2824e-01
Epoch 312, 50% 	 Loss : 2.3282e-02 	 Res : 3.3785e-03 	 Jac : 1.6140e-02 	 Enc : 3.4122e-03 	 AEnc : 1.2517e-04 	 MSE : 2.2622e-01
Epoch 312, 75% 	 Loss : 2.3279e-02 	 Res : 3.4281e-03 	 Jac : 1.6091e-02 	 Enc : 3.4225e-03 	 AEnc : 1.2389e-04 	 MSE : 2.1402e-01
Training Epoch 312 : 	 Train : 2.33582e-02 	 Res : 3.41511e-03 	 Jac : 1.60962e-02 	 Enc : 3.41582e-03 	 AE : 1.87379e-04 	 MSE : 2.43677e-01
Validation Epoch 312 : 	 Train : 2.32425e-02 	 Res : 3.40449e-03 	 Jac : 1.61208e-02 	 Enc : 3.41036e-03 	 AE : 7.97673e-05 	 MSE : 2.27099e-01
Training Epoch 312 finished, took current epoch 497.27s, cumulative time 149684.67s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 313, 25% 	 Loss : 2.3280e-02 	 Res : 3.4272e-03 	 Jac : 1.6117e-02 	 Enc : 3.4125e-03 	 AEnc : 8.2925e-05 	 MSE : 2.4014e-01
Epoch 313, 50% 	 Loss : 2.3149e-02 	 Res : 3.3682e-03 	 Jac : 1.6010e-02 	 Enc : 3.4142e-03 	 AEnc : 1.0751e-04 	 MSE : 2.4905e-01
Epoch 313, 75% 	 Loss : 2.3225e-02 	 Res : 3.3297e-03 	 Jac : 1.6157e-02 	 Enc : 3.4189e-03 	 AEnc : 8.9928e-05 	 MSE : 2.2901e-01
Training Epoch 313 : 	 Train : 2.33330e-02 	 Res : 3.44019e-03 	 Jac : 1.61047e-02 	 Enc : 3.41345e-03 	 AE : 9.03538e-05 	 MSE : 2.84267e-01
Validation Epoch 313 : 	 Train : 2.33144e-02 	 Res : 3.45645e-03 	 Jac : 1.60558e-02 	 Enc : 3.42281e-03 	 AE : 7.74432e-05 	 MSE : 3.01915e-01
Training Epoch 313 finished, took current epoch 501.70s, cumulative time 150186.34s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 314, 25% 	 Loss : 2.3104e-02 	 Res : 3.2841e-03 	 Jac : 1.6073e-02 	 Enc : 3.4192e-03 	 AEnc : 8.0260e-05 	 MSE : 2.4739e-01
Epoch 314, 50% 	 Loss : 2.3411e-02 	 Res : 3.4353e-03 	 Jac : 1.6170e-02 	 Enc : 3.4191e-03 	 AEnc : 1.1419e-04 	 MSE : 2.7176e-01
Epoch 314, 75% 	 Loss : 2.3155e-02 	 Res : 3.3899e-03 	 Jac : 1.5997e-02 	 Enc : 3.3913e-03 	 AEnc : 1.0416e-04 	 MSE : 2.7286e-01
Training Epoch 314 : 	 Train : 2.32713e-02 	 Res : 3.39735e-03 	 Jac : 1.61098e-02 	 Enc : 3.41397e-03 	 AE : 1.00083e-04 	 MSE : 2.50108e-01
Validation Epoch 314 : 	 Train : 2.30619e-02 	 Res : 3.34627e-03 	 Jac : 1.60230e-02 	 Enc : 3.41176e-03 	 AE : 8.39152e-05 	 MSE : 1.97029e-01
Training Epoch 314 finished, took current epoch 494.90s, cumulative time 150681.21s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
MODEL SAVED
Epoch 315, 25% 	 Loss : 2.3175e-02 	 Res : 3.3950e-03 	 Jac : 1.6031e-02 	 Enc : 3.4082e-03 	 AEnc : 1.1499e-04 	 MSE : 2.2573e-01
Epoch 315, 50% 	 Loss : 2.3287e-02 	 Res : 3.4655e-03 	 Jac : 1.6015e-02 	 Enc : 3.3944e-03 	 AEnc : 9.4946e-05 	 MSE : 3.1733e-01
Epoch 315, 75% 	 Loss : 2.3336e-02 	 Res : 3.3997e-03 	 Jac : 1.6097e-02 	 Enc : 3.4276e-03 	 AEnc : 8.8031e-05 	 MSE : 3.2349e-01
Training Epoch 315 : 	 Train : 2.32790e-02 	 Res : 3.42119e-03 	 Jac : 1.60633e-02 	 Enc : 3.41207e-03 	 AE : 9.63908e-05 	 MSE : 2.86062e-01
Validation Epoch 315 : 	 Train : 2.30417e-02 	 Res : 3.34941e-03 	 Jac : 1.59506e-02 	 Enc : 3.41378e-03 	 AE : 8.07459e-05 	 MSE : 2.47192e-01
Training Epoch 315 finished, took current epoch 492.94s, cumulative time 151174.13s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 316, 25% 	 Loss : 2.3445e-02 	 Res : 3.4836e-03 	 Jac : 1.6138e-02 	 Enc : 3.4210e-03 	 AEnc : 9.7988e-05 	 MSE : 3.0532e-01
Epoch 316, 50% 	 Loss : 2.3298e-02 	 Res : 3.4689e-03 	 Jac : 1.6015e-02 	 Enc : 3.4118e-03 	 AEnc : 8.4765e-05 	 MSE : 3.1771e-01
Epoch 316, 75% 	 Loss : 2.3473e-02 	 Res : 3.5482e-03 	 Jac : 1.5984e-02 	 Enc : 3.4084e-03 	 AEnc : 9.3405e-05 	 MSE : 4.3892e-01
Training Epoch 316 : 	 Train : 2.34180e-02 	 Res : 3.50153e-03 	 Jac : 1.60383e-02 	 Enc : 3.41150e-03 	 AE : 8.92872e-05 	 MSE : 3.77333e-01
Validation Epoch 316 : 	 Train : 2.32854e-02 	 Res : 3.44200e-03 	 Jac : 1.60255e-02 	 Enc : 3.42185e-03 	 AE : 8.12349e-05 	 MSE : 3.14807e-01
Training Epoch 316 finished, took current epoch 490.82s, cumulative time 151664.95s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 317, 25% 	 Loss : 2.3604e-02 	 Res : 3.5569e-03 	 Jac : 1.6110e-02 	 Enc : 3.4253e-03 	 AEnc : 8.6050e-05 	 MSE : 4.2558e-01
Epoch 317, 50% 	 Loss : 2.3584e-02 	 Res : 3.5270e-03 	 Jac : 1.6107e-02 	 Enc : 3.4032e-03 	 AEnc : 8.9375e-05 	 MSE : 4.5778e-01
Epoch 317, 75% 	 Loss : 2.3544e-02 	 Res : 3.5567e-03 	 Jac : 1.6060e-02 	 Enc : 3.4110e-03 	 AEnc : 8.2263e-05 	 MSE : 4.3444e-01
Training Epoch 317 : 	 Train : 2.35669e-02 	 Res : 3.54111e-03 	 Jac : 1.60799e-02 	 Enc : 3.41284e-03 	 AE : 8.98814e-05 	 MSE : 4.43156e-01
Validation Epoch 317 : 	 Train : 2.37223e-02 	 Res : 3.62368e-03 	 Jac : 1.61340e-02 	 Enc : 3.40313e-03 	 AE : 1.60039e-04 	 MSE : 4.01435e-01
Training Epoch 317 finished, took current epoch 494.97s, cumulative time 152159.91s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 318, 25% 	 Loss : 2.3386e-02 	 Res : 3.4183e-03 	 Jac : 1.6188e-02 	 Enc : 3.4036e-03 	 AEnc : 1.0649e-04 	 MSE : 2.6936e-01
Epoch 318, 50% 	 Loss : 2.3208e-02 	 Res : 3.4405e-03 	 Jac : 1.5943e-02 	 Enc : 3.4233e-03 	 AEnc : 1.8148e-04 	 MSE : 2.1997e-01
Epoch 318, 75% 	 Loss : 2.3715e-02 	 Res : 3.6187e-03 	 Jac : 1.6051e-02 	 Enc : 3.4171e-03 	 AEnc : 3.4715e-04 	 MSE : 2.8078e-01
Training Epoch 318 : 	 Train : 2.34276e-02 	 Res : 3.45643e-03 	 Jac : 1.60828e-02 	 Enc : 3.41151e-03 	 AE : 2.27813e-04 	 MSE : 2.48991e-01
Validation Epoch 318 : 	 Train : 2.34614e-02 	 Res : 3.39090e-03 	 Jac : 1.59793e-02 	 Enc : 3.40640e-03 	 AE : 4.42719e-04 	 MSE : 2.42172e-01
Training Epoch 318 finished, took current epoch 507.71s, cumulative time 152667.59s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 319, 25% 	 Loss : 2.3257e-02 	 Res : 3.3527e-03 	 Jac : 1.6118e-02 	 Enc : 3.4126e-03 	 AEnc : 1.6083e-04 	 MSE : 2.1287e-01
Epoch 319, 50% 	 Loss : 2.3216e-02 	 Res : 3.4538e-03 	 Jac : 1.5990e-02 	 Enc : 3.4256e-03 	 AEnc : 9.4961e-05 	 MSE : 2.5095e-01
Epoch 319, 75% 	 Loss : 2.3247e-02 	 Res : 3.3760e-03 	 Jac : 1.6112e-02 	 Enc : 3.3904e-03 	 AEnc : 7.4420e-05 	 MSE : 2.9439e-01
Training Epoch 319 : 	 Train : 2.33049e-02 	 Res : 3.41893e-03 	 Jac : 1.60814e-02 	 Enc : 3.41048e-03 	 AE : 1.06706e-04 	 MSE : 2.87349e-01
Validation Epoch 319 : 	 Train : 2.35296e-02 	 Res : 3.57332e-03 	 Jac : 1.60899e-02 	 Enc : 3.40887e-03 	 AE : 1.02551e-04 	 MSE : 3.54945e-01
Training Epoch 319 finished, took current epoch 484.00s, cumulative time 153151.58s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 320, 25% 	 Loss : 2.3114e-02 	 Res : 3.3402e-03 	 Jac : 1.6073e-02 	 Enc : 3.4126e-03 	 AEnc : 8.7440e-05 	 MSE : 2.0112e-01
Epoch 320, 50% 	 Loss : 2.3286e-02 	 Res : 3.3799e-03 	 Jac : 1.6146e-02 	 Enc : 3.4199e-03 	 AEnc : 1.0008e-04 	 MSE : 2.4007e-01
Epoch 320, 75% 	 Loss : 2.3295e-02 	 Res : 3.3587e-03 	 Jac : 1.6157e-02 	 Enc : 3.3966e-03 	 AEnc : 9.5277e-05 	 MSE : 2.8771e-01
Training Epoch 320 : 	 Train : 2.32681e-02 	 Res : 3.39356e-03 	 Jac : 1.61172e-02 	 Enc : 3.40923e-03 	 AE : 9.97173e-05 	 MSE : 2.48467e-01
Validation Epoch 320 : 	 Train : 2.31649e-02 	 Res : 3.38203e-03 	 Jac : 1.59489e-02 	 Enc : 3.41590e-03 	 AE : 1.23480e-04 	 MSE : 2.94589e-01
Training Epoch 320 finished, took current epoch 502.16s, cumulative time 153653.74s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 321, 25% 	 Loss : 2.3430e-02 	 Res : 3.4876e-03 	 Jac : 1.6145e-02 	 Enc : 3.4167e-03 	 AEnc : 1.0027e-04 	 MSE : 2.8015e-01
Epoch 321, 50% 	 Loss : 2.3093e-02 	 Res : 3.2989e-03 	 Jac : 1.6079e-02 	 Enc : 3.3895e-03 	 AEnc : 8.9481e-05 	 MSE : 2.3653e-01
Epoch 321, 75% 	 Loss : 2.3186e-02 	 Res : 3.3938e-03 	 Jac : 1.6006e-02 	 Enc : 3.4134e-03 	 AEnc : 1.0007e-04 	 MSE : 2.7346e-01
Training Epoch 321 : 	 Train : 2.32105e-02 	 Res : 3.39435e-03 	 Jac : 1.60613e-02 	 Enc : 3.40870e-03 	 AE : 9.72091e-05 	 MSE : 2.48887e-01
Validation Epoch 321 : 	 Train : 2.30470e-02 	 Res : 3.32025e-03 	 Jac : 1.60485e-02 	 Enc : 3.40698e-03 	 AE : 8.27356e-05 	 MSE : 1.88547e-01
Training Epoch 321 finished, took current epoch 500.79s, cumulative time 154154.50s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
MODEL SAVED
Epoch 322, 25% 	 Loss : 2.3198e-02 	 Res : 3.3884e-03 	 Jac : 1.6078e-02 	 Enc : 3.4060e-03 	 AEnc : 8.4335e-05 	 MSE : 2.4115e-01
Epoch 322, 50% 	 Loss : 2.3318e-02 	 Res : 3.4192e-03 	 Jac : 1.6148e-02 	 Enc : 3.4291e-03 	 AEnc : 1.0172e-04 	 MSE : 2.1964e-01
Epoch 322, 75% 	 Loss : 2.3107e-02 	 Res : 3.2853e-03 	 Jac : 1.6119e-02 	 Enc : 3.4070e-03 	 AEnc : 9.4326e-05 	 MSE : 2.0198e-01
Training Epoch 322 : 	 Train : 2.32056e-02 	 Res : 3.37533e-03 	 Jac : 1.60982e-02 	 Enc : 3.40817e-03 	 AE : 9.29694e-05 	 MSE : 2.30875e-01
Validation Epoch 322 : 	 Train : 2.35178e-02 	 Res : 3.58465e-03 	 Jac : 1.60618e-02 	 Enc : 3.40488e-03 	 AE : 7.83066e-05 	 MSE : 3.88204e-01
Training Epoch 322 finished, took current epoch 504.35s, cumulative time 154658.83s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 323, 25% 	 Loss : 2.3308e-02 	 Res : 3.4417e-03 	 Jac : 1.6069e-02 	 Enc : 3.3968e-03 	 AEnc : 8.9121e-05 	 MSE : 3.1133e-01
Epoch 323, 50% 	 Loss : 2.3189e-02 	 Res : 3.3829e-03 	 Jac : 1.6044e-02 	 Enc : 3.4120e-03 	 AEnc : 8.6626e-05 	 MSE : 2.6284e-01
Epoch 323, 75% 	 Loss : 2.3303e-02 	 Res : 3.3717e-03 	 Jac : 1.6137e-02 	 Enc : 3.4103e-03 	 AEnc : 9.5333e-05 	 MSE : 2.8918e-01
Training Epoch 323 : 	 Train : 2.32692e-02 	 Res : 3.41307e-03 	 Jac : 1.60624e-02 	 Enc : 3.40892e-03 	 AE : 9.48204e-05 	 MSE : 2.89947e-01
Validation Epoch 323 : 	 Train : 2.32319e-02 	 Res : 3.44047e-03 	 Jac : 1.59977e-02 	 Enc : 3.40186e-03 	 AE : 7.11434e-05 	 MSE : 3.20712e-01
Training Epoch 323 finished, took current epoch 507.08s, cumulative time 155165.87s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 324, 25% 	 Loss : 2.3213e-02 	 Res : 3.3775e-03 	 Jac : 1.6032e-02 	 Enc : 3.4236e-03 	 AEnc : 8.8851e-05 	 MSE : 2.9107e-01
Epoch 324, 50% 	 Loss : 2.3133e-02 	 Res : 3.4018e-03 	 Jac : 1.5974e-02 	 Enc : 3.3961e-03 	 AEnc : 7.9795e-05 	 MSE : 2.8126e-01
Epoch 324, 75% 	 Loss : 2.3274e-02 	 Res : 3.4403e-03 	 Jac : 1.6037e-02 	 Enc : 3.4083e-03 	 AEnc : 9.1121e-05 	 MSE : 2.9714e-01
Training Epoch 324 : 	 Train : 2.32578e-02 	 Res : 3.42774e-03 	 Jac : 1.60384e-02 	 Enc : 3.40914e-03 	 AE : 9.45441e-05 	 MSE : 2.87945e-01
Validation Epoch 324 : 	 Train : 2.34545e-02 	 Res : 3.49381e-03 	 Jac : 1.59959e-02 	 Enc : 3.41970e-03 	 AE : 2.38043e-04 	 MSE : 3.07118e-01
Training Epoch 324 finished, took current epoch 504.87s, cumulative time 155670.69s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 325, 25% 	 Loss : 2.3190e-02 	 Res : 3.4184e-03 	 Jac : 1.5996e-02 	 Enc : 3.4234e-03 	 AEnc : 1.1342e-04 	 MSE : 2.3834e-01
Epoch 325, 50% 	 Loss : 2.3477e-02 	 Res : 3.5466e-03 	 Jac : 1.6039e-02 	 Enc : 3.4181e-03 	 AEnc : 1.0450e-04 	 MSE : 3.6947e-01
Epoch 325, 75% 	 Loss : 2.3216e-02 	 Res : 3.3132e-03 	 Jac : 1.6048e-02 	 Enc : 3.3837e-03 	 AEnc : 2.3372e-04 	 MSE : 2.3662e-01
Training Epoch 325 : 	 Train : 2.33249e-02 	 Res : 3.43633e-03 	 Jac : 1.60510e-02 	 Enc : 3.40783e-03 	 AE : 1.48465e-04 	 MSE : 2.81201e-01
Validation Epoch 325 : 	 Train : 2.30934e-02 	 Res : 3.34272e-03 	 Jac : 1.60604e-02 	 Enc : 3.40527e-03 	 AE : 9.07998e-05 	 MSE : 1.94190e-01
Training Epoch 325 finished, took current epoch 533.77s, cumulative time 156204.45s
Current Learning rate DEQ : 2.3737807549714975e-05
Current Learning rate AUTOENC : 4.747561509942995e-05
Epoch 326, 25% 	 Loss : 2.3146e-02 	 Res : 3.3505e-03 	 Jac : 1.6084e-02 	 Enc : 3.4052e-03 	 AEnc : 1.0347e-04 	 MSE : 2.0270e-01
Epoch 326, 50% 	 Loss : 2.3174e-02 	 Res : 3.3875e-03 	 Jac : 1.6045e-02 	 Enc : 3.4175e-03 	 AEnc : 1.1047e-04 	 MSE : 2.1410e-01
Epoch 326, 75% 	 Loss : 2.3029e-02 	 Res : 3.3196e-03 	 Jac : 1.6033e-02 	 Enc : 3.3951e-03 	 AEnc : 7.9351e-05 	 MSE : 2.0199e-01
Training Epoch 326 : 	 Train : 2.31502e-02 	 Res : 3.37564e-03 	 Jac : 1.60432e-02 	 Enc : 3.40539e-03 	 AE : 9.53391e-05 	 MSE : 2.30593e-01
Validation Epoch 326 : 	 Train : 2.31601e-02 	 Res : 3.37448e-03 	 Jac : 1.60508e-02 	 Enc : 3.39814e-03 	 AE : 8.73987e-05 	 MSE : 2.49284e-01
Training Epoch 326 finished, took current epoch 551.60s, cumulative time 156756.03s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 327, 25% 	 Loss : 2.3086e-02 	 Res : 3.3136e-03 	 Jac : 1.6105e-02 	 Enc : 3.3810e-03 	 AEnc : 8.6738e-05 	 MSE : 2.0011e-01
Epoch 327, 50% 	 Loss : 2.3261e-02 	 Res : 3.4600e-03 	 Jac : 1.5965e-02 	 Enc : 3.4215e-03 	 AEnc : 8.8558e-05 	 MSE : 3.2645e-01
Epoch 327, 75% 	 Loss : 2.3112e-02 	 Res : 3.3435e-03 	 Jac : 1.6034e-02 	 Enc : 3.4052e-03 	 AEnc : 8.6515e-05 	 MSE : 2.4356e-01
Training Epoch 327 : 	 Train : 2.31710e-02 	 Res : 3.37838e-03 	 Jac : 1.60529e-02 	 Enc : 3.40377e-03 	 AE : 8.60200e-05 	 MSE : 2.49922e-01
Validation Epoch 327 : 	 Train : 2.41632e-02 	 Res : 4.31539e-03 	 Jac : 1.59525e-02 	 Enc : 3.41452e-03 	 AE : 8.13215e-05 	 MSE : 3.99440e-01
Training Epoch 327 finished, took current epoch 552.14s, cumulative time 157308.16s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 328, 25% 	 Loss : 2.3070e-02 	 Res : 3.3259e-03 	 Jac : 1.6042e-02 	 Enc : 3.3884e-03 	 AEnc : 7.0276e-05 	 MSE : 2.4322e-01
Epoch 328, 50% 	 Loss : 2.7439e-02 	 Res : 6.5987e-03 	 Jac : 1.6166e-02 	 Enc : 3.4154e-03 	 AEnc : 1.3791e-04 	 MSE : 1.1210e+00
Epoch 328, 75% 	 Loss : 2.3775e-02 	 Res : 3.6629e-03 	 Jac : 1.6160e-02 	 Enc : 3.4160e-03 	 AEnc : 8.6165e-05 	 MSE : 4.5029e-01
Training Epoch 328 : 	 Train : 2.43356e-02 	 Res : 4.22566e-03 	 Jac : 1.60954e-02 	 Enc : 3.40529e-03 	 AE : 9.13661e-05 	 MSE : 5.17968e-01
Validation Epoch 328 : 	 Train : 2.41153e-02 	 Res : 4.17258e-03 	 Jac : 1.60504e-02 	 Enc : 3.40503e-03 	 AE : 8.49437e-05 	 MSE : 4.02300e-01
Training Epoch 328 finished, took current epoch 547.64s, cumulative time 157855.78s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 329, 25% 	 Loss : 2.3144e-02 	 Res : 3.3542e-03 	 Jac : 1.6073e-02 	 Enc : 3.3956e-03 	 AEnc : 8.3473e-05 	 MSE : 2.3786e-01
Epoch 329, 50% 	 Loss : 2.3114e-02 	 Res : 3.3953e-03 	 Jac : 1.5964e-02 	 Enc : 3.4131e-03 	 AEnc : 8.8039e-05 	 MSE : 2.5364e-01
Epoch 329, 75% 	 Loss : 2.3135e-02 	 Res : 3.2992e-03 	 Jac : 1.6153e-02 	 Enc : 3.3959e-03 	 AEnc : 8.5833e-05 	 MSE : 2.0098e-01
Training Epoch 329 : 	 Train : 2.31377e-02 	 Res : 3.33267e-03 	 Jac : 1.60969e-02 	 Enc : 3.40141e-03 	 AE : 8.48934e-05 	 MSE : 2.21828e-01
Validation Epoch 329 : 	 Train : 2.30527e-02 	 Res : 3.30927e-03 	 Jac : 1.60622e-02 	 Enc : 3.40655e-03 	 AE : 7.96641e-05 	 MSE : 1.95013e-01
Training Epoch 329 finished, took current epoch 534.59s, cumulative time 158390.31s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
MODEL SAVED
Epoch 330, 25% 	 Loss : 2.2977e-02 	 Res : 3.2594e-03 	 Jac : 1.6060e-02 	 Enc : 3.3961e-03 	 AEnc : 7.6932e-05 	 MSE : 1.8511e-01
Epoch 330, 50% 	 Loss : 2.3130e-02 	 Res : 3.3586e-03 	 Jac : 1.6030e-02 	 Enc : 3.4043e-03 	 AEnc : 9.0232e-05 	 MSE : 2.4695e-01
Epoch 330, 75% 	 Loss : 2.3205e-02 	 Res : 3.3721e-03 	 Jac : 1.6122e-02 	 Enc : 3.4053e-03 	 AEnc : 8.2664e-05 	 MSE : 2.2254e-01
Training Epoch 330 : 	 Train : 2.31054e-02 	 Res : 3.33278e-03 	 Jac : 1.60668e-02 	 Enc : 3.40154e-03 	 AE : 8.40567e-05 	 MSE : 2.20236e-01
Validation Epoch 330 : 	 Train : 2.30559e-02 	 Res : 3.32318e-03 	 Jac : 1.60587e-02 	 Enc : 3.40646e-03 	 AE : 8.14104e-05 	 MSE : 1.86138e-01
Training Epoch 330 finished, took current epoch 536.58s, cumulative time 158926.87s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 331, 25% 	 Loss : 2.3122e-02 	 Res : 3.3530e-03 	 Jac : 1.6043e-02 	 Enc : 3.4167e-03 	 AEnc : 8.2631e-05 	 MSE : 2.2614e-01
Epoch 331, 50% 	 Loss : 2.3265e-02 	 Res : 3.3856e-03 	 Jac : 1.6136e-02 	 Enc : 3.3953e-03 	 AEnc : 9.5070e-05 	 MSE : 2.5228e-01
Epoch 331, 75% 	 Loss : 2.3103e-02 	 Res : 3.3262e-03 	 Jac : 1.6070e-02 	 Enc : 3.3950e-03 	 AEnc : 8.2119e-05 	 MSE : 2.2886e-01
Training Epoch 331 : 	 Train : 2.31258e-02 	 Res : 3.33539e-03 	 Jac : 1.60727e-02 	 Enc : 3.39973e-03 	 AE : 8.37700e-05 	 MSE : 2.34180e-01
Validation Epoch 331 : 	 Train : 2.39207e-02 	 Res : 3.96205e-03 	 Jac : 1.60637e-02 	 Enc : 3.41367e-03 	 AE : 9.25420e-05 	 MSE : 3.88767e-01
Training Epoch 331 finished, took current epoch 539.10s, cumulative time 159465.96s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 332, 25% 	 Loss : 2.3200e-02 	 Res : 3.3356e-03 	 Jac : 1.6165e-02 	 Enc : 3.4123e-03 	 AEnc : 9.3096e-05 	 MSE : 1.9380e-01
Epoch 332, 50% 	 Loss : 2.3074e-02 	 Res : 3.3180e-03 	 Jac : 1.6089e-02 	 Enc : 3.3643e-03 	 AEnc : 7.6123e-05 	 MSE : 2.2670e-01
Epoch 332, 75% 	 Loss : 2.4218e-02 	 Res : 4.0805e-03 	 Jac : 1.6186e-02 	 Enc : 3.4344e-03 	 AEnc : 8.8916e-05 	 MSE : 4.2818e-01
Training Epoch 332 : 	 Train : 2.34079e-02 	 Res : 3.52484e-03 	 Jac : 1.61229e-02 	 Enc : 3.40207e-03 	 AE : 8.50888e-05 	 MSE : 2.73024e-01
Validation Epoch 332 : 	 Train : 2.31205e-02 	 Res : 3.32373e-03 	 Jac : 1.60797e-02 	 Enc : 3.39554e-03 	 AE : 9.50065e-05 	 MSE : 2.26476e-01
Training Epoch 332 finished, took current epoch 539.87s, cumulative time 160005.80s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 333, 25% 	 Loss : 2.3133e-02 	 Res : 3.2989e-03 	 Jac : 1.6036e-02 	 Enc : 3.3857e-03 	 AEnc : 2.0017e-04 	 MSE : 2.1167e-01
Epoch 333, 50% 	 Loss : 2.3160e-02 	 Res : 3.3737e-03 	 Jac : 1.6052e-02 	 Enc : 3.4120e-03 	 AEnc : 1.1082e-04 	 MSE : 2.1060e-01
Epoch 333, 75% 	 Loss : 2.3048e-02 	 Res : 3.2949e-03 	 Jac : 1.6077e-02 	 Enc : 3.3922e-03 	 AEnc : 9.0148e-05 	 MSE : 1.9322e-01
Training Epoch 333 : 	 Train : 2.31227e-02 	 Res : 3.32911e-03 	 Jac : 1.60596e-02 	 Enc : 3.40065e-03 	 AE : 1.23525e-04 	 MSE : 2.09737e-01
Validation Epoch 333 : 	 Train : 2.29787e-02 	 Res : 3.27812e-03 	 Jac : 1.60484e-02 	 Enc : 3.39881e-03 	 AE : 7.77155e-05 	 MSE : 1.75653e-01
Training Epoch 333 finished, took current epoch 542.71s, cumulative time 160548.49s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
MODEL SAVED
Epoch 334, 25% 	 Loss : 2.3152e-02 	 Res : 3.3300e-03 	 Jac : 1.6105e-02 	 Enc : 3.4022e-03 	 AEnc : 9.0218e-05 	 MSE : 2.2431e-01
Epoch 334, 50% 	 Loss : 2.3244e-02 	 Res : 3.4694e-03 	 Jac : 1.6024e-02 	 Enc : 3.3942e-03 	 AEnc : 8.5609e-05 	 MSE : 2.7033e-01
Epoch 334, 75% 	 Loss : 2.2897e-02 	 Res : 3.2462e-03 	 Jac : 1.5948e-02 	 Enc : 3.4203e-03 	 AEnc : 8.6399e-05 	 MSE : 1.9551e-01
Training Epoch 334 : 	 Train : 2.30569e-02 	 Res : 3.33858e-03 	 Jac : 1.60083e-02 	 Enc : 3.39783e-03 	 AE : 8.58415e-05 	 MSE : 2.26378e-01
Validation Epoch 334 : 	 Train : 2.31169e-02 	 Res : 3.35543e-03 	 Jac : 1.60314e-02 	 Enc : 3.39176e-03 	 AE : 9.69895e-05 	 MSE : 2.41277e-01
Training Epoch 334 finished, took current epoch 529.92s, cumulative time 161078.40s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 335, 25% 	 Loss : 2.3078e-02 	 Res : 3.3274e-03 	 Jac : 1.6065e-02 	 Enc : 3.3952e-03 	 AEnc : 8.7325e-05 	 MSE : 2.0294e-01
Epoch 335, 50% 	 Loss : 2.3252e-02 	 Res : 3.3055e-03 	 Jac : 1.6269e-02 	 Enc : 3.4058e-03 	 AEnc : 8.2251e-05 	 MSE : 1.9000e-01
Epoch 335, 75% 	 Loss : 2.3142e-02 	 Res : 3.3444e-03 	 Jac : 1.6042e-02 	 Enc : 3.3817e-03 	 AEnc : 8.5700e-05 	 MSE : 2.8901e-01
Training Epoch 335 : 	 Train : 2.31873e-02 	 Res : 3.33483e-03 	 Jac : 1.61462e-02 	 Enc : 3.39709e-03 	 AE : 8.62070e-05 	 MSE : 2.22967e-01
Validation Epoch 335 : 	 Train : 2.29702e-02 	 Res : 3.27655e-03 	 Jac : 1.60146e-02 	 Enc : 3.39226e-03 	 AE : 8.36150e-05 	 MSE : 2.03191e-01
Training Epoch 335 finished, took current epoch 540.60s, cumulative time 161618.96s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
MODEL SAVED
Epoch 336, 25% 	 Loss : 2.2989e-02 	 Res : 3.3085e-03 	 Jac : 1.6002e-02 	 Enc : 3.3897e-03 	 AEnc : 9.0516e-05 	 MSE : 1.9798e-01
Epoch 336, 50% 	 Loss : 2.3230e-02 	 Res : 3.2861e-03 	 Jac : 1.6219e-02 	 Enc : 3.4050e-03 	 AEnc : 8.5732e-05 	 MSE : 2.3382e-01
Epoch 336, 75% 	 Loss : 2.3142e-02 	 Res : 3.3689e-03 	 Jac : 1.6074e-02 	 Enc : 3.3963e-03 	 AEnc : 7.3928e-05 	 MSE : 2.2928e-01
Training Epoch 336 : 	 Train : 2.31022e-02 	 Res : 3.32098e-03 	 Jac : 1.60832e-02 	 Enc : 3.39554e-03 	 AE : 8.05487e-05 	 MSE : 2.21987e-01
Validation Epoch 336 : 	 Train : 2.29343e-02 	 Res : 3.28364e-03 	 Jac : 1.60043e-02 	 Enc : 3.39692e-03 	 AE : 6.97160e-05 	 MSE : 1.79710e-01
Training Epoch 336 finished, took current epoch 545.44s, cumulative time 162164.37s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 337, 25% 	 Loss : 2.3149e-02 	 Res : 3.3825e-03 	 Jac : 1.6009e-02 	 Enc : 3.4107e-03 	 AEnc : 7.6908e-05 	 MSE : 2.6983e-01
Epoch 337, 50% 	 Loss : 2.2814e-02 	 Res : 3.1989e-03 	 Jac : 1.5953e-02 	 Enc : 3.3729e-03 	 AEnc : 7.9664e-05 	 MSE : 2.0965e-01
Epoch 337, 75% 	 Loss : 2.3061e-02 	 Res : 3.3243e-03 	 Jac : 1.6026e-02 	 Enc : 3.4198e-03 	 AEnc : 9.4558e-05 	 MSE : 1.9577e-01
Training Epoch 337 : 	 Train : 2.30580e-02 	 Res : 3.32205e-03 	 Jac : 1.60295e-02 	 Enc : 3.39666e-03 	 AE : 8.61229e-05 	 MSE : 2.23679e-01
Validation Epoch 337 : 	 Train : 2.31214e-02 	 Res : 3.39894e-03 	 Jac : 1.59361e-02 	 Enc : 3.39728e-03 	 AE : 7.38028e-05 	 MSE : 3.15311e-01
Training Epoch 337 finished, took current epoch 535.03s, cumulative time 162699.39s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 338, 25% 	 Loss : 2.3204e-02 	 Res : 3.3604e-03 	 Jac : 1.6121e-02 	 Enc : 3.4041e-03 	 AEnc : 9.0442e-05 	 MSE : 2.2758e-01
Epoch 338, 50% 	 Loss : 2.3157e-02 	 Res : 3.3165e-03 	 Jac : 1.6162e-02 	 Enc : 3.3874e-03 	 AEnc : 8.1436e-05 	 MSE : 2.0961e-01
Epoch 338, 75% 	 Loss : 2.2991e-02 	 Res : 3.2712e-03 	 Jac : 1.6026e-02 	 Enc : 3.3939e-03 	 AEnc : 7.8003e-05 	 MSE : 2.2151e-01
Training Epoch 338 : 	 Train : 2.31026e-02 	 Res : 3.32390e-03 	 Jac : 1.60634e-02 	 Enc : 3.39510e-03 	 AE : 8.33340e-05 	 MSE : 2.36831e-01
Validation Epoch 338 : 	 Train : 2.31919e-02 	 Res : 3.37617e-03 	 Jac : 1.60040e-02 	 Enc : 3.40144e-03 	 AE : 8.17396e-05 	 MSE : 3.28499e-01
Training Epoch 338 finished, took current epoch 538.16s, cumulative time 163237.49s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 339, 25% 	 Loss : 2.3296e-02 	 Res : 3.3984e-03 	 Jac : 1.6133e-02 	 Enc : 3.3828e-03 	 AEnc : 8.1721e-05 	 MSE : 2.9935e-01
Epoch 339, 50% 	 Loss : 2.3476e-02 	 Res : 3.5586e-03 	 Jac : 1.6086e-02 	 Enc : 3.3910e-03 	 AEnc : 8.6094e-05 	 MSE : 3.5426e-01
Epoch 339, 75% 	 Loss : 2.3122e-02 	 Res : 3.3267e-03 	 Jac : 1.6019e-02 	 Enc : 3.3790e-03 	 AEnc : 7.1608e-05 	 MSE : 3.2615e-01
Training Epoch 339 : 	 Train : 2.32859e-02 	 Res : 3.40582e-03 	 Jac : 1.61010e-02 	 Enc : 3.39343e-03 	 AE : 8.23506e-05 	 MSE : 3.03363e-01
Validation Epoch 339 : 	 Train : 2.29480e-02 	 Res : 3.26484e-03 	 Jac : 1.60273e-02 	 Enc : 3.39462e-03 	 AE : 8.63659e-05 	 MSE : 1.74886e-01
Training Epoch 339 finished, took current epoch 533.80s, cumulative time 163771.25s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
MODEL SAVED
Epoch 340, 25% 	 Loss : 2.3066e-02 	 Res : 3.2808e-03 	 Jac : 1.6071e-02 	 Enc : 3.3938e-03 	 AEnc : 8.5240e-05 	 MSE : 2.3600e-01
Epoch 340, 50% 	 Loss : 2.3038e-02 	 Res : 3.3502e-03 	 Jac : 1.5983e-02 	 Enc : 3.3860e-03 	 AEnc : 8.9819e-05 	 MSE : 2.2805e-01
Epoch 340, 75% 	 Loss : 2.2984e-02 	 Res : 3.3006e-03 	 Jac : 1.6024e-02 	 Enc : 3.3979e-03 	 AEnc : 7.6166e-05 	 MSE : 1.8577e-01
Training Epoch 340 : 	 Train : 2.29943e-02 	 Res : 3.29917e-03 	 Jac : 1.60146e-02 	 Enc : 3.39210e-03 	 AE : 8.12881e-05 	 MSE : 2.07130e-01
Validation Epoch 340 : 	 Train : 2.29272e-02 	 Res : 3.27630e-03 	 Jac : 1.60054e-02 	 Enc : 3.39062e-03 	 AE : 6.90229e-05 	 MSE : 1.85817e-01
Training Epoch 340 finished, took current epoch 545.92s, cumulative time 164317.15s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 341, 25% 	 Loss : 2.3070e-02 	 Res : 3.3550e-03 	 Jac : 1.6043e-02 	 Enc : 3.3900e-03 	 AEnc : 7.8863e-05 	 MSE : 2.0285e-01
Epoch 341, 50% 	 Loss : 2.2907e-02 	 Res : 3.2715e-03 	 Jac : 1.5954e-02 	 Enc : 3.3890e-03 	 AEnc : 7.3814e-05 	 MSE : 2.1871e-01
Epoch 341, 75% 	 Loss : 2.3043e-02 	 Res : 3.3068e-03 	 Jac : 1.6032e-02 	 Enc : 3.3920e-03 	 AEnc : 7.8786e-05 	 MSE : 2.3396e-01
Training Epoch 341 : 	 Train : 2.30254e-02 	 Res : 3.29943e-03 	 Jac : 1.60319e-02 	 Enc : 3.39112e-03 	 AE : 7.90027e-05 	 MSE : 2.23903e-01
Validation Epoch 341 : 	 Train : 2.29937e-02 	 Res : 3.27604e-03 	 Jac : 1.60423e-02 	 Enc : 3.39652e-03 	 AE : 7.95815e-05 	 MSE : 1.99252e-01
Training Epoch 341 finished, took current epoch 539.19s, cumulative time 164856.32s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 342, 25% 	 Loss : 2.2929e-02 	 Res : 3.3186e-03 	 Jac : 1.5942e-02 	 Enc : 3.3686e-03 	 AEnc : 7.5528e-05 	 MSE : 2.2389e-01
Epoch 342, 50% 	 Loss : 2.3062e-02 	 Res : 3.3235e-03 	 Jac : 1.6029e-02 	 Enc : 3.4002e-03 	 AEnc : 7.9658e-05 	 MSE : 2.2906e-01
Epoch 342, 75% 	 Loss : 2.3372e-02 	 Res : 3.3899e-03 	 Jac : 1.6133e-02 	 Enc : 3.4137e-03 	 AEnc : 7.9296e-05 	 MSE : 3.5604e-01
Training Epoch 342 : 	 Train : 2.31022e-02 	 Res : 3.33502e-03 	 Jac : 1.60329e-02 	 Enc : 3.39072e-03 	 AE : 7.73339e-05 	 MSE : 2.66279e-01
Validation Epoch 342 : 	 Train : 2.31216e-02 	 Res : 3.36599e-03 	 Jac : 1.59550e-02 	 Enc : 3.39918e-03 	 AE : 8.09219e-05 	 MSE : 3.20517e-01
Training Epoch 342 finished, took current epoch 536.03s, cumulative time 165392.32s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 343, 25% 	 Loss : 2.3232e-02 	 Res : 3.3450e-03 	 Jac : 1.6161e-02 	 Enc : 3.3610e-03 	 AEnc : 1.2079e-04 	 MSE : 2.4390e-01
Epoch 343, 50% 	 Loss : 2.2946e-02 	 Res : 3.2964e-03 	 Jac : 1.5936e-02 	 Enc : 3.4002e-03 	 AEnc : 9.8406e-05 	 MSE : 2.1513e-01
Epoch 343, 75% 	 Loss : 2.3234e-02 	 Res : 3.3375e-03 	 Jac : 1.6176e-02 	 Enc : 3.3954e-03 	 AEnc : 9.3228e-05 	 MSE : 2.3126e-01
Training Epoch 343 : 	 Train : 2.30968e-02 	 Res : 3.31714e-03 	 Jac : 1.60592e-02 	 Enc : 3.38953e-03 	 AE : 9.92987e-05 	 MSE : 2.31662e-01
Validation Epoch 343 : 	 Train : 2.30476e-02 	 Res : 3.30096e-03 	 Jac : 1.60616e-02 	 Enc : 3.38403e-03 	 AE : 7.43914e-05 	 MSE : 2.26559e-01
Training Epoch 343 finished, took current epoch 547.92s, cumulative time 165940.20s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 344, 25% 	 Loss : 2.2985e-02 	 Res : 3.2850e-03 	 Jac : 1.6006e-02 	 Enc : 3.3639e-03 	 AEnc : 9.6017e-05 	 MSE : 2.3399e-01
Epoch 344, 50% 	 Loss : 2.3105e-02 	 Res : 3.3026e-03 	 Jac : 1.6090e-02 	 Enc : 3.4066e-03 	 AEnc : 9.8302e-05 	 MSE : 2.0772e-01
Epoch 344, 75% 	 Loss : 2.3037e-02 	 Res : 3.2863e-03 	 Jac : 1.6047e-02 	 Enc : 3.4044e-03 	 AEnc : 9.2600e-05 	 MSE : 2.0600e-01
Training Epoch 344 : 	 Train : 2.30739e-02 	 Res : 3.29794e-03 	 Jac : 1.60708e-02 	 Enc : 3.38793e-03 	 AE : 8.98151e-05 	 MSE : 2.27400e-01
Validation Epoch 344 : 	 Train : 2.29600e-02 	 Res : 3.27035e-03 	 Jac : 1.60134e-02 	 Enc : 3.39402e-03 	 AE : 7.15451e-05 	 MSE : 2.10700e-01
Training Epoch 344 finished, took current epoch 541.34s, cumulative time 166481.52s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 345, 25% 	 Loss : 2.3068e-02 	 Res : 3.2908e-03 	 Jac : 1.6084e-02 	 Enc : 3.3912e-03 	 AEnc : 7.5528e-05 	 MSE : 2.2551e-01
Epoch 345, 50% 	 Loss : 2.3069e-02 	 Res : 3.2462e-03 	 Jac : 1.6142e-02 	 Enc : 3.3870e-03 	 AEnc : 7.9306e-05 	 MSE : 2.1466e-01
Epoch 345, 75% 	 Loss : 2.3050e-02 	 Res : 3.2934e-03 	 Jac : 1.6095e-02 	 Enc : 3.3916e-03 	 AEnc : 7.2439e-05 	 MSE : 1.9803e-01
Training Epoch 345 : 	 Train : 2.30909e-02 	 Res : 3.30652e-03 	 Jac : 1.60832e-02 	 Enc : 3.38689e-03 	 AE : 7.66457e-05 	 MSE : 2.37640e-01
Validation Epoch 345 : 	 Train : 2.32002e-02 	 Res : 3.37261e-03 	 Jac : 1.59964e-02 	 Enc : 3.39794e-03 	 AE : 8.89163e-05 	 MSE : 3.44314e-01
Training Epoch 345 finished, took current epoch 548.67s, cumulative time 167030.16s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 346, 25% 	 Loss : 2.3054e-02 	 Res : 3.3045e-03 	 Jac : 1.6058e-02 	 Enc : 3.3874e-03 	 AEnc : 8.2027e-05 	 MSE : 2.2214e-01
Epoch 346, 50% 	 Loss : 2.3019e-02 	 Res : 3.2987e-03 	 Jac : 1.6023e-02 	 Enc : 3.3801e-03 	 AEnc : 7.2492e-05 	 MSE : 2.4476e-01
Epoch 346, 75% 	 Loss : 2.2896e-02 	 Res : 3.2294e-03 	 Jac : 1.6011e-02 	 Enc : 3.3891e-03 	 AEnc : 8.9715e-05 	 MSE : 1.7624e-01
Training Epoch 346 : 	 Train : 2.29694e-02 	 Res : 3.27402e-03 	 Jac : 1.60204e-02 	 Enc : 3.38622e-03 	 AE : 8.10080e-05 	 MSE : 2.07794e-01
Validation Epoch 346 : 	 Train : 2.28443e-02 	 Res : 3.26422e-03 	 Jac : 1.59448e-02 	 Enc : 3.38822e-03 	 AE : 7.05375e-05 	 MSE : 1.76519e-01
Training Epoch 346 finished, took current epoch 547.16s, cumulative time 167577.30s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
MODEL SAVED
Epoch 347, 25% 	 Loss : 2.3209e-02 	 Res : 3.3716e-03 	 Jac : 1.6102e-02 	 Enc : 3.4078e-03 	 AEnc : 8.2150e-05 	 MSE : 2.4552e-01
Epoch 347, 50% 	 Loss : 2.3067e-02 	 Res : 3.1938e-03 	 Jac : 1.6203e-02 	 Enc : 3.3665e-03 	 AEnc : 7.1391e-05 	 MSE : 2.3218e-01
Epoch 347, 75% 	 Loss : 2.3162e-02 	 Res : 3.3364e-03 	 Jac : 1.6121e-02 	 Enc : 3.3976e-03 	 AEnc : 6.9889e-05 	 MSE : 2.3712e-01
Training Epoch 347 : 	 Train : 2.31049e-02 	 Res : 3.30172e-03 	 Jac : 1.61061e-02 	 Enc : 3.38396e-03 	 AE : 7.61848e-05 	 MSE : 2.36858e-01
Validation Epoch 347 : 	 Train : 2.29747e-02 	 Res : 3.28088e-03 	 Jac : 1.60361e-02 	 Enc : 3.38039e-03 	 AE : 6.38218e-05 	 MSE : 2.13476e-01
Training Epoch 347 finished, took current epoch 542.84s, cumulative time 168120.09s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 348, 25% 	 Loss : 2.3001e-02 	 Res : 3.3021e-03 	 Jac : 1.5977e-02 	 Enc : 3.4078e-03 	 AEnc : 7.3610e-05 	 MSE : 2.4098e-01
Epoch 348, 50% 	 Loss : 2.3225e-02 	 Res : 3.4008e-03 	 Jac : 1.6063e-02 	 Enc : 3.3872e-03 	 AEnc : 7.1759e-05 	 MSE : 3.0235e-01
Epoch 348, 75% 	 Loss : 2.3149e-02 	 Res : 3.3102e-03 	 Jac : 1.6117e-02 	 Enc : 3.3495e-03 	 AEnc : 6.7475e-05 	 MSE : 3.0572e-01
Training Epoch 348 : 	 Train : 2.30869e-02 	 Res : 3.32785e-03 	 Jac : 1.60424e-02 	 Enc : 3.38385e-03 	 AE : 7.22986e-05 	 MSE : 2.60411e-01
Validation Epoch 348 : 	 Train : 2.29524e-02 	 Res : 3.26501e-03 	 Jac : 1.60518e-02 	 Enc : 3.38761e-03 	 AE : 6.61708e-05 	 MSE : 1.81732e-01
Training Epoch 348 finished, took current epoch 536.17s, cumulative time 168656.20s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 349, 25% 	 Loss : 2.2984e-02 	 Res : 3.2700e-03 	 Jac : 1.6082e-02 	 Enc : 3.3742e-03 	 AEnc : 7.2092e-05 	 MSE : 1.8576e-01
Epoch 349, 50% 	 Loss : 2.2961e-02 	 Res : 3.2983e-03 	 Jac : 1.6000e-02 	 Enc : 3.3774e-03 	 AEnc : 9.4984e-05 	 MSE : 1.9057e-01
Epoch 349, 75% 	 Loss : 2.2991e-02 	 Res : 3.2753e-03 	 Jac : 1.6023e-02 	 Enc : 3.3992e-03 	 AEnc : 9.1469e-05 	 MSE : 2.0297e-01
Training Epoch 349 : 	 Train : 2.29505e-02 	 Res : 3.26529e-03 	 Jac : 1.60171e-02 	 Enc : 3.38272e-03 	 AE : 8.13871e-05 	 MSE : 2.04004e-01
Validation Epoch 349 : 	 Train : 2.30056e-02 	 Res : 3.28124e-03 	 Jac : 1.60938e-02 	 Enc : 3.38774e-03 	 AE : 6.83888e-05 	 MSE : 1.74476e-01
Training Epoch 349 finished, took current epoch 545.23s, cumulative time 169201.39s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 350, 25% 	 Loss : 2.3079e-02 	 Res : 3.3232e-03 	 Jac : 1.6035e-02 	 Enc : 3.3831e-03 	 AEnc : 8.0234e-05 	 MSE : 2.5709e-01
Epoch 350, 50% 	 Loss : 2.3223e-02 	 Res : 3.3340e-03 	 Jac : 1.6129e-02 	 Enc : 3.3798e-03 	 AEnc : 7.5854e-05 	 MSE : 3.0427e-01
Epoch 350, 75% 	 Loss : 2.3082e-02 	 Res : 3.3515e-03 	 Jac : 1.5964e-02 	 Enc : 3.3878e-03 	 AEnc : 6.9621e-05 	 MSE : 3.0892e-01
Training Epoch 350 : 	 Train : 2.31081e-02 	 Res : 3.33088e-03 	 Jac : 1.60365e-02 	 Enc : 3.38196e-03 	 AE : 7.22369e-05 	 MSE : 2.86547e-01
Validation Epoch 350 : 	 Train : 2.30057e-02 	 Res : 3.27952e-03 	 Jac : 1.60293e-02 	 Enc : 3.38875e-03 	 AE : 7.59631e-05 	 MSE : 2.32190e-01
Training Epoch 350 finished, took current epoch 542.86s, cumulative time 169744.23s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 351, 25% 	 Loss : 2.2824e-02 	 Res : 3.2074e-03 	 Jac : 1.5975e-02 	 Enc : 3.3945e-03 	 AEnc : 7.0505e-05 	 MSE : 1.7624e-01
Epoch 351, 50% 	 Loss : 2.2969e-02 	 Res : 3.2872e-03 	 Jac : 1.6033e-02 	 Enc : 3.3789e-03 	 AEnc : 8.4632e-05 	 MSE : 1.8576e-01
Epoch 351, 75% 	 Loss : 2.3035e-02 	 Res : 3.2791e-03 	 Jac : 1.6103e-02 	 Enc : 3.3792e-03 	 AEnc : 6.2758e-05 	 MSE : 2.1113e-01
Training Epoch 351 : 	 Train : 2.29304e-02 	 Res : 3.25337e-03 	 Jac : 1.60340e-02 	 Enc : 3.38041e-03 	 AE : 7.35147e-05 	 MSE : 1.89126e-01
Validation Epoch 351 : 	 Train : 2.29882e-02 	 Res : 3.30136e-03 	 Jac : 1.59452e-02 	 Enc : 3.38543e-03 	 AE : 9.02447e-05 	 MSE : 2.65964e-01
Training Epoch 351 finished, took current epoch 545.65s, cumulative time 170289.86s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 352, 25% 	 Loss : 2.3074e-02 	 Res : 3.3344e-03 	 Jac : 1.6038e-02 	 Enc : 3.3757e-03 	 AEnc : 7.9965e-05 	 MSE : 2.4642e-01
Epoch 352, 50% 	 Loss : 2.3003e-02 	 Res : 3.3169e-03 	 Jac : 1.5986e-02 	 Enc : 3.3651e-03 	 AEnc : 7.4442e-05 	 MSE : 2.5984e-01
Epoch 352, 75% 	 Loss : 2.3050e-02 	 Res : 3.3068e-03 	 Jac : 1.6064e-02 	 Enc : 3.4042e-03 	 AEnc : 7.5537e-05 	 MSE : 1.9906e-01
Training Epoch 352 : 	 Train : 2.30359e-02 	 Res : 3.29994e-03 	 Jac : 1.60495e-02 	 Enc : 3.37812e-03 	 AE : 8.31345e-05 	 MSE : 2.25224e-01
Validation Epoch 352 : 	 Train : 2.28836e-02 	 Res : 3.26404e-03 	 Jac : 1.59886e-02 	 Enc : 3.38216e-03 	 AE : 7.42685e-05 	 MSE : 1.74476e-01
Training Epoch 352 finished, took current epoch 543.11s, cumulative time 170832.90s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
MODEL SAVED
Epoch 353, 25% 	 Loss : 2.3146e-02 	 Res : 3.3686e-03 	 Jac : 1.5965e-02 	 Enc : 3.3704e-03 	 AEnc : 7.3346e-05 	 MSE : 3.6895e-01
Epoch 353, 50% 	 Loss : 2.3069e-02 	 Res : 3.3453e-03 	 Jac : 1.6036e-02 	 Enc : 3.3707e-03 	 AEnc : 8.7601e-05 	 MSE : 2.2955e-01
Epoch 353, 75% 	 Loss : 2.3105e-02 	 Res : 3.3031e-03 	 Jac : 1.6094e-02 	 Enc : 3.3865e-03 	 AEnc : 8.1006e-05 	 MSE : 2.4049e-01
Training Epoch 353 : 	 Train : 2.30678e-02 	 Res : 3.31176e-03 	 Jac : 1.60350e-02 	 Enc : 3.37674e-03 	 AE : 7.78996e-05 	 MSE : 2.66448e-01
Validation Epoch 353 : 	 Train : 2.31400e-02 	 Res : 3.32524e-03 	 Jac : 1.60688e-02 	 Enc : 3.38806e-03 	 AE : 6.33121e-05 	 MSE : 2.94676e-01
Training Epoch 353 finished, took current epoch 545.23s, cumulative time 171378.09s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 354, 25% 	 Loss : 2.2973e-02 	 Res : 3.2508e-03 	 Jac : 1.6055e-02 	 Enc : 3.3632e-03 	 AEnc : 6.9411e-05 	 MSE : 2.3427e-01
Epoch 354, 50% 	 Loss : 2.2968e-02 	 Res : 3.2837e-03 	 Jac : 1.6024e-02 	 Enc : 3.3749e-03 	 AEnc : 6.5181e-05 	 MSE : 2.2011e-01
Epoch 354, 75% 	 Loss : 2.2964e-02 	 Res : 3.2619e-03 	 Jac : 1.6006e-02 	 Enc : 3.3891e-03 	 AEnc : 6.9358e-05 	 MSE : 2.3774e-01
Training Epoch 354 : 	 Train : 2.30542e-02 	 Res : 3.30232e-03 	 Jac : 1.60342e-02 	 Enc : 3.37543e-03 	 AE : 6.93874e-05 	 MSE : 2.72819e-01
Validation Epoch 354 : 	 Train : 2.29215e-02 	 Res : 3.24414e-03 	 Jac : 1.60484e-02 	 Enc : 3.38186e-03 	 AE : 6.40117e-05 	 MSE : 1.83050e-01
Training Epoch 354 finished, took current epoch 541.13s, cumulative time 171919.17s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
MODEL SAVED
Epoch 355, 25% 	 Loss : 2.2883e-02 	 Res : 3.2031e-03 	 Jac : 1.6048e-02 	 Enc : 3.3505e-03 	 AEnc : 6.9853e-05 	 MSE : 2.1153e-01
Epoch 355, 50% 	 Loss : 2.3021e-02 	 Res : 3.2962e-03 	 Jac : 1.6052e-02 	 Enc : 3.3983e-03 	 AEnc : 6.4084e-05 	 MSE : 2.1043e-01
Epoch 355, 75% 	 Loss : 2.2994e-02 	 Res : 3.2669e-03 	 Jac : 1.6059e-02 	 Enc : 3.3745e-03 	 AEnc : 7.3004e-05 	 MSE : 2.1994e-01
Training Epoch 355 : 	 Train : 2.30895e-02 	 Res : 3.30850e-03 	 Jac : 1.60624e-02 	 Enc : 3.37463e-03 	 AE : 7.57838e-05 	 MSE : 2.68097e-01
Validation Epoch 355 : 	 Train : 2.28893e-02 	 Res : 3.25319e-03 	 Jac : 1.59701e-02 	 Enc : 3.36997e-03 	 AE : 9.58580e-05 	 MSE : 2.00266e-01
Training Epoch 355 finished, took current epoch 543.07s, cumulative time 172462.22s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 356, 25% 	 Loss : 2.2902e-02 	 Res : 3.2404e-03 	 Jac : 1.6006e-02 	 Enc : 3.3540e-03 	 AEnc : 8.7651e-05 	 MSE : 2.1365e-01
Epoch 356, 50% 	 Loss : 2.2872e-02 	 Res : 3.2189e-03 	 Jac : 1.6035e-02 	 Enc : 3.3578e-03 	 AEnc : 7.4589e-05 	 MSE : 1.8593e-01
Epoch 356, 75% 	 Loss : 2.3076e-02 	 Res : 3.2960e-03 	 Jac : 1.6076e-02 	 Enc : 3.3912e-03 	 AEnc : 9.2599e-05 	 MSE : 2.1976e-01
Training Epoch 356 : 	 Train : 2.30214e-02 	 Res : 3.27342e-03 	 Jac : 1.60466e-02 	 Enc : 3.37293e-03 	 AE : 1.09906e-04 	 MSE : 2.18492e-01
Validation Epoch 356 : 	 Train : 2.31043e-02 	 Res : 3.30952e-03 	 Jac : 1.60773e-02 	 Enc : 3.37478e-03 	 AE : 1.02751e-04 	 MSE : 2.39999e-01
Training Epoch 356 finished, took current epoch 544.88s, cumulative time 173007.10s
Current Learning rate DEQ : 1.661646528480048e-05
Current Learning rate AUTOENC : 3.323293056960096e-05
Epoch 357, 25% 	 Loss : 2.3025e-02 	 Res : 3.2279e-03 	 Jac : 1.6149e-02 	 Enc : 3.3669e-03 	 AEnc : 9.6384e-05 	 MSE : 1.8410e-01
Epoch 357, 50% 	 Loss : 2.3065e-02 	 Res : 3.2663e-03 	 Jac : 1.6125e-02 	 Enc : 3.3823e-03 	 AEnc : 8.8160e-05 	 MSE : 2.0322e-01
Epoch 357, 75% 	 Loss : 2.3103e-02 	 Res : 3.3364e-03 	 Jac : 1.6090e-02 	 Enc : 3.3631e-03 	 AEnc : 7.6157e-05 	 MSE : 2.3728e-01
Training Epoch 357 : 	 Train : 2.30150e-02 	 Res : 3.25456e-03 	 Jac : 1.61054e-02 	 Enc : 3.37124e-03 	 AE : 8.14145e-05 	 MSE : 2.02295e-01
Validation Epoch 357 : 	 Train : 2.29755e-02 	 Res : 3.30332e-03 	 Jac : 1.60500e-02 	 Enc : 3.36842e-03 	 AE : 5.51866e-05 	 MSE : 1.98584e-01
Training Epoch 357 finished, took current epoch 532.91s, cumulative time 173539.96s
Current Learning rate DEQ : 1.1631525699360336e-05
Current Learning rate AUTOENC : 2.3263051398720672e-05
Epoch 358, 25% 	 Loss : 2.2986e-02 	 Res : 3.2452e-03 	 Jac : 1.6129e-02 	 Enc : 3.3725e-03 	 AEnc : 6.7480e-05 	 MSE : 1.7243e-01
Epoch 358, 50% 	 Loss : 2.2861e-02 	 Res : 3.1593e-03 	 Jac : 1.6068e-02 	 Enc : 3.3607e-03 	 AEnc : 8.0366e-05 	 MSE : 1.9266e-01
Epoch 358, 75% 	 Loss : 2.2946e-02 	 Res : 3.2562e-03 	 Jac : 1.6089e-02 	 Enc : 3.3706e-03 	 AEnc : 6.5065e-05 	 MSE : 1.6562e-01
Training Epoch 358 : 	 Train : 2.29472e-02 	 Res : 3.23636e-03 	 Jac : 1.60850e-02 	 Enc : 3.36943e-03 	 AE : 7.54757e-05 	 MSE : 1.80879e-01
Validation Epoch 358 : 	 Train : 2.29324e-02 	 Res : 3.26188e-03 	 Jac : 1.59850e-02 	 Enc : 3.37688e-03 	 AE : 5.82100e-05 	 MSE : 2.50450e-01
Training Epoch 358 finished, took current epoch 542.83s, cumulative time 174082.74s
Current Learning rate DEQ : 1.1631525699360336e-05
Current Learning rate AUTOENC : 2.3263051398720672e-05
Epoch 359, 25% 	 Loss : 2.2949e-02 	 Res : 3.2490e-03 	 Jac : 1.6070e-02 	 Enc : 3.3693e-03 	 AEnc : 7.1729e-05 	 MSE : 1.8857e-01
Epoch 359, 50% 	 Loss : 2.2846e-02 	 Res : 3.2185e-03 	 Jac : 1.6004e-02 	 Enc : 3.3771e-03 	 AEnc : 6.9791e-05 	 MSE : 1.7613e-01
Epoch 359, 75% 	 Loss : 2.3072e-02 	 Res : 3.2926e-03 	 Jac : 1.6129e-02 	 Enc : 3.3669e-03 	 AEnc : 7.3471e-05 	 MSE : 2.1089e-01
Training Epoch 359 : 	 Train : 2.29447e-02 	 Res : 3.23586e-03 	 Jac : 1.60656e-02 	 Enc : 3.37010e-03 	 AE : 7.44126e-05 	 MSE : 1.98776e-01
Validation Epoch 359 : 	 Train : 2.29310e-02 	 Res : 3.21393e-03 	 Jac : 1.61019e-02 	 Enc : 3.36812e-03 	 AE : 6.94900e-05 	 MSE : 1.77639e-01
Training Epoch 359 finished, took current epoch 564.48s, cumulative time 174647.15s
Current Learning rate DEQ : 1.1631525699360336e-05
Current Learning rate AUTOENC : 2.3263051398720672e-05
MODEL SAVED
Epoch 360, 25% 	 Loss : 2.2911e-02 	 Res : 3.2278e-03 	 Jac : 1.6081e-02 	 Enc : 3.3541e-03 	 AEnc : 6.4207e-05 	 MSE : 1.8321e-01
Epoch 360, 50% 	 Loss : 2.2829e-02 	 Res : 3.1564e-03 	 Jac : 1.6041e-02 	 Enc : 3.3724e-03 	 AEnc : 6.9999e-05 	 MSE : 1.8955e-01
Epoch 360, 75% 	 Loss : 2.2959e-02 	 Res : 3.2422e-03 	 Jac : 1.6073e-02 	 Enc : 3.3868e-03 	 AEnc : 6.9907e-05 	 MSE : 1.8793e-01
Training Epoch 360 : 	 Train : 2.29248e-02 	 Res : 3.22428e-03 	 Jac : 1.60728e-02 	 Enc : 3.36865e-03 	 AE : 6.65298e-05 	 MSE : 1.92602e-01
Validation Epoch 360 : 	 Train : 2.32120e-02 	 Res : 3.34267e-03 	 Jac : 1.60707e-02 	 Enc : 3.37854e-03 	 AE : 5.99612e-05 	 MSE : 3.60156e-01
Training Epoch 360 finished, took current epoch 554.53s, cumulative time 175201.66s
Current Learning rate DEQ : 1.1631525699360336e-05
Current Learning rate AUTOENC : 2.3263051398720672e-05
Epoch 361, 25% 	 Loss : 2.2858e-02 	 Res : 3.1595e-03 	 Jac : 1.6097e-02 	 Enc : 3.3472e-03 	 AEnc : 6.5420e-05 	 MSE : 1.8818e-01
Epoch 361, 50% 	 Loss : 2.2849e-02 	 Res : 3.2023e-03 	 Jac : 1.6017e-02 	 Enc : 3.3744e-03 	 AEnc : 7.3710e-05 	 MSE : 1.8075e-01
Epoch 361, 75% 	 Loss : 2.2764e-02 	 Res : 3.2005e-03 	 Jac : 1.5904e-02 	 Enc : 3.3723e-03 	 AEnc : 7.0395e-05 	 MSE : 2.1677e-01
Training Epoch 361 : 	 Train : 2.28804e-02 	 Res : 3.22860e-03 	 Jac : 1.60226e-02 	 Enc : 3.36760e-03 	 AE : 6.89915e-05 	 MSE : 1.92606e-01
Validation Epoch 361 : 	 Train : 2.27868e-02 	 Res : 3.23176e-03 	 Jac : 1.59174e-02 	 Enc : 3.37388e-03 	 AE : 6.79867e-05 	 MSE : 1.95762e-01
Training Epoch 361 finished, took current epoch 558.56s, cumulative time 175760.21s
Current Learning rate DEQ : 1.1631525699360336e-05
Current Learning rate AUTOENC : 2.3263051398720672e-05
Epoch 362, 25% 	 Loss : 2.2975e-02 	 Res : 3.2072e-03 	 Jac : 1.6144e-02 	 Enc : 3.3670e-03 	 AEnc : 6.7968e-05 	 MSE : 1.8956e-01
Epoch 362, 50% 	 Loss : 2.3371e-02 	 Res : 3.5060e-03 	 Jac : 1.6016e-02 	 Enc : 3.3759e-03 	 AEnc : 7.1795e-05 	 MSE : 4.0170e-01
Epoch 362, 75% 	 Loss : 2.3033e-02 	 Res : 3.2673e-03 	 Jac : 1.6142e-02 	 Enc : 3.3639e-03 	 AEnc : 6.4170e-05 	 MSE : 1.9516e-01
Training Epoch 362 : 	 Train : 2.30737e-02 	 Res : 3.29426e-03 	 Jac : 1.60960e-02 	 Enc : 3.36678e-03 	 AE : 6.95913e-05 	 MSE : 2.47034e-01
Validation Epoch 362 : 	 Train : 2.27322e-02 	 Res : 3.19803e-03 	 Jac : 1.59300e-02 	 Enc : 3.36774e-03 	 AE : 5.28015e-05 	 MSE : 1.83619e-01
Training Epoch 362 finished, took current epoch 550.47s, cumulative time 176310.60s
Current Learning rate DEQ : 1.1631525699360336e-05
Current Learning rate AUTOENC : 2.3263051398720672e-05
MODEL SAVED
Epoch 363, 25% 	 Loss : 2.2781e-02 	 Res : 3.2134e-03 	 Jac : 1.5974e-02 	 Enc : 3.3587e-03 	 AEnc : 6.6324e-05 	 MSE : 1.6831e-01
Epoch 363, 50% 	 Loss : 2.2889e-02 	 Res : 3.2821e-03 	 Jac : 1.6004e-02 	 Enc : 3.3615e-03 	 AEnc : 5.5724e-05 	 MSE : 1.8545e-01
Epoch 363, 75% 	 Loss : 2.2904e-02 	 Res : 3.2413e-03 	 Jac : 1.5999e-02 	 Enc : 3.3916e-03 	 AEnc : 6.7316e-05 	 MSE : 2.0533e-01
Training Epoch 363 : 	 Train : 2.28455e-02 	 Res : 3.22910e-03 	 Jac : 1.59962e-02 	 Enc : 3.36607e-03 	 AE : 6.56524e-05 	 MSE : 1.88433e-01
Validation Epoch 363 : 	 Train : 2.28921e-02 	 Res : 3.25663e-03 	 Jac : 1.60120e-02 	 Enc : 3.37002e-03 	 AE : 7.52132e-05 	 MSE : 1.78298e-01
Training Epoch 363 finished, took current epoch 552.32s, cumulative time 176862.87s
Current Learning rate DEQ : 1.1631525699360336e-05
Current Learning rate AUTOENC : 2.3263051398720672e-05
Epoch 364, 25% 	 Loss : 2.2861e-02 	 Res : 3.1713e-03 	 Jac : 1.6045e-02 	 Enc : 3.3699e-03 	 AEnc : 7.0045e-05 	 MSE : 2.0517e-01
Epoch 364, 50% 	 Loss : 2.4776e-02 	 Res : 4.7103e-03 	 Jac : 1.6068e-02 	 Enc : 3.3749e-03 	 AEnc : 1.0044e-04 	 MSE : 5.2260e-01
Epoch 364, 75% 	 Loss : 2.3074e-02 	 Res : 3.3332e-03 	 Jac : 1.6011e-02 	 Enc : 3.3651e-03 	 AEnc : 6.9987e-05 	 MSE : 2.9510e-01
Training Epoch 364 : 	 Train : 2.34524e-02 	 Res : 3.62341e-03 	 Jac : 1.60577e-02 	 Enc : 3.36646e-03 	 AE : 7.79583e-05 	 MSE : 3.26864e-01
Validation Epoch 364 : 	 Train : 2.28518e-02 	 Res : 3.23053e-03 	 Jac : 1.59802e-02 	 Enc : 3.36024e-03 	 AE : 5.30559e-05 	 MSE : 2.27831e-01
Training Epoch 364 finished, took current epoch 557.66s, cumulative time 177420.48s
Current Learning rate DEQ : 1.1631525699360336e-05
Current Learning rate AUTOENC : 2.3263051398720672e-05
Epoch 365, 25% 	 Loss : 2.2879e-02 	 Res : 3.2506e-03 	 Jac : 1.6011e-02 	 Enc : 3.3754e-03 	 AEnc : 6.8067e-05 	 MSE : 1.7427e-01
Epoch 365, 50% 	 Loss : 2.2879e-02 	 Res : 3.1976e-03 	 Jac : 1.6084e-02 	 Enc : 3.3589e-03 	 AEnc : 6.9765e-05 	 MSE : 1.6828e-01
Epoch 365, 75% 	 Loss : 2.2833e-02 	 Res : 3.1943e-03 	 Jac : 1.6034e-02 	 Enc : 3.3537e-03 	 AEnc : 6.1660e-05 	 MSE : 1.8986e-01
Training Epoch 365 : 	 Train : 2.28786e-02 	 Res : 3.22041e-03 	 Jac : 1.60401e-02 	 Enc : 3.36500e-03 	 AE : 6.74537e-05 	 MSE : 1.85656e-01
Validation Epoch 365 : 	 Train : 2.29444e-02 	 Res : 3.27953e-03 	 Jac : 1.59916e-02 	 Enc : 3.36881e-03 	 AE : 6.22884e-05 	 MSE : 2.42204e-01
Training Epoch 365 finished, took current epoch 547.81s, cumulative time 177968.24s
Current Learning rate DEQ : 1.1631525699360336e-05
Current Learning rate AUTOENC : 2.3263051398720672e-05
Epoch 366, 25% 	 Loss : 2.2969e-02 	 Res : 3.2628e-03 	 Jac : 1.6073e-02 	 Enc : 3.3737e-03 	 AEnc : 7.0793e-05 	 MSE : 1.8873e-01
Epoch 366, 50% 	 Loss : 2.2825e-02 	 Res : 3.1674e-03 	 Jac : 1.6059e-02 	 Enc : 3.3634e-03 	 AEnc : 6.6208e-05 	 MSE : 1.6950e-01
Epoch 366, 75% 	 Loss : 2.2849e-02 	 Res : 3.1812e-03 	 Jac : 1.6042e-02 	 Enc : 3.3515e-03 	 AEnc : 8.5656e-05 	 MSE : 1.8908e-01
Training Epoch 366 : 	 Train : 2.29075e-02 	 Res : 3.23583e-03 	 Jac : 1.60316e-02 	 Enc : 3.36323e-03 	 AE : 7.59714e-05 	 MSE : 2.00874e-01
Validation Epoch 366 : 	 Train : 2.28100e-02 	 Res : 3.18209e-03 	 Jac : 1.60240e-02 	 Enc : 3.36191e-03 	 AE : 6.44520e-05 	 MSE : 1.77518e-01
Training Epoch 366 finished, took current epoch 549.61s, cumulative time 178517.78s
Current Learning rate DEQ : 1.1631525699360336e-05
Current Learning rate AUTOENC : 2.3263051398720672e-05
MODEL SAVED
Epoch 367, 25% 	 Loss : 2.2841e-02 	 Res : 3.1983e-03 	 Jac : 1.6012e-02 	 Enc : 3.3678e-03 	 AEnc : 7.2035e-05 	 MSE : 1.9073e-01
Epoch 367, 50% 	 Loss : 2.2810e-02 	 Res : 3.1944e-03 	 Jac : 1.5999e-02 	 Enc : 3.3519e-03 	 AEnc : 7.0039e-05 	 MSE : 1.9400e-01
Epoch 367, 75% 	 Loss : 2.2948e-02 	 Res : 3.2687e-03 	 Jac : 1.6043e-02 	 Enc : 3.3571e-03 	 AEnc : 6.9054e-05 	 MSE : 2.1067e-01
Training Epoch 367 : 	 Train : 2.28894e-02 	 Res : 3.23117e-03 	 Jac : 1.60271e-02 	 Enc : 3.36225e-03 	 AE : 7.02693e-05 	 MSE : 1.98645e-01
Validation Epoch 367 : 	 Train : 2.28598e-02 	 Res : 3.24192e-03 	 Jac : 1.60004e-02 	 Enc : 3.35955e-03 	 AE : 6.14603e-05 	 MSE : 1.96423e-01
Training Epoch 367 finished, took current epoch 547.54s, cumulative time 179065.28s
Current Learning rate DEQ : 1.1631525699360336e-05
Current Learning rate AUTOENC : 2.3263051398720672e-05
Epoch 368, 25% 	 Loss : 2.3112e-02 	 Res : 3.2989e-03 	 Jac : 1.6150e-02 	 Enc : 3.3863e-03 	 AEnc : 6.9112e-05 	 MSE : 2.0733e-01
Epoch 368, 50% 	 Loss : 2.2946e-02 	 Res : 3.2323e-03 	 Jac : 1.6025e-02 	 Enc : 3.3660e-03 	 AEnc : 7.0777e-05 	 MSE : 2.5268e-01
Epoch 368, 75% 	 Loss : 2.2806e-02 	 Res : 3.1204e-03 	 Jac : 1.6084e-02 	 Enc : 3.3392e-03 	 AEnc : 6.5967e-05 	 MSE : 1.9564e-01
Training Epoch 368 : 	 Train : 2.29492e-02 	 Res : 3.22880e-03 	 Jac : 1.60812e-02 	 Enc : 3.36119e-03 	 AE : 7.02357e-05 	 MSE : 2.07779e-01
Validation Epoch 368 : 	 Train : 2.29212e-02 	 Res : 3.20954e-03 	 Jac : 1.60782e-02 	 Enc : 3.35762e-03 	 AE : 6.49476e-05 	 MSE : 2.10891e-01
Training Epoch 368 finished, took current epoch 550.55s, cumulative time 179615.80s
Current Learning rate DEQ : 1.1631525699360336e-05
Current Learning rate AUTOENC : 2.3263051398720672e-05
Epoch 369, 25% 	 Loss : 2.2827e-02 	 Res : 3.2027e-03 	 Jac : 1.5992e-02 	 Enc : 3.3556e-03 	 AEnc : 9.0955e-05 	 MSE : 1.8627e-01
Epoch 369, 50% 	 Loss : 2.2691e-02 	 Res : 3.1600e-03 	 Jac : 1.5919e-02 	 Enc : 3.3653e-03 	 AEnc : 6.9472e-05 	 MSE : 1.7676e-01
Epoch 369, 75% 	 Loss : 2.2860e-02 	 Res : 3.2049e-03 	 Jac : 1.6050e-02 	 Enc : 3.3635e-03 	 AEnc : 6.7144e-05 	 MSE : 1.7509e-01
Training Epoch 369 : 	 Train : 2.28186e-02 	 Res : 3.19503e-03 	 Jac : 1.60128e-02 	 Enc : 3.36112e-03 	 AE : 7.36637e-05 	 MSE : 1.76024e-01
Validation Epoch 369 : 	 Train : 2.30671e-02 	 Res : 3.27701e-03 	 Jac : 1.60529e-02 	 Enc : 3.35433e-03 	 AE : 6.42447e-05 	 MSE : 3.18597e-01
Training Epoch 369 finished, took current epoch 553.29s, cumulative time 180169.04s
Current Learning rate DEQ : 1.1631525699360336e-05
Current Learning rate AUTOENC : 2.3263051398720672e-05
Epoch 370, 25% 	 Loss : 2.2737e-02 	 Res : 3.1833e-03 	 Jac : 1.5952e-02 	 Enc : 3.3389e-03 	 AEnc : 6.1350e-05 	 MSE : 2.0160e-01
Epoch 370, 50% 	 Loss : 2.3297e-02 	 Res : 3.3791e-03 	 Jac : 1.6056e-02 	 Enc : 3.3761e-03 	 AEnc : 6.2265e-05 	 MSE : 4.2329e-01
Epoch 370, 75% 	 Loss : 2.2842e-02 	 Res : 3.2243e-03 	 Jac : 1.5980e-02 	 Enc : 3.3687e-03 	 AEnc : 6.6179e-05 	 MSE : 2.0240e-01
Training Epoch 370 : 	 Train : 2.29581e-02 	 Res : 3.25303e-03 	 Jac : 1.60298e-02 	 Enc : 3.35908e-03 	 AE : 6.69799e-05 	 MSE : 2.49194e-01
Validation Epoch 370 : 	 Train : 2.28103e-02 	 Res : 3.18002e-03 	 Jac : 1.59513e-02 	 Enc : 3.35826e-03 	 AE : 1.36650e-04 	 MSE : 1.84068e-01
Training Epoch 370 finished, took current epoch 546.86s, cumulative time 180715.87s
Current Learning rate DEQ : 1.1631525699360336e-05
Current Learning rate AUTOENC : 2.3263051398720672e-05
MODEL SAVED
Epoch 371, 25% 	 Loss : 2.2861e-02 	 Res : 3.1726e-03 	 Jac : 1.6062e-02 	 Enc : 3.3506e-03 	 AEnc : 7.3031e-05 	 MSE : 2.0244e-01
Epoch 371, 50% 	 Loss : 2.3002e-02 	 Res : 3.2543e-03 	 Jac : 1.6113e-02 	 Enc : 3.3758e-03 	 AEnc : 6.9330e-05 	 MSE : 1.8879e-01
Epoch 371, 75% 	 Loss : 2.2881e-02 	 Res : 3.2644e-03 	 Jac : 1.5921e-02 	 Enc : 3.3440e-03 	 AEnc : 6.8680e-05 	 MSE : 2.8231e-01
Training Epoch 371 : 	 Train : 2.29341e-02 	 Res : 3.24577e-03 	 Jac : 1.60219e-02 	 Enc : 3.35826e-03 	 AE : 7.02575e-05 	 MSE : 2.37920e-01
Validation Epoch 371 : 	 Train : 2.27630e-02 	 Res : 3.19899e-03 	 Jac : 1.59839e-02 	 Enc : 3.36267e-03 	 AE : 5.69802e-05 	 MSE : 1.60395e-01
Training Epoch 371 finished, took current epoch 536.04s, cumulative time 181251.86s
Current Learning rate DEQ : 1.1631525699360336e-05
Current Learning rate AUTOENC : 2.3263051398720672e-05
Epoch 372, 25% 	 Loss : 2.2744e-02 	 Res : 3.1704e-03 	 Jac : 1.5979e-02 	 Enc : 3.3512e-03 	 AEnc : 6.4417e-05 	 MSE : 1.7926e-01
Epoch 372, 50% 	 Loss : 2.2938e-02 	 Res : 3.2804e-03 	 Jac : 1.6035e-02 	 Enc : 3.3715e-03 	 AEnc : 6.8786e-05 	 MSE : 1.8228e-01
Epoch 372, 75% 	 Loss : 2.2740e-02 	 Res : 3.1394e-03 	 Jac : 1.5999e-02 	 Enc : 3.3465e-03 	 AEnc : 6.5286e-05 	 MSE : 1.8927e-01
Training Epoch 372 : 	 Train : 2.28030e-02 	 Res : 3.20917e-03 	 Jac : 1.59854e-02 	 Enc : 3.35759e-03 	 AE : 6.48462e-05 	 MSE : 1.86017e-01
Validation Epoch 372 : 	 Train : 2.28567e-02 	 Res : 3.25157e-03 	 Jac : 1.59365e-02 	 Enc : 3.36771e-03 	 AE : 5.75442e-05 	 MSE : 2.43340e-01
Training Epoch 372 finished, took current epoch 539.71s, cumulative time 181791.56s
Current Learning rate DEQ : 1.1631525699360336e-05
Current Learning rate AUTOENC : 2.3263051398720672e-05
Epoch 373, 25% 	 Loss : 2.2812e-02 	 Res : 3.2281e-03 	 Jac : 1.5956e-02 	 Enc : 3.3758e-03 	 AEnc : 6.6612e-05 	 MSE : 1.8621e-01
Epoch 373, 50% 	 Loss : 2.2939e-02 	 Res : 3.1818e-03 	 Jac : 1.6167e-02 	 Enc : 3.3415e-03 	 AEnc : 7.6554e-05 	 MSE : 1.7158e-01
Epoch 373, 75% 	 Loss : 2.2904e-02 	 Res : 3.2071e-03 	 Jac : 1.6098e-02 	 Enc : 3.3588e-03 	 AEnc : 5.7983e-05 	 MSE : 1.8256e-01
Training Epoch 373 : 	 Train : 2.28125e-02 	 Res : 3.19635e-03 	 Jac : 1.60140e-02 	 Enc : 3.35621e-03 	 AE : 6.63366e-05 	 MSE : 1.79605e-01
Validation Epoch 373 : 	 Train : 2.29028e-02 	 Res : 3.22157e-03 	 Jac : 1.60969e-02 	 Enc : 3.35583e-03 	 AE : 5.42064e-05 	 MSE : 1.74253e-01
Training Epoch 373 finished, took current epoch 516.90s, cumulative time 182308.45s
Current Learning rate DEQ : 8.142067989552235e-06
Current Learning rate AUTOENC : 1.628413597910447e-05
Epoch 374, 25% 	 Loss : 2.2684e-02 	 Res : 3.1889e-03 	 Jac : 1.5923e-02 	 Enc : 3.3528e-03 	 AEnc : 5.8061e-05 	 MSE : 1.6095e-01
Epoch 374, 50% 	 Loss : 2.2746e-02 	 Res : 3.2105e-03 	 Jac : 1.5933e-02 	 Enc : 3.3650e-03 	 AEnc : 7.0612e-05 	 MSE : 1.6676e-01
Epoch 374, 75% 	 Loss : 2.3915e-02 	 Res : 3.7852e-03 	 Jac : 1.6127e-02 	 Enc : 3.3507e-03 	 AEnc : 6.7895e-05 	 MSE : 5.8393e-01
Training Epoch 374 : 	 Train : 2.30408e-02 	 Res : 3.32883e-03 	 Jac : 1.60232e-02 	 Enc : 3.35468e-03 	 AE : 6.32238e-05 	 MSE : 2.70878e-01
Validation Epoch 374 : 	 Train : 2.29156e-02 	 Res : 3.18858e-03 	 Jac : 1.61219e-02 	 Enc : 3.35975e-03 	 AE : 5.48193e-05 	 MSE : 1.90570e-01
Training Epoch 374 finished, took current epoch 537.81s, cumulative time 182846.22s
Current Learning rate DEQ : 8.142067989552235e-06
Current Learning rate AUTOENC : 1.628413597910447e-05
Epoch 375, 25% 	 Loss : 2.2725e-02 	 Res : 3.1779e-03 	 Jac : 1.5958e-02 	 Enc : 3.3693e-03 	 AEnc : 6.0794e-05 	 MSE : 1.5945e-01
Epoch 375, 50% 	 Loss : 2.2618e-02 	 Res : 3.1023e-03 	 Jac : 1.5943e-02 	 Enc : 3.3375e-03 	 AEnc : 6.2398e-05 	 MSE : 1.7305e-01
Epoch 375, 75% 	 Loss : 2.2835e-02 	 Res : 3.1999e-03 	 Jac : 1.6073e-02 	 Enc : 3.3453e-03 	 AEnc : 5.8661e-05 	 MSE : 1.5842e-01
Training Epoch 375 : 	 Train : 2.27939e-02 	 Res : 3.18897e-03 	 Jac : 1.60140e-02 	 Enc : 3.35384e-03 	 AE : 6.25078e-05 	 MSE : 1.74572e-01
Validation Epoch 375 : 	 Train : 2.29107e-02 	 Res : 3.17929e-03 	 Jac : 1.61215e-02 	 Enc : 3.35656e-03 	 AE : 9.05643e-05 	 MSE : 1.62737e-01
Training Epoch 375 finished, took current epoch 526.33s, cumulative time 183372.48s
Current Learning rate DEQ : 8.142067989552235e-06
Current Learning rate AUTOENC : 1.628413597910447e-05
MODEL SAVED
Epoch 376, 25% 	 Loss : 2.2786e-02 	 Res : 3.2004e-03 	 Jac : 1.5965e-02 	 Enc : 3.3536e-03 	 AEnc : 6.8734e-05 	 MSE : 1.9791e-01
Epoch 376, 50% 	 Loss : 2.2730e-02 	 Res : 3.1901e-03 	 Jac : 1.5978e-02 	 Enc : 3.3402e-03 	 AEnc : 6.2368e-05 	 MSE : 1.5933e-01
Epoch 376, 75% 	 Loss : 2.2748e-02 	 Res : 3.1958e-03 	 Jac : 1.5959e-02 	 Enc : 3.3530e-03 	 AEnc : 6.2912e-05 	 MSE : 1.7734e-01
Training Epoch 376 : 	 Train : 2.27543e-02 	 Res : 3.19337e-03 	 Jac : 1.59646e-02 	 Enc : 3.35179e-03 	 AE : 6.42390e-05 	 MSE : 1.80376e-01
Validation Epoch 376 : 	 Train : 2.28131e-02 	 Res : 3.22230e-03 	 Jac : 1.59835e-02 	 Enc : 3.34828e-03 	 AE : 5.77785e-05 	 MSE : 2.01250e-01
Training Epoch 376 finished, took current epoch 524.73s, cumulative time 183897.19s
Current Learning rate DEQ : 8.142067989552235e-06
Current Learning rate AUTOENC : 1.628413597910447e-05
Epoch 377, 25% 	 Loss : 2.2713e-02 	 Res : 3.1697e-03 	 Jac : 1.5951e-02 	 Enc : 3.3359e-03 	 AEnc : 6.3829e-05 	 MSE : 1.9210e-01
Epoch 377, 50% 	 Loss : 2.2728e-02 	 Res : 3.1556e-03 	 Jac : 1.5992e-02 	 Enc : 3.3450e-03 	 AEnc : 6.1790e-05 	 MSE : 1.7341e-01
Epoch 377, 75% 	 Loss : 2.2808e-02 	 Res : 3.2528e-03 	 Jac : 1.5965e-02 	 Enc : 3.3513e-03 	 AEnc : 6.2454e-05 	 MSE : 1.7627e-01
Training Epoch 377 : 	 Train : 2.27631e-02 	 Res : 3.18778e-03 	 Jac : 1.59842e-02 	 Enc : 3.35172e-03 	 AE : 6.43404e-05 	 MSE : 1.75100e-01
Validation Epoch 377 : 	 Train : 2.27693e-02 	 Res : 3.17931e-03 	 Jac : 1.60065e-02 	 Enc : 3.34827e-03 	 AE : 5.74365e-05 	 MSE : 1.77789e-01
Training Epoch 377 finished, took current epoch 512.04s, cumulative time 184409.21s
Current Learning rate DEQ : 8.142067989552235e-06
Current Learning rate AUTOENC : 1.628413597910447e-05
Epoch 378, 25% 	 Loss : 2.2777e-02 	 Res : 3.1542e-03 	 Jac : 1.6021e-02 	 Enc : 3.3599e-03 	 AEnc : 6.5687e-05 	 MSE : 1.7582e-01
Epoch 378, 50% 	 Loss : 2.2792e-02 	 Res : 3.2008e-03 	 Jac : 1.5980e-02 	 Enc : 3.3532e-03 	 AEnc : 6.3321e-05 	 MSE : 1.9501e-01
Epoch 378, 75% 	 Loss : 2.2909e-02 	 Res : 3.2469e-03 	 Jac : 1.6059e-02 	 Enc : 3.3577e-03 	 AEnc : 7.2283e-05 	 MSE : 1.7266e-01
Training Epoch 378 : 	 Train : 2.28217e-02 	 Res : 3.18673e-03 	 Jac : 1.60379e-02 	 Enc : 3.34997e-03 	 AE : 7.14768e-05 	 MSE : 1.75644e-01
Validation Epoch 378 : 	 Train : 2.27451e-02 	 Res : 3.17176e-03 	 Jac : 1.59785e-02 	 Enc : 3.34854e-03 	 AE : 7.17301e-05 	 MSE : 1.74508e-01
Training Epoch 378 finished, took current epoch 528.18s, cumulative time 184937.34s
Current Learning rate DEQ : 8.142067989552235e-06
Current Learning rate AUTOENC : 1.628413597910447e-05
MODEL SAVED
Epoch 379, 25% 	 Loss : 2.2880e-02 	 Res : 3.1878e-03 	 Jac : 1.6092e-02 	 Enc : 3.3533e-03 	 AEnc : 6.3266e-05 	 MSE : 1.8357e-01
Epoch 379, 50% 	 Loss : 2.2721e-02 	 Res : 3.1209e-03 	 Jac : 1.6015e-02 	 Enc : 3.3445e-03 	 AEnc : 6.7275e-05 	 MSE : 1.7350e-01
Epoch 379, 75% 	 Loss : 2.2756e-02 	 Res : 3.1559e-03 	 Jac : 1.6031e-02 	 Enc : 3.3485e-03 	 AEnc : 7.0761e-05 	 MSE : 1.5003e-01
Training Epoch 379 : 	 Train : 2.28008e-02 	 Res : 3.17345e-03 	 Jac : 1.60439e-02 	 Enc : 3.35005e-03 	 AE : 6.56089e-05 	 MSE : 1.67801e-01
Validation Epoch 379 : 	 Train : 2.28083e-02 	 Res : 3.18591e-03 	 Jac : 1.59932e-02 	 Enc : 3.35607e-03 	 AE : 7.75828e-05 	 MSE : 1.95531e-01
Training Epoch 379 finished, took current epoch 526.62s, cumulative time 185463.94s
Current Learning rate DEQ : 8.142067989552235e-06
Current Learning rate AUTOENC : 1.628413597910447e-05
Epoch 380, 25% 	 Loss : 2.2773e-02 	 Res : 3.1484e-03 	 Jac : 1.6042e-02 	 Enc : 3.3553e-03 	 AEnc : 6.6529e-05 	 MSE : 1.6027e-01
Epoch 380, 50% 	 Loss : 2.2713e-02 	 Res : 3.1776e-03 	 Jac : 1.5960e-02 	 Enc : 3.3312e-03 	 AEnc : 6.3272e-05 	 MSE : 1.8045e-01
Epoch 380, 75% 	 Loss : 2.2862e-02 	 Res : 3.1897e-03 	 Jac : 1.6077e-02 	 Enc : 3.3660e-03 	 AEnc : 6.3870e-05 	 MSE : 1.6568e-01
Training Epoch 380 : 	 Train : 2.27506e-02 	 Res : 3.17605e-03 	 Jac : 1.59883e-02 	 Enc : 3.34885e-03 	 AE : 6.50244e-05 	 MSE : 1.72365e-01
Validation Epoch 380 : 	 Train : 2.26570e-02 	 Res : 3.15515e-03 	 Jac : 1.59107e-02 	 Enc : 3.34659e-03 	 AE : 6.24986e-05 	 MSE : 1.82151e-01
Training Epoch 380 finished, took current epoch 538.84s, cumulative time 186002.74s
Current Learning rate DEQ : 8.142067989552235e-06
Current Learning rate AUTOENC : 1.628413597910447e-05
MODEL SAVED
Epoch 381, 25% 	 Loss : 2.2799e-02 	 Res : 3.1200e-03 	 Jac : 1.6055e-02 	 Enc : 3.3604e-03 	 AEnc : 8.4155e-05 	 MSE : 1.7897e-01
Epoch 381, 50% 	 Loss : 2.2937e-02 	 Res : 3.2646e-03 	 Jac : 1.6067e-02 	 Enc : 3.3551e-03 	 AEnc : 6.7314e-05 	 MSE : 1.8313e-01
Epoch 381, 75% 	 Loss : 2.2733e-02 	 Res : 3.1599e-03 	 Jac : 1.5996e-02 	 Enc : 3.3398e-03 	 AEnc : 6.2952e-05 	 MSE : 1.7415e-01
Training Epoch 381 : 	 Train : 2.28300e-02 	 Res : 3.18241e-03 	 Jac : 1.60481e-02 	 Enc : 3.34781e-03 	 AE : 7.02793e-05 	 MSE : 1.81387e-01
Validation Epoch 381 : 	 Train : 2.27533e-02 	 Res : 3.16655e-03 	 Jac : 1.59790e-02 	 Enc : 3.34555e-03 	 AE : 5.90642e-05 	 MSE : 2.03111e-01
Training Epoch 381 finished, took current epoch 529.10s, cumulative time 186531.82s
Current Learning rate DEQ : 8.142067989552235e-06
Current Learning rate AUTOENC : 1.628413597910447e-05
Epoch 382, 25% 	 Loss : 2.2923e-02 	 Res : 3.2551e-03 	 Jac : 1.6066e-02 	 Enc : 3.3479e-03 	 AEnc : 9.1117e-05 	 MSE : 1.6337e-01
Epoch 382, 50% 	 Loss : 2.2774e-02 	 Res : 3.1441e-03 	 Jac : 1.6051e-02 	 Enc : 3.3450e-03 	 AEnc : 6.2241e-05 	 MSE : 1.7070e-01
Epoch 382, 75% 	 Loss : 2.2759e-02 	 Res : 3.1518e-03 	 Jac : 1.6015e-02 	 Enc : 3.3524e-03 	 AEnc : 6.2048e-05 	 MSE : 1.7797e-01
Training Epoch 382 : 	 Train : 2.27937e-02 	 Res : 3.17937e-03 	 Jac : 1.60181e-02 	 Enc : 3.34690e-03 	 AE : 7.06995e-05 	 MSE : 1.78633e-01
Validation Epoch 382 : 	 Train : 2.27085e-02 	 Res : 3.18357e-03 	 Jac : 1.59755e-02 	 Enc : 3.34713e-03 	 AE : 5.08490e-05 	 MSE : 1.51501e-01
Training Epoch 382 finished, took current epoch 517.75s, cumulative time 187049.55s
Current Learning rate DEQ : 8.142067989552235e-06
Current Learning rate AUTOENC : 1.628413597910447e-05
Epoch 383, 25% 	 Loss : 2.2784e-02 	 Res : 3.2184e-03 	 Jac : 1.5981e-02 	 Enc : 3.3526e-03 	 AEnc : 7.0509e-05 	 MSE : 1.6127e-01
Epoch 383, 50% 	 Loss : 2.2658e-02 	 Res : 3.2355e-03 	 Jac : 1.5808e-02 	 Enc : 3.3311e-03 	 AEnc : 6.0179e-05 	 MSE : 2.2266e-01
Epoch 383, 75% 	 Loss : 2.2681e-02 	 Res : 3.1246e-03 	 Jac : 1.6010e-02 	 Enc : 3.3340e-03 	 AEnc : 5.4128e-05 	 MSE : 1.5785e-01
Training Epoch 383 : 	 Train : 2.27132e-02 	 Res : 3.18584e-03 	 Jac : 1.59411e-02 	 Enc : 3.34561e-03 	 AE : 6.14272e-05 	 MSE : 1.79167e-01
Validation Epoch 383 : 	 Train : 2.26741e-02 	 Res : 3.16317e-03 	 Jac : 1.59529e-02 	 Enc : 3.34870e-03 	 AE : 5.87449e-05 	 MSE : 1.50519e-01
Training Epoch 383 finished, took current epoch 519.33s, cumulative time 187568.87s
Current Learning rate DEQ : 8.142067989552235e-06
Current Learning rate AUTOENC : 1.628413597910447e-05
Epoch 384, 25% 	 Loss : 2.2607e-02 	 Res : 3.1174e-03 	 Jac : 1.5935e-02 	 Enc : 3.3515e-03 	 AEnc : 5.2877e-05 	 MSE : 1.4962e-01
Epoch 384, 50% 	 Loss : 2.2728e-02 	 Res : 3.2250e-03 	 Jac : 1.5939e-02 	 Enc : 3.3386e-03 	 AEnc : 6.3290e-05 	 MSE : 1.6183e-01
Epoch 384, 75% 	 Loss : 2.3037e-02 	 Res : 3.3191e-03 	 Jac : 1.6040e-02 	 Enc : 3.3400e-03 	 AEnc : 6.6928e-05 	 MSE : 2.7090e-01
Training Epoch 384 : 	 Train : 2.27837e-02 	 Res : 3.21337e-03 	 Jac : 1.59684e-02 	 Enc : 3.34515e-03 	 AE : 6.07329e-05 	 MSE : 1.95993e-01
Validation Epoch 384 : 	 Train : 2.27359e-02 	 Res : 3.15742e-03 	 Jac : 1.60167e-02 	 Enc : 3.34523e-03 	 AE : 5.68894e-05 	 MSE : 1.59718e-01
Training Epoch 384 finished, took current epoch 535.32s, cumulative time 188104.16s
Current Learning rate DEQ : 8.142067989552235e-06
Current Learning rate AUTOENC : 1.628413597910447e-05
Epoch 385, 25% 	 Loss : 2.2789e-02 	 Res : 3.1903e-03 	 Jac : 1.6014e-02 	 Enc : 3.3494e-03 	 AEnc : 5.7559e-05 	 MSE : 1.7839e-01
Epoch 385, 50% 	 Loss : 2.2822e-02 	 Res : 3.2490e-03 	 Jac : 1.5968e-02 	 Enc : 3.3518e-03 	 AEnc : 6.5996e-05 	 MSE : 1.8717e-01
Epoch 385, 75% 	 Loss : 2.2658e-02 	 Res : 3.1222e-03 	 Jac : 1.5969e-02 	 Enc : 3.3408e-03 	 AEnc : 6.0448e-05 	 MSE : 1.6551e-01
Training Epoch 385 : 	 Train : 2.27227e-02 	 Res : 3.17457e-03 	 Jac : 1.59697e-02 	 Enc : 3.34403e-03 	 AE : 6.00522e-05 	 MSE : 1.74372e-01
Validation Epoch 385 : 	 Train : 2.29921e-02 	 Res : 3.24548e-03 	 Jac : 1.61185e-02 	 Enc : 3.34222e-03 	 AE : 4.98616e-05 	 MSE : 2.35984e-01
Training Epoch 385 finished, took current epoch 523.26s, cumulative time 188627.38s
Current Learning rate DEQ : 8.142067989552235e-06
Current Learning rate AUTOENC : 1.628413597910447e-05
Epoch 386, 25% 	 Loss : 2.2908e-02 	 Res : 3.2453e-03 	 Jac : 1.5993e-02 	 Enc : 3.3382e-03 	 AEnc : 5.6966e-05 	 MSE : 2.7456e-01
Epoch 386, 50% 	 Loss : 2.2746e-02 	 Res : 3.1506e-03 	 Jac : 1.6000e-02 	 Enc : 3.3553e-03 	 AEnc : 6.8342e-05 	 MSE : 1.7155e-01
Epoch 386, 75% 	 Loss : 2.2762e-02 	 Res : 3.2168e-03 	 Jac : 1.5948e-02 	 Enc : 3.3478e-03 	 AEnc : 6.7127e-05 	 MSE : 1.8224e-01
Training Epoch 386 : 	 Train : 2.28102e-02 	 Res : 3.20483e-03 	 Jac : 1.59969e-02 	 Enc : 3.34349e-03 	 AE : 6.53251e-05 	 MSE : 1.99611e-01
Validation Epoch 386 : 	 Train : 2.26825e-02 	 Res : 3.15540e-03 	 Jac : 1.59751e-02 	 Enc : 3.34446e-03 	 AE : 5.32650e-05 	 MSE : 1.54245e-01
Training Epoch 386 finished, took current epoch 529.81s, cumulative time 189157.18s
Current Learning rate DEQ : 8.142067989552235e-06
Current Learning rate AUTOENC : 1.628413597910447e-05
Epoch 387, 25% 	 Loss : 2.2777e-02 	 Res : 3.1800e-03 	 Jac : 1.6040e-02 	 Enc : 3.3280e-03 	 AEnc : 6.3011e-05 	 MSE : 1.6642e-01
Epoch 387, 50% 	 Loss : 2.2691e-02 	 Res : 3.1697e-03 	 Jac : 1.5947e-02 	 Enc : 3.3535e-03 	 AEnc : 6.1696e-05 	 MSE : 1.5865e-01
Epoch 387, 75% 	 Loss : 2.2767e-02 	 Res : 3.1272e-03 	 Jac : 1.6056e-02 	 Enc : 3.3465e-03 	 AEnc : 6.3414e-05 	 MSE : 1.7374e-01
Training Epoch 387 : 	 Train : 2.27422e-02 	 Res : 3.16223e-03 	 Jac : 1.60089e-02 	 Enc : 3.34274e-03 	 AE : 6.27681e-05 	 MSE : 1.65489e-01
Validation Epoch 387 : 	 Train : 2.28419e-02 	 Res : 3.15263e-03 	 Jac : 1.61112e-02 	 Enc : 3.34459e-03 	 AE : 6.73697e-05 	 MSE : 1.66153e-01
Training Epoch 387 finished, took current epoch 525.18s, cumulative time 189682.31s
Current Learning rate DEQ : 8.142067989552235e-06
Current Learning rate AUTOENC : 1.628413597910447e-05
MODEL SAVED
Epoch 388, 25% 	 Loss : 2.2773e-02 	 Res : 3.1862e-03 	 Jac : 1.6021e-02 	 Enc : 3.3373e-03 	 AEnc : 6.4259e-05 	 MSE : 1.6439e-01
Epoch 388, 50% 	 Loss : 2.2808e-02 	 Res : 3.1453e-03 	 Jac : 1.6064e-02 	 Enc : 3.3358e-03 	 AEnc : 7.2388e-05 	 MSE : 1.9043e-01
Epoch 388, 75% 	 Loss : 2.2702e-02 	 Res : 3.1767e-03 	 Jac : 1.5956e-02 	 Enc : 3.3475e-03 	 AEnc : 6.2216e-05 	 MSE : 1.5938e-01
Training Epoch 388 : 	 Train : 2.28086e-02 	 Res : 3.18782e-03 	 Jac : 1.60261e-02 	 Enc : 3.34236e-03 	 AE : 6.55834e-05 	 MSE : 1.86762e-01
Validation Epoch 388 : 	 Train : 2.27307e-02 	 Res : 3.15664e-03 	 Jac : 1.60032e-02 	 Enc : 3.34298e-03 	 AE : 6.73544e-05 	 MSE : 1.60518e-01
Training Epoch 388 finished, took current epoch 518.87s, cumulative time 190201.14s
Current Learning rate DEQ : 8.142067989552235e-06
Current Learning rate AUTOENC : 1.628413597910447e-05
Epoch 389, 25% 	 Loss : 2.2858e-02 	 Res : 3.2220e-03 	 Jac : 1.6044e-02 	 Enc : 3.3356e-03 	 AEnc : 6.4196e-05 	 MSE : 1.9196e-01
Epoch 389, 50% 	 Loss : 2.2760e-02 	 Res : 3.2339e-03 	 Jac : 1.5950e-02 	 Enc : 3.3514e-03 	 AEnc : 5.8132e-05 	 MSE : 1.6670e-01
Epoch 389, 75% 	 Loss : 2.2546e-02 	 Res : 3.1142e-03 	 Jac : 1.5871e-02 	 Enc : 3.3366e-03 	 AEnc : 5.3736e-05 	 MSE : 1.6994e-01
Training Epoch 389 : 	 Train : 2.27121e-02 	 Res : 3.16529e-03 	 Jac : 1.59768e-02 	 Enc : 3.34122e-03 	 AE : 5.87234e-05 	 MSE : 1.70109e-01
Validation Epoch 389 : 	 Train : 2.29333e-02 	 Res : 3.20086e-03 	 Jac : 1.60867e-02 	 Enc : 3.34146e-03 	 AE : 6.46179e-05 	 MSE : 2.39640e-01
Training Epoch 389 finished, took current epoch 511.60s, cumulative time 190712.73s
Current Learning rate DEQ : 8.142067989552235e-06
Current Learning rate AUTOENC : 1.628413597910447e-05
Epoch 390, 25% 	 Loss : 2.2760e-02 	 Res : 3.1300e-03 	 Jac : 1.6066e-02 	 Enc : 3.3430e-03 	 AEnc : 6.7525e-05 	 MSE : 1.5360e-01
Epoch 390, 50% 	 Loss : 2.2748e-02 	 Res : 3.1736e-03 	 Jac : 1.6000e-02 	 Enc : 3.3507e-03 	 AEnc : 6.6946e-05 	 MSE : 1.5632e-01
Epoch 390, 75% 	 Loss : 2.2966e-02 	 Res : 3.3914e-03 	 Jac : 1.5921e-02 	 Enc : 3.3339e-03 	 AEnc : 5.2528e-05 	 MSE : 2.6706e-01
Training Epoch 390 : 	 Train : 2.28205e-02 	 Res : 3.20653e-03 	 Jac : 1.60241e-02 	 Enc : 3.34071e-03 	 AE : 5.99485e-05 	 MSE : 1.89271e-01
Validation Epoch 390 : 	 Train : 2.27641e-02 	 Res : 3.14981e-03 	 Jac : 1.60235e-02 	 Enc : 3.34096e-03 	 AE : 6.97004e-05 	 MSE : 1.80131e-01
Training Epoch 390 finished, took current epoch 516.71s, cumulative time 191229.41s
Current Learning rate DEQ : 8.142067989552235e-06
Current Learning rate AUTOENC : 1.628413597910447e-05
MODEL SAVED
Epoch 391, 25% 	 Loss : 2.2673e-02 	 Res : 3.1560e-03 	 Jac : 1.5957e-02 	 Enc : 3.3310e-03 	 AEnc : 5.7381e-05 	 MSE : 1.7145e-01
Epoch 391, 50% 	 Loss : 2.3099e-02 	 Res : 3.3371e-03 	 Jac : 1.6068e-02 	 Enc : 3.3426e-03 	 AEnc : 7.4155e-05 	 MSE : 2.7786e-01
Epoch 391, 75% 	 Loss : 2.2667e-02 	 Res : 3.1710e-03 	 Jac : 1.5922e-02 	 Enc : 3.3433e-03 	 AEnc : 5.6847e-05 	 MSE : 1.7341e-01
Training Epoch 391 : 	 Train : 2.27839e-02 	 Res : 3.20749e-03 	 Jac : 1.59713e-02 	 Enc : 3.33926e-03 	 AE : 6.26155e-05 	 MSE : 2.03250e-01
Validation Epoch 391 : 	 Train : 2.26857e-02 	 Res : 3.15091e-03 	 Jac : 1.59775e-02 	 Enc : 3.33889e-03 	 AE : 5.78407e-05 	 MSE : 1.60538e-01
Training Epoch 391 finished, took current epoch 521.43s, cumulative time 191750.80s
Current Learning rate DEQ : 5.699447592686564e-06
Current Learning rate AUTOENC : 1.1398895185373128e-05
Epoch 392, 25% 	 Loss : 2.2725e-02 	 Res : 3.1210e-03 	 Jac : 1.6050e-02 	 Enc : 3.3334e-03 	 AEnc : 5.8863e-05 	 MSE : 1.6155e-01
Epoch 392, 50% 	 Loss : 2.2585e-02 	 Res : 3.1463e-03 	 Jac : 1.5889e-02 	 Enc : 3.3404e-03 	 AEnc : 5.4103e-05 	 MSE : 1.5461e-01
Epoch 392, 75% 	 Loss : 2.2739e-02 	 Res : 3.0954e-03 	 Jac : 1.6100e-02 	 Enc : 3.3410e-03 	 AEnc : 5.1648e-05 	 MSE : 1.5066e-01
Training Epoch 392 : 	 Train : 2.27148e-02 	 Res : 3.15097e-03 	 Jac : 1.60067e-02 	 Enc : 3.33865e-03 	 AE : 5.77171e-05 	 MSE : 1.60755e-01
Validation Epoch 392 : 	 Train : 2.29135e-02 	 Res : 3.22510e-03 	 Jac : 1.60859e-02 	 Enc : 3.33721e-03 	 AE : 5.29109e-05 	 MSE : 2.12393e-01
Training Epoch 392 finished, took current epoch 524.46s, cumulative time 192275.21s
Current Learning rate DEQ : 5.699447592686564e-06
Current Learning rate AUTOENC : 1.1398895185373128e-05
Epoch 393, 25% 	 Loss : 2.2689e-02 	 Res : 3.1148e-03 	 Jac : 1.6043e-02 	 Enc : 3.3208e-03 	 AEnc : 5.5590e-05 	 MSE : 1.5518e-01
Epoch 393, 50% 	 Loss : 2.2717e-02 	 Res : 3.1785e-03 	 Jac : 1.5964e-02 	 Enc : 3.3491e-03 	 AEnc : 5.2874e-05 	 MSE : 1.7270e-01
Epoch 393, 75% 	 Loss : 2.2739e-02 	 Res : 3.1998e-03 	 Jac : 1.5974e-02 	 Enc : 3.3385e-03 	 AEnc : 6.2866e-05 	 MSE : 1.6366e-01
Training Epoch 393 : 	 Train : 2.27286e-02 	 Res : 3.16514e-03 	 Jac : 1.59929e-02 	 Enc : 3.33796e-03 	 AE : 5.82486e-05 	 MSE : 1.74350e-01
Validation Epoch 393 : 	 Train : 2.27057e-02 	 Res : 3.14314e-03 	 Jac : 1.60012e-02 	 Enc : 3.33756e-03 	 AE : 6.13300e-05 	 MSE : 1.62421e-01
Training Epoch 393 finished, took current epoch 523.40s, cumulative time 192798.57s
Current Learning rate DEQ : 5.699447592686564e-06
Current Learning rate AUTOENC : 1.1398895185373128e-05
MODEL SAVED
Epoch 394, 25% 	 Loss : 2.2519e-02 	 Res : 3.1151e-03 	 Jac : 1.5873e-02 	 Enc : 3.3123e-03 	 AEnc : 4.1646e-05 	 MSE : 1.7706e-01
Epoch 394, 50% 	 Loss : 2.2975e-02 	 Res : 3.2385e-03 	 Jac : 1.6159e-02 	 Enc : 3.3501e-03 	 AEnc : 6.4335e-05 	 MSE : 1.6312e-01
Epoch 394, 75% 	 Loss : 2.2708e-02 	 Res : 3.1722e-03 	 Jac : 1.5920e-02 	 Enc : 3.3392e-03 	 AEnc : 6.2059e-05 	 MSE : 2.1404e-01
Training Epoch 394 : 	 Train : 2.27201e-02 	 Res : 3.16729e-03 	 Jac : 1.59767e-02 	 Enc : 3.33727e-03 	 AE : 5.85636e-05 	 MSE : 1.80362e-01
Validation Epoch 394 : 	 Train : 2.26749e-02 	 Res : 3.13876e-03 	 Jac : 1.59830e-02 	 Enc : 3.33968e-03 	 AE : 5.57772e-05 	 MSE : 1.57698e-01
Training Epoch 394 finished, took current epoch 533.42s, cumulative time 193331.96s
Current Learning rate DEQ : 5.699447592686564e-06
Current Learning rate AUTOENC : 1.1398895185373128e-05
MODEL SAVED
Epoch 395, 25% 	 Loss : 2.2814e-02 	 Res : 3.2481e-03 	 Jac : 1.6000e-02 	 Enc : 3.3416e-03 	 AEnc : 6.2144e-05 	 MSE : 1.6223e-01
Epoch 395, 50% 	 Loss : 2.2554e-02 	 Res : 3.0537e-03 	 Jac : 1.5962e-02 	 Enc : 3.3216e-03 	 AEnc : 5.5657e-05 	 MSE : 1.6068e-01
Epoch 395, 75% 	 Loss : 2.2746e-02 	 Res : 3.1598e-03 	 Jac : 1.6006e-02 	 Enc : 3.3413e-03 	 AEnc : 6.2316e-05 	 MSE : 1.7660e-01
Training Epoch 395 : 	 Train : 2.26942e-02 	 Res : 3.14871e-03 	 Jac : 1.59858e-02 	 Enc : 3.33720e-03 	 AE : 5.80294e-05 	 MSE : 1.64500e-01
Validation Epoch 395 : 	 Train : 2.27448e-02 	 Res : 3.14743e-03 	 Jac : 1.60540e-02 	 Enc : 3.33903e-03 	 AE : 5.18843e-05 	 MSE : 1.52493e-01
Training Epoch 395 finished, took current epoch 510.59s, cumulative time 193842.51s
Current Learning rate DEQ : 5.699447592686564e-06
Current Learning rate AUTOENC : 1.1398895185373128e-05
Epoch 396, 25% 	 Loss : 2.2682e-02 	 Res : 3.1691e-03 	 Jac : 1.5959e-02 	 Enc : 3.3447e-03 	 AEnc : 5.4756e-05 	 MSE : 1.5530e-01
Epoch 396, 50% 	 Loss : 2.2761e-02 	 Res : 3.1059e-03 	 Jac : 1.6108e-02 	 Enc : 3.3290e-03 	 AEnc : 6.0684e-05 	 MSE : 1.5702e-01
Epoch 396, 75% 	 Loss : 2.2694e-02 	 Res : 3.1480e-03 	 Jac : 1.5999e-02 	 Enc : 3.3423e-03 	 AEnc : 5.4818e-05 	 MSE : 1.5022e-01
Training Epoch 396 : 	 Train : 2.27034e-02 	 Res : 3.13929e-03 	 Jac : 1.60151e-02 	 Enc : 3.33655e-03 	 AE : 5.92077e-05 	 MSE : 1.53171e-01
Validation Epoch 396 : 	 Train : 2.27062e-02 	 Res : 3.14215e-03 	 Jac : 1.60236e-02 	 Enc : 3.33809e-03 	 AE : 4.82450e-05 	 MSE : 1.54069e-01
Training Epoch 396 finished, took current epoch 522.34s, cumulative time 194364.84s
Current Learning rate DEQ : 5.699447592686564e-06
Current Learning rate AUTOENC : 1.1398895185373128e-05
Epoch 397, 25% 	 Loss : 2.2643e-02 	 Res : 3.1235e-03 	 Jac : 1.5969e-02 	 Enc : 3.3386e-03 	 AEnc : 5.8411e-05 	 MSE : 1.5367e-01
Epoch 397, 50% 	 Loss : 2.2856e-02 	 Res : 3.2088e-03 	 Jac : 1.6102e-02 	 Enc : 3.3288e-03 	 AEnc : 5.7332e-05 	 MSE : 1.5993e-01
Epoch 397, 75% 	 Loss : 2.2549e-02 	 Res : 3.0772e-03 	 Jac : 1.5928e-02 	 Enc : 3.3262e-03 	 AEnc : 5.5067e-05 	 MSE : 1.6251e-01
Training Epoch 397 : 	 Train : 2.26946e-02 	 Res : 3.14464e-03 	 Jac : 1.59962e-02 	 Enc : 3.33395e-03 	 AE : 5.92449e-05 	 MSE : 1.60582e-01
Validation Epoch 397 : 	 Train : 2.26551e-02 	 Res : 3.14956e-03 	 Jac : 1.59592e-02 	 Enc : 3.33604e-03 	 AE : 4.95611e-05 	 MSE : 1.60746e-01
Training Epoch 397 finished, took current epoch 522.65s, cumulative time 194887.44s
Current Learning rate DEQ : 5.699447592686564e-06
Current Learning rate AUTOENC : 1.1398895185373128e-05
Epoch 398, 25% 	 Loss : 2.2605e-02 	 Res : 3.1194e-03 	 Jac : 1.5953e-02 	 Enc : 3.3191e-03 	 AEnc : 5.4328e-05 	 MSE : 1.5829e-01
Epoch 398, 50% 	 Loss : 2.2627e-02 	 Res : 3.1514e-03 	 Jac : 1.5910e-02 	 Enc : 3.3507e-03 	 AEnc : 5.3604e-05 	 MSE : 1.6099e-01
Epoch 398, 75% 	 Loss : 2.2911e-02 	 Res : 3.2022e-03 	 Jac : 1.6120e-02 	 Enc : 3.3531e-03 	 AEnc : 6.6767e-05 	 MSE : 1.6810e-01
Training Epoch 398 : 	 Train : 2.27046e-02 	 Res : 3.14298e-03 	 Jac : 1.60070e-02 	 Enc : 3.33473e-03 	 AE : 5.66338e-05 	 MSE : 1.63229e-01
Validation Epoch 398 : 	 Train : 2.27834e-02 	 Res : 3.14099e-03 	 Jac : 1.60588e-02 	 Enc : 3.33552e-03 	 AE : 5.93482e-05 	 MSE : 1.88667e-01
Training Epoch 398 finished, took current epoch 527.85s, cumulative time 195415.27s
Current Learning rate DEQ : 5.699447592686564e-06
Current Learning rate AUTOENC : 1.1398895185373128e-05
Epoch 399, 25% 	 Loss : 2.2658e-02 	 Res : 3.1475e-03 	 Jac : 1.5965e-02 	 Enc : 3.3387e-03 	 AEnc : 5.4768e-05 	 MSE : 1.5120e-01
Epoch 399, 50% 	 Loss : 2.3308e-02 	 Res : 3.4287e-03 	 Jac : 1.6053e-02 	 Enc : 3.3300e-03 	 AEnc : 5.4975e-05 	 MSE : 4.4136e-01
Epoch 399, 75% 	 Loss : 2.2738e-02 	 Res : 3.1566e-03 	 Jac : 1.6025e-02 	 Enc : 3.3335e-03 	 AEnc : 5.8651e-05 	 MSE : 1.6444e-01
Training Epoch 399 : 	 Train : 2.30489e-02 	 Res : 3.34136e-03 	 Jac : 1.59987e-02 	 Enc : 3.33380e-03 	 AE : 5.78980e-05 	 MSE : 3.17151e-01
Validation Epoch 399 : 	 Train : 2.27151e-02 	 Res : 3.17283e-03 	 Jac : 1.59195e-02 	 Enc : 3.33924e-03 	 AE : 5.48562e-05 	 MSE : 2.28737e-01
Training Epoch 399 finished, took current epoch 517.59s, cumulative time 195932.84s
Current Learning rate DEQ : 5.699447592686564e-06
Current Learning rate AUTOENC : 1.1398895185373128e-05